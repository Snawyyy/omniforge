[
  {
    "id": 0,
    "hash": "43b76714d230bbe319bdf0de327c7192",
    "content": "RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with language generation.",
    "file": "document_0"
  },
  {
    "id": 1,
    "hash": "dac60aa8d5e5861796640a8d9b3190a3",
    "content": "The RAG model retrieves relevant documents from a knowledge base and uses them to generate more accurate responses.",
    "file": "document_0"
  },
  {
    "id": 2,
    "hash": "f9ed7c2f9da6b1462806979d984ab5f3",
    "content": "FAISS is a library for efficient similarity search and clustering of dense vectors, often used in RAG systems.",
    "file": "document_0"
  },
  {
    "id": 3,
    "hash": "192336175c79d0194d2e51a613cbfa1b",
    "content": "Sentence transformers are used to create embeddings for documents and queries in RAG systems.",
    "file": "document_0"
  },
  {
    "id": 4,
    "hash": "92c5abaa3019f7294e5af489622302f5",
    "content": "Retrieval-Augmented Generation improves language models by allowing them to access external knowledge sources.",
    "file": "document_0"
  },
  {
    "id": 5,
    "hash": "92408c5c2b26cc7bb3e006f75f4f6f08",
    "content": "In RAG systems, documents are indexed and searchable by their semantic embeddings rather than just keywords.",
    "file": "document_0"
  },
  {
    "id": 6,
    "hash": "26ed14b833f20c4d6715cd2f9c44381a",
    "content": "Python is a great language for implementing RAG systems due to libraries like sentence-transformers and faiss.",
    "file": "document_0"
  },
  {
    "id": 7,
    "hash": "964a8aed30280d1b398f7b17dc6366bb",
    "content": "The retrieval component of RAG is crucial for finding relevant information before generation.",
    "file": "document_0"
  },
  {
    "id": 8,
    "hash": "1b61704bafe182154c395ea08a3acb39",
    "content": "\"\"\"\nOmni - AI-powered code generation and project-aware editing CLI tool\n\nIntegrates modular UI, memory, personality, and AST-based code editing.\n\"\"\"\nimport os\nimport subprocess\nimport requests\nimport json\nimport sys\nimport re\nimport argparse\nimport ast\nfrom datetime import datetime\nimport threading\nimport queue as Queue\nimport time\nfrom typing import List, Dict, Optional\nfrom rich import print\nfrom rich.panel import Panel\nfrom rich.console import Console\nfrom rich.tree import Tree\nfrom ui_manager import UIManager\nfrom personality_manager import PersonalityManager\nfrom memory_manager import MemoryManager\nfrom code_editor import CodeEditor\nfrom file_creator import FileCreator\nfrom git_manager import GitManager\nimport traceback\nDEFAULT_BACKEND = 'openrouter'\nOLLAMA_MODEL = 'phi4-reasoning'\nOPENROUTER_MODEL = 'qwen/qwen3-coder'\nDEFAULT_SAVE_DIR = os.path.expanduser('/mnt/ProjectData/omni/omni_saves/')\nCONFIG_FILE = 'config.json'\nMEMORY_FILE = 'memory.json'\nOLLAMA_API_URL = 'http://localhost:11434/api/generate'\nOPENROUTER_API_URL = 'https://openrouter.ai/api/v1/chat/completions'\nOPENROUTER_MODELS_API_URL = 'https://openrouter.ai/api/v1/models'\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\ncurrent_backend = DEFAULT_BACKEND\ncurrent_model = (OLLAMA_MODEL if DEFAULT_BACKEND == 'ollama' else\n    OPENROUTER_MODEL)\nOLLAMA_MODELS = {'deepseek': 'deepseek-coder:6.7b', 'codellama':\n    'codellama:13b', 'mistral': 'mistral:latest', 'llama2': 'llama2:latest',\n    'phind': 'phind-codellama:34b'}\nos.makedirs(DEFAULT_SAVE_DIR, exist_ok=True)\nTEMPLATES = {'flask':\n    \"\"\"from flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/')\ndef home():\n    return '<h1>Hello, Flask!</h1>'\n\nif __name__ == '__main__':\n    app.run(debug=True)\"\"\"\n    , 'html5':\n    \"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>New Page</title>\n</head>\n<body>\n    <h1>Hello World</h1>\n</body>\n</html>\"\"\"\n    , 'scraper':\n    \"\"\"import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        print(soup.title.text)\n    except Exception as e:\n        print(f\"[bold red]Error scraping {url}:[/] {e}\")\n\nif __name__ == \"__main__\":\n    scrape(\"https://example.com\")\"\"\"\n    }\nconsole = Console()\npersonality_manager = PersonalityManager(CONFIG_FILE)\nmemory_manager = MemoryManager(MEMORY_FILE)\nui_manager = UIManager()\nlast_query: Optional[str] = None\nlast_response: Optional[str] = None\nlast_code: Optional[str] = None\n\n\ndef start_ollama_server() ->None:\n    if current_backend != 'ollama':\n        return\n    try:\n        requests.get('http://localhost:11434', timeout=1)\n    except requests.exceptions.ConnectionError:\n        print('[cyan]Starting Ollama server...[/]')\n        subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL)\n\n\ndef query_llm(prompt: str) ->str:\n    personality = personality_manager.get_current_personality()\n    system_prompt = personality.get('system_prompt', '') if personality else ''\n    memory_context = memory_manager.get_memory_context()\n    rag_context = ''\n    try:\n        from rag_manager import RAGManager\n        project_root = memory_manager.get_project_root()\n        if project_root:\n            rag_manager = RAGManager()\n            if rag_manager.get_document_count() > 0:\n                results = rag_manager.search(prompt, k=3)\n                if results:\n                    rag_context = '\\n\\nRelevant context from codebase:\\n'\n                    for i, (doc, score, meta) in enumerate(results, 1):\n                        file_path = meta.get('file', 'Unknown')\n                        rag_context += f'{i}. [{file_path}] {doc}\\n'\n    except Exception:\n        pass\n    full_prompt = (\n        f'{system_prompt}\\n\\n{memory_context}{rag_context}\\n\\nUser: {prompt}')\n    with ui_manager.show_spinner('AI is listening and thinking...'):\n        if current_backend == 'ollama':\n            response = query_ollama(full_prompt)\n        elif current_backend == 'openrouter':\n            response = query_openrouter(full_prompt)\n        else:\n            response = '[bold red]Error:[/] Unknown backend'\n    return response\n\n\ndef query_openrouter(prompt: str) ->str:\n    if not OPENROUTER_API_KEY:\n        return '[bold red]Error:[/] OPENROUTER_API_KEY not set.'\n    headers = {'Authorization': f'Bearer {OPENROUTER_API_KEY}',\n        'Content-Type': 'application/json'}\n    payload = {'model': current_model, 'messages': [{'role': 'user',\n        'content': prompt}]}\n    try:\n        response = requests.post(OPENROUTER_API_URL, headers=headers, json=\n            payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['choices'][0]['message']['content']\n    except Exception as e:\n        error_details = ''\n        try:\n            error_details = response.json()\n        except:\n            error_details = response.text if hasattr(response, 'text'\n                ) else str(e)\n        return (\n            f'[bold red]OpenRouter Error:[/] {e}\\n[dim]Details: {error_details}[/dim]'\n            )\n\n\ndef query_ollama(prompt: str) ->str:\n    payload = {'model': current_model, 'prompt': prompt, 'stream': False}\n    try:\n        response = requests.post(OLLAMA_API_URL, json=payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['response']\n    except Exception as e:\n        return f'[bold red]Ollama Error:[/] {e}'\n\n\ndef extract_code(text: str) ->List[tuple[str, str]]:\n    matches = re.findall('```(\\\\w*)\\\\n([\\\\s\\\\S]*?)```', text)\n    return [(lang or 'text', code.strip()) for lang, code in matches\n        ] if matches else []\n\n\ndef list_models(args: list=None) ->None:\n    if current_backend == 'ollama':\n        print('[bold cyan]Popular Ollama Models:[/]')\n        for name, model_id in OLLAMA_MODELS.items():\n            print(\n                f\"{'\u2b50' if model_id == current_model else '  '} [yellow]{name:12}[/] \u2192 {model_id}\"\n                )\n    elif current_backend == 'openrouter':\n        list_openrouter_models(args or [])\n\n\ndef list_openrouter_models(args: list):\n    try:\n        from simple_term_menu import TerminalMenu\n    except ImportError:\n        ui_manager.show_error(\n            \"'simple-term-menu' is required. `pip install simple-term-menu`\")\n        return\n    try:\n        with ui_manager.show_spinner('Fetching models...'):\n            response = requests.get(OPENROUTER_MODELS_API_URL)\n            response.raise_for_status()\n        api_models_data = response.json().get('data', [])\n    except requests.RequestException as e:\n        ui_manager.show_error(f'Error fetching models: {e}')\n        return\n    all_models, sources = [], set()\n    for model_data in api_models_data:\n        if (model_id := model_data.get('id')):\n            sources.add(model_id.split('/')[0])\n            pricing = model_data.get('pricing', {})\n            is_free = pricing.get('prompt') == '0' and pricing.get('completion'\n                ) == '0'\n            all_models.append({'id': model_id, 'name': model_data.get(\n                'name'), 'source': model_id.split('/')[0], 'is_free': is_free})\n    all_models.sort(key=lambda x: (x['source'], x['name']))\n    if args and args[0].lower() == 'sources':\n        print('[bold cyan]Available Model Sources:[/]')\n        [print(f'  [yellow]{s}[/]') for s in sorted(list(sources))]\n        return\n    models_to_display, title = all_models, 'Select an OpenRouter Model'\n    if args:\n        filter_keyword = args[0].lower()\n        title = f\"Select a Model from '{filter_keyword}'\"\n        models_to_display = [m for m in all_models if filter_keyword in m[\n            'source'].lower()]\n        if not models_to_display:\n            ui_manager.show_error(f\"No models for source: '{filter_keyword}'\")\n            return\n    menu_entries = [\n        f\"{'\u2b50' if m['id'] == current_model else '  '} {m['name']} [dim]({m['id']}){' [green](FREE)[/]' if m['is_free'] else ''}[/dim]\"\n         for m in models_to_display]\n    try:\n        cursor_idx = next((i for i, m in enumerate(models_to_display) if m[\n            'id'] == current_model), 0)\n        chosen_index = TerminalMenu(menu_entries, title=f'{title}',\n            cursor_index=cursor_idx, cycle_cursor=True, clear_screen=True\n            ).show()\n        if chosen_index is not None:\n            set_model(models_to_display[chosen_index]['id'])\n        else:\n            print('Model selection cancelled.')\n    except Exception as e:\n        ui_manager.show_error(f'Menu display error: {e}')\n\n\ndef set_model(model_id: str) ->None:\n    global current_model\n    current_model = model_id\n    ui_manager.show_success(f'Model set to: {current_model}')\n\n\ndef switch_backend(backend_name: str) ->None:\n    global current_backend, current_model\n    backend_name = backend_name.lower()\n    if backend_name not in ['ollama', 'openrouter']:\n        ui_manager.show_error(f'Unknown backend: {backend_name}')\n        return\n    current_backend = backend_name\n    current_model = (OLLAMA_MODEL if backend_name == 'ollama' else\n        OPENROUTER_MODEL)\n    ui_manager.show_success(\n        f'Switched to {backend_name} backend with model: {current_model}')\n    if backend_name == 'ollama':\n        start_ollama_server()\n\n\ndef generate_project_manifest(path: str) ->tuple[str, List[str]]:\n    manifest = ''\n    file_paths = []\n    tree = Tree(f'[bold cyan]Project: {os.path.basename(path)}[/]')\n    exclude_dirs = {'__pycache__', '.git', 'venv', 'node_modules', '.idea'}\n    for root, dirs, files in os.walk(path):\n        dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.\n            startswith('.')]\n        relative_path = os.path.relpath(root, path)\n        branch = tree\n        if relative_path != '.':\n            parts = relative_path.split(os.sep)\n            for part in parts:\n                child = next((c for c in branch.children if c.label ==\n                    f'[magenta]{part}[/]'), None)\n                if not child:\n                    child = branch.add(f'[magenta]{part}[/]')\n                branch = child\n        for fname in sorted(files):\n            ext = os.path.splitext(fname)[1]\n            if ext not in ('.py', '.js', '.html', '.css', '.md', '.txt'):\n                continue\n            rel_path = os.path.join(relative_path, fname\n                ) if relative_path != '.' else fname\n            file_paths.append(rel_path)\n            branch.add(f'[green]{fname}[/]' if ext == '.py' else\n                f'[dim]{fname}[/]')\n            manifest += f'File: {rel_path}\\n\\n'\n    console.print(tree)\n    return manifest.strip(), file_paths\n\n\ndef look_command(path: str) ->None:\n    \"\"\"\n    Scans a directory or file and loads it into memory. It can resolve paths\n    relative to the current working directory or the project root in memory.\n    If a new directory is scanned, the previous 'look' context is cleared\n    to ensure the context remains relevant.\n    \"\"\"\n    resolved_path = resolve_file_path(path)\n    if not resolved_path:\n        ui_manager.show_error(f'\u274c Path not found: {path}')\n        return\n    if resolved_path != os.path.abspath(path):\n        ui_manager.show_success(\n            f\"Found '{path}' in project. Using: {resolved_path}\")\n    if os.path.isdir(resolved_path):\n        ui_manager.show_success(\n            \"New project directory detected. Clearing previous 'look' context.\"\n            )\n        memory_manager.memory['look'] = []\n        with ui_manager.show_spinner('Generating project manifest...'):\n            manifest = generate_project_manifest(resolved_path)\n        memory_manager.add_look_data(resolved_path, manifest)\n        ui_manager.show_success('\u2705 Project manifest added to memory.')\n    else:\n        try:\n            with ui_manager.show_spinner('Loading file...'):\n                with open(resolved_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n            for item in memory_manager.memory['look']:\n                if item.get('file') == resolved_path:\n                    item['content'] = content\n                    memory_manager.save_memory()\n                    ui_manager.show_success(\n                        '\u2705 Refreshed file content in memory.')\n                    return\n            memory_manager.add_look_data(resolved_path, content)\n            ui_manager.show_success('\u2705 File content added to memory.')\n        except Exception as e:\n            ui_manager.show_error(f'\u274c Error reading file: {e}')\n\n\ndef resolve_file_path(path: str) ->Optional[str]:\n    \"\"\"Resolves a file path, checking CWD first, then against project root in memory.\"\"\"\n    if os.path.exists(path):\n        return os.path.abspath(path)\n    project_root = memory_manager.get_project_root()\n    if project_root:\n        full_path = os.path.join(project_root, path)\n        if os.path.exists(full_path):\n            return full_path\n    return None\n\n\ndef _create_prompt_for_file_creation(file_name: str, instruction: str) ->str:\n    \"\"\"\n    Generate a robust prompt for file creation that instructs the AI to act as an expert,\n    produce complete and clean code, and avoid any extra commentary.\n    \"\"\"\n    return f\"\"\"You are an expert programmer tasked with creating a new file. Your goal is to generate complete, production-ready content based on the user's instruction.\n\nIMPORTANT RULES:\n- Provide ONLY the raw file content - no explanations, notes, or commentary outside the file itself\n- Include all necessary imports, boilerplate, and complete implementations\n- If creating code, ensure it's syntactically correct and follows best practices\n- For configuration files, use appropriate formatting (JSON, YAML, etc.)\n- For documentation files, use proper markdown formatting\n\nFile to create: {file_name}\nUser instruction: {instruction}\n\nGenerate the complete file content now:\"\"\"\n\n\ndef handle_file_create_command(file_path: str, instruction: str):\n    \"\"\"\n    Uses the LLM to generate content for a new file based on an instruction.\n    \"\"\"\n    global last_code\n    if os.path.exists(file_path):\n        if ui_manager.get_user_input(\n            f\"File '{file_path}' already exists. Overwrite? (y/n): \").lower(\n            ) not in ['yes', 'y']:\n            ui_manager.show_error('File creation cancelled.')\n            return\n    prompt = _create_prompt_for_file_creation(os.path.basename(file_path),\n        instruction)\n    with ui_manager.show_spinner(\n        f\"AI is generating content for '{file_path}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    if code_blocks:\n        new_content = code_blocks[0][1]\n    else:\n        new_content = response.strip()\n    if not new_content:\n        ui_manager.show_error('AI did not return any content.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    print(Panel(new_content, title=\n        f'[bold yellow]Proposed content for {file_path}[/]', border_style=\n        'yellow'))\n    if ui_manager.get_user_input('Create this file? (y/n): ').lower() in ['yes'\n        , 'y']:\n        try:\n            FileCreator.create(file_path, new_content)\n            last_code = new_content\n            ui_manager.show_success(f'File created successfully: {file_path}')\n        except IOError as e:\n            ui_manager.show_error(f'Error creating file: {e}')\n    else:\n        ui_manager.show_error('File creation cancelled.')\n\n\ndef look_all_command() ->None:\n    \"\"\"\n    Finds the project manifest in memory, reads every file listed, and adds their content to memory.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first to generate a manifest.\"\n            )\n        return\n    manifest_data = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and item.get('type'\n            ) == 'directory':\n            manifest_data = item.get('content')\n            break\n    if not manifest_data or not isinstance(manifest_data, (list, tuple)\n        ) or len(manifest_data) != 2:\n        ui_manager.show_error(\n            \"Could not find a valid project manifest in memory. Please run 'look <directory>' again.\"\n            )\n        return\n    file_paths = manifest_data[1]\n    if not file_paths:\n        ui_manager.show_error('No files found in the project manifest.')\n        return\n    total_files = len(file_paths)\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Loading {total_files} files from project manifest...'):\n        for file_path_relative in file_paths:\n            full_path = os.path.join(project_root, file_path_relative)\n            if os.path.isfile(full_path):\n                try:\n                    with open(full_path, 'r', encoding='utf-8') as f:\n                        content = f.read().strip()\n                    if not any(look['file'] == full_path for look in\n                        memory_manager.memory['look']):\n                        memory_manager.add_look_data(full_path, content)\n                        loaded_count += 1\n                except Exception as e:\n                    print(\n                        f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\"\n                        )\n    ui_manager.show_success(\n        f'\u2705 Loaded content for {loaded_count} new files into memory.')\n\n\ndef _load_all_project_files_if_needed():\n    \"\"\"\n    Checks if a project is loaded and automatically loads any files from its\n    manifest that are not already in the 'look' memory. This ensures a\n    complete context for editing and refactoring commands.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        return\n    manifest_content = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and 'File:' in item.get('content',\n            ''):\n            manifest_content = item['content']\n            break\n    if not manifest_content:\n        return\n    existing_file_paths = {item['file'] for item in memory_manager.memory.\n        get('look', []) if item.get('type') == 'file'}\n    file_paths_relative = re.findall('File: (.*)', manifest_content)\n    files_to_load = []\n    for rel_path in file_paths_relative:\n        full_path = os.path.join(project_root, rel_path)\n        if full_path not in existing_file_paths and os.path.isfile(full_path):\n            files_to_load.append((full_path, rel_path))\n    if not files_to_load:\n        return\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Auto-loading {len(files_to_load)} project files for context...'):\n        for full_path, file_path_relative in files_to_load:\n            try:\n                with open(full_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n                memory_manager.add_look_data(full_path, content)\n                loaded_count += 1\n            except Exception as e:\n                print(f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\")\n    if loaded_count > 0:\n        ui_manager.show_success(\n            f'\u2705 Loaded {loaded_count} new file(s) into memory for full project context.'\n            )\n\n\ndef _create_prompt_for_element_selection(file_name: str, instruction: str,\n    elements: List[str], element_structures: Dict[str, Dict]) ->str:\n    \"\"\"\n    Create a helper for the first stage of the 'edit' command. This prompt asks the AI\n    to analyze the user's instruction and intelligently select the most relevant code element to modify.\n    \"\"\"\n    element_details = []\n    for elem in elements:\n        if elem in element_structures:\n            struct = element_structures[elem]\n            detail = (\n                f\"{elem} ({struct['type']}, lines {struct['line_start']}-{struct['line_end']})\"\n                )\n            element_details.append(detail)\n        else:\n            element_details.append(elem)\n    return f\"\"\"You are an expert code analyzer. Your task is to identify what should be modified based on the user's instruction.\n\nFile: {file_name}\nAvailable elements: {', '.join(element_details) if element_details else 'None'}\n\nUser instruction: {instruction}\n\nRESPONSE FORMAT:\nChoose one of these response types:\n1. \"ELEMENT: <element_name>\" - to edit an entire function/class\n2. \"PARTIAL: <element_name> LINES: <start>-<end>\" - to edit specific lines within an element\n3. \"FILE\" - to edit the entire file or multiple elements\n\nRULES:\n- If the instruction mentions specific line numbers or a specific part of a function, use PARTIAL\n- If the instruction targets an entire function/class, use ELEMENT\n- If the instruction requires changes to multiple elements or file structure, use FILE\n- For PARTIAL edits, provide absolute line numbers from the original file\n\nWhat should be edited?\"\"\"\n\n\ndef _create_prompt_for_element_rewrite(file_name: str, element_name: str,\n    instruction: str, original_code: str, is_full_file: bool=False) ->str:\n    \"\"\"\n    Create a helper for the second stage of the 'edit' command. This prompt instructs the AI\n    to rewrite a specific code element (or the whole file) based on the user's request,\n    demanding a complete and syntactically correct code block as output.\n    \"\"\"\n    if is_full_file:\n        return f\"\"\"You are an expert programmer. Rewrite the entire file to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the entire file\n- Ensure all syntax is correct and the code is ready to run\n- Preserve existing functionality unless explicitly asked to change it\n- Include all necessary imports and maintain the file's structure\n- Do NOT include any explanations or comments outside the code\n\nFile: {file_name}\nTask: {instruction}\n\nCurrent file content:\n```python\n{original_code}\n```\n\nGenerate the complete updated file now:\"\"\"\n    else:\n        return f\"\"\"You are an expert programmer. Rewrite the specified element to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the element\n- Include any necessary imports at the top of your code block\n- Ensure the code is syntactically correct and maintains the same interface\n- Do NOT include explanations or comments outside the code block\n- The code must be a drop-in replacement for the original element\n\nFile: {file_name}\nElement to modify: {element_name}\nTask: {instruction}\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the complete updated element now:\"\"\"\n\n\ndef _create_prompt_for_partial_edit(file_name: str, element_name: str,\n    instruction: str, original_snippet: str, line_start: int, line_end: int,\n    full_element_code: str) ->str:\n    \"\"\"\n    Create a prompt for partial edits within a function or class.\n    This allows surgical changes to specific parts of code.\n    \"\"\"\n    return f\"\"\"You are an expert programmer. Make a surgical edit to a specific part of a function/class.\n\nCONTEXT:\n- File: {file_name}\n- Element: {element_name}\n- Lines to modify: {line_start}-{line_end}\n- Task: {instruction}\n\nIMPORTANT RULES:\n- Provide ONLY the code that will replace lines {line_start}-{line_end}\n- Your code must fit seamlessly into the existing function\n- Maintain proper indentation (the code will be auto-indented)\n- Do NOT include the function definition or other parts\n- Do NOT include explanations outside the code\n\nFull element for context:\n```python\n{full_element_code}\n```\n\nCode section to replace (lines {line_start}-{line_end}):\n```python\n{original_snippet}\n```\n\nGenerate ONLY the replacement code for the specified lines:\"\"\"\n\n\ndef handle_file_edit_command(file_path: str, instruction: str):\n    \"\"\"\n    Handles the entire workflow for editing a single file, ensuring full\n    project context is loaded before the AI makes any decisions.\n    Now supports partial edits within functions.\n    \"\"\"\n    global last_code\n    _load_all_project_files_if_needed()\n    resolved_path = resolve_file_path(file_path)\n    if not resolved_path:\n        ui_manager.show_error(f'File not found: {file_path}')\n        return\n    if resolved_path != os.path.abspath(file_path):\n        ui_manager.show_success(\n            f\"Found '{file_path}' in project. Using: {resolved_path}\")\n    try:\n        editor = CodeEditor(resolved_path)\n    except (ValueError, FileNotFoundError) as e:\n        ui_manager.show_error(str(e))\n        return\n    elements = editor.list_elements()\n    element_structures = {}\n    for elem in elements:\n        struct = editor.get_element_structure(elem)\n        if struct:\n            element_structures[elem] = struct\n    prompt1 = _create_prompt_for_element_selection(os.path.basename(\n        resolved_path), instruction, elements, element_structures)\n    with ui_manager.show_spinner('AI is analyzing file...'):\n        ai_response = query_llm(prompt1).strip()\n    if ai_response.upper() == 'FILE':\n        ui_manager.show_success('AI has chosen to edit the entire file.')\n        original_snippet = editor.source_code\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), 'entire file', instruction, original_snippet,\n            is_full_file=True)\n        edit_type = 'FILE'\n        element_to_edit = None\n        line_range = None\n    elif ai_response.startswith('PARTIAL:'):\n        parts = ai_response.split()\n        element_to_edit = parts[1]\n        if 'LINES:' in ai_response:\n            line_part = ai_response.split('LINES:')[1].strip()\n            if '-' in line_part:\n                line_start, line_end = map(int, line_part.split('-'))\n                line_range = line_start, line_end\n            else:\n                ui_manager.show_error('Invalid line range format')\n                return\n        else:\n            ui_manager.show_error('Missing line range for partial edit')\n            return\n        if element_to_edit not in elements:\n            ui_manager.show_error(f\"Element '{element_to_edit}' not found\")\n            return\n        ui_manager.show_success(\n            f\"AI selected partial edit of '{element_to_edit}' (lines {line_start}-{line_end})\"\n            )\n        original_snippet = editor.get_element_body_snippet(element_to_edit,\n            line_start, line_end)\n        if not original_snippet:\n            original_snippet = editor.get_source_of(element_to_edit)\n        full_element_code = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_partial_edit(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet,\n            line_start, line_end, full_element_code)\n        edit_type = 'PARTIAL'\n    elif ai_response.startswith('ELEMENT:'):\n        element_to_edit = ai_response.split(':', 1)[1].strip()\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    else:\n        element_to_edit = ai_response.splitlines()[0]\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    with ui_manager.show_spinner(f'AI is editing...'):\n        response = query_llm(prompt2)\n    code_blocks = extract_code(response)\n    if not code_blocks:\n        ui_manager.show_error('AI did not return a valid code block.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    new_code = code_blocks[0][1]\n    success = False\n    if edit_type == 'FILE':\n        try:\n            editor.tree = ast.parse(new_code)\n            success = True\n        except SyntaxError as e:\n            ui_manager.show_error(f'AI returned invalid Python syntax: {e}')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    elif edit_type == 'PARTIAL':\n        success = editor.replace_partial(element_to_edit, new_code,\n            line_start=line_range[0], line_end=line_range[1])\n        if not success:\n            ui_manager.show_error('Failed to apply partial edit.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    else:\n        success = editor.replace_element(element_to_edit, new_code)\n        if not success:\n            ui_manager.show_error(\n                'AI returned invalid code; could not be parsed or applied.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    if not (diff := editor.get_diff()):\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(diff, title=\n        f'[bold yellow]Proposed Changes for {resolved_path}[/]'))\n    if ui_manager.get_user_input('Apply changes? (y/n): ').lower() in ['yes',\n        'y']:\n        editor.save_changes()\n        last_code = editor.get_modified_source()\n        ui_manager.show_success(f'Changes saved to {resolved_path}.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_plan(instruction: str, memory_context: str\n    ) ->str:\n    \"\"\"\n    Create a specialized prompt-generation function for the 'refactor' command.\n    This prompt will explicitly define the required JSON structure for the plan\n    and instruct the AI to act as an expert project manager.\n    \"\"\"\n    return f\"\"\"You are an expert project manager and software architect. Analyze the project context and create a detailed refactoring plan.\n\nYour plan must be a valid JSON object with this exact structure:\n{{\n    \"actions\": [\n        {{\n            \"type\": \"MODIFY\" | \"CREATE\" | \"DELETE\" | \"PARTIAL\",\n            \"file\": \"relative/path/to/file.py\",\n            \"element\": \"function_or_class_name\",  // For MODIFY/DELETE/PARTIAL\n            \"element_name\": \"new_element_name\",    // For CREATE\n            \"line_start\": 10,                      // For PARTIAL only\n            \"line_end\": 20,                        // For PARTIAL only\n            \"reason\": \"Clear explanation of why this change is needed\",\n            \"description\": \"What this action will accomplish\",\n            \"anchor_element\": \"optional_anchor\",   // Optional for CREATE\n            \"position\": \"before\" | \"after\"         // Optional for CREATE\n        }}\n    ]\n}}\n\nACTION TYPES:\n- MODIFY: Change an entire function, class, or method\n- PARTIAL: Change specific lines within a function/class (requires line_start and line_end)\n- CREATE: Add new functions, classes, or files\n- DELETE: Remove functions, classes, variables, or imports\n\nRULES FOR YOUR PLAN:\n- Use PARTIAL when you only need to change a small part of a function\n- Use MODIFY when restructuring an entire function or class\n- Each action must have all required fields based on its type\n- File paths must be relative to the project root\n- Be specific and surgical - avoid unnecessary changes\n- Consider dependencies between changes\n- Order actions logically (e.g., create dependencies before using them)\n\n### Project Context ###\n{memory_context}\n\n### Refactoring Request ###\n{instruction}\n\nGenerate ONLY the JSON plan - no explanations or markdown:\"\"\"\n\n\ndef _get_refactor_plan(instruction: str) ->Optional[List[Dict]]:\n    \"\"\"\n    Generates a refactoring plan from the LLM.\n\n    This function encapsulates the logic for checking project context,\n    constructing a prompt, querying the LLM, and parsing the resulting\n    JSON plan for a refactoring task.\n\n    Args:\n        instruction: The user's high-level refactoring instruction.\n\n    Returns:\n        A list of action dictionaries if a valid plan is generated,\n        otherwise None.\n    \"\"\"\n    if not memory_manager.get_project_root():\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return None\n    memory_context = memory_manager.get_memory_context()\n    plan_prompt = _create_prompt_for_refactor_plan(instruction, memory_context)\n    with ui_manager.show_spinner('AI is creating an execution plan...'):\n        plan_str = query_llm(plan_prompt)\n    try:\n        match = re.search('\\\\{.*\\\\}', plan_str, re.DOTALL)\n        if not match:\n            raise ValueError('No JSON object found in the response.')\n        plan = json.loads(match.group(0))\n        actions = plan.get('actions', [])\n        if not actions:\n            raise ValueError(\"No 'actions' key found in plan or plan is empty.\"\n                )\n        return actions\n    except (json.JSONDecodeError, ValueError) as e:\n        ui_manager.show_error(f'AI failed to generate a valid plan: {e}')\n        print(Panel(plan_str, title=\"[yellow]AI's Invalid Plan Response[/]\",\n            border_style='yellow'))\n        return None\n\n\ndef _display_and_confirm_plan(plan: Dict) ->bool:\n    \"\"\"\n    Displays the generated execution plan to the user and asks for confirmation.\n\n    This helper function separates the UI interaction of plan confirmation from\n    the main refactoring logic.\n\n    Args:\n        plan: A dictionary, expected to contain an 'actions' key with a list of action dicts.\n\n    Returns:\n        True if the user confirms the plan, False otherwise.\n    \"\"\"\n    actions = plan.get('actions', [])\n    if not actions:\n        ui_manager.show_error('The generated plan is empty. Aborting.')\n        return False\n    ui_manager.show_success('AI has created a plan:')\n    for i, action in enumerate(actions):\n        action_type = action.get('type', 'N/A')\n        element = action.get('element') or action.get('element_name', 'N/A')\n        reason = action.get('reason') or action.get('description', '')\n        file_path = action.get('file', '')\n        if action_type == 'PARTIAL':\n            line_start = action.get('line_start', '?')\n            line_end = action.get('line_end', '?')\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} (lines {line_start}-{line_end}) - {reason}'\n                )\n        else:\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} - {reason}'\n                )\n    if ui_manager.get_user_input('\\nProceed with this plan? (y/n): ').lower(\n        ) in ['yes', 'y']:\n        return True\n    else:\n        ui_manager.show_error('Execution aborted by user.')\n        return False\n\n\ndef _apply_refactor_changes(editors: Dict[str, CodeEditor]) ->None:\n    \"\"\"\n    Consolidates changes from multiple CodeEditor instances, shows a unified\n    diff, and prompts the user to apply them.\n    \n    This helper function abstracts the final step of a refactor, ensuring\n    all proposed modifications are presented to the user for a final review\n    before any files are written to disk.\n\n    Args:\n        editors: A dictionary mapping absolute file paths to their\n                 corresponding CodeEditor instances which hold the\n                 proposed changes in their AST.\n    \"\"\"\n    full_diff = ''\n    for editor in editors.values():\n        diff = editor.get_diff()\n        if diff:\n            full_diff += diff + '\\n'\n    if not full_diff.strip():\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(full_diff, title=\n        '[bold yellow]Proposed Project-Wide Changes[/]'))\n    if ui_manager.get_user_input('Apply all changes? (y/n): ').lower() in [\n        'yes', 'y']:\n        for editor in editors.values():\n            editor.save_changes()\n        ui_manager.show_success('\u2705 Project changes applied successfully.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_action(action_type: str, file_path: str,\n    action_details: Dict) ->str:\n    \"\"\"\n    Create a helper to generate prompts for individual 'CREATE' or 'MODIFY' steps\n    within a refactor plan. This ensures the AI produces code for the specific\n    sub-task in the correct context.\n    \"\"\"\n    if action_type == 'MODIFY':\n        element_name = action_details['element_name']\n        reason = action_details['reason']\n        original_code = action_details['original_code']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- Element: {element_name}\n- Reason for change: {reason}\n\nRULES:\n- Provide ONLY the complete updated code for the element\n- Include any necessary imports at the top\n- Ensure the code integrates properly with the rest of the file\n- Maintain the same function/class signature unless the change requires otherwise\n- No explanations outside the code block\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the updated element code:\"\"\"\n    elif action_type == 'CREATE':\n        element_name = action_details['element_name']\n        description = action_details['description']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- New element to create: {element_name}\n- Purpose: {description}\n\nRULES:\n- Provide ONLY the complete code for the new element\n- Include all necessary imports at the top\n- Follow the coding style and patterns used in the project\n- Ensure the code is production-ready and well-structured\n- For non-Python files, provide the complete file content\n- No explanations outside the code block\n\nGenerate the new element code:\"\"\"\n\n\ndef _process_refactor_action(action: Dict, project_base_path: str, editors:\n    Dict) ->bool:\n    \"\"\"\n    Processes a single refactoring action from the plan.\n\n    This function handles the execution of a single action from the refactoring plan,\n    including LLM code generation and applying changes to in-memory editors or files.\n\n    Args:\n        action: A dictionary containing action details (type, file, element, etc.)\n        project_base_path: The absolute path to the project root\n        editors: Dictionary mapping file paths to their CodeEditor instances\n\n    Returns:\n        True if the action was processed successfully, False otherwise\n    \"\"\"\n    file_path_relative = action.get('file')\n    if not file_path_relative:\n        ui_manager.show_error(\n            f\"Action is missing 'file' key. Skipping: {action}\")\n        return False\n    file_path_absolute = os.path.join(project_base_path, file_path_relative)\n    action_type = action.get('type', '').upper()\n    prompt, element_name = '', ''\n    if action_type == 'MODIFY':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_source_of(element_name)\n            if not original_snippet:\n                ui_manager.show_error(\n                    f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                    )\n                return False\n            action_details = {'element_name': element_name, 'reason':\n                reason, 'original_code': original_snippet}\n            prompt = _create_prompt_for_refactor_action('MODIFY',\n                file_path_relative, action_details)\n    elif action_type == 'PARTIAL':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        line_start = action.get('line_start')\n        line_end = action.get('line_end')\n        if not all([element_name, line_start, line_end]):\n            ui_manager.show_error(\n                f'PARTIAL action missing required fields. Skipping: {action}')\n            return False\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_element_body_snippet(element_name,\n                line_start, line_end)\n            if not original_snippet:\n                original_snippet = editor.get_source_of(element_name)\n                if not original_snippet:\n                    ui_manager.show_error(\n                        f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                        )\n                    return False\n            full_element_code = editor.get_source_of(element_name)\n            prompt = _create_prompt_for_partial_edit(file_path_relative,\n                element_name, reason, original_snippet, line_start,\n                line_end, full_element_code)\n    elif action_type == 'CREATE':\n        element_name = action.get('element_name')\n        description = action.get('description')\n        action_details = {'element_name': element_name, 'description':\n            description}\n        prompt = _create_prompt_for_refactor_action('CREATE',\n            file_path_relative, action_details)\n    else:\n        ui_manager.show_error(f\"Invalid action type '{action_type}'. Skipping.\"\n            )\n        return False\n    with ui_manager.show_spinner(\n        f\"AI: {action_type} on '{element_name or file_path_relative}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    new_content = code_blocks[0][1] if code_blocks else response.strip()\n    if not new_content:\n        ui_manager.show_error(\n            f'AI failed to generate content for action: {action}')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return False\n    if not file_path_relative.endswith('.py'):\n        try:\n            FileCreator.create(file_path_absolute, new_content)\n            ui_manager.show_success(\n                f\"File '{file_path_relative}' created/updated.\")\n            return True\n        except IOError as e:\n            ui_manager.show_error(\n                f\"Failed to create file '{file_path_relative}': {e}\")\n            return False\n    if file_path_absolute not in editors:\n        try:\n            if not os.path.exists(file_path_absolute):\n                os.makedirs(os.path.dirname(file_path_absolute), exist_ok=True)\n                with open(file_path_absolute, 'w') as f:\n                    f.write('')\n            editors[file_path_absolute] = CodeEditor(file_path_absolute)\n        except Exception as e:\n            ui_manager.show_error(\n                f'Error loading file {file_path_absolute}: {e}')\n            return False\n    editor = editors[file_path_absolute]\n    if action_type == 'MODIFY':\n        if not editor.replace_element(element_name, new_content):\n            ui_manager.show_error(\n                f\"Failed to apply MODIFY change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic MODIFY Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'PARTIAL':\n        if not editor.replace_partial(element_name, new_content, line_start,\n            line_end):\n            ui_manager.show_error(\n                f\"Failed to apply PARTIAL change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic PARTIAL Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'CREATE':\n        anchor = action.get('anchor_element')\n        position = action.get('position', 'after')\n        if not editor.add_element(new_content, anchor_name=anchor, before=\n            position == 'before'):\n            ui_manager.show_error(\n                f\"Failed to apply CREATE change for '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic CREATE Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    return True\n\n\ndef handle_project_refactor_command(instruction: str):\n    \"\"\"\n    Orchestrates a multi-file, multi-step code refactoring process.\n    \n    This function serves as a high-level orchestrator that delegates specific tasks\n    to helper functions, improving readability, modularity, and maintainability.\n    \"\"\"\n    _load_all_project_files_if_needed()\n    actions = _get_refactor_plan(instruction)\n    if not actions:\n        return\n    plan = {'actions': actions}\n    if not _display_and_confirm_plan(plan):\n        return\n    editors: Dict[str, CodeEditor] = {}\n    project_base_path = memory_manager.get_project_root()\n    successful_actions = 0\n    total_actions = len(actions)\n    for i, action in enumerate(actions, 1):\n        ui_manager.show_success(f'Processing action {i}/{total_actions}...')\n        action_type = action.get('type', '').upper()\n        file_path_relative = action.get('file')\n        if not file_path_relative:\n            ui_manager.show_error(\n                f\"Action is missing 'file' key. Skipping: {action}\")\n            continue\n        file_path_absolute = os.path.join(project_base_path, file_path_relative\n            )\n        if action_type == 'DELETE':\n            element_name = action.get('element')\n            if not element_name:\n                ui_manager.show_error(\n                    f\"DELETE action missing 'element' key. Skipping: {action}\")\n                continue\n            if not file_path_relative.endswith('.py'):\n                ui_manager.show_error(\n                    f'DELETE actions are only supported for Python files. Skipping.'\n                    )\n                continue\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    continue\n            editor = editors[file_path_absolute]\n            if editor.delete_element(element_name):\n                successful_actions += 1\n                ui_manager.show_success(\n                    f\"Successfully deleted '{element_name}' from '{file_path_relative}'.\"\n                    )\n            else:\n                ui_manager.show_error(\n                    f\"Failed to delete '{element_name}' from '{file_path_relative}'.\"\n                    )\n        elif _process_refactor_action(action, project_base_path, editors):\n            successful_actions += 1\n        else:\n            ui_manager.show_error(\n                f'Action {i} failed, continuing with remaining actions...')\n    if successful_actions == 0:\n        ui_manager.show_error('No actions were successfully executed.')\n        return\n    elif successful_actions < total_actions:\n        ui_manager.show_error(\n            f'Only {successful_actions}/{total_actions} actions completed successfully.'\n            )\n    else:\n        ui_manager.show_success(\n            f'All {total_actions} actions completed successfully.')\n    _apply_refactor_changes(editors)\n\n\ndef _create_prompt_for_commit_message(diff: str) ->str:\n    \"\"\"\n    Create a dedicated prompt function for the 'commit' command. This prompt will\n    instruct the AI to analyze a git diff and generate a concise commit message\n    following the Conventional Commits standard.\n    \"\"\"\n    return f\"\"\"You are an expert developer writing a Git commit message. Your task is to analyze the provided git diff and create a professional commit message.\n\nCOMMIT MESSAGE RULES:\n- Follow the Conventional Commits specification\n- Format: <type>(<optional scope>): <subject>\n- Types: feat, fix, docs, style, refactor, perf, test, build, ci, chore, revert\n- Subject line: max 50 characters, imperative mood, no period\n- Optional body: explain what and why (not how), wrap at 72 characters\n- Be specific and concise\n- Focus on the intent and impact of the changes\n\nEXAMPLES OF GOOD COMMIT MESSAGES:\n- feat(auth): add OAuth2 integration for Google login\n- fix(api): handle null response in user endpoint\n- refactor(database): optimize query performance for large datasets\n- docs(readme): update installation instructions for Windows\n\nRespond with ONLY the commit message - no markdown, quotes, or explanations.\n\n--- GIT DIFF TO ANALYZE ---\n{diff}\n\nGenerate the commit message:\"\"\"\n\n\ndef handle_commit_command():\n    \"\"\"\n    Orchestrates an AI-assisted Git commit workflow with improved error handling.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return\n    try:\n        git_manager = GitManager(project_root)\n    except ValueError as e:\n        ui_manager.show_error(str(e))\n        return\n    changed_files = git_manager.get_changed_files()\n    if not changed_files:\n        ui_manager.show_success(\n            'No changes to commit. Everything is up to date.')\n        return\n    staged_diff = git_manager.get_diff(staged=True)\n    unstaged_diff = git_manager.get_diff()\n    full_diff = f'{staged_diff}\\n{unstaged_diff}'.strip()\n    if not full_diff.strip():\n        ui_manager.show_success(\n            'No content changes detected (e.g., only file mode changes).')\n        return\n    prompt = _create_prompt_for_commit_message(full_diff)\n    commit_message = query_llm(prompt).strip()\n    if not commit_message:\n        ui_manager.show_error(\n            'AI failed to generate a commit message. Aborting.')\n        return\n    files_to_commit_str = '\\n'.join(f'- {f}' for f in changed_files)\n    plan_panel_content = f\"\"\"[bold]Files to be staged:[/]\n[yellow]{files_to_commit_str}[/]\n\n[bold]AI-Generated Commit Message:[/]\n[green]{commit_message}[/]\"\"\"\n    print(Panel(plan_panel_content, title='[bold cyan]Commit Plan[/]',\n        border_style='cyan'))\n    if ui_manager.get_user_input('\\nProceed with commit? (y/n): ').lower() in [\n        'yes', 'y']:\n        try:\n            git_manager.add(changed_files)\n            ui_manager.show_success('\u2705 Files staged.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Staging failed: {e.stderr}')\n            return\n        try:\n            git_manager.commit(commit_message)\n            ui_manager.show_success('\u2705 Commit successful.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Commit failed: {e.stderr}')\n            return\n        if ui_manager.get_user_input('Push changes to remote? (y/n): ').lower(\n            ) in ['yes', 'y']:\n            try:\n                git_manager.push()\n                ui_manager.show_success('\u2705 Push successful.')\n            except subprocess.CalledProcessError as e:\n                ui_manager.show_error(f'Push failed: {e.stderr}')\n        else:\n            ui_manager.show_error('Push cancelled.')\n    else:\n        ui_manager.show_error('Commit aborted by user.')\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef interactive_mode() ->None:\n    global last_query, last_response, last_code\n    try:\n        from Testing.overlay_engine import show_sequential_popup\n        gui_available = True\n    except ImportError:\n        gui_available = False\n    print(Panel(\n        \"\"\"[bold cyan]Omni Interactive Mode[/]\n[dim]Type 'help' for commands, 'exit' to quit.[/dim]\"\"\"\n        , border_style='cyan'))\n    personality_name = personality_manager.get_current_personality().get('name'\n        , 'Default')\n    gui_enabled = False\n    if gui_available:\n        try:\n            with open(CONFIG_FILE, 'r') as f:\n                config = json.load(f)\n                if config.get('gui_enabled', False):\n                    gui_enabled = True\n        except (FileNotFoundError, json.JSONDecodeError):\n            pass\n    refresh_status_panel(personality_name)\n    while True:\n        try:\n            user_input = ui_manager.get_user_input('\\n> ')\n            if not user_input:\n                continue\n            command, *args = user_input.split(maxsplit=1)\n            arg_str = args[0] if args else ''\n            if command == 'exit':\n                memory_manager.save_memory()\n                print('[bold cyan]Goodbye![/]')\n                break\n            elif command == 'help':\n                print(\n                    \"\"\"[bold]Commands:[/]\n\n  [bold cyan]Core & Project Commands[/]\n  [yellow]send <prompt>[/]        - Ask the LLM a question.\n  [yellow]look <path>[/]          - Read file or scan directory into memory.\n  [yellow]look_all[/]            - Recursively scan the project directory into memory.\n  [yellow]create <file> \"instr\"[/] - Create a new file using AI.\n  [yellow]edit <file> \"instr\"[/]   - Edit a specific file using AI.\n  [yellow]refactor \"instr\"[/]      - Refactor project in memory based on instruction.\n  [yellow]commit[/]               - Commit changes with an AI-generated message.\n  [yellow]rag <query>[/]         - Query the RAG system for context retrieval.\n\n  [bold cyan]File & Code Management[/]\n  [yellow]save <filename>[/]     - Save last AI response to a file.\n  [yellow]list[/]               - List saved files.\n  [yellow]run[/]                 - Run the last generated Python code.\n\n  [bold cyan]Session & Config[/]\n  [yellow]history[/]             - Show the full chat history.\n  [yellow]memory clear[/]        - Clear the chat and file memory.\n  [yellow]backend <name>[/]      - Switch AI backend (e.g., openrouter, ollama).\n  [yellow]models [src][/]        - Interactively list and select models.\n  [yellow]set model <id>[/]      - Set the model directly by its ID.\n  [yellow]personality <cmd>[/]   - Manage AI personalities ('list', 'set', 'add').\n\"\"\"\n                    )\n            elif command == 'send':\n                last_query = arg_str\n                response = query_llm(arg_str)\n                last_response = response\n                if gui_enabled:\n                    threading.Thread(target=show_sequential_popup, args=(\n                        100, 100, response, f'Omni - {personality_name}'),\n                        daemon=True).start()\n                print(Panel(response, title='[cyan]Response[/]'))\n                if (code_blocks := extract_code(response)):\n                    last_code = code_blocks[0][1]\n            elif command == 'look':\n                look_command(arg_str)\n            elif command == 'look_all':\n                look_all_command()\n            elif command == 'create':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_create_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: create <file_path> \"<instruction>\"')\n            elif command == 'edit':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_edit_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: edit <file_path> \"<instruction>\"')\n            elif command == 'refactor':\n                if not arg_str:\n                    ui_manager.show_error('Usage: refactor \"<instruction>\"')\n                else:\n                    handle_project_refactor_command(arg_str.strip('\"'))\n            elif command == 'commit':\n                handle_commit_command()\n            elif command == 'models':\n                list_models(arg_str.split())\n            elif command == 'set' and arg_str.startswith('model '):\n                set_model(arg_str[6:])\n            elif command == 'backend':\n                switch_backend(arg_str)\n            elif command == 'history':\n                ui_manager.display_history(memory_manager.get_memory_context())\n            elif command == 'memory' and arg_str == 'clear':\n                memory_manager.clear_memory()\n                ui_manager.show_success('\u2705 Memory cleared')\n            elif command == 'personality':\n                p_args = arg_str.split(maxsplit=1)\n                cmd = p_args[0] if p_args else ''\n                p_arg_str = p_args[1] if len(p_args) > 1 else ''\n                if cmd == 'list':\n                    for p in personality_manager.list_personalities():\n                        print(f\"- {p['name']}: {p['description']}\")\n                elif cmd == 'set' and p_arg_str:\n                    if personality_manager.set_current_personality(p_arg_str):\n                        personality_name = p_arg_str\n                        ui_manager.show_success(\n                            f'Set personality to {personality_name}')\n                    else:\n                        ui_manager.show_error('Personality not found.')\n                else:\n                    ui_manager.show_error(\n                        \"Invalid personality command. Use 'list' or 'set <name>'.\"\n                        )\n            elif command == 'run':\n                run_python_code()\n            elif command == 'save':\n                if last_response:\n                    save_code(last_response, arg_str or\n                        f\"omni_save_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n                        )\n                else:\n                    ui_manager.show_error('No response to save.')\n            elif command == 'list':\n                files = sorted(os.listdir(DEFAULT_SAVE_DIR))\n                print('\\n'.join(f'  - {f}' for f in files) if files else\n                    '[yellow]No saved files.[/]')\n            elif command == 'rag':\n                if not arg_str:\n                    ui_manager.show_error('Usage: rag \"<query>\"')\n                else:\n                    from rag_manager import RAGManager\n                    project_root = memory_manager.get_project_root()\n                    if not project_root:\n                        ui_manager.show_error(\n                            \"No project context in memory. Use 'look <directory>' first.\"\n                            )\n                        continue\n                    rag = RAGManager()\n                    if rag.get_document_count() == 0:\n                        ui_manager.show_error(\n                            'RAG index is empty. Please add documents first.')\n                        continue\n                    results = rag.search(arg_str, k=3)\n                    if not results:\n                        ui_manager.show_error('No relevant documents found.')\n                        continue\n                    print(Panel('[bold]RAG Results:[/]', title=\n                        '[cyan]Retrieval-Augmented Generation[/]'))\n                    for i, (content, score, metadata) in enumerate(results, 1):\n                        file_path = metadata.get('file', 'Unknown')\n                        print(\n                            f'[bold cyan]{i}. {file_path}[/] (Score: {score:.4f})'\n                            )\n                        print(Panel(content[:500] + '...' if len(content) >\n                            500 else content, border_style='dim'))\n                    follow_up = ui_manager.get_user_input(\n                        \"\"\"\nWould you like to ask a follow-up question with this context? (y/n): \"\"\"\n                        )\n                    if follow_up.lower() in ['y', 'yes']:\n                        follow_up_query = ui_manager.get_user_input(\n                            'Follow-up query: ')\n                        if follow_up_query:\n                            context_parts = [\n                                f'Document {i} (Score: {score:.4f}):\\n{content}'\n                                 for i, (content, score, _) in enumerate(\n                                results, 1)]\n                            context = '\\n\\n'.join(context_parts)\n                            rag_prompt = f\"\"\"Based on the following context, please answer the question.\n\nContext:\n{context}\n\nQuestion: {follow_up_query}\"\"\"\n                            response = query_llm(rag_prompt)\n                            print(Panel(response, title=\n                                '[cyan]RAG-Augmented Response[/]'))\n            else:\n                ui_manager.show_error(\"Unknown command. Type 'help'.\")\n            refresh_status_panel(personality_name)\n        except KeyboardInterrupt:\n            memory_manager.save_memory()\n            print('\\n[bold cyan]Goodbye![/]')\n            break\n        except Exception as e:\n            ui_manager.show_error(f'An unexpected error occurred: {e}')\n\n\ndef run_python_code() ->None:\n    global last_code\n    if not last_code:\n        ui_manager.show_error('No Python code in memory to run.')\n        return\n    temp_file = os.path.join(DEFAULT_SAVE_DIR, 'temp_run.py')\n    try:\n        with open(temp_file, 'w') as f:\n            f.write(last_code)\n        print('[bold cyan]\\n--- Running Code ---\\n[/]')\n        subprocess.run([sys.executable, temp_file], check=True)\n        print('[bold cyan]\\n--- Code Finished ---\\n[/]')\n    except Exception as e:\n        ui_manager.show_error(f'Error running code: {e}')\n    finally:\n        if os.path.exists(temp_file):\n            os.remove(temp_file)\n\n\ndef save_code(content: str, filename: str) ->None:\n    filepath = os.path.join(DEFAULT_SAVE_DIR, filename)\n    try:\n        with open(filepath, 'w') as f:\n            f.write(content)\n        ui_manager.show_success(f'Saved to: {filepath}')\n    except IOError as e:\n        ui_manager.show_error(f'Error saving file: {e}')\n\n\ndef main() ->None:\n    try:\n        import astor\n    except ImportError:\n        print(\"[bold red]Error:[/] 'astor' is required. `pip install astor`\")\n        sys.exit(1)\n    try:\n        import simple_term_menu\n    except ImportError:\n        print(\n            \"[bold red]Error:[/] 'simple-term-menu' is required. `pip install simple-term-menu`\"\n            )\n        sys.exit(1)\n    parser = argparse.ArgumentParser(description=\n        'Omni - AI-powered code tool', add_help=False)\n    parser.add_argument('command', nargs='?', help='Main command.')\n    parser.add_argument('args', nargs='*', help='Arguments for the command.')\n    parser.add_argument('-h', '--help', action='store_true')\n    args, _ = parser.parse_known_args()\n    if args.help or not args.command:\n        interactive_mode()\n    elif args.command == 'look' and args.args:\n        look_command(args.args[0])\n    elif args.command == 'edit' and len(args.args) >= 2:\n        handle_file_edit_command(args.args[0], ' '.join(args.args[1:]))\n    elif args.command == 'models':\n        list_models(args.args)\n    else:\n        interactive_mode()\n\n\ndef refresh_status_panel(personality_name: str) ->None:\n    ui_manager.display_status_panel(personality_name, current_backend,\n        current_model, len(memory_manager.memory.get('chat', [])), len(\n        memory_manager.memory.get('look', [])))\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/omni.py"
  },
  {
    "id": 9,
    "hash": "392cb7cce7185587da5fc1b6a30c1fef",
    "content": "import json\nimport os\nfrom typing import List, Dict, Optional\nfrom rag_manager import RAGManager\n\n\nclass MemoryManager:\n    \"\"\"Manages persistent chat memory, look data, and RAG integration via JSON.\"\"\"\n\n    def __init__(self, memory_file: str):\n        self.memory_file = memory_file\n        self.memory: Dict[str, List] = self.load_memory()\n        self.rag_manager = RAGManager()\n\n    def load_memory(self) ->Dict[str, List]:\n        try:\n            with open(self.memory_file, 'r') as f:\n                return json.load(f)\n        except FileNotFoundError:\n            default = {'chat': [], 'look': []}\n            self.save_memory(default)\n            return default\n        except json.JSONDecodeError:\n            print('[yellow]Invalid memory file. Resetting.[/]')\n            return {'chat': [], 'look': []}\n\n    def save_memory(self, memory: Optional[Dict[str, List]]=None) ->None:\n        if memory is None:\n            memory = self.memory\n        with open(self.memory_file, 'w') as f:\n            json.dump(memory, f, indent=4)\n\n    def add_message(self, role: str, content: str) ->None:\n        self.memory['chat'].append({'role': role, 'content': content})\n        self.save_memory()\n\n    def add_look_data(self, file_path: str, content: str) ->None:\n        \"\"\"\n    Adds a watched item (directory or file) to memory, distinguishing its type.\n\n    This method stores structured data that differentiates between a project\n    directory (containing a manifest) and a single file (containing its content).\n    It also prevents duplicate entries by updating existing ones.\n\n    Args:\n        file_path: The path to the directory or file.\n        content: The manifest for a directory or the content for a file.\n    \"\"\"\n        item_type = 'directory' if os.path.isdir(file_path) else 'file'\n        for item in self.memory['look']:\n            if item.get('file') == file_path:\n                item['content'] = content\n                item['type'] = item_type\n                self.save_memory()\n                return\n        self.memory['look'].append({'type': item_type, 'file': file_path,\n            'content': content})\n        self.save_memory()\n        if item_type == 'file':\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    file_content = f.read()\n                self.rag_manager.add_documents([file_content], [{'file':\n                    file_path}])\n            except Exception as e:\n                print(\n                    f'[yellow]Warning: Could not add {file_path} to RAG index: {e}[/]'\n                    )\n\n    def get_memory_context(self) -> str:\n        \"\"\"\n        Dynamically builds the context using RAG and chat history.\n\n        It retrieves relevant file content from the RAG index based on the latest\n        user query, includes project manifests for directories, and appends the\n        recent chat history.\n        \"\"\"\n        context = ''\n        # 1. Add project manifests for any watched directories\n        for look in self.memory.get('look', []):\n            path = look.get('file')\n            if path and os.path.isdir(path):\n                content = look.get('content', '')\n                context += f'--- Project Manifest for {path} ---\\n{content}\\n\\n'\n\n        # 2. Find the last user message to use as a query for the RAG system\n        last_user_message = next((msg['content'] for msg in reversed(self.memory.get('chat', [])) if msg['role'] == 'user'), None)\n\n        # 3. If a user message exists, search the RAG index for relevant context\n        if last_user_message:\n            rag_results = self.search_rag(last_user_message, k=3)\n            if rag_results:\n                context += '--- Relevant context from RAG ---\\n'\n                # Format and add each RAG result to the context\n                for doc, score, meta in rag_results:\n                    file_path = meta.get('file', 'Unknown source')\n                    context += f'Source: {file_path} (Score: {score:.4f})\\n'\n                    context += f'Content: {doc}\\n---\\n'\n                context += '\\n'\n\n        # 4. Append the full chat history for conversational context\n        for msg in self.memory.get('chat', []):\n            context += f\"{msg['role'].capitalize()}: {msg['content']}\\n\"\n\n        return context.strip()\n\n    def clear_memory(self) ->None:\n        self.memory = {'chat': [], 'look': []}\n        self.save_memory()\n        self.rag_manager.clear_index()\n\n    def search_rag(self, query: str, k: int=3) ->List[tuple]:\n        \"\"\"\n        Search the RAG index for relevant documents.\n        \n        Args:\n            query: The search query\n            k: Number of results to return\n            \n        Returns:\n            List of (document_content, score, metadata) tuples\n        \"\"\"\n        return self.rag_manager.search(query, k)\n",
    "file": "/mnt/ProjectData/omni/memory_manager.py"
  },
  {
    "id": 10,
    "hash": "2914352eefed9d60de098e021dd79b67",
    "content": "import os\nimport sys\nimport argparse\nfrom typing import List\nfrom rag_manager import RAGManager\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\ndef create_sample_data() ->List[str]:\n    \"\"\"Create sample documents for the RAG example.\"\"\"\n    return [\n        'RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with language generation.'\n        ,\n        'The RAG model retrieves relevant documents from a knowledge base and uses them to generate more accurate responses.'\n        ,\n        'FAISS is a library for efficient similarity search and clustering of dense vectors, often used in RAG systems.'\n        ,\n        'Sentence transformers are used to create embeddings for documents and queries in RAG systems.'\n        ,\n        'Retrieval-Augmented Generation improves language models by allowing them to access external knowledge sources.'\n        ,\n        'In RAG systems, documents are indexed and searchable by their semantic embeddings rather than just keywords.'\n        ,\n        'Python is a great language for implementing RAG systems due to libraries like sentence-transformers and faiss.'\n        ,\n        'The retrieval component of RAG is crucial for finding relevant information before generation.'\n        ]\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_cli_example.py"
  },
  {
    "id": 11,
    "hash": "f59a27842056dbb0dc95d0f29c1c5de8",
    "content": "Hello! I'm OmniForge, an AI coding assistant. I can help you scan, understand, and refactor your codebase using local (Ollama) or remote (OpenRouter) LLMs.\n\nI see you've opened the OmniForge project directory. Some key things I can help with:\n\n1. **Project Analysis**: I can look at your files to understand the structure\n2. **Code Editing**: I can make precise edits to functions/classes using AST-based transformations\n3. **Refactoring**: I can perform multi-file architectural changes with a plan\n4. **File Creation**: I can generate new files based on instructions\n\nFor example:\n- `look .` to scan the project\n- `edit code_editor.py \"add docstrings to main methods\"`\n- `refactor \"extract git operations into a separate module\"`\n- `create new_module.py \"implement a simple HTTP client\"`\n\nWhat would you like to do with this project?",
    "file": "/mnt/ProjectData/omni/requirements.txt"
  },
  {
    "id": 12,
    "hash": "dbd143839288b400cafdedb655258434",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n",
    "file": "/mnt/ProjectData/omni/vectordb_manager.py"
  },
  {
    "id": 13,
    "hash": "c27b11d2eaa8e13cdf8e698417efb75e",
    "content": "import os\nimport sys\nfrom typing import List, Dict, Tuple\n\"\"\"\nExample script demonstrating RAG (Retrieval-Augmented Generation) usage.\n\nThis script shows how to use a simple RAG implementation to answer questions\nbased on a given context or knowledge base.\n\"\"\"\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\nclass SimpleRAG:\n    \"\"\"A simple RAG implementation for demonstration purposes.\"\"\"\n\n    def __init__(self, knowledge_base: List[str]):\n        \"\"\"\n        Initialize the RAG with a knowledge base.\n        \n        Args:\n            knowledge_base: A list of strings representing the knowledge base.\n        \"\"\"\n        self.knowledge_base = knowledge_base\n\n    def retrieve(self, query: str, top_k: int=3) ->List[str]:\n        \"\"\"\n        Retrieve relevant documents from the knowledge base.\n        \n        This is a simplified implementation using keyword matching.\n        In a real implementation, you would use embeddings and vector search.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            A list of relevant documents.\n        \"\"\"\n        query_words = set(query.lower().split())\n        scores = []\n        for doc in self.knowledge_base:\n            doc_words = set(doc.lower().split())\n            score = len(query_words.intersection(doc_words))\n            scores.append((score, doc))\n        scores.sort(reverse=True)\n        return [doc for score, doc in scores[:top_k]]\n\n    def generate(self, query: str, retrieved_docs: List[str]) ->str:\n        \"\"\"\n        Generate an answer based on the query and retrieved documents.\n        \n        In a real implementation, this would use an LLM to generate the response.\n        For this example, we'll create a simple template-based response.\n        \n        Args:\n            query: The query string.\n            retrieved_docs: The retrieved documents.\n            \n        Returns:\n            A generated answer.\n        \"\"\"\n        context = '\\n'.join(retrieved_docs)\n        prompt = f\"\"\"\n        Context information:\n        {context}\n        \n        Question: {query}\n        \n        Based on the context provided above, please answer the question.\n        If the context doesn't contain relevant information, say so.\n        \"\"\"\n        return self._simple_response_generator(query, retrieved_docs)\n\n    def _simple_response_generator(self, query: str, retrieved_docs: List[str]\n        ) ->str:\n        \"\"\"\n        A simple response generator for demonstration.\n        \"\"\"\n        for doc in retrieved_docs:\n            if 'example' in doc.lower():\n                return (\n                    f'Based on the context provided, I found information about examples. {query} relates to the examples in the knowledge base.'\n                    )\n        return (\n            f\"I couldn't find specific information about '{query}' in the provided context. Please provide more details or check the knowledge base.\"\n            )\n\n    def query(self, query: str, top_k: int=3) ->str:\n        \"\"\"\n        Process a query through the full RAG pipeline.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            The generated answer.\n        \"\"\"\n        retrieved_docs = self.retrieve(query, top_k)\n        answer = self.generate(query, retrieved_docs)\n        return answer\n\n\ndef main():\n    \"\"\"Main function demonstrating the RAG implementation.\"\"\"\n    knowledge_base = ['This is an example document about machine learning.',\n        'Natural language processing is a subfield of artificial intelligence.'\n        , 'Python is a popular programming language for data science.',\n        'The quick brown fox jumps over the lazy dog.',\n        'RAG stands for Retrieval-Augmented Generation.',\n        'Vector databases are used for similarity search in RAG systems.',\n        'Transformers are a type of neural network architecture.',\n        'This example shows how to implement a simple RAG system.']\n    rag = SimpleRAG(knowledge_base)\n    queries = ['What is RAG?', 'How is Python used in data science?',\n        'Tell me about machine learning']\n    print('Simple RAG Example')\n    print('=' * 50)\n    for query in queries:\n        print(f'\\nQuery: {query}')\n        answer = rag.query(query)\n        print(f'Answer: {answer}')\n        print('-' * 30)\n    print(\"\\nInteractive Mode (type 'quit' to exit):\")\n    while True:\n        try:\n            user_query = input('\\nEnter your question: ').strip()\n            if user_query.lower() in ['quit', 'exit', 'q']:\n                break\n            if user_query:\n                answer = rag.query(user_query)\n                print(f'Answer: {answer}')\n        except KeyboardInterrupt:\n            print('\\nGoodbye!')\n            break\n        except EOFError:\n            break\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_example.py"
  },
  {
    "id": 14,
    "hash": "f151986bf2efa7602242590a357fab83",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n    Initialize the RAG manager.\n\n    Args:\n        model_name: Name of the sentence transformer model to use\n        index_path: Path to save/load the FAISS index\n    \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the RAG manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n",
    "file": "/mnt/ProjectData/omni/rag_manager.py"
  },
  {
    "id": 15,
    "hash": "99dbcf73fb2f6f7d59ca44f4bba10e71",
    "content": "[\n  {\n    \"id\": 0,\n    \"hash\": \"43b76714d230bbe319bdf0de327c7192\",\n    \"content\": \"RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with language generation.\",\n    \"file\": \"document_0\"\n  },\n  {\n    \"id\": 1,\n    \"hash\": \"dac60aa8d5e5861796640a8d9b3190a3\",\n    \"content\": \"The RAG model retrieves relevant documents from a knowledge base and uses them to generate more accurate responses.\",\n    \"file\": \"document_0\"\n  },\n  {\n    \"id\": 2,\n    \"hash\": \"f9ed7c2f9da6b1462806979d984ab5f3\",\n    \"content\": \"FAISS is a library for efficient similarity search and clustering of dense vectors, often used in RAG systems.\",\n    \"file\": \"document_0\"\n  },\n  {\n    \"id\": 3,\n    \"hash\": \"192336175c79d0194d2e51a613cbfa1b\",\n    \"content\": \"Sentence transformers are used to create embeddings for documents and queries in RAG systems.\",\n    \"file\": \"document_0\"\n  },\n  {\n    \"id\": 4,\n    \"hash\": \"92c5abaa3019f7294e5af489622302f5\",\n    \"content\": \"Retrieval-Augmented Generation improves language models by allowing them to access external knowledge sources.\",\n    \"file\": \"document_0\"\n  },\n  {\n    \"id\": 5,\n    \"hash\": \"92408c5c2b26cc7bb3e006f75f4f6f08\",\n    \"content\": \"In RAG systems, documents are indexed and searchable by their semantic embeddings rather than just keywords.\",\n    \"file\": \"document_0\"\n  },\n  {\n    \"id\": 6,\n    \"hash\": \"26ed14b833f20c4d6715cd2f9c44381a\",\n    \"content\": \"Python is a great language for implementing RAG systems due to libraries like sentence-transformers and faiss.\",\n    \"file\": \"document_0\"\n  },\n  {\n    \"id\": 7,\n    \"hash\": \"964a8aed30280d1b398f7b17dc6366bb\",\n    \"content\": \"The retrieval component of RAG is crucial for finding relevant information before generation.\",\n    \"file\": \"document_0\"\n  },\n  {\n    \"id\": 8,\n    \"hash\": \"1b61704bafe182154c395ea08a3acb39\",\n    \"content\": \"\\\"\\\"\\\"\\nOmni - AI-powered code generation and project-aware editing CLI tool\\n\\nIntegrates modular UI, memory, personality, and AST-based code editing.\\n\\\"\\\"\\\"\\nimport os\\nimport subprocess\\nimport requests\\nimport json\\nimport sys\\nimport re\\nimport argparse\\nimport ast\\nfrom datetime import datetime\\nimport threading\\nimport queue as Queue\\nimport time\\nfrom typing import List, Dict, Optional\\nfrom rich import print\\nfrom rich.panel import Panel\\nfrom rich.console import Console\\nfrom rich.tree import Tree\\nfrom ui_manager import UIManager\\nfrom personality_manager import PersonalityManager\\nfrom memory_manager import MemoryManager\\nfrom code_editor import CodeEditor\\nfrom file_creator import FileCreator\\nfrom git_manager import GitManager\\nimport traceback\\nDEFAULT_BACKEND = 'openrouter'\\nOLLAMA_MODEL = 'phi4-reasoning'\\nOPENROUTER_MODEL = 'qwen/qwen3-coder'\\nDEFAULT_SAVE_DIR = os.path.expanduser('/mnt/ProjectData/omni/omni_saves/')\\nCONFIG_FILE = 'config.json'\\nMEMORY_FILE = 'memory.json'\\nOLLAMA_API_URL = 'http://localhost:11434/api/generate'\\nOPENROUTER_API_URL = 'https://openrouter.ai/api/v1/chat/completions'\\nOPENROUTER_MODELS_API_URL = 'https://openrouter.ai/api/v1/models'\\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\\ncurrent_backend = DEFAULT_BACKEND\\ncurrent_model = (OLLAMA_MODEL if DEFAULT_BACKEND == 'ollama' else\\n    OPENROUTER_MODEL)\\nOLLAMA_MODELS = {'deepseek': 'deepseek-coder:6.7b', 'codellama':\\n    'codellama:13b', 'mistral': 'mistral:latest', 'llama2': 'llama2:latest',\\n    'phind': 'phind-codellama:34b'}\\nos.makedirs(DEFAULT_SAVE_DIR, exist_ok=True)\\nTEMPLATES = {'flask':\\n    \\\"\\\"\\\"from flask import Flask, jsonify\\n\\napp = Flask(__name__)\\n\\n@app.route('/')\\ndef home():\\n    return '<h1>Hello, Flask!</h1>'\\n\\nif __name__ == '__main__':\\n    app.run(debug=True)\\\"\\\"\\\"\\n    , 'html5':\\n    \\\"\\\"\\\"<!DOCTYPE html>\\n<html lang=\\\"en\\\">\\n<head>\\n    <meta charset=\\\"UTF-8\\\">\\n    <meta name=\\\"viewport\\\" content=\\\"width=device-width, initial-scale=1.0\\\">\\n    <title>New Page</title>\\n</head>\\n<body>\\n    <h1>Hello World</h1>\\n</body>\\n</html>\\\"\\\"\\\"\\n    , 'scraper':\\n    \\\"\\\"\\\"import requests\\nfrom bs4 import BeautifulSoup\\n\\ndef scrape(url):\\n    try:\\n        response = requests.get(url)\\n        response.raise_for_status()\\n        soup = BeautifulSoup(response.content, 'html.parser')\\n        print(soup.title.text)\\n    except Exception as e:\\n        print(f\\\"[bold red]Error scraping {url}:[/] {e}\\\")\\n\\nif __name__ == \\\"__main__\\\":\\n    scrape(\\\"https://example.com\\\")\\\"\\\"\\\"\\n    }\\nconsole = Console()\\npersonality_manager = PersonalityManager(CONFIG_FILE)\\nmemory_manager = MemoryManager(MEMORY_FILE)\\nui_manager = UIManager()\\nlast_query: Optional[str] = None\\nlast_response: Optional[str] = None\\nlast_code: Optional[str] = None\\n\\n\\ndef start_ollama_server() ->None:\\n    if current_backend != 'ollama':\\n        return\\n    try:\\n        requests.get('http://localhost:11434', timeout=1)\\n    except requests.exceptions.ConnectionError:\\n        print('[cyan]Starting Ollama server...[/]')\\n        subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL,\\n            stderr=subprocess.DEVNULL)\\n\\n\\ndef query_llm(prompt: str) ->str:\\n    personality = personality_manager.get_current_personality()\\n    system_prompt = personality.get('system_prompt', '') if personality else ''\\n    memory_context = memory_manager.get_memory_context()\\n    rag_context = ''\\n    try:\\n        from rag_manager import RAGManager\\n        project_root = memory_manager.get_project_root()\\n        if project_root:\\n            rag_manager = RAGManager()\\n            if rag_manager.get_document_count() > 0:\\n                results = rag_manager.search(prompt, k=3)\\n                if results:\\n                    rag_context = '\\\\n\\\\nRelevant context from codebase:\\\\n'\\n                    for i, (doc, score, meta) in enumerate(results, 1):\\n                        file_path = meta.get('file', 'Unknown')\\n                        rag_context += f'{i}. [{file_path}] {doc}\\\\n'\\n    except Exception:\\n        pass\\n    full_prompt = (\\n        f'{system_prompt}\\\\n\\\\n{memory_context}{rag_context}\\\\n\\\\nUser: {prompt}')\\n    with ui_manager.show_spinner('AI is listening and thinking...'):\\n        if current_backend == 'ollama':\\n            response = query_ollama(full_prompt)\\n        elif current_backend == 'openrouter':\\n            response = query_openrouter(full_prompt)\\n        else:\\n            response = '[bold red]Error:[/] Unknown backend'\\n    return response\\n\\n\\ndef query_openrouter(prompt: str) ->str:\\n    if not OPENROUTER_API_KEY:\\n        return '[bold red]Error:[/] OPENROUTER_API_KEY not set.'\\n    headers = {'Authorization': f'Bearer {OPENROUTER_API_KEY}',\\n        'Content-Type': 'application/json'}\\n    payload = {'model': current_model, 'messages': [{'role': 'user',\\n        'content': prompt}]}\\n    try:\\n        response = requests.post(OPENROUTER_API_URL, headers=headers, json=\\n            payload, timeout=90)\\n        response.raise_for_status()\\n        return response.json()['choices'][0]['message']['content']\\n    except Exception as e:\\n        error_details = ''\\n        try:\\n            error_details = response.json()\\n        except:\\n            error_details = response.text if hasattr(response, 'text'\\n                ) else str(e)\\n        return (\\n            f'[bold red]OpenRouter Error:[/] {e}\\\\n[dim]Details: {error_details}[/dim]'\\n            )\\n\\n\\ndef query_ollama(prompt: str) ->str:\\n    payload = {'model': current_model, 'prompt': prompt, 'stream': False}\\n    try:\\n        response = requests.post(OLLAMA_API_URL, json=payload, timeout=90)\\n        response.raise_for_status()\\n        return response.json()['response']\\n    except Exception as e:\\n        return f'[bold red]Ollama Error:[/] {e}'\\n\\n\\ndef extract_code(text: str) ->List[tuple[str, str]]:\\n    matches = re.findall('```(\\\\\\\\w*)\\\\\\\\n([\\\\\\\\s\\\\\\\\S]*?)```', text)\\n    return [(lang or 'text', code.strip()) for lang, code in matches\\n        ] if matches else []\\n\\n\\ndef list_models(args: list=None) ->None:\\n    if current_backend == 'ollama':\\n        print('[bold cyan]Popular Ollama Models:[/]')\\n        for name, model_id in OLLAMA_MODELS.items():\\n            print(\\n                f\\\"{'\\u2b50' if model_id == current_model else '  '} [yellow]{name:12}[/] \\u2192 {model_id}\\\"\\n                )\\n    elif current_backend == 'openrouter':\\n        list_openrouter_models(args or [])\\n\\n\\ndef list_openrouter_models(args: list):\\n    try:\\n        from simple_term_menu import TerminalMenu\\n    except ImportError:\\n        ui_manager.show_error(\\n            \\\"'simple-term-menu' is required. `pip install simple-term-menu`\\\")\\n        return\\n    try:\\n        with ui_manager.show_spinner('Fetching models...'):\\n            response = requests.get(OPENROUTER_MODELS_API_URL)\\n            response.raise_for_status()\\n        api_models_data = response.json().get('data', [])\\n    except requests.RequestException as e:\\n        ui_manager.show_error(f'Error fetching models: {e}')\\n        return\\n    all_models, sources = [], set()\\n    for model_data in api_models_data:\\n        if (model_id := model_data.get('id')):\\n            sources.add(model_id.split('/')[0])\\n            pricing = model_data.get('pricing', {})\\n            is_free = pricing.get('prompt') == '0' and pricing.get('completion'\\n                ) == '0'\\n            all_models.append({'id': model_id, 'name': model_data.get(\\n                'name'), 'source': model_id.split('/')[0], 'is_free': is_free})\\n    all_models.sort(key=lambda x: (x['source'], x['name']))\\n    if args and args[0].lower() == 'sources':\\n        print('[bold cyan]Available Model Sources:[/]')\\n        [print(f'  [yellow]{s}[/]') for s in sorted(list(sources))]\\n        return\\n    models_to_display, title = all_models, 'Select an OpenRouter Model'\\n    if args:\\n        filter_keyword = args[0].lower()\\n        title = f\\\"Select a Model from '{filter_keyword}'\\\"\\n        models_to_display = [m for m in all_models if filter_keyword in m[\\n            'source'].lower()]\\n        if not models_to_display:\\n            ui_manager.show_error(f\\\"No models for source: '{filter_keyword}'\\\")\\n            return\\n    menu_entries = [\\n        f\\\"{'\\u2b50' if m['id'] == current_model else '  '} {m['name']} [dim]({m['id']}){' [green](FREE)[/]' if m['is_free'] else ''}[/dim]\\\"\\n         for m in models_to_display]\\n    try:\\n        cursor_idx = next((i for i, m in enumerate(models_to_display) if m[\\n            'id'] == current_model), 0)\\n        chosen_index = TerminalMenu(menu_entries, title=f'{title}',\\n            cursor_index=cursor_idx, cycle_cursor=True, clear_screen=True\\n            ).show()\\n        if chosen_index is not None:\\n            set_model(models_to_display[chosen_index]['id'])\\n        else:\\n            print('Model selection cancelled.')\\n    except Exception as e:\\n        ui_manager.show_error(f'Menu display error: {e}')\\n\\n\\ndef set_model(model_id: str) ->None:\\n    global current_model\\n    current_model = model_id\\n    ui_manager.show_success(f'Model set to: {current_model}')\\n\\n\\ndef switch_backend(backend_name: str) ->None:\\n    global current_backend, current_model\\n    backend_name = backend_name.lower()\\n    if backend_name not in ['ollama', 'openrouter']:\\n        ui_manager.show_error(f'Unknown backend: {backend_name}')\\n        return\\n    current_backend = backend_name\\n    current_model = (OLLAMA_MODEL if backend_name == 'ollama' else\\n        OPENROUTER_MODEL)\\n    ui_manager.show_success(\\n        f'Switched to {backend_name} backend with model: {current_model}')\\n    if backend_name == 'ollama':\\n        start_ollama_server()\\n\\n\\ndef generate_project_manifest(path: str) ->tuple[str, List[str]]:\\n    manifest = ''\\n    file_paths = []\\n    tree = Tree(f'[bold cyan]Project: {os.path.basename(path)}[/]')\\n    exclude_dirs = {'__pycache__', '.git', 'venv', 'node_modules', '.idea'}\\n    for root, dirs, files in os.walk(path):\\n        dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.\\n            startswith('.')]\\n        relative_path = os.path.relpath(root, path)\\n        branch = tree\\n        if relative_path != '.':\\n            parts = relative_path.split(os.sep)\\n            for part in parts:\\n                child = next((c for c in branch.children if c.label ==\\n                    f'[magenta]{part}[/]'), None)\\n                if not child:\\n                    child = branch.add(f'[magenta]{part}[/]')\\n                branch = child\\n        for fname in sorted(files):\\n            ext = os.path.splitext(fname)[1]\\n            if ext not in ('.py', '.js', '.html', '.css', '.md', '.txt'):\\n                continue\\n            rel_path = os.path.join(relative_path, fname\\n                ) if relative_path != '.' else fname\\n            file_paths.append(rel_path)\\n            branch.add(f'[green]{fname}[/]' if ext == '.py' else\\n                f'[dim]{fname}[/]')\\n            manifest += f'File: {rel_path}\\\\n\\\\n'\\n    console.print(tree)\\n    return manifest.strip(), file_paths\\n\\n\\ndef look_command(path: str) ->None:\\n    \\\"\\\"\\\"\\n    Scans a directory or file and loads it into memory. It can resolve paths\\n    relative to the current working directory or the project root in memory.\\n    If a new directory is scanned, the previous 'look' context is cleared\\n    to ensure the context remains relevant.\\n    \\\"\\\"\\\"\\n    resolved_path = resolve_file_path(path)\\n    if not resolved_path:\\n        ui_manager.show_error(f'\\u274c Path not found: {path}')\\n        return\\n    if resolved_path != os.path.abspath(path):\\n        ui_manager.show_success(\\n            f\\\"Found '{path}' in project. Using: {resolved_path}\\\")\\n    if os.path.isdir(resolved_path):\\n        ui_manager.show_success(\\n            \\\"New project directory detected. Clearing previous 'look' context.\\\"\\n            )\\n        memory_manager.memory['look'] = []\\n        with ui_manager.show_spinner('Generating project manifest...'):\\n            manifest = generate_project_manifest(resolved_path)\\n        memory_manager.add_look_data(resolved_path, manifest)\\n        ui_manager.show_success('\\u2705 Project manifest added to memory.')\\n    else:\\n        try:\\n            with ui_manager.show_spinner('Loading file...'):\\n                with open(resolved_path, 'r', encoding='utf-8') as f:\\n                    content = f.read().strip()\\n            for item in memory_manager.memory['look']:\\n                if item.get('file') == resolved_path:\\n                    item['content'] = content\\n                    memory_manager.save_memory()\\n                    ui_manager.show_success(\\n                        '\\u2705 Refreshed file content in memory.')\\n                    return\\n            memory_manager.add_look_data(resolved_path, content)\\n            ui_manager.show_success('\\u2705 File content added to memory.')\\n        except Exception as e:\\n            ui_manager.show_error(f'\\u274c Error reading file: {e}')\\n\\n\\ndef resolve_file_path(path: str) ->Optional[str]:\\n    \\\"\\\"\\\"Resolves a file path, checking CWD first, then against project root in memory.\\\"\\\"\\\"\\n    if os.path.exists(path):\\n        return os.path.abspath(path)\\n    project_root = memory_manager.get_project_root()\\n    if project_root:\\n        full_path = os.path.join(project_root, path)\\n        if os.path.exists(full_path):\\n            return full_path\\n    return None\\n\\n\\ndef _create_prompt_for_file_creation(file_name: str, instruction: str) ->str:\\n    \\\"\\\"\\\"\\n    Generate a robust prompt for file creation that instructs the AI to act as an expert,\\n    produce complete and clean code, and avoid any extra commentary.\\n    \\\"\\\"\\\"\\n    return f\\\"\\\"\\\"You are an expert programmer tasked with creating a new file. Your goal is to generate complete, production-ready content based on the user's instruction.\\n\\nIMPORTANT RULES:\\n- Provide ONLY the raw file content - no explanations, notes, or commentary outside the file itself\\n- Include all necessary imports, boilerplate, and complete implementations\\n- If creating code, ensure it's syntactically correct and follows best practices\\n- For configuration files, use appropriate formatting (JSON, YAML, etc.)\\n- For documentation files, use proper markdown formatting\\n\\nFile to create: {file_name}\\nUser instruction: {instruction}\\n\\nGenerate the complete file content now:\\\"\\\"\\\"\\n\\n\\ndef handle_file_create_command(file_path: str, instruction: str):\\n    \\\"\\\"\\\"\\n    Uses the LLM to generate content for a new file based on an instruction.\\n    \\\"\\\"\\\"\\n    global last_code\\n    if os.path.exists(file_path):\\n        if ui_manager.get_user_input(\\n            f\\\"File '{file_path}' already exists. Overwrite? (y/n): \\\").lower(\\n            ) not in ['yes', 'y']:\\n            ui_manager.show_error('File creation cancelled.')\\n            return\\n    prompt = _create_prompt_for_file_creation(os.path.basename(file_path),\\n        instruction)\\n    with ui_manager.show_spinner(\\n        f\\\"AI is generating content for '{file_path}'...\\\"):\\n        response = query_llm(prompt)\\n    code_blocks = extract_code(response)\\n    if code_blocks:\\n        new_content = code_blocks[0][1]\\n    else:\\n        new_content = response.strip()\\n    if not new_content:\\n        ui_manager.show_error('AI did not return any content.')\\n        print(Panel(response, title=\\\"[yellow]AI's Raw Response[/]\\\"))\\n        return\\n    print(Panel(new_content, title=\\n        f'[bold yellow]Proposed content for {file_path}[/]', border_style=\\n        'yellow'))\\n    if ui_manager.get_user_input('Create this file? (y/n): ').lower() in ['yes'\\n        , 'y']:\\n        try:\\n            FileCreator.create(file_path, new_content)\\n            last_code = new_content\\n            ui_manager.show_success(f'File created successfully: {file_path}')\\n        except IOError as e:\\n            ui_manager.show_error(f'Error creating file: {e}')\\n    else:\\n        ui_manager.show_error('File creation cancelled.')\\n\\n\\ndef look_all_command() ->None:\\n    \\\"\\\"\\\"\\n    Finds the project manifest in memory, reads every file listed, and adds their content to memory.\\n    \\\"\\\"\\\"\\n    project_root = memory_manager.get_project_root()\\n    if not project_root:\\n        ui_manager.show_error(\\n            \\\"No project context in memory. Use 'look <directory>' first to generate a manifest.\\\"\\n            )\\n        return\\n    manifest_data = None\\n    for item in memory_manager.memory.get('look', []):\\n        if item.get('file') == project_root and item.get('type'\\n            ) == 'directory':\\n            manifest_data = item.get('content')\\n            break\\n    if not manifest_data or not isinstance(manifest_data, (list, tuple)\\n        ) or len(manifest_data) != 2:\\n        ui_manager.show_error(\\n            \\\"Could not find a valid project manifest in memory. Please run 'look <directory>' again.\\\"\\n            )\\n        return\\n    file_paths = manifest_data[1]\\n    if not file_paths:\\n        ui_manager.show_error('No files found in the project manifest.')\\n        return\\n    total_files = len(file_paths)\\n    loaded_count = 0\\n    with ui_manager.show_spinner(\\n        f'Loading {total_files} files from project manifest...'):\\n        for file_path_relative in file_paths:\\n            full_path = os.path.join(project_root, file_path_relative)\\n            if os.path.isfile(full_path):\\n                try:\\n                    with open(full_path, 'r', encoding='utf-8') as f:\\n                        content = f.read().strip()\\n                    if not any(look['file'] == full_path for look in\\n                        memory_manager.memory['look']):\\n                        memory_manager.add_look_data(full_path, content)\\n                        loaded_count += 1\\n                except Exception as e:\\n                    print(\\n                        f\\\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\\\"\\n                        )\\n    ui_manager.show_success(\\n        f'\\u2705 Loaded content for {loaded_count} new files into memory.')\\n\\n\\ndef _load_all_project_files_if_needed():\\n    \\\"\\\"\\\"\\n    Checks if a project is loaded and automatically loads any files from its\\n    manifest that are not already in the 'look' memory. This ensures a\\n    complete context for editing and refactoring commands.\\n    \\\"\\\"\\\"\\n    project_root = memory_manager.get_project_root()\\n    if not project_root:\\n        return\\n    manifest_content = None\\n    for item in memory_manager.memory.get('look', []):\\n        if item.get('file') == project_root and 'File:' in item.get('content',\\n            ''):\\n            manifest_content = item['content']\\n            break\\n    if not manifest_content:\\n        return\\n    existing_file_paths = {item['file'] for item in memory_manager.memory.\\n        get('look', []) if item.get('type') == 'file'}\\n    file_paths_relative = re.findall('File: (.*)', manifest_content)\\n    files_to_load = []\\n    for rel_path in file_paths_relative:\\n        full_path = os.path.join(project_root, rel_path)\\n        if full_path not in existing_file_paths and os.path.isfile(full_path):\\n            files_to_load.append((full_path, rel_path))\\n    if not files_to_load:\\n        return\\n    loaded_count = 0\\n    with ui_manager.show_spinner(\\n        f'Auto-loading {len(files_to_load)} project files for context...'):\\n        for full_path, file_path_relative in files_to_load:\\n            try:\\n                with open(full_path, 'r', encoding='utf-8') as f:\\n                    content = f.read().strip()\\n                memory_manager.add_look_data(full_path, content)\\n                loaded_count += 1\\n            except Exception as e:\\n                print(f\\\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\\\")\\n    if loaded_count > 0:\\n        ui_manager.show_success(\\n            f'\\u2705 Loaded {loaded_count} new file(s) into memory for full project context.'\\n            )\\n\\n\\ndef _create_prompt_for_element_selection(file_name: str, instruction: str,\\n    elements: List[str], element_structures: Dict[str, Dict]) ->str:\\n    \\\"\\\"\\\"\\n    Create a helper for the first stage of the 'edit' command. This prompt asks the AI\\n    to analyze the user's instruction and intelligently select the most relevant code element to modify.\\n    \\\"\\\"\\\"\\n    element_details = []\\n    for elem in elements:\\n        if elem in element_structures:\\n            struct = element_structures[elem]\\n            detail = (\\n                f\\\"{elem} ({struct['type']}, lines {struct['line_start']}-{struct['line_end']})\\\"\\n                )\\n            element_details.append(detail)\\n        else:\\n            element_details.append(elem)\\n    return f\\\"\\\"\\\"You are an expert code analyzer. Your task is to identify what should be modified based on the user's instruction.\\n\\nFile: {file_name}\\nAvailable elements: {', '.join(element_details) if element_details else 'None'}\\n\\nUser instruction: {instruction}\\n\\nRESPONSE FORMAT:\\nChoose one of these response types:\\n1. \\\"ELEMENT: <element_name>\\\" - to edit an entire function/class\\n2. \\\"PARTIAL: <element_name> LINES: <start>-<end>\\\" - to edit specific lines within an element\\n3. \\\"FILE\\\" - to edit the entire file or multiple elements\\n\\nRULES:\\n- If the instruction mentions specific line numbers or a specific part of a function, use PARTIAL\\n- If the instruction targets an entire function/class, use ELEMENT\\n- If the instruction requires changes to multiple elements or file structure, use FILE\\n- For PARTIAL edits, provide absolute line numbers from the original file\\n\\nWhat should be edited?\\\"\\\"\\\"\\n\\n\\ndef _create_prompt_for_element_rewrite(file_name: str, element_name: str,\\n    instruction: str, original_code: str, is_full_file: bool=False) ->str:\\n    \\\"\\\"\\\"\\n    Create a helper for the second stage of the 'edit' command. This prompt instructs the AI\\n    to rewrite a specific code element (or the whole file) based on the user's request,\\n    demanding a complete and syntactically correct code block as output.\\n    \\\"\\\"\\\"\\n    if is_full_file:\\n        return f\\\"\\\"\\\"You are an expert programmer. Rewrite the entire file to accomplish the user's task.\\n\\nIMPORTANT RULES:\\n- Provide ONLY the complete, updated code for the entire file\\n- Ensure all syntax is correct and the code is ready to run\\n- Preserve existing functionality unless explicitly asked to change it\\n- Include all necessary imports and maintain the file's structure\\n- Do NOT include any explanations or comments outside the code\\n\\nFile: {file_name}\\nTask: {instruction}\\n\\nCurrent file content:\\n```python\\n{original_code}\\n```\\n\\nGenerate the complete updated file now:\\\"\\\"\\\"\\n    else:\\n        return f\\\"\\\"\\\"You are an expert programmer. Rewrite the specified element to accomplish the user's task.\\n\\nIMPORTANT RULES:\\n- Provide ONLY the complete, updated code for the element\\n- Include any necessary imports at the top of your code block\\n- Ensure the code is syntactically correct and maintains the same interface\\n- Do NOT include explanations or comments outside the code block\\n- The code must be a drop-in replacement for the original element\\n\\nFile: {file_name}\\nElement to modify: {element_name}\\nTask: {instruction}\\n\\nCurrent element code:\\n```python\\n{original_code}\\n```\\n\\nGenerate the complete updated element now:\\\"\\\"\\\"\\n\\n\\ndef _create_prompt_for_partial_edit(file_name: str, element_name: str,\\n    instruction: str, original_snippet: str, line_start: int, line_end: int,\\n    full_element_code: str) ->str:\\n    \\\"\\\"\\\"\\n    Create a prompt for partial edits within a function or class.\\n    This allows surgical changes to specific parts of code.\\n    \\\"\\\"\\\"\\n    return f\\\"\\\"\\\"You are an expert programmer. Make a surgical edit to a specific part of a function/class.\\n\\nCONTEXT:\\n- File: {file_name}\\n- Element: {element_name}\\n- Lines to modify: {line_start}-{line_end}\\n- Task: {instruction}\\n\\nIMPORTANT RULES:\\n- Provide ONLY the code that will replace lines {line_start}-{line_end}\\n- Your code must fit seamlessly into the existing function\\n- Maintain proper indentation (the code will be auto-indented)\\n- Do NOT include the function definition or other parts\\n- Do NOT include explanations outside the code\\n\\nFull element for context:\\n```python\\n{full_element_code}\\n```\\n\\nCode section to replace (lines {line_start}-{line_end}):\\n```python\\n{original_snippet}\\n```\\n\\nGenerate ONLY the replacement code for the specified lines:\\\"\\\"\\\"\\n\\n\\ndef handle_file_edit_command(file_path: str, instruction: str):\\n    \\\"\\\"\\\"\\n    Handles the entire workflow for editing a single file, ensuring full\\n    project context is loaded before the AI makes any decisions.\\n    Now supports partial edits within functions.\\n    \\\"\\\"\\\"\\n    global last_code\\n    _load_all_project_files_if_needed()\\n    resolved_path = resolve_file_path(file_path)\\n    if not resolved_path:\\n        ui_manager.show_error(f'File not found: {file_path}')\\n        return\\n    if resolved_path != os.path.abspath(file_path):\\n        ui_manager.show_success(\\n            f\\\"Found '{file_path}' in project. Using: {resolved_path}\\\")\\n    try:\\n        editor = CodeEditor(resolved_path)\\n    except (ValueError, FileNotFoundError) as e:\\n        ui_manager.show_error(str(e))\\n        return\\n    elements = editor.list_elements()\\n    element_structures = {}\\n    for elem in elements:\\n        struct = editor.get_element_structure(elem)\\n        if struct:\\n            element_structures[elem] = struct\\n    prompt1 = _create_prompt_for_element_selection(os.path.basename(\\n        resolved_path), instruction, elements, element_structures)\\n    with ui_manager.show_spinner('AI is analyzing file...'):\\n        ai_response = query_llm(prompt1).strip()\\n    if ai_response.upper() == 'FILE':\\n        ui_manager.show_success('AI has chosen to edit the entire file.')\\n        original_snippet = editor.source_code\\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\\n            resolved_path), 'entire file', instruction, original_snippet,\\n            is_full_file=True)\\n        edit_type = 'FILE'\\n        element_to_edit = None\\n        line_range = None\\n    elif ai_response.startswith('PARTIAL:'):\\n        parts = ai_response.split()\\n        element_to_edit = parts[1]\\n        if 'LINES:' in ai_response:\\n            line_part = ai_response.split('LINES:')[1].strip()\\n            if '-' in line_part:\\n                line_start, line_end = map(int, line_part.split('-'))\\n                line_range = line_start, line_end\\n            else:\\n                ui_manager.show_error('Invalid line range format')\\n                return\\n        else:\\n            ui_manager.show_error('Missing line range for partial edit')\\n            return\\n        if element_to_edit not in elements:\\n            ui_manager.show_error(f\\\"Element '{element_to_edit}' not found\\\")\\n            return\\n        ui_manager.show_success(\\n            f\\\"AI selected partial edit of '{element_to_edit}' (lines {line_start}-{line_end})\\\"\\n            )\\n        original_snippet = editor.get_element_body_snippet(element_to_edit,\\n            line_start, line_end)\\n        if not original_snippet:\\n            original_snippet = editor.get_source_of(element_to_edit)\\n        full_element_code = editor.get_source_of(element_to_edit)\\n        prompt2 = _create_prompt_for_partial_edit(os.path.basename(\\n            resolved_path), element_to_edit, instruction, original_snippet,\\n            line_start, line_end, full_element_code)\\n        edit_type = 'PARTIAL'\\n    elif ai_response.startswith('ELEMENT:'):\\n        element_to_edit = ai_response.split(':', 1)[1].strip()\\n        if element_to_edit not in elements:\\n            ui_manager.show_error(\\n                f\\\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\\\"\\n                )\\n            return\\n        ui_manager.show_success(f\\\"AI selected '{element_to_edit}' for editing.\\\"\\n            )\\n        original_snippet = editor.get_source_of(element_to_edit)\\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\\n            resolved_path), element_to_edit, instruction, original_snippet)\\n        edit_type = 'ELEMENT'\\n        line_range = None\\n    else:\\n        element_to_edit = ai_response.splitlines()[0]\\n        if element_to_edit not in elements:\\n            ui_manager.show_error(\\n                f\\\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\\\"\\n                )\\n            return\\n        ui_manager.show_success(f\\\"AI selected '{element_to_edit}' for editing.\\\"\\n            )\\n        original_snippet = editor.get_source_of(element_to_edit)\\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\\n            resolved_path), element_to_edit, instruction, original_snippet)\\n        edit_type = 'ELEMENT'\\n        line_range = None\\n    with ui_manager.show_spinner(f'AI is editing...'):\\n        response = query_llm(prompt2)\\n    code_blocks = extract_code(response)\\n    if not code_blocks:\\n        ui_manager.show_error('AI did not return a valid code block.')\\n        print(Panel(response, title=\\\"[yellow]AI's Raw Response[/]\\\"))\\n        return\\n    new_code = code_blocks[0][1]\\n    success = False\\n    if edit_type == 'FILE':\\n        try:\\n            editor.tree = ast.parse(new_code)\\n            success = True\\n        except SyntaxError as e:\\n            ui_manager.show_error(f'AI returned invalid Python syntax: {e}')\\n            print(Panel(response, title=\\\"[yellow]AI's Raw Response[/]\\\"))\\n            return\\n    elif edit_type == 'PARTIAL':\\n        success = editor.replace_partial(element_to_edit, new_code,\\n            line_start=line_range[0], line_end=line_range[1])\\n        if not success:\\n            ui_manager.show_error('Failed to apply partial edit.')\\n            print(Panel(response, title=\\\"[yellow]AI's Raw Response[/]\\\"))\\n            return\\n    else:\\n        success = editor.replace_element(element_to_edit, new_code)\\n        if not success:\\n            ui_manager.show_error(\\n                'AI returned invalid code; could not be parsed or applied.')\\n            print(Panel(response, title=\\\"[yellow]AI's Raw Response[/]\\\"))\\n            return\\n    if not (diff := editor.get_diff()):\\n        ui_manager.show_success('AI made no changes.')\\n        return\\n    print(Panel(diff, title=\\n        f'[bold yellow]Proposed Changes for {resolved_path}[/]'))\\n    if ui_manager.get_user_input('Apply changes? (y/n): ').lower() in ['yes',\\n        'y']:\\n        editor.save_changes()\\n        last_code = editor.get_modified_source()\\n        ui_manager.show_success(f'Changes saved to {resolved_path}.')\\n    else:\\n        ui_manager.show_error('Changes discarded.')\\n\\n\\ndef _create_prompt_for_refactor_plan(instruction: str, memory_context: str\\n    ) ->str:\\n    \\\"\\\"\\\"\\n    Create a specialized prompt-generation function for the 'refactor' command.\\n    This prompt will explicitly define the required JSON structure for the plan\\n    and instruct the AI to act as an expert project manager.\\n    \\\"\\\"\\\"\\n    return f\\\"\\\"\\\"You are an expert project manager and software architect. Analyze the project context and create a detailed refactoring plan.\\n\\nYour plan must be a valid JSON object with this exact structure:\\n{{\\n    \\\"actions\\\": [\\n        {{\\n            \\\"type\\\": \\\"MODIFY\\\" | \\\"CREATE\\\" | \\\"DELETE\\\" | \\\"PARTIAL\\\",\\n            \\\"file\\\": \\\"relative/path/to/file.py\\\",\\n            \\\"element\\\": \\\"function_or_class_name\\\",  // For MODIFY/DELETE/PARTIAL\\n            \\\"element_name\\\": \\\"new_element_name\\\",    // For CREATE\\n            \\\"line_start\\\": 10,                      // For PARTIAL only\\n            \\\"line_end\\\": 20,                        // For PARTIAL only\\n            \\\"reason\\\": \\\"Clear explanation of why this change is needed\\\",\\n            \\\"description\\\": \\\"What this action will accomplish\\\",\\n            \\\"anchor_element\\\": \\\"optional_anchor\\\",   // Optional for CREATE\\n            \\\"position\\\": \\\"before\\\" | \\\"after\\\"         // Optional for CREATE\\n        }}\\n    ]\\n}}\\n\\nACTION TYPES:\\n- MODIFY: Change an entire function, class, or method\\n- PARTIAL: Change specific lines within a function/class (requires line_start and line_end)\\n- CREATE: Add new functions, classes, or files\\n- DELETE: Remove functions, classes, variables, or imports\\n\\nRULES FOR YOUR PLAN:\\n- Use PARTIAL when you only need to change a small part of a function\\n- Use MODIFY when restructuring an entire function or class\\n- Each action must have all required fields based on its type\\n- File paths must be relative to the project root\\n- Be specific and surgical - avoid unnecessary changes\\n- Consider dependencies between changes\\n- Order actions logically (e.g., create dependencies before using them)\\n\\n### Project Context ###\\n{memory_context}\\n\\n### Refactoring Request ###\\n{instruction}\\n\\nGenerate ONLY the JSON plan - no explanations or markdown:\\\"\\\"\\\"\\n\\n\\ndef _get_refactor_plan(instruction: str) ->Optional[List[Dict]]:\\n    \\\"\\\"\\\"\\n    Generates a refactoring plan from the LLM.\\n\\n    This function encapsulates the logic for checking project context,\\n    constructing a prompt, querying the LLM, and parsing the resulting\\n    JSON plan for a refactoring task.\\n\\n    Args:\\n        instruction: The user's high-level refactoring instruction.\\n\\n    Returns:\\n        A list of action dictionaries if a valid plan is generated,\\n        otherwise None.\\n    \\\"\\\"\\\"\\n    if not memory_manager.get_project_root():\\n        ui_manager.show_error(\\n            \\\"No project context in memory. Use 'look <directory>' first.\\\")\\n        return None\\n    memory_context = memory_manager.get_memory_context()\\n    plan_prompt = _create_prompt_for_refactor_plan(instruction, memory_context)\\n    with ui_manager.show_spinner('AI is creating an execution plan...'):\\n        plan_str = query_llm(plan_prompt)\\n    try:\\n        match = re.search('\\\\\\\\{.*\\\\\\\\}', plan_str, re.DOTALL)\\n        if not match:\\n            raise ValueError('No JSON object found in the response.')\\n        plan = json.loads(match.group(0))\\n        actions = plan.get('actions', [])\\n        if not actions:\\n            raise ValueError(\\\"No 'actions' key found in plan or plan is empty.\\\"\\n                )\\n        return actions\\n    except (json.JSONDecodeError, ValueError) as e:\\n        ui_manager.show_error(f'AI failed to generate a valid plan: {e}')\\n        print(Panel(plan_str, title=\\\"[yellow]AI's Invalid Plan Response[/]\\\",\\n            border_style='yellow'))\\n        return None\\n\\n\\ndef _display_and_confirm_plan(plan: Dict) ->bool:\\n    \\\"\\\"\\\"\\n    Displays the generated execution plan to the user and asks for confirmation.\\n\\n    This helper function separates the UI interaction of plan confirmation from\\n    the main refactoring logic.\\n\\n    Args:\\n        plan: A dictionary, expected to contain an 'actions' key with a list of action dicts.\\n\\n    Returns:\\n        True if the user confirms the plan, False otherwise.\\n    \\\"\\\"\\\"\\n    actions = plan.get('actions', [])\\n    if not actions:\\n        ui_manager.show_error('The generated plan is empty. Aborting.')\\n        return False\\n    ui_manager.show_success('AI has created a plan:')\\n    for i, action in enumerate(actions):\\n        action_type = action.get('type', 'N/A')\\n        element = action.get('element') or action.get('element_name', 'N/A')\\n        reason = action.get('reason') or action.get('description', '')\\n        file_path = action.get('file', '')\\n        if action_type == 'PARTIAL':\\n            line_start = action.get('line_start', '?')\\n            line_end = action.get('line_end', '?')\\n            print(\\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} (lines {line_start}-{line_end}) - {reason}'\\n                )\\n        else:\\n            print(\\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} - {reason}'\\n                )\\n    if ui_manager.get_user_input('\\\\nProceed with this plan? (y/n): ').lower(\\n        ) in ['yes', 'y']:\\n        return True\\n    else:\\n        ui_manager.show_error('Execution aborted by user.')\\n        return False\\n\\n\\ndef _apply_refactor_changes(editors: Dict[str, CodeEditor]) ->None:\\n    \\\"\\\"\\\"\\n    Consolidates changes from multiple CodeEditor instances, shows a unified\\n    diff, and prompts the user to apply them.\\n    \\n    This helper function abstracts the final step of a refactor, ensuring\\n    all proposed modifications are presented to the user for a final review\\n    before any files are written to disk.\\n\\n    Args:\\n        editors: A dictionary mapping absolute file paths to their\\n                 corresponding CodeEditor instances which hold the\\n                 proposed changes in their AST.\\n    \\\"\\\"\\\"\\n    full_diff = ''\\n    for editor in editors.values():\\n        diff = editor.get_diff()\\n        if diff:\\n            full_diff += diff + '\\\\n'\\n    if not full_diff.strip():\\n        ui_manager.show_success('AI made no changes.')\\n        return\\n    print(Panel(full_diff, title=\\n        '[bold yellow]Proposed Project-Wide Changes[/]'))\\n    if ui_manager.get_user_input('Apply all changes? (y/n): ').lower() in [\\n        'yes', 'y']:\\n        for editor in editors.values():\\n            editor.save_changes()\\n        ui_manager.show_success('\\u2705 Project changes applied successfully.')\\n    else:\\n        ui_manager.show_error('Changes discarded.')\\n\\n\\ndef _create_prompt_for_refactor_action(action_type: str, file_path: str,\\n    action_details: Dict) ->str:\\n    \\\"\\\"\\\"\\n    Create a helper to generate prompts for individual 'CREATE' or 'MODIFY' steps\\n    within a refactor plan. This ensures the AI produces code for the specific\\n    sub-task in the correct context.\\n    \\\"\\\"\\\"\\n    if action_type == 'MODIFY':\\n        element_name = action_details['element_name']\\n        reason = action_details['reason']\\n        original_code = action_details['original_code']\\n        return f\\\"\\\"\\\"You are implementing a specific refactoring task as part of a larger plan.\\n\\nREFACTORING CONTEXT:\\n- File: {file_path}\\n- Element: {element_name}\\n- Reason for change: {reason}\\n\\nRULES:\\n- Provide ONLY the complete updated code for the element\\n- Include any necessary imports at the top\\n- Ensure the code integrates properly with the rest of the file\\n- Maintain the same function/class signature unless the change requires otherwise\\n- No explanations outside the code block\\n\\nCurrent element code:\\n```python\\n{original_code}\\n```\\n\\nGenerate the updated element code:\\\"\\\"\\\"\\n    elif action_type == 'CREATE':\\n        element_name = action_details['element_name']\\n        description = action_details['description']\\n        return f\\\"\\\"\\\"You are implementing a specific refactoring task as part of a larger plan.\\n\\nREFACTORING CONTEXT:\\n- File: {file_path}\\n- New element to create: {element_name}\\n- Purpose: {description}\\n\\nRULES:\\n- Provide ONLY the complete code for the new element\\n- Include all necessary imports at the top\\n- Follow the coding style and patterns used in the project\\n- Ensure the code is production-ready and well-structured\\n- For non-Python files, provide the complete file content\\n- No explanations outside the code block\\n\\nGenerate the new element code:\\\"\\\"\\\"\\n\\n\\ndef _process_refactor_action(action: Dict, project_base_path: str, editors:\\n    Dict) ->bool:\\n    \\\"\\\"\\\"\\n    Processes a single refactoring action from the plan.\\n\\n    This function handles the execution of a single action from the refactoring plan,\\n    including LLM code generation and applying changes to in-memory editors or files.\\n\\n    Args:\\n        action: A dictionary containing action details (type, file, element, etc.)\\n        project_base_path: The absolute path to the project root\\n        editors: Dictionary mapping file paths to their CodeEditor instances\\n\\n    Returns:\\n        True if the action was processed successfully, False otherwise\\n    \\\"\\\"\\\"\\n    file_path_relative = action.get('file')\\n    if not file_path_relative:\\n        ui_manager.show_error(\\n            f\\\"Action is missing 'file' key. Skipping: {action}\\\")\\n        return False\\n    file_path_absolute = os.path.join(project_base_path, file_path_relative)\\n    action_type = action.get('type', '').upper()\\n    prompt, element_name = '', ''\\n    if action_type == 'MODIFY':\\n        element_name = action.get('element')\\n        reason = action.get('reason')\\n        if file_path_relative.endswith('.py'):\\n            if file_path_absolute not in editors:\\n                try:\\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\\n                        )\\n                except Exception as e:\\n                    ui_manager.show_error(\\n                        f'Error loading file {file_path_absolute}: {e}')\\n                    return False\\n            editor = editors[file_path_absolute]\\n            original_snippet = editor.get_source_of(element_name)\\n            if not original_snippet:\\n                ui_manager.show_error(\\n                    f\\\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\\\"\\n                    )\\n                return False\\n            action_details = {'element_name': element_name, 'reason':\\n                reason, 'original_code': original_snippet}\\n            prompt = _create_prompt_for_refactor_action('MODIFY',\\n                file_path_relative, action_details)\\n    elif action_type == 'PARTIAL':\\n        element_name = action.get('element')\\n        reason = action.get('reason')\\n        line_start = action.get('line_start')\\n        line_end = action.get('line_end')\\n        if not all([element_name, line_start, line_end]):\\n            ui_manager.show_error(\\n                f'PARTIAL action missing required fields. Skipping: {action}')\\n            return False\\n        if file_path_relative.endswith('.py'):\\n            if file_path_absolute not in editors:\\n                try:\\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\\n                        )\\n                except Exception as e:\\n                    ui_manager.show_error(\\n                        f'Error loading file {file_path_absolute}: {e}')\\n                    return False\\n            editor = editors[file_path_absolute]\\n            original_snippet = editor.get_element_body_snippet(element_name,\\n                line_start, line_end)\\n            if not original_snippet:\\n                original_snippet = editor.get_source_of(element_name)\\n                if not original_snippet:\\n                    ui_manager.show_error(\\n                        f\\\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\\\"\\n                        )\\n                    return False\\n            full_element_code = editor.get_source_of(element_name)\\n            prompt = _create_prompt_for_partial_edit(file_path_relative,\\n                element_name, reason, original_snippet, line_start,\\n                line_end, full_element_code)\\n    elif action_type == 'CREATE':\\n        element_name = action.get('element_name')\\n        description = action.get('description')\\n        action_details = {'element_name': element_name, 'description':\\n            description}\\n        prompt = _create_prompt_for_refactor_action('CREATE',\\n            file_path_relative, action_details)\\n    else:\\n        ui_manager.show_error(f\\\"Invalid action type '{action_type}'. Skipping.\\\"\\n            )\\n        return False\\n    with ui_manager.show_spinner(\\n        f\\\"AI: {action_type} on '{element_name or file_path_relative}'...\\\"):\\n        response = query_llm(prompt)\\n    code_blocks = extract_code(response)\\n    new_content = code_blocks[0][1] if code_blocks else response.strip()\\n    if not new_content:\\n        ui_manager.show_error(\\n            f'AI failed to generate content for action: {action}')\\n        print(Panel(response, title=\\\"[yellow]AI's Raw Response[/]\\\"))\\n        return False\\n    if not file_path_relative.endswith('.py'):\\n        try:\\n            FileCreator.create(file_path_absolute, new_content)\\n            ui_manager.show_success(\\n                f\\\"File '{file_path_relative}' created/updated.\\\")\\n            return True\\n        except IOError as e:\\n            ui_manager.show_error(\\n                f\\\"Failed to create file '{file_path_relative}': {e}\\\")\\n            return False\\n    if file_path_absolute not in editors:\\n        try:\\n            if not os.path.exists(file_path_absolute):\\n                os.makedirs(os.path.dirname(file_path_absolute), exist_ok=True)\\n                with open(file_path_absolute, 'w') as f:\\n                    f.write('')\\n            editors[file_path_absolute] = CodeEditor(file_path_absolute)\\n        except Exception as e:\\n            ui_manager.show_error(\\n                f'Error loading file {file_path_absolute}: {e}')\\n            return False\\n    editor = editors[file_path_absolute]\\n    if action_type == 'MODIFY':\\n        if not editor.replace_element(element_name, new_content):\\n            ui_manager.show_error(\\n                f\\\"Failed to apply MODIFY change to '{element_name}'.\\\")\\n            print(Panel(new_content, title=\\n                f\\\"[red]Problematic MODIFY Code for '{element_name}'[/]\\\",\\n                border_style='red'))\\n            return False\\n    elif action_type == 'PARTIAL':\\n        if not editor.replace_partial(element_name, new_content, line_start,\\n            line_end):\\n            ui_manager.show_error(\\n                f\\\"Failed to apply PARTIAL change to '{element_name}'.\\\")\\n            print(Panel(new_content, title=\\n                f\\\"[red]Problematic PARTIAL Code for '{element_name}'[/]\\\",\\n                border_style='red'))\\n            return False\\n    elif action_type == 'CREATE':\\n        anchor = action.get('anchor_element')\\n        position = action.get('position', 'after')\\n        if not editor.add_element(new_content, anchor_name=anchor, before=\\n            position == 'before'):\\n            ui_manager.show_error(\\n                f\\\"Failed to apply CREATE change for '{element_name}'.\\\")\\n            print(Panel(new_content, title=\\n                f\\\"[red]Problematic CREATE Code for '{element_name}'[/]\\\",\\n                border_style='red'))\\n            return False\\n    return True\\n\\n\\ndef handle_project_refactor_command(instruction: str):\\n    \\\"\\\"\\\"\\n    Orchestrates a multi-file, multi-step code refactoring process.\\n    \\n    This function serves as a high-level orchestrator that delegates specific tasks\\n    to helper functions, improving readability, modularity, and maintainability.\\n    \\\"\\\"\\\"\\n    _load_all_project_files_if_needed()\\n    actions = _get_refactor_plan(instruction)\\n    if not actions:\\n        return\\n    plan = {'actions': actions}\\n    if not _display_and_confirm_plan(plan):\\n        return\\n    editors: Dict[str, CodeEditor] = {}\\n    project_base_path = memory_manager.get_project_root()\\n    successful_actions = 0\\n    total_actions = len(actions)\\n    for i, action in enumerate(actions, 1):\\n        ui_manager.show_success(f'Processing action {i}/{total_actions}...')\\n        action_type = action.get('type', '').upper()\\n        file_path_relative = action.get('file')\\n        if not file_path_relative:\\n            ui_manager.show_error(\\n                f\\\"Action is missing 'file' key. Skipping: {action}\\\")\\n            continue\\n        file_path_absolute = os.path.join(project_base_path, file_path_relative\\n            )\\n        if action_type == 'DELETE':\\n            element_name = action.get('element')\\n            if not element_name:\\n                ui_manager.show_error(\\n                    f\\\"DELETE action missing 'element' key. Skipping: {action}\\\")\\n                continue\\n            if not file_path_relative.endswith('.py'):\\n                ui_manager.show_error(\\n                    f'DELETE actions are only supported for Python files. Skipping.'\\n                    )\\n                continue\\n            if file_path_absolute not in editors:\\n                try:\\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\\n                        )\\n                except Exception as e:\\n                    ui_manager.show_error(\\n                        f'Error loading file {file_path_absolute}: {e}')\\n                    continue\\n            editor = editors[file_path_absolute]\\n            if editor.delete_element(element_name):\\n                successful_actions += 1\\n                ui_manager.show_success(\\n                    f\\\"Successfully deleted '{element_name}' from '{file_path_relative}'.\\\"\\n                    )\\n            else:\\n                ui_manager.show_error(\\n                    f\\\"Failed to delete '{element_name}' from '{file_path_relative}'.\\\"\\n                    )\\n        elif _process_refactor_action(action, project_base_path, editors):\\n            successful_actions += 1\\n        else:\\n            ui_manager.show_error(\\n                f'Action {i} failed, continuing with remaining actions...')\\n    if successful_actions == 0:\\n        ui_manager.show_error('No actions were successfully executed.')\\n        return\\n    elif successful_actions < total_actions:\\n        ui_manager.show_error(\\n            f'Only {successful_actions}/{total_actions} actions completed successfully.'\\n            )\\n    else:\\n        ui_manager.show_success(\\n            f'All {total_actions} actions completed successfully.')\\n    _apply_refactor_changes(editors)\\n\\n\\ndef _create_prompt_for_commit_message(diff: str) ->str:\\n    \\\"\\\"\\\"\\n    Create a dedicated prompt function for the 'commit' command. This prompt will\\n    instruct the AI to analyze a git diff and generate a concise commit message\\n    following the Conventional Commits standard.\\n    \\\"\\\"\\\"\\n    return f\\\"\\\"\\\"You are an expert developer writing a Git commit message. Your task is to analyze the provided git diff and create a professional commit message.\\n\\nCOMMIT MESSAGE RULES:\\n- Follow the Conventional Commits specification\\n- Format: <type>(<optional scope>): <subject>\\n- Types: feat, fix, docs, style, refactor, perf, test, build, ci, chore, revert\\n- Subject line: max 50 characters, imperative mood, no period\\n- Optional body: explain what and why (not how), wrap at 72 characters\\n- Be specific and concise\\n- Focus on the intent and impact of the changes\\n\\nEXAMPLES OF GOOD COMMIT MESSAGES:\\n- feat(auth): add OAuth2 integration for Google login\\n- fix(api): handle null response in user endpoint\\n- refactor(database): optimize query performance for large datasets\\n- docs(readme): update installation instructions for Windows\\n\\nRespond with ONLY the commit message - no markdown, quotes, or explanations.\\n\\n--- GIT DIFF TO ANALYZE ---\\n{diff}\\n\\nGenerate the commit message:\\\"\\\"\\\"\\n\\n\\ndef handle_commit_command():\\n    \\\"\\\"\\\"\\n    Orchestrates an AI-assisted Git commit workflow with improved error handling.\\n    \\\"\\\"\\\"\\n    project_root = memory_manager.get_project_root()\\n    if not project_root:\\n        ui_manager.show_error(\\n            \\\"No project context in memory. Use 'look <directory>' first.\\\")\\n        return\\n    try:\\n        git_manager = GitManager(project_root)\\n    except ValueError as e:\\n        ui_manager.show_error(str(e))\\n        return\\n    changed_files = git_manager.get_changed_files()\\n    if not changed_files:\\n        ui_manager.show_success(\\n            'No changes to commit. Everything is up to date.')\\n        return\\n    staged_diff = git_manager.get_diff(staged=True)\\n    unstaged_diff = git_manager.get_diff()\\n    full_diff = f'{staged_diff}\\\\n{unstaged_diff}'.strip()\\n    if not full_diff.strip():\\n        ui_manager.show_success(\\n            'No content changes detected (e.g., only file mode changes).')\\n        return\\n    prompt = _create_prompt_for_commit_message(full_diff)\\n    commit_message = query_llm(prompt).strip()\\n    if not commit_message:\\n        ui_manager.show_error(\\n            'AI failed to generate a commit message. Aborting.')\\n        return\\n    files_to_commit_str = '\\\\n'.join(f'- {f}' for f in changed_files)\\n    plan_panel_content = f\\\"\\\"\\\"[bold]Files to be staged:[/]\\n[yellow]{files_to_commit_str}[/]\\n\\n[bold]AI-Generated Commit Message:[/]\\n[green]{commit_message}[/]\\\"\\\"\\\"\\n    print(Panel(plan_panel_content, title='[bold cyan]Commit Plan[/]',\\n        border_style='cyan'))\\n    if ui_manager.get_user_input('\\\\nProceed with commit? (y/n): ').lower() in [\\n        'yes', 'y']:\\n        try:\\n            git_manager.add(changed_files)\\n            ui_manager.show_success('\\u2705 Files staged.')\\n        except subprocess.CalledProcessError as e:\\n            ui_manager.show_error(f'Staging failed: {e.stderr}')\\n            return\\n        try:\\n            git_manager.commit(commit_message)\\n            ui_manager.show_success('\\u2705 Commit successful.')\\n        except subprocess.CalledProcessError as e:\\n            ui_manager.show_error(f'Commit failed: {e.stderr}')\\n            return\\n        if ui_manager.get_user_input('Push changes to remote? (y/n): ').lower(\\n            ) in ['yes', 'y']:\\n            try:\\n                git_manager.push()\\n                ui_manager.show_success('\\u2705 Push successful.')\\n            except subprocess.CalledProcessError as e:\\n                ui_manager.show_error(f'Push failed: {e.stderr}')\\n        else:\\n            ui_manager.show_error('Push cancelled.')\\n    else:\\n        ui_manager.show_error('Commit aborted by user.')\\n\\n\\ndef handle_rag_query_command(query: str):\\n    \\\"\\\"\\\"\\n    Handles RAG query commands in the CLI.\\n    \\n    This function provides a way to query the RAG system from the command line interface.\\n    It loads the RAG manager, performs the query, and displays the results.\\n    \\n    Args:\\n        query: The query string to search for in the RAG system.\\n    \\\"\\\"\\\"\\n    try:\\n        rag_manager = RAGManager()\\n        if rag_manager.get_document_count() == 0:\\n            ui_manager.show_error('RAG index is empty. Add documents first.')\\n            return\\n        results = rag_manager.search(query, k=3)\\n        if not results:\\n            ui_manager.show_error('No relevant documents found.')\\n            return\\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\\n            border_style='cyan'))\\n        for i, (doc, score, metadata) in enumerate(results, 1):\\n            file_info = metadata.get('file', 'Unknown source')\\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\\n            result_panel = Panel(\\n                f\\\"\\\"\\\"[dim]Source:[/] {file_info}\\n[dim]Relevance:[/] {score:.4f}\\n\\n{content_preview}\\\"\\\"\\\"\\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\\n                expand=False)\\n            print(result_panel)\\n        if ui_manager.get_user_input(\\n            '\\\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\\n            'y']:\\n            context = '\\\\n\\\\n'.join([\\n                f'Document {i} (Score: {score:.4f}):\\\\n{doc}' for i, (doc,\\n                score, _) in enumerate(results, 1)])\\n            prompt = f\\\"\\\"\\\"Based on the following retrieved documents, please answer the query: \\\"{query}\\\"\\n\\nRetrieved Documents:\\n{context}\\n\\nPlease provide a comprehensive answer based only on the information in the documents above.\\nIf the documents don't contain enough information to answer the query, please say so.\\\"\\\"\\\"\\n            with ui_manager.show_spinner('AI is generating response...'):\\n                response = query_llm(prompt)\\n            print(Panel(response, title=\\n                '[bold green]AI-Generated Response[/bold green]',\\n                border_style='green'))\\n    except Exception as e:\\n        ui_manager.show_error(f'Error processing RAG query: {e}')\\n        if os.getenv('OMNIFORGE_DEBUG'):\\n            import traceback\\n            traceback.print_exc()\\n\\n\\ndef handle_rag_query_command(query: str):\\n    \\\"\\\"\\\"\\n    Handles RAG query commands in the CLI.\\n    \\n    This function provides a way to query the RAG system from the command line interface.\\n    It loads the RAG manager, performs the query, and displays the results.\\n    \\n    Args:\\n        query: The query string to search for in the RAG system.\\n    \\\"\\\"\\\"\\n    try:\\n        rag_manager = RAGManager()\\n        if rag_manager.get_document_count() == 0:\\n            ui_manager.show_error('RAG index is empty. Add documents first.')\\n            return\\n        results = rag_manager.search(query, k=3)\\n        if not results:\\n            ui_manager.show_error('No relevant documents found.')\\n            return\\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\\n            border_style='cyan'))\\n        for i, (doc, score, metadata) in enumerate(results, 1):\\n            file_info = metadata.get('file', 'Unknown source')\\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\\n            result_panel = Panel(\\n                f\\\"\\\"\\\"[dim]Source:[/] {file_info}\\n[dim]Relevance:[/] {score:.4f}\\n\\n{content_preview}\\\"\\\"\\\"\\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\\n                expand=False)\\n            print(result_panel)\\n        if ui_manager.get_user_input(\\n            '\\\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\\n            'y']:\\n            context = '\\\\n\\\\n'.join([\\n                f'Document {i} (Score: {score:.4f}):\\\\n{doc}' for i, (doc,\\n                score, _) in enumerate(results, 1)])\\n            prompt = f\\\"\\\"\\\"Based on the following retrieved documents, please answer the query: \\\"{query}\\\"\\n\\nRetrieved Documents:\\n{context}\\n\\nPlease provide a comprehensive answer based only on the information in the documents above.\\nIf the documents don't contain enough information to answer the query, please say so.\\\"\\\"\\\"\\n            with ui_manager.show_spinner('AI is generating response...'):\\n                response = query_llm(prompt)\\n            print(Panel(response, title=\\n                '[bold green]AI-Generated Response[/bold green]',\\n                border_style='green'))\\n    except Exception as e:\\n        ui_manager.show_error(f'Error processing RAG query: {e}')\\n        if os.getenv('OMNIFORGE_DEBUG'):\\n            import traceback\\n            traceback.print_exc()\\n\\n\\ndef interactive_mode() ->None:\\n    global last_query, last_response, last_code\\n    try:\\n        from Testing.overlay_engine import show_sequential_popup\\n        gui_available = True\\n    except ImportError:\\n        gui_available = False\\n    print(Panel(\\n        \\\"\\\"\\\"[bold cyan]Omni Interactive Mode[/]\\n[dim]Type 'help' for commands, 'exit' to quit.[/dim]\\\"\\\"\\\"\\n        , border_style='cyan'))\\n    personality_name = personality_manager.get_current_personality().get('name'\\n        , 'Default')\\n    gui_enabled = False\\n    if gui_available:\\n        try:\\n            with open(CONFIG_FILE, 'r') as f:\\n                config = json.load(f)\\n                if config.get('gui_enabled', False):\\n                    gui_enabled = True\\n        except (FileNotFoundError, json.JSONDecodeError):\\n            pass\\n    refresh_status_panel(personality_name)\\n    while True:\\n        try:\\n            user_input = ui_manager.get_user_input('\\\\n> ')\\n            if not user_input:\\n                continue\\n            command, *args = user_input.split(maxsplit=1)\\n            arg_str = args[0] if args else ''\\n            if command == 'exit':\\n                memory_manager.save_memory()\\n                print('[bold cyan]Goodbye![/]')\\n                break\\n            elif command == 'help':\\n                print(\\n                    \\\"\\\"\\\"[bold]Commands:[/]\\n\\n  [bold cyan]Core & Project Commands[/]\\n  [yellow]send <prompt>[/]        - Ask the LLM a question.\\n  [yellow]look <path>[/]          - Read file or scan directory into memory.\\n  [yellow]look_all[/]            - Recursively scan the project directory into memory.\\n  [yellow]create <file> \\\"instr\\\"[/] - Create a new file using AI.\\n  [yellow]edit <file> \\\"instr\\\"[/]   - Edit a specific file using AI.\\n  [yellow]refactor \\\"instr\\\"[/]      - Refactor project in memory based on instruction.\\n  [yellow]commit[/]               - Commit changes with an AI-generated message.\\n  [yellow]rag <query>[/]         - Query the RAG system for context retrieval.\\n\\n  [bold cyan]File & Code Management[/]\\n  [yellow]save <filename>[/]     - Save last AI response to a file.\\n  [yellow]list[/]               - List saved files.\\n  [yellow]run[/]                 - Run the last generated Python code.\\n\\n  [bold cyan]Session & Config[/]\\n  [yellow]history[/]             - Show the full chat history.\\n  [yellow]memory clear[/]        - Clear the chat and file memory.\\n  [yellow]backend <name>[/]      - Switch AI backend (e.g., openrouter, ollama).\\n  [yellow]models [src][/]        - Interactively list and select models.\\n  [yellow]set model <id>[/]      - Set the model directly by its ID.\\n  [yellow]personality <cmd>[/]   - Manage AI personalities ('list', 'set', 'add').\\n\\\"\\\"\\\"\\n                    )\\n            elif command == 'send':\\n                last_query = arg_str\\n                response = query_llm(arg_str)\\n                last_response = response\\n                if gui_enabled:\\n                    threading.Thread(target=show_sequential_popup, args=(\\n                        100, 100, response, f'Omni - {personality_name}'),\\n                        daemon=True).start()\\n                print(Panel(response, title='[cyan]Response[/]'))\\n                if (code_blocks := extract_code(response)):\\n                    last_code = code_blocks[0][1]\\n            elif command == 'look':\\n                look_command(arg_str)\\n            elif command == 'look_all':\\n                look_all_command()\\n            elif command == 'create':\\n                try:\\n                    file_path, instruction = arg_str.split(' ', 1)\\n                    handle_file_create_command(file_path.strip('\\\"'),\\n                        instruction.strip('\\\"'))\\n                except (ValueError, IndexError):\\n                    ui_manager.show_error(\\n                        'Usage: create <file_path> \\\"<instruction>\\\"')\\n            elif command == 'edit':\\n                try:\\n                    file_path, instruction = arg_str.split(' ', 1)\\n                    handle_file_edit_command(file_path.strip('\\\"'),\\n                        instruction.strip('\\\"'))\\n                except (ValueError, IndexError):\\n                    ui_manager.show_error(\\n                        'Usage: edit <file_path> \\\"<instruction>\\\"')\\n            elif command == 'refactor':\\n                if not arg_str:\\n                    ui_manager.show_error('Usage: refactor \\\"<instruction>\\\"')\\n                else:\\n                    handle_project_refactor_command(arg_str.strip('\\\"'))\\n            elif command == 'commit':\\n                handle_commit_command()\\n            elif command == 'models':\\n                list_models(arg_str.split())\\n            elif command == 'set' and arg_str.startswith('model '):\\n                set_model(arg_str[6:])\\n            elif command == 'backend':\\n                switch_backend(arg_str)\\n            elif command == 'history':\\n                ui_manager.display_history(memory_manager.get_memory_context())\\n            elif command == 'memory' and arg_str == 'clear':\\n                memory_manager.clear_memory()\\n                ui_manager.show_success('\\u2705 Memory cleared')\\n            elif command == 'personality':\\n                p_args = arg_str.split(maxsplit=1)\\n                cmd = p_args[0] if p_args else ''\\n                p_arg_str = p_args[1] if len(p_args) > 1 else ''\\n                if cmd == 'list':\\n                    for p in personality_manager.list_personalities():\\n                        print(f\\\"- {p['name']}: {p['description']}\\\")\\n                elif cmd == 'set' and p_arg_str:\\n                    if personality_manager.set_current_personality(p_arg_str):\\n                        personality_name = p_arg_str\\n                        ui_manager.show_success(\\n                            f'Set personality to {personality_name}')\\n                    else:\\n                        ui_manager.show_error('Personality not found.')\\n                else:\\n                    ui_manager.show_error(\\n                        \\\"Invalid personality command. Use 'list' or 'set <name>'.\\\"\\n                        )\\n            elif command == 'run':\\n                run_python_code()\\n            elif command == 'save':\\n                if last_response:\\n                    save_code(last_response, arg_str or\\n                        f\\\"omni_save_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\\\"\\n                        )\\n                else:\\n                    ui_manager.show_error('No response to save.')\\n            elif command == 'list':\\n                files = sorted(os.listdir(DEFAULT_SAVE_DIR))\\n                print('\\\\n'.join(f'  - {f}' for f in files) if files else\\n                    '[yellow]No saved files.[/]')\\n            elif command == 'rag':\\n                if not arg_str:\\n                    ui_manager.show_error('Usage: rag \\\"<query>\\\"')\\n                else:\\n                    from rag_manager import RAGManager\\n                    project_root = memory_manager.get_project_root()\\n                    if not project_root:\\n                        ui_manager.show_error(\\n                            \\\"No project context in memory. Use 'look <directory>' first.\\\"\\n                            )\\n                        continue\\n                    rag = RAGManager()\\n                    if rag.get_document_count() == 0:\\n                        ui_manager.show_error(\\n                            'RAG index is empty. Please add documents first.')\\n                        continue\\n                    results = rag.search(arg_str, k=3)\\n                    if not results:\\n                        ui_manager.show_error('No relevant documents found.')\\n                        continue\\n                    print(Panel('[bold]RAG Results:[/]', title=\\n                        '[cyan]Retrieval-Augmented Generation[/]'))\\n                    for i, (content, score, metadata) in enumerate(results, 1):\\n                        file_path = metadata.get('file', 'Unknown')\\n                        print(\\n                            f'[bold cyan]{i}. {file_path}[/] (Score: {score:.4f})'\\n                            )\\n                        print(Panel(content[:500] + '...' if len(content) >\\n                            500 else content, border_style='dim'))\\n                    follow_up = ui_manager.get_user_input(\\n                        \\\"\\\"\\\"\\nWould you like to ask a follow-up question with this context? (y/n): \\\"\\\"\\\"\\n                        )\\n                    if follow_up.lower() in ['y', 'yes']:\\n                        follow_up_query = ui_manager.get_user_input(\\n                            'Follow-up query: ')\\n                        if follow_up_query:\\n                            context_parts = [\\n                                f'Document {i} (Score: {score:.4f}):\\\\n{content}'\\n                                 for i, (content, score, _) in enumerate(\\n                                results, 1)]\\n                            context = '\\\\n\\\\n'.join(context_parts)\\n                            rag_prompt = f\\\"\\\"\\\"Based on the following context, please answer the question.\\n\\nContext:\\n{context}\\n\\nQuestion: {follow_up_query}\\\"\\\"\\\"\\n                            response = query_llm(rag_prompt)\\n                            print(Panel(response, title=\\n                                '[cyan]RAG-Augmented Response[/]'))\\n            else:\\n                ui_manager.show_error(\\\"Unknown command. Type 'help'.\\\")\\n            refresh_status_panel(personality_name)\\n        except KeyboardInterrupt:\\n            memory_manager.save_memory()\\n            print('\\\\n[bold cyan]Goodbye![/]')\\n            break\\n        except Exception as e:\\n            ui_manager.show_error(f'An unexpected error occurred: {e}')\\n\\n\\ndef run_python_code() ->None:\\n    global last_code\\n    if not last_code:\\n        ui_manager.show_error('No Python code in memory to run.')\\n        return\\n    temp_file = os.path.join(DEFAULT_SAVE_DIR, 'temp_run.py')\\n    try:\\n        with open(temp_file, 'w') as f:\\n            f.write(last_code)\\n        print('[bold cyan]\\\\n--- Running Code ---\\\\n[/]')\\n        subprocess.run([sys.executable, temp_file], check=True)\\n        print('[bold cyan]\\\\n--- Code Finished ---\\\\n[/]')\\n    except Exception as e:\\n        ui_manager.show_error(f'Error running code: {e}')\\n    finally:\\n        if os.path.exists(temp_file):\\n            os.remove(temp_file)\\n\\n\\ndef save_code(content: str, filename: str) ->None:\\n    filepath = os.path.join(DEFAULT_SAVE_DIR, filename)\\n    try:\\n        with open(filepath, 'w') as f:\\n            f.write(content)\\n        ui_manager.show_success(f'Saved to: {filepath}')\\n    except IOError as e:\\n        ui_manager.show_error(f'Error saving file: {e}')\\n\\n\\ndef main() ->None:\\n    try:\\n        import astor\\n    except ImportError:\\n        print(\\\"[bold red]Error:[/] 'astor' is required. `pip install astor`\\\")\\n        sys.exit(1)\\n    try:\\n        import simple_term_menu\\n    except ImportError:\\n        print(\\n            \\\"[bold red]Error:[/] 'simple-term-menu' is required. `pip install simple-term-menu`\\\"\\n            )\\n        sys.exit(1)\\n    parser = argparse.ArgumentParser(description=\\n        'Omni - AI-powered code tool', add_help=False)\\n    parser.add_argument('command', nargs='?', help='Main command.')\\n    parser.add_argument('args', nargs='*', help='Arguments for the command.')\\n    parser.add_argument('-h', '--help', action='store_true')\\n    args, _ = parser.parse_known_args()\\n    if args.help or not args.command:\\n        interactive_mode()\\n    elif args.command == 'look' and args.args:\\n        look_command(args.args[0])\\n    elif args.command == 'edit' and len(args.args) >= 2:\\n        handle_file_edit_command(args.args[0], ' '.join(args.args[1:]))\\n    elif args.command == 'models':\\n        list_models(args.args)\\n    else:\\n        interactive_mode()\\n\\n\\ndef refresh_status_panel(personality_name: str) ->None:\\n    ui_manager.display_status_panel(personality_name, current_backend,\\n        current_model, len(memory_manager.memory.get('chat', [])), len(\\n        memory_manager.memory.get('look', [])))\\n\\n\\nif __name__ == '__main__':\\n    main()\\n\",\n    \"file\": \"/mnt/ProjectData/omni/omni.py\"\n  },\n  {\n    \"id\": 9,\n    \"hash\": \"392cb7cce7185587da5fc1b6a30c1fef\",\n    \"content\": \"import json\\nimport os\\nfrom typing import List, Dict, Optional\\nfrom rag_manager import RAGManager\\n\\n\\nclass MemoryManager:\\n    \\\"\\\"\\\"Manages persistent chat memory, look data, and RAG integration via JSON.\\\"\\\"\\\"\\n\\n    def __init__(self, memory_file: str):\\n        self.memory_file = memory_file\\n        self.memory: Dict[str, List] = self.load_memory()\\n        self.rag_manager = RAGManager()\\n\\n    def load_memory(self) ->Dict[str, List]:\\n        try:\\n            with open(self.memory_file, 'r') as f:\\n                return json.load(f)\\n        except FileNotFoundError:\\n            default = {'chat': [], 'look': []}\\n            self.save_memory(default)\\n            return default\\n        except json.JSONDecodeError:\\n            print('[yellow]Invalid memory file. Resetting.[/]')\\n            return {'chat': [], 'look': []}\\n\\n    def save_memory(self, memory: Optional[Dict[str, List]]=None) ->None:\\n        if memory is None:\\n            memory = self.memory\\n        with open(self.memory_file, 'w') as f:\\n            json.dump(memory, f, indent=4)\\n\\n    def add_message(self, role: str, content: str) ->None:\\n        self.memory['chat'].append({'role': role, 'content': content})\\n        self.save_memory()\\n\\n    def add_look_data(self, file_path: str, content: str) ->None:\\n        \\\"\\\"\\\"\\n    Adds a watched item (directory or file) to memory, distinguishing its type.\\n\\n    This method stores structured data that differentiates between a project\\n    directory (containing a manifest) and a single file (containing its content).\\n    It also prevents duplicate entries by updating existing ones.\\n\\n    Args:\\n        file_path: The path to the directory or file.\\n        content: The manifest for a directory or the content for a file.\\n    \\\"\\\"\\\"\\n        item_type = 'directory' if os.path.isdir(file_path) else 'file'\\n        for item in self.memory['look']:\\n            if item.get('file') == file_path:\\n                item['content'] = content\\n                item['type'] = item_type\\n                self.save_memory()\\n                return\\n        self.memory['look'].append({'type': item_type, 'file': file_path,\\n            'content': content})\\n        self.save_memory()\\n        if item_type == 'file':\\n            try:\\n                with open(file_path, 'r', encoding='utf-8') as f:\\n                    file_content = f.read()\\n                self.rag_manager.add_documents([file_content], [{'file':\\n                    file_path}])\\n            except Exception as e:\\n                print(\\n                    f'[yellow]Warning: Could not add {file_path} to RAG index: {e}[/]'\\n                    )\\n\\n    def get_memory_context(self) -> str:\\n        \\\"\\\"\\\"\\n        Dynamically builds the context using RAG and chat history.\\n\\n        It retrieves relevant file content from the RAG index based on the latest\\n        user query, includes project manifests for directories, and appends the\\n        recent chat history.\\n        \\\"\\\"\\\"\\n        context = ''\\n        # 1. Add project manifests for any watched directories\\n        for look in self.memory.get('look', []):\\n            path = look.get('file')\\n            if path and os.path.isdir(path):\\n                content = look.get('content', '')\\n                context += f'--- Project Manifest for {path} ---\\\\n{content}\\\\n\\\\n'\\n\\n        # 2. Find the last user message to use as a query for the RAG system\\n        last_user_message = next((msg['content'] for msg in reversed(self.memory.get('chat', [])) if msg['role'] == 'user'), None)\\n\\n        # 3. If a user message exists, search the RAG index for relevant context\\n        if last_user_message:\\n            rag_results = self.search_rag(last_user_message, k=3)\\n            if rag_results:\\n                context += '--- Relevant context from RAG ---\\\\n'\\n                # Format and add each RAG result to the context\\n                for doc, score, meta in rag_results:\\n                    file_path = meta.get('file', 'Unknown source')\\n                    context += f'Source: {file_path} (Score: {score:.4f})\\\\n'\\n                    context += f'Content: {doc}\\\\n---\\\\n'\\n                context += '\\\\n'\\n\\n        # 4. Append the full chat history for conversational context\\n        for msg in self.memory.get('chat', []):\\n            context += f\\\"{msg['role'].capitalize()}: {msg['content']}\\\\n\\\"\\n\\n        return context.strip()\\n\\n    def clear_memory(self) ->None:\\n        self.memory = {'chat': [], 'look': []}\\n        self.save_memory()\\n        self.rag_manager.clear_index()\\n\\n    def search_rag(self, query: str, k: int=3) ->List[tuple]:\\n        \\\"\\\"\\\"\\n        Search the RAG index for relevant documents.\\n        \\n        Args:\\n            query: The search query\\n            k: Number of results to return\\n            \\n        Returns:\\n            List of (document_content, score, metadata) tuples\\n        \\\"\\\"\\\"\\n        return self.rag_manager.search(query, k)\\n\",\n    \"file\": \"/mnt/ProjectData/omni/memory_manager.py\"\n  },\n  {\n    \"id\": 10,\n    \"hash\": \"2914352eefed9d60de098e021dd79b67\",\n    \"content\": \"import os\\nimport sys\\nimport argparse\\nfrom typing import List\\nfrom rag_manager import RAGManager\\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\\n    '..')))\\n\\n\\ndef create_sample_data() ->List[str]:\\n    \\\"\\\"\\\"Create sample documents for the RAG example.\\\"\\\"\\\"\\n    return [\\n        'RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with language generation.'\\n        ,\\n        'The RAG model retrieves relevant documents from a knowledge base and uses them to generate more accurate responses.'\\n        ,\\n        'FAISS is a library for efficient similarity search and clustering of dense vectors, often used in RAG systems.'\\n        ,\\n        'Sentence transformers are used to create embeddings for documents and queries in RAG systems.'\\n        ,\\n        'Retrieval-Augmented Generation improves language models by allowing them to access external knowledge sources.'\\n        ,\\n        'In RAG systems, documents are indexed and searchable by their semantic embeddings rather than just keywords.'\\n        ,\\n        'Python is a great language for implementing RAG systems due to libraries like sentence-transformers and faiss.'\\n        ,\\n        'The retrieval component of RAG is crucial for finding relevant information before generation.'\\n        ]\\n\\n\\ndef main():\\n    \\\"\\\"\\\"Main function demonstrating RAG through CLI.\\\"\\\"\\\"\\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\\n    parser.add_argument('--add', '-a', type=str, help=\\n        'Add a new document to the index')\\n    parser.add_argument('--list', '-l', action='store_true', help=\\n        'List all documents in the index')\\n    parser.add_argument('--clear', '-c', action='store_true', help=\\n        'Clear the index')\\n    parser.add_argument('--init', '-i', action='store_true', help=\\n        'Initialize with sample data')\\n    args = parser.parse_args()\\n    rag_manager = RAGManager()\\n    if args.clear:\\n        rag_manager.clear_index()\\n        print('Index cleared.')\\n        return\\n    if args.init:\\n        documents = create_sample_data()\\n        rag_manager.add_documents(documents)\\n        print(f'Added {len(documents)} sample documents to index.')\\n        return\\n    if args.add:\\n        rag_manager.add_documents([args.add])\\n        print(f'Added document: {args.add}')\\n        return\\n    if args.list:\\n        if rag_manager.get_document_count() == 0:\\n            print(\\n                'No documents in index. Use --init to add sample data or --add to add documents.'\\n                )\\n        else:\\n            print(\\n                f'Documents in index ({rag_manager.get_document_count()} total):'\\n                )\\n            for i, meta in enumerate(rag_manager.metadata):\\n                print(f\\\"  {i + 1}. {meta['content']}\\\")\\n        return\\n    if args.query:\\n        if rag_manager.get_document_count() == 0:\\n            print(\\n                'Index is empty. Use --init to add sample data or --add to add documents.'\\n                )\\n            return\\n        results = rag_manager.search(args.query, k=3)\\n        print(f\\\"Top 3 results for '{args.query}':\\\")\\n        for i, (doc, score, meta) in enumerate(results, 1):\\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\\n        return\\n    parser.print_help()\\n\\n\\ndef main():\\n    \\\"\\\"\\\"Main function demonstrating RAG through CLI.\\\"\\\"\\\"\\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\\n    parser.add_argument('--add', '-a', type=str, help=\\n        'Add a new document to the index')\\n    parser.add_argument('--list', '-l', action='store_true', help=\\n        'List all documents in the index')\\n    parser.add_argument('--clear', '-c', action='store_true', help=\\n        'Clear the index')\\n    parser.add_argument('--init', '-i', action='store_true', help=\\n        'Initialize with sample data')\\n    args = parser.parse_args()\\n    rag_manager = RAGManager()\\n    if args.clear:\\n        rag_manager.clear_index()\\n        print('Index cleared.')\\n        return\\n    if args.init:\\n        documents = create_sample_data()\\n        rag_manager.add_documents(documents)\\n        print(f'Added {len(documents)} sample documents to index.')\\n        return\\n    if args.add:\\n        rag_manager.add_documents([args.add])\\n        print(f'Added document: {args.add}')\\n        return\\n    if args.list:\\n        if rag_manager.get_document_count() == 0:\\n            print(\\n                'No documents in index. Use --init to add sample data or --add to add documents.'\\n                )\\n        else:\\n            print(\\n                f'Documents in index ({rag_manager.get_document_count()} total):'\\n                )\\n            for i, meta in enumerate(rag_manager.metadata):\\n                print(f\\\"  {i + 1}. {meta['content']}\\\")\\n        return\\n    if args.query:\\n        if rag_manager.get_document_count() == 0:\\n            print(\\n                'Index is empty. Use --init to add sample data or --add to add documents.'\\n                )\\n            return\\n        results = rag_manager.search(args.query, k=3)\\n        print(f\\\"Top 3 results for '{args.query}':\\\")\\n        for i, (doc, score, meta) in enumerate(results, 1):\\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\\n        return\\n    parser.print_help()\\n\\n\\nif __name__ == '__main__':\\n    main()\\n\",\n    \"file\": \"/mnt/ProjectData/omni/rag_cli_example.py\"\n  },\n  {\n    \"id\": 11,\n    \"hash\": \"f59a27842056dbb0dc95d0f29c1c5de8\",\n    \"content\": \"Hello! I'm OmniForge, an AI coding assistant. I can help you scan, understand, and refactor your codebase using local (Ollama) or remote (OpenRouter) LLMs.\\n\\nI see you've opened the OmniForge project directory. Some key things I can help with:\\n\\n1. **Project Analysis**: I can look at your files to understand the structure\\n2. **Code Editing**: I can make precise edits to functions/classes using AST-based transformations\\n3. **Refactoring**: I can perform multi-file architectural changes with a plan\\n4. **File Creation**: I can generate new files based on instructions\\n\\nFor example:\\n- `look .` to scan the project\\n- `edit code_editor.py \\\"add docstrings to main methods\\\"`\\n- `refactor \\\"extract git operations into a separate module\\\"`\\n- `create new_module.py \\\"implement a simple HTTP client\\\"`\\n\\nWhat would you like to do with this project?\",\n    \"file\": \"/mnt/ProjectData/omni/requirements.txt\"\n  },\n  {\n    \"id\": 12,\n    \"hash\": \"dbd143839288b400cafdedb655258434\",\n    \"content\": \"import os\\nimport json\\nimport hashlib\\nfrom typing import List, Dict, Optional, Tuple\\nfrom sentence_transformers import SentenceTransformer\\nimport numpy as np\\nimport faiss\\nfrom pathlib import Path\\n\\n\\nclass VectorDBManager:\\n    \\\"\\\"\\\"Manages vector database operations for RAG using sentence transformers and FAISS.\\\"\\\"\\\"\\n\\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\\n        Optional[str]=None):\\n        \\\"\\\"\\\"\\n        Initialize the VectorDB manager.\\n\\n        Args:\\n            model_name: Name of the sentence transformer model to use\\n            index_path: Path to save/load the FAISS index\\n        \\\"\\\"\\\"\\n        self.model = SentenceTransformer(model_name)\\n        self.index_path = index_path or 'vectordb_index.bin'\\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\\n        self.dimension = self.model.get_sentence_embedding_dimension()\\n        self.index = None\\n        self.metadata: List[Dict] = []\\n        self._initialize_index()\\n\\n    def _initialize_index(self):\\n        \\\"\\\"\\\"Initialize or load the FAISS index.\\\"\\\"\\\"\\n        if os.path.exists(self.index_path) and os.path.exists(self.\\n            metadata_path):\\n            self.index = faiss.read_index(self.index_path)\\n            with open(self.metadata_path, 'r') as f:\\n                self.metadata = json.load(f)\\n        else:\\n            self.index = faiss.IndexFlatIP(self.dimension)\\n            self.metadata = []\\n\\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\\n        Dict]]=None):\\n        \\\"\\\"\\\"\\n        Add documents to the vector database.\\n\\n        Args:\\n            documents: List of text documents to add\\n            metadatas: Optional list of metadata for each document\\n        \\\"\\\"\\\"\\n        if metadatas is None:\\n            metadatas = [{}] * len(documents)\\n        embeddings = self.model.encode(documents)\\n        faiss.normalize_L2(embeddings)\\n        self.index.add(embeddings.astype(np.float32))\\n        for i, meta in enumerate(metadatas):\\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\\n                'content': documents[i], **meta}\\n            self.metadata.append(meta_entry)\\n        self._save_index()\\n\\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\\n        \\\"\\\"\\\"\\n        Search for relevant documents.\\n\\n        Args:\\n            query: Query string\\n            k: Number of results to return\\n\\n        Returns:\\n            List of (document, score, metadata) tuples\\n        \\\"\\\"\\\"\\n        query_embedding = self.model.encode([query])\\n        faiss.normalize_L2(query_embedding)\\n        scores, indices = self.index.search(query_embedding.astype(np.\\n            float32), k)\\n        results = []\\n        for score, idx in zip(scores[0], indices[0]):\\n            if idx < len(self.metadata):\\n                doc_info = self.metadata[idx]\\n                results.append((doc_info['content'], float(score), doc_info))\\n        return results\\n\\n    def _save_index(self):\\n        \\\"\\\"\\\"Save the FAISS index and metadata to disk.\\\"\\\"\\\"\\n        faiss.write_index(self.index, self.index_path)\\n        with open(self.metadata_path, 'w') as f:\\n            json.dump(self.metadata, f, indent=2)\\n\\n    def get_document_count(self) ->int:\\n        \\\"\\\"\\\"Get the number of documents in the index.\\\"\\\"\\\"\\n        return len(self.metadata)\\n\\n    def clear_index(self):\\n        \\\"\\\"\\\"Clear the index and metadata.\\\"\\\"\\\"\\n        self.index = faiss.IndexFlatIP(self.dimension)\\n        self.metadata = []\\n        self._save_index()\\n\\n\\nclass VectorDBManager:\\n    \\\"\\\"\\\"Manages vector database operations for RAG using sentence transformers and FAISS.\\\"\\\"\\\"\\n\\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\\n        Optional[str]=None):\\n        \\\"\\\"\\\"\\n        Initialize the VectorDB manager.\\n\\n        Args:\\n            model_name: Name of the sentence transformer model to use\\n            index_path: Path to save/load the FAISS index\\n        \\\"\\\"\\\"\\n        self.model = SentenceTransformer(model_name)\\n        self.index_path = index_path or 'vectordb_index.bin'\\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\\n        self.dimension = self.model.get_sentence_embedding_dimension()\\n        self.index = None\\n        self.metadata: List[Dict] = []\\n        self._initialize_index()\\n\\n    def _initialize_index(self):\\n        \\\"\\\"\\\"Initialize or load the FAISS index.\\\"\\\"\\\"\\n        if os.path.exists(self.index_path) and os.path.exists(self.\\n            metadata_path):\\n            self.index = faiss.read_index(self.index_path)\\n            with open(self.metadata_path, 'r') as f:\\n                self.metadata = json.load(f)\\n        else:\\n            self.index = faiss.IndexFlatIP(self.dimension)\\n            self.metadata = []\\n\\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\\n        Dict]]=None):\\n        \\\"\\\"\\\"\\n        Add documents to the vector database.\\n\\n        Args:\\n            documents: List of text documents to add\\n            metadatas: Optional list of metadata for each document\\n        \\\"\\\"\\\"\\n        if metadatas is None:\\n            metadatas = [{}] * len(documents)\\n        embeddings = self.model.encode(documents)\\n        faiss.normalize_L2(embeddings)\\n        self.index.add(embeddings.astype(np.float32))\\n        for i, meta in enumerate(metadatas):\\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\\n                'content': documents[i], **meta}\\n            self.metadata.append(meta_entry)\\n        self._save_index()\\n\\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\\n        \\\"\\\"\\\"\\n        Search for relevant documents.\\n\\n        Args:\\n            query: Query string\\n            k: Number of results to return\\n\\n        Returns:\\n            List of (document, score, metadata) tuples\\n        \\\"\\\"\\\"\\n        query_embedding = self.model.encode([query])\\n        faiss.normalize_L2(query_embedding)\\n        scores, indices = self.index.search(query_embedding.astype(np.\\n            float32), k)\\n        results = []\\n        for score, idx in zip(scores[0], indices[0]):\\n            if idx < len(self.metadata):\\n                doc_info = self.metadata[idx]\\n                results.append((doc_info['content'], float(score), doc_info))\\n        return results\\n\\n    def _save_index(self):\\n        \\\"\\\"\\\"Save the FAISS index and metadata to disk.\\\"\\\"\\\"\\n        faiss.write_index(self.index, self.index_path)\\n        with open(self.metadata_path, 'w') as f:\\n            json.dump(self.metadata, f, indent=2)\\n\\n    def get_document_count(self) ->int:\\n        \\\"\\\"\\\"Get the number of documents in the index.\\\"\\\"\\\"\\n        return len(self.metadata)\\n\\n    def clear_index(self):\\n        \\\"\\\"\\\"Clear the index and metadata.\\\"\\\"\\\"\\n        self.index = faiss.IndexFlatIP(self.dimension)\\n        self.metadata = []\\n        self._save_index()\\n\\n\\nclass VectorDBManager:\\n    \\\"\\\"\\\"Manages vector database operations for RAG using sentence transformers and FAISS.\\\"\\\"\\\"\\n\\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\\n        Optional[str]=None):\\n        \\\"\\\"\\\"\\n        Initialize the VectorDB manager.\\n\\n        Args:\\n            model_name: Name of the sentence transformer model to use\\n            index_path: Path to save/load the FAISS index\\n        \\\"\\\"\\\"\\n        self.model = SentenceTransformer(model_name)\\n        self.index_path = index_path or 'vectordb_index.bin'\\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\\n        self.dimension = self.model.get_sentence_embedding_dimension()\\n        self.index = None\\n        self.metadata: List[Dict] = []\\n        self._initialize_index()\\n\\n    def _initialize_index(self):\\n        \\\"\\\"\\\"Initialize or load the FAISS index.\\\"\\\"\\\"\\n        if os.path.exists(self.index_path) and os.path.exists(self.\\n            metadata_path):\\n            self.index = faiss.read_index(self.index_path)\\n            with open(self.metadata_path, 'r') as f:\\n                self.metadata = json.load(f)\\n        else:\\n            self.index = faiss.IndexFlatIP(self.dimension)\\n            self.metadata = []\\n\\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\\n        Dict]]=None):\\n        \\\"\\\"\\\"\\n        Add documents to the vector database.\\n\\n        Args:\\n            documents: List of text documents to add\\n            metadatas: Optional list of metadata for each document\\n        \\\"\\\"\\\"\\n        if metadatas is None:\\n            metadatas = [{}] * len(documents)\\n        embeddings = self.model.encode(documents)\\n        faiss.normalize_L2(embeddings)\\n        self.index.add(embeddings.astype(np.float32))\\n        for i, meta in enumerate(metadatas):\\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\\n                'content': documents[i], **meta}\\n            self.metadata.append(meta_entry)\\n        self._save_index()\\n\\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\\n        \\\"\\\"\\\"\\n        Search for relevant documents.\\n\\n        Args:\\n            query: Query string\\n            k: Number of results to return\\n\\n        Returns:\\n            List of (document, score, metadata) tuples\\n        \\\"\\\"\\\"\\n        query_embedding = self.model.encode([query])\\n        faiss.normalize_L2(query_embedding)\\n        scores, indices = self.index.search(query_embedding.astype(np.\\n            float32), k)\\n        results = []\\n        for score, idx in zip(scores[0], indices[0]):\\n            if idx < len(self.metadata):\\n                doc_info = self.metadata[idx]\\n                results.append((doc_info['content'], float(score), doc_info))\\n        return results\\n\\n    def _save_index(self):\\n        \\\"\\\"\\\"Save the FAISS index and metadata to disk.\\\"\\\"\\\"\\n        faiss.write_index(self.index, self.index_path)\\n        with open(self.metadata_path, 'w') as f:\\n            json.dump(self.metadata, f, indent=2)\\n\\n    def get_document_count(self) ->int:\\n        \\\"\\\"\\\"Get the number of documents in the index.\\\"\\\"\\\"\\n        return len(self.metadata)\\n\\n    def clear_index(self):\\n        \\\"\\\"\\\"Clear the index and metadata.\\\"\\\"\\\"\\n        self.index = faiss.IndexFlatIP(self.dimension)\\n        self.metadata = []\\n        self._save_index()\\n\",\n    \"file\": \"/mnt/ProjectData/omni/vectordb_manager.py\"\n  },\n  {\n    \"id\": 13,\n    \"hash\": \"c27b11d2eaa8e13cdf8e698417efb75e\",\n    \"content\": \"import os\\nimport sys\\nfrom typing import List, Dict, Tuple\\n\\\"\\\"\\\"\\nExample script demonstrating RAG (Retrieval-Augmented Generation) usage.\\n\\nThis script shows how to use a simple RAG implementation to answer questions\\nbased on a given context or knowledge base.\\n\\\"\\\"\\\"\\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\\n    '..')))\\n\\n\\nclass SimpleRAG:\\n    \\\"\\\"\\\"A simple RAG implementation for demonstration purposes.\\\"\\\"\\\"\\n\\n    def __init__(self, knowledge_base: List[str]):\\n        \\\"\\\"\\\"\\n        Initialize the RAG with a knowledge base.\\n        \\n        Args:\\n            knowledge_base: A list of strings representing the knowledge base.\\n        \\\"\\\"\\\"\\n        self.knowledge_base = knowledge_base\\n\\n    def retrieve(self, query: str, top_k: int=3) ->List[str]:\\n        \\\"\\\"\\\"\\n        Retrieve relevant documents from the knowledge base.\\n        \\n        This is a simplified implementation using keyword matching.\\n        In a real implementation, you would use embeddings and vector search.\\n        \\n        Args:\\n            query: The query string.\\n            top_k: Number of top documents to retrieve.\\n            \\n        Returns:\\n            A list of relevant documents.\\n        \\\"\\\"\\\"\\n        query_words = set(query.lower().split())\\n        scores = []\\n        for doc in self.knowledge_base:\\n            doc_words = set(doc.lower().split())\\n            score = len(query_words.intersection(doc_words))\\n            scores.append((score, doc))\\n        scores.sort(reverse=True)\\n        return [doc for score, doc in scores[:top_k]]\\n\\n    def generate(self, query: str, retrieved_docs: List[str]) ->str:\\n        \\\"\\\"\\\"\\n        Generate an answer based on the query and retrieved documents.\\n        \\n        In a real implementation, this would use an LLM to generate the response.\\n        For this example, we'll create a simple template-based response.\\n        \\n        Args:\\n            query: The query string.\\n            retrieved_docs: The retrieved documents.\\n            \\n        Returns:\\n            A generated answer.\\n        \\\"\\\"\\\"\\n        context = '\\\\n'.join(retrieved_docs)\\n        prompt = f\\\"\\\"\\\"\\n        Context information:\\n        {context}\\n        \\n        Question: {query}\\n        \\n        Based on the context provided above, please answer the question.\\n        If the context doesn't contain relevant information, say so.\\n        \\\"\\\"\\\"\\n        return self._simple_response_generator(query, retrieved_docs)\\n\\n    def _simple_response_generator(self, query: str, retrieved_docs: List[str]\\n        ) ->str:\\n        \\\"\\\"\\\"\\n        A simple response generator for demonstration.\\n        \\\"\\\"\\\"\\n        for doc in retrieved_docs:\\n            if 'example' in doc.lower():\\n                return (\\n                    f'Based on the context provided, I found information about examples. {query} relates to the examples in the knowledge base.'\\n                    )\\n        return (\\n            f\\\"I couldn't find specific information about '{query}' in the provided context. Please provide more details or check the knowledge base.\\\"\\n            )\\n\\n    def query(self, query: str, top_k: int=3) ->str:\\n        \\\"\\\"\\\"\\n        Process a query through the full RAG pipeline.\\n        \\n        Args:\\n            query: The query string.\\n            top_k: Number of top documents to retrieve.\\n            \\n        Returns:\\n            The generated answer.\\n        \\\"\\\"\\\"\\n        retrieved_docs = self.retrieve(query, top_k)\\n        answer = self.generate(query, retrieved_docs)\\n        return answer\\n\\n\\ndef main():\\n    \\\"\\\"\\\"Main function demonstrating the RAG implementation.\\\"\\\"\\\"\\n    knowledge_base = ['This is an example document about machine learning.',\\n        'Natural language processing is a subfield of artificial intelligence.'\\n        , 'Python is a popular programming language for data science.',\\n        'The quick brown fox jumps over the lazy dog.',\\n        'RAG stands for Retrieval-Augmented Generation.',\\n        'Vector databases are used for similarity search in RAG systems.',\\n        'Transformers are a type of neural network architecture.',\\n        'This example shows how to implement a simple RAG system.']\\n    rag = SimpleRAG(knowledge_base)\\n    queries = ['What is RAG?', 'How is Python used in data science?',\\n        'Tell me about machine learning']\\n    print('Simple RAG Example')\\n    print('=' * 50)\\n    for query in queries:\\n        print(f'\\\\nQuery: {query}')\\n        answer = rag.query(query)\\n        print(f'Answer: {answer}')\\n        print('-' * 30)\\n    print(\\\"\\\\nInteractive Mode (type 'quit' to exit):\\\")\\n    while True:\\n        try:\\n            user_query = input('\\\\nEnter your question: ').strip()\\n            if user_query.lower() in ['quit', 'exit', 'q']:\\n                break\\n            if user_query:\\n                answer = rag.query(user_query)\\n                print(f'Answer: {answer}')\\n        except KeyboardInterrupt:\\n            print('\\\\nGoodbye!')\\n            break\\n        except EOFError:\\n            break\\n\\n\\nif __name__ == '__main__':\\n    main()\\n\",\n    \"file\": \"/mnt/ProjectData/omni/rag_example.py\"\n  },\n  {\n    \"id\": 14,\n    \"hash\": \"f151986bf2efa7602242590a357fab83\",\n    \"content\": \"import os\\nimport json\\nimport hashlib\\nfrom typing import List, Dict, Optional, Tuple\\nfrom sentence_transformers import SentenceTransformer\\nimport numpy as np\\nimport faiss\\nfrom pathlib import Path\\n\\n\\nclass RAGManager:\\n    \\\"\\\"\\\"Manages Retrieval-Augmented Generation operations using sentence transformers.\\\"\\\"\\\"\\n\\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\\n        Optional[str]=None):\\n        \\\"\\\"\\\"\\n    Initialize the RAG manager.\\n\\n    Args:\\n        model_name: Name of the sentence transformer model to use\\n        index_path: Path to save/load the FAISS index\\n    \\\"\\\"\\\"\\n        self.model_name = model_name\\n        from vectordb_manager import VectorDBManager\\n        self.vectordb = VectorDBManager(model_name, index_path)\\n        self.model = self.vectordb.model\\n        self.index_path = self.vectordb.index_path\\n        self.metadata_path = self.vectordb.metadata_path\\n        self.dimension = self.vectordb.dimension\\n        self.index = self.vectordb.index\\n        self.metadata = self.vectordb.metadata\\n\\n    def _initialize_index(self):\\n        \\\"\\\"\\\"Initialize or load the FAISS index.\\\"\\\"\\\"\\n        if os.path.exists(self.index_path) and os.path.exists(self.\\n            metadata_path):\\n            self.index = faiss.read_index(self.index_path)\\n            with open(self.metadata_path, 'r') as f:\\n                self.metadata = json.load(f)\\n        else:\\n            self.index = faiss.IndexFlatIP(self.dimension)\\n            self.metadata = []\\n\\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\\n        Dict]]=None):\\n        \\\"\\\"\\\"\\n        Add documents to the RAG index.\\n\\n        Args:\\n            documents: List of text documents to add\\n            metadatas: Optional list of metadata for each document\\n        \\\"\\\"\\\"\\n        if metadatas is None:\\n            metadatas = [{}] * len(documents)\\n        for i, meta in enumerate(metadatas):\\n            if 'file' not in meta:\\n                meta['file'] = f'document_{len(self.metadata) + i}'\\n        self.vectordb.add_documents(documents, metadatas)\\n        self.metadata = self.vectordb.metadata\\n\\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\\n        \\\"\\\"\\\"\\n        Search for relevant documents.\\n\\n        Args:\\n            query: Query string\\n            k: Number of results to return\\n\\n        Returns:\\n            List of (document, score, metadata) tuples\\n        \\\"\\\"\\\"\\n        from vectordb_manager import VectorDBManager\\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\\n            self.index_path)\\n        results = temp_vdb.search(query, k)\\n        return results\\n\\n    def _save_index(self):\\n        \\\"\\\"\\\"Save the FAISS index and metadata to disk.\\\"\\\"\\\"\\n        faiss.write_index(self.index, self.index_path)\\n        with open(self.metadata_path, 'w') as f:\\n            json.dump(self.metadata, f, indent=2)\\n\\n    def get_document_count(self) ->int:\\n        \\\"\\\"\\\"Get the number of documents in the index.\\\"\\\"\\\"\\n        return len(self.metadata)\\n\\n    def clear_index(self):\\n        \\\"\\\"\\\"Clear the index and metadata.\\\"\\\"\\\"\\n        self.index = faiss.IndexFlatIP(self.dimension)\\n        self.metadata = []\\n        self._save_index()\\n\\n\\nclass RAGManager:\\n    \\\"\\\"\\\"Manages Retrieval-Augmented Generation operations using sentence transformers.\\\"\\\"\\\"\\n\\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\\n        Optional[str]=None):\\n        \\\"\\\"\\\"\\n        Initialize the RAG manager.\\n\\n        Args:\\n            model_name: Name of the sentence transformer model to use\\n            index_path: Path to save/load the FAISS index\\n        \\\"\\\"\\\"\\n        self.model_name = model_name\\n        from vectordb_manager import VectorDBManager\\n        self.vectordb = VectorDBManager(model_name, index_path)\\n        self.model = self.vectordb.model\\n        self.index_path = self.vectordb.index_path\\n        self.metadata_path = self.vectordb.metadata_path\\n        self.dimension = self.vectordb.dimension\\n        self.index = self.vectordb.index\\n        self.metadata = self.vectordb.metadata\\n\\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\\n        Dict]]=None):\\n        \\\"\\\"\\\"\\n        Add documents to the RAG index.\\n\\n        Args:\\n            documents: List of text documents to add\\n            metadatas: Optional list of metadata for each document\\n        \\\"\\\"\\\"\\n        if metadatas is None:\\n            metadatas = [{}] * len(documents)\\n        for i, meta in enumerate(metadatas):\\n            if 'file' not in meta:\\n                meta['file'] = f'document_{len(self.metadata) + i}'\\n        self.vectordb.add_documents(documents, metadatas)\\n        self.metadata = self.vectordb.metadata\\n\\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\\n        \\\"\\\"\\\"\\n        Search for relevant documents.\\n\\n        Args:\\n            query: Query string\\n            k: Number of results to return\\n\\n        Returns:\\n            List of (document, score, metadata) tuples\\n        \\\"\\\"\\\"\\n        from vectordb_manager import VectorDBManager\\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\\n            self.index_path)\\n        results = temp_vdb.search(query, k)\\n        return results\\n\\n    def get_document_count(self) ->int:\\n        \\\"\\\"\\\"Get the number of documents in the index.\\\"\\\"\\\"\\n        return len(self.metadata)\\n\\n    def clear_index(self):\\n        \\\"\\\"\\\"Clear the index and metadata.\\\"\\\"\\\"\\n        self.index = faiss.IndexFlatIP(self.dimension)\\n        self.metadata = []\\n\",\n    \"file\": \"/mnt/ProjectData/omni/rag_manager.py\"\n  }\n]",
    "file": "/mnt/ProjectData/omni/vectordb_index_metadata.json"
  },
  {
    "id": 16,
    "hash": "6774a805052356775d8c4f0367253dc1",
    "content": "# OmniForge\n\n**Project\u2011Aware AI CLI for AST\u2011Precise Edits (\u201cScalpel\u201d) & Multi\u2011File Refactors (\u201cBlueprint\u201d).**\n\n> *OmniForge (a.k.a. the \"DualForge\" engine) helps you **scan**, **understand**, and **reforge** your codebase with local (Ollama) or remote (OpenRouter) LLMs. It is an independent open\u2011source project not affiliated with other products using the name \u201cOmni.\u201d*\n\n---\n\n## Core Features\n\n* **Project\u2011Aware Refactoring (`refactor`)**: Provide a high\u2011level goal (e.g. *\u201cmove all DB logic into `db/` and centralize config\u201d*). OmniForge generates & shows a multi\u2011step plan before touching files.\n* **Surgical AST Editing (`edit`)**: Target a single function/class. OmniForge parses the file, locates the node, applies a structural change, and shows you a diff.\n* **Context Ingestion (`look`)**: Scan a directory or single file to build a project manifest (paths + hashes + size + language hints) that guides subsequent edits/refactors.\n* **Dual Backends**: Seamlessly switch between **`openrouter`** (remote models) and **`ollama`** (local models) via `backend <name>`.\n* **Interactive Model Picker (`models`)**: Filter by source/provider and select from an up\u2011to\u2011date model list inside the terminal.\n* **Session Memory & History**: `history` shows conversation / action log; `memory clear` resets the working context.\n* **Safe AST\u2011Based Transformations**: Reduces syntax breakage vs naive text substitution. New imports / dependencies are auto\u2011inserted when possible.\n* **Dry\u2011Run Transparency**: Every multi\u2011file refactor presents (1) a generated plan, (2) per\u2011file proposed changes, (3) a consolidated diff for confirmation.\n\n---\n\n## Conceptual Modes\n\n| Mode          | Command(s) | Purpose                                              | Analogy              |\n| ------------- | ---------- | ---------------------------------------------------- | -------------------- |\n| **Survey**    | `look`     | Index project / ingest context                       | Mapping the terrain  |\n| **Scalpel**   | `edit`     | Precise single\u2011file structural change                | Surgery              |\n| **Blueprint** | `refactor` | Multi\u2011file architectural transformation              | Architecture         |\n| **Cast**      | `run`      | Execute last generated runnable block (if supported) | Forging the artifact |\n\nYou can reference these terms in docs, help screens, or UI banners for clarity.\n\n---\n\n## Installation\n\n> Requires Python 3.10+ and a Unix\u2011like shell.\n\n```bash\n# 1. Clone\ngit clone https://github.com/Snawyyy/omniforge.git\ncd omniforge\n\n# 2. (Optional) Inspect requirements\ncat requirements.txt\n\n# 3. Run installer (creates venv + installs deps)\nchmod +x install.sh\n./install.sh\n\n# 4. Activate environment\nsource venv/bin/activate\n\n# 5. Run CLI (interactive shell)\n./omni        # or: python omni.py\n```\n\nIf you later package it, expose a script entry point named `omni` while keeping an internal package name like `omniforge` to avoid namespace collisions.\n\n---\n\n## Configuration\n\nCreate a `.env` file to supply secrets (e.g. OpenRouter API key).\n\n```bash\ncp .env.example .env   # if example exists; otherwise create manually\n```\n\nIn `.env`:\n\n```dotenv\nOPENROUTER_API_KEY=\"sk-or-...\"\n```\n\n(Do **not** commit real keys. Ensure `.env` is listed in `.gitignore`.)\n\nOptional future keys can include local model paths, default model name, or feature flags.\n\n---\n\n## Quick Start Workflow\n\n```text\n> look .\n(Index project: builds manifest)\n\n> refactor \"extract hardcoded API URL to config/settings.py and update all imports\"\n(Shows plan \u2192 ask for confirmation)\n\n> edit src/utils.py \"add a doctring for calculate_average explaining parameters and return value\"\n(Shows targeted diff \u2192 confirm or abort)\n\n> models openai\n(Choose a different model)\n\n> backend ollama\n(Switch to local inference)\n```\n\n---\n\n## Command Reference\n\n| Command               | Example                                         | Description                                                                 |\n| --------------------- | ----------------------------------------------- | --------------------------------------------------------------------------- |\n| `look <path>`         | `look .`                                        | Scan directory or file; update project context manifest.                    |\n| `edit <file> \"instr\"` | `edit utils.py \"add error handling\"`            | AST\u2011guided targeted modification of a single file element or whole file.    |\n| `refactor \"goal\"`     | `refactor \"split monolith api.py into package\"` | High\u2011level multi\u2011file transformation with plan + diff review.               |\n| `send <prompt>`       | `send summarize module layout`                  | Generic prompt to current model with current context summary.               |\n| `models [filter]`     | `models google`                                 | Interactive model selector (filter by provider/source).                     |\n| `backend <name>`      | `backend ollama`                                | Switch between `openrouter` / `ollama`.                                     |\n| `history`             | `history`                                       | Display session interaction log.                                            |\n| `memory clear`        | `memory clear`                                  | Clear internal AI context memory (project manifest may persist separately). |\n| `run`                 | `run`                                           | Execute the last generated runnable code snippet (if feature implemented).  |\n| `help`                | `help`                                          | Show help / usage summary.                                                  |\n\n---\n\n## How It Works (High Level)\n\n1. **Ingestion (`look`)**: Walks the directory (configurable ignore patterns), captures file metadata (path, size, language), optionally caches abbreviated content or hashes.\n2. **Prompt Construction**: Merges user instruction + contextual manifest + focused snippets (for `edit`) or diff summaries (for `refactor`).\n3. **AST Layer** (Python initially): Parses target file(s); identifies node(s) (function/class) based on name + heuristic similarity; applies transformations guided by model output (structured hints or patch templates) rather than raw blind overwrite.\n4. **Plan (Refactor)**: Model proposes steps (CREATE / MODIFY / RENAME / DELETE). User approves. Each step executed & validated; errors surface early.\n5. **Diff Presentation**: A unified colorized diff shown; user confirms to write changes.\n6. **Safety**: If AST parse fails or patch violates syntax, changes abort (or fallback to text patch with warning).\n\n---\n\n## Roadmap (Indicative)\n\n| Milestone | Features                                                                    |\n| --------- | --------------------------------------------------------------------------- |\n| 0.1.0     | Core commands (`look`, `edit`, `refactor`, `models`, `backend`, `history`). |\n| 0.2.0     | Config file (`omniforge.toml`), ignore patterns, improved diff viewer.      |\n| 0.3.0     | Multi-language AST adapters (JS/TS via `tree-sitter`).                      |\n| 0.4.0     | Test impact analysis & auto test file generation.                           |\n| 0.5.0     | Refactor preview metrics (LOC touched, complexity delta).                   |\n| 0.6.0     | Inline security / lint feedback integration.                                |\n| 0.7.0     | Partial GUI / TUI dashboard mode.                                           |\n\n(Adjust roadmap as project evolves.)\n\n---\n\n## Developer Notes\n\n* Keep `.env`, virtual environment dirs (`venv/`), caches, large artifacts in `.gitignore`.\n* Consider adding a thin `omniforge/` package directory now for future PyPI packaging.\n* Implement a pluggable *Model Adapter* layer to abstract provider differences (OpenRouter vs Ollama).\n* Logging: Provide `--verbose` or `OMNIFORGE_DEBUG=1` env flag.\n* Add a JSONL log of commands & decisions to enable replay or supervised improvements.\n\n---\n\n## Contributing\n\n1. Fork & create a feature branch: `git checkout -b feat/<short-name>`\n2. Run and add tests (if/when test harness exists in `tests/`).\n3. Ensure style/format (e.g. `ruff`, `black`) passes.\n4. Submit pull request with concise description + before/after examples.\n\nIssues / discussions welcome for architecture proposals, AST adapters, or performance improvements.\n\n---\n\n## License\n\nReleased under the **MIT License**. See `LICENSE` file for full text.\n\n---\n\n## Name & Trademark Disclaimer\n\n\u201cOmniForge\u201d is an independent open-source tool and not affiliated with The Omni Group or any other third-party products using similar names. If a future naming conflict arises, a soft alias strategy (keeping the `omni` CLI) will preserve user workflows.\n\n---\n\n## Example Session (Illustrative)\n\n```text\n$ ./omni\nOMNIFORGE 0.1.0  (backend=openrouter | model=anthropic/claude-3)\nType 'help' or 'look .' to begin.\n\n> look .\nIndexed 42 files (Python=30, Markdown=5, JSON=7)\n\n> refactor \"centralize logging into logging_util.py and update imports\"\nPlan:\n  [1] CREATE logging_util.py\n  [2] MODIFY app.py (replace inline log setup)\n  [3] MODIFY worker.py (import logging_util)\nProceed? (y/n) y\n... (diff preview) ...\nApply changes? (y/n) y\nRefactor complete in 3.2s.\n\n> edit worker.py \"add retry with exponential backoff to fetch_data\"\nParsed worker.py \u2713\nApplied modification (function: fetch_data)\nDiff shown. Accept? (y/n) y\nSaved.\n```\n\n---\n\n## Philosophy\n\n*The next wave of developer AI goes beyond paste\u2011in prompts.* OmniForge treats your repository as *structured material*, enabling incremental, auditable, and safer evolution rather than opaque code dumps. By combining **context scanning**, **AST precision**, and **human approval loops**, it aims to become a trustworthy co\u2011developer rather than an occasionally helpful code generator.\n\n---\n\n## Feedback / Support\n\nOpen a GitHub Issue for bugs & feature requests. For conceptual discussions (roadmap, design choices), use Discussions.\n\n---\n\nHappy forging!\n",
    "file": "/mnt/ProjectData/omni/README.md"
  },
  {
    "id": 17,
    "hash": "17ef2c48d5827115cc9579bd067e6ec9",
    "content": "\"\"\"\nCodeEditor - Enhanced AST-based Python code manipulation tool\n\nThis module provides a class to programmatically parse, analyze,\nand edit Python source code using Abstract Syntax Trees (AST).\nIt supports both full element replacement and surgical partial edits\nwithin functions and classes using asttokens for precise source mapping.\n\"\"\"\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Union, Tuple\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n    print(\"Warning: asttokens not installed. Partial edits will be limited.\")\n\n\nclass CodeEditor:\n    \"\"\"An enhanced class to safely edit Python files using AST with partial edit support.\"\"\"\n\n    def __init__(self, file_path: str):\n        self.file_path = file_path\n        self.source_code = self._read_file()\n        self.tree: ast.AST = self._parse_source()\n        self.nodes: Dict[str, ast.AST] = self._map_nodes()\n        # Enhanced source tracking with asttokens\n        if ASTTOKENS_AVAILABLE:\n            self.atok = asttokens.ASTTokens(self.source_code, parse=True)\n        else:\n            self.atok = None\n\n    def _read_file(self) -> str:\n        try:\n            with open(self.file_path, 'r') as f:\n                return f.read()\n        except FileNotFoundError:\n            raise ValueError(f'File not found: {self.file_path}')\n\n    def _parse_source(self) -> ast.AST:\n        try:\n            return ast.parse(self.source_code)\n        except SyntaxError as e:\n            raise ValueError(f'Invalid Python syntax in {self.file_path}: {e}')\n\n    def _map_nodes(self) -> Dict[str, ast.AST]:\n        nodes = {}\n        for node in ast.walk(self.tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def list_elements(self) -> List[str]:\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        node = self.nodes.get(element_name)\n        return astor.to_source(node) if node else None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"\n        Get detailed structure information about an element including\n        line numbers and internal components.\n        \"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n        \n        structure = {\n            'name': element_name,\n            'type': node.__class__.__name__,\n            'line_start': node.lineno if hasattr(node, 'lineno') else None,\n            'line_end': node.end_lineno if hasattr(node, 'end_lineno') else None,\n            'body_items': []\n        }\n        \n        if hasattr(node, 'body'):\n            for i, item in enumerate(node.body):\n                item_info = {\n                    'index': i,\n                    'type': item.__class__.__name__,\n                    'line_start': item.lineno if hasattr(item, 'lineno') else None,\n                    'line_end': item.end_lineno if hasattr(item, 'end_lineno') else None\n                }\n                \n                # Add more details for common statement types\n                if isinstance(item, ast.Assign) and item.targets:\n                    target = item.targets[0]\n                    if isinstance(target, ast.Name):\n                        item_info['assigns'] = target.id\n                elif isinstance(item, (ast.If, ast.While, ast.For)):\n                    item_info['has_body'] = bool(item.body)\n                elif isinstance(item, ast.Return):\n                    item_info['returns'] = True\n                    \n                structure['body_items'].append(item_info)\n                \n        return structure\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int, line_end: Optional[int] = None) -> Optional[Tuple[int, ast.AST]]:\n        \"\"\"\n        Find a statement in a body by line number range.\n        Returns (index, statement) or None.\n        \"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = stmt.end_lineno if hasattr(stmt, 'end_lineno') else stmt.lineno\n                    if stmt.lineno <= line_start <= stmt_end or stmt.lineno <= line_end <= stmt_end:\n                        return (i, stmt)\n                else:\n                    if stmt.lineno == line_start:\n                        return (i, stmt)\n        return None\n\n    def replace_partial(self, element_name: str, new_code: str, \n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"\n        Replace a partial section of an element (function/class).\n        \n        Args:\n            element_name: Name of the function/class to modify\n            new_code: New code to insert (can be multiple statements)\n            line_start: Starting line number within the element (1-based, absolute)\n            line_end: Ending line number within the element (inclusive)\n            statement_index: Alternative to line numbers - replace the Nth statement\n            \n        Returns:\n            True if successful, False otherwise\n        \"\"\"\n        if element_name not in self.nodes:\n            return False\n            \n        node = self.nodes[element_name]\n        if not hasattr(node, 'body') or not isinstance(node.body, list):\n            return False\n            \n        try:\n            # Parse the new code\n            if new_code.strip().startswith('def ') or new_code.strip().startswith('class '):\n                # If it's a full function/class, extract just the body\n                new_ast = ast.parse(new_code)\n                new_statements = new_ast.body[0].body\n            else:\n                # Parse as a module and get all statements\n                new_ast = ast.parse(new_code)\n                new_statements = new_ast.body\n        except SyntaxError:\n            return False\n            \n        if not new_statements:\n            return False\n            \n        # Find what to replace\n        if statement_index is not None:\n            # Replace by index\n            if 0 <= statement_index < len(node.body):\n                node.body[statement_index:statement_index+1] = new_statements\n                return True\n        elif line_start is not None:\n            # Replace by line number\n            result = self._find_statement_in_body(node.body, line_start, line_end)\n            if result:\n                idx, _ = result\n                if line_end:\n                    # Find end index\n                    end_idx = idx\n                    for i in range(idx + 1, len(node.body)):\n                        stmt = node.body[i]\n                        if hasattr(stmt, 'end_lineno') and stmt.end_lineno <= line_end:\n                            end_idx = i\n                        else:\n                            break\n                    node.body[idx:end_idx+1] = new_statements\n                else:\n                    node.body[idx:idx+1] = new_statements\n                return True\n                \n        return False\n\n    def insert_in_element(self, element_name: str, new_code: str, \n                         position: str = 'end', \n                         after_line: Optional[int] = None,\n                         before_line: Optional[int] = None) -> bool:\n        \"\"\"\n        Insert new code into an element without replacing existing code.\n        \n        Args:\n            element_name: Name of the function/class\n            new_code: Code to insert\n            position: 'start', 'end', or use after_line/before_line\n            after_line: Insert after this line number\n            before_line: Insert before this line number\n            \n        Returns:\n            True if successful\n        \"\"\"\n        if element_name not in self.nodes:\n            return False\n            \n        node = self.nodes[element_name]\n        if not hasattr(node, 'body') or not isinstance(node.body, list):\n            return False\n            \n        try:\n            new_ast = ast.parse(new_code)\n            new_statements = new_ast.body\n        except SyntaxError:\n            return False\n            \n        if not new_statements:\n            return False\n            \n        if position == 'start':\n            node.body[0:0] = new_statements\n        elif position == 'end':\n            node.body.extend(new_statements)\n        elif after_line:\n            result = self._find_statement_in_body(node.body, after_line)\n            if result:\n                idx, _ = result\n                node.body[idx+1:idx+1] = new_statements\n            else:\n                return False\n        elif before_line:\n            result = self._find_statement_in_body(node.body, before_line)\n            if result:\n                idx, _ = result\n                node.body[idx:idx] = new_statements\n            else:\n                return False\n        else:\n            return False\n            \n        return True\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"\n        Get a specific snippet from within an element's body by line numbers.\n        \"\"\"\n        if not self.atok:\n            return None\n            \n        node = self.nodes.get(element_name)\n        if not node or not hasattr(node, 'body'):\n            return None\n            \n        # Find statements in the range\n        statements = []\n        for stmt in node.body:\n            if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                if line_start <= stmt.lineno <= line_end or line_start <= stmt.end_lineno <= line_end:\n                    statements.append(stmt)\n                    \n        if not statements:\n            return None\n            \n        # Generate source for the statements\n        return '\\n'.join(astor.to_source(stmt).strip() for stmt in statements)\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.ImportFrom]]) -> None:\n        \"\"\"Intelligently adds new import nodes to the top of the AST.\"\"\"\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                existing_imports_str.add(astor.to_source(node).strip())\n                last_import_index = i\n        for new_import in reversed(new_import_nodes):\n            new_import_str = astor.to_source(new_import).strip()\n            if new_import_str not in existing_imports_str:\n                self.tree.body.insert(last_import_index + 1, new_import)\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"\n        Replaces a target element with a new block of code.\n\n        This method is more robust than a simple node-for-node replacement.\n        It parses the `new_code`, separates imports (which are moved to the top\n        of the file) from the main code body (functions, classes, variables, etc.),\n        and then replaces the single original element node in the AST with the\n        entire new code body. This allows the AI to return code blocks that\n        include helper constants or other statements along with the primary\n        function or class definition.\n\n        Args:\n            element_name: The name of the function or class to replace.\n            new_code: A string containing the new Python code.\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        if element_name not in self.nodes:\n            return False\n        try:\n            new_ast_module = ast.parse(new_code)\n        except SyntaxError:\n            return False\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n        if not new_code_body:\n            return False\n        if new_imports:\n            self._add_imports(new_imports)\n        for node in ast.walk(self.tree):\n            if hasattr(node, 'body') and isinstance(node.body, list):\n                try:\n                    old_node = self.nodes[element_name]\n                    idx = node.body.index(old_node)\n                    node.body.pop(idx)\n                    for i, new_node in enumerate(new_code_body):\n                        node.body.insert(idx + i, new_node)\n                    del self.nodes[element_name]\n                    for n in new_code_body:\n                        if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                            self.nodes[n.name] = n\n                    return True\n                except (ValueError, KeyError):\n                    continue\n        return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None,\n                   before: bool = False) -> bool:\n        \"\"\"\n        Adds a new block of code (function, class, variables) to the file.\n\n        This method intelligently handles code snippets from the AI. It separates\n        any import statements and adds them to the top of the file. The rest of\n        the code block is inserted at an appropriate location, determined either\n        by an `anchor_name` or by placing it before the main execution block\n        (`if __name__ == '__main__'`).\n\n        Args:\n            new_code: The string containing the new function/class/variables.\n            anchor_name: The name of an existing element to insert relative to.\n            before: If True, insert before the anchor; otherwise, after.\n\n        Returns:\n            True if the element block was added successfully, False otherwise.\n        \"\"\"\n        try:\n            new_ast_module = ast.parse(new_code)\n        except (SyntaxError, IndexError):\n            return False\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n        if not new_code_body:\n            return False\n        if new_imports:\n            self._add_imports(new_imports)\n        insertion_index = -1\n        main_block_idx = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, ast.If) and isinstance(node.test, ast.Compare) and isinstance(node.test.left, ast.Name) and node.test.left.id == '__name__' and len(node.test.ops) == 1 and isinstance(node.test.ops[0], ast.Eq) and len(node.test.comparators) == 1:\n                comp = node.test.comparators[0]\n                if isinstance(comp, ast.Constant) and comp.value == '__main__' or isinstance(comp, ast.Str) and comp.s == '__main__':\n                    main_block_idx = i\n                    break\n        if anchor_name:\n            if anchor_name not in self.nodes:\n                return False\n            anchor_node = self.nodes[anchor_name]\n            try:\n                anchor_idx = self.tree.body.index(anchor_node)\n                proposed_index = anchor_idx if before else anchor_idx + 1\n                if main_block_idx != -1:\n                    insertion_index = min(proposed_index, main_block_idx)\n                else:\n                    insertion_index = proposed_index\n            except ValueError:\n                return False\n        elif main_block_idx != -1:\n            insertion_index = main_block_idx\n        if insertion_index == -1:\n            self.tree.body.extend(new_code_body)\n        else:\n            for i, new_node in enumerate(new_code_body):\n                self.tree.body.insert(insertion_index + i, new_node)\n        for node in new_code_body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                self.nodes[node.name] = node\n        return True\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"\n        Deletes a function, class, variable (ast.Assign), or import (ast.Import/ast.ImportFrom) by its name from the AST.\n        Handles top-level elements primarily, with walking for functions and classes.\n\n        Args:\n            element_name: The name of the element to delete (function, class, variable, or imported name).\n\n        Returns:\n            True if the element was successfully deleted, False otherwise.\n        \"\"\"\n        deleted = False\n        if element_name in self.nodes:\n            node_to_delete = self.nodes[element_name]\n            for node in ast.walk(self.tree):\n                if hasattr(node, 'body') and isinstance(node.body, list):\n                    try:\n                        node.body.remove(node_to_delete)\n                        deleted = True\n                        break\n                    except ValueError:\n                        continue\n            if deleted:\n                del self.nodes[element_name]\n                self.nodes = self._map_nodes()\n                return True\n        new_body = []\n        for node in self.tree.body:\n            if isinstance(node, ast.Assign):\n                match = False\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id == element_name:\n                        match = True\n                        break\n                if match:\n                    deleted = True\n                    continue\n            elif isinstance(node, ast.Import):\n                new_aliases = []\n                for alias in node.names:\n                    if (alias.name == element_name or alias.asname == element_name):\n                        deleted = True\n                    else:\n                        new_aliases.append(alias)\n                if new_aliases:\n                    node.names = new_aliases\n                elif deleted:\n                    continue\n            elif isinstance(node, ast.ImportFrom):\n                new_aliases = []\n                for alias in node.names:\n                    if (alias.name == element_name or alias.asname == element_name):\n                        deleted = True\n                    else:\n                        new_aliases.append(alias)\n                if new_aliases:\n                    node.names = new_aliases\n                elif deleted:\n                    continue\n            new_body.append(node)\n        self.tree.body = new_body\n        if deleted:\n            self.nodes = self._map_nodes()\n        return deleted\n\n    def apply_arbitrary_change(self, new_source_code: str) -> bool:\n        \"\"\"\n        Rewrites the entire file's AST from a new source string.\n\n        This method parses the provided new_source_code into a new AST.\n        If the code is syntactically valid, it replaces the class's internal\n        AST (`self.tree`), remaps the file's nodes, and returns True. If\n        parsing fails, it returns False.\n        \"\"\"\n        try:\n            new_tree = ast.parse(new_source_code)\n            self.tree = new_tree\n            self.nodes = self._map_nodes()\n            # Recreate asttokens if available\n            if ASTTOKENS_AVAILABLE:\n                self.source_code = new_source_code\n                self.atok = asttokens.ASTTokens(self.source_code, parse=True)\n            return True\n        except SyntaxError:\n            return False\n\n    def get_modified_source(self) -> str:\n        return astor.to_source(self.tree)\n\n    def get_diff(self) -> str:\n        modified_source = self.get_modified_source()\n        return ''.join(difflib.unified_diff(\n            self.source_code.splitlines(keepends=True), \n            modified_source.splitlines(keepends=True),\n            fromfile=f'{self.file_path} (original)', \n            tofile=f'{self.file_path} (modified)'\n        ))\n\n    def save_changes(self) -> None:\n        modified_source = self.get_modified_source()\n        with open(self.file_path, 'w') as f:\n            f.write(modified_source)",
    "file": "/mnt/ProjectData/omni/code_editor.py"
  },
  {
    "id": 18,
    "hash": "cc52aa524d0929867d5d2ea3697229e6",
    "content": "\"\"\"\nGenerated file.\n\"\"\"\nimport os\n\"\"\"\nFileCreator - A utility for creating files.\n\nThis module provides a simple, encapsulated way to create files,\nensuring that their parent directories exist before writing.\n\"\"\"\n\n\nclass FileCreator:\n    \"\"\"\n    A utility class to handle the creation of new files.\n    \"\"\"\n\n    @staticmethod\n    def create(file_path: str, content: str) ->None:\n        \"\"\"\n        Creates a file at the specified path with the given content.\n\n        This method will automatically create any necessary parent\n        directories for the file path.\n\n        Args:\n            file_path: The full path where the file should be created.\n            content: The string content to write to the file.\n\n        Raises:\n            IOError: If there is an error creating the directories or writing the file.\n        \"\"\"\n        try:\n            directory = os.path.dirname(file_path)\n            if directory:\n                os.makedirs(directory, exist_ok=True)\n            with open(file_path, 'w', encoding='utf-8') as f:\n                f.write(content)\n        except (IOError, OSError) as e:\n            raise IOError(f\"Failed to create file '{file_path}': {e}\") from e\n",
    "file": "/mnt/ProjectData/omni/file_creator.py"
  },
  {
    "id": 19,
    "hash": "04a24ceab008bd649d0530d309c72e42",
    "content": "import subprocess\nimport os\nfrom typing import List, Optional, Union\n\n\nclass GitManager:\n    \"\"\"\n    Encapsulates Git-related logic for a specific repository.\n\n    This class provides methods to perform common Git operations such as\n    checking status, getting diffs, staging, committing, and pushing changes.\n    It relies on the Git command-line tool being installed and accessible\n    in the system's PATH.\n    \"\"\"\n\n    def __init__(self, repo_path: str):\n        \"\"\"\n        Initializes the GitManager for a given repository path.\n\n        Args:\n            repo_path: The absolute or relative path to the Git repository.\n\n        Raises:\n            ValueError: If the provided path is not a valid Git repository.\n        \"\"\"\n        if not os.path.isdir(os.path.join(repo_path, '.git')):\n            raise ValueError(\n                f\"The path '{repo_path}' is not a valid Git repository.\")\n        self.repo_path = repo_path\n\n    def _run_command(self, command: List[str]) ->str:\n        \"\"\"\n        Executes a Git command in the repository's directory.\n\n        Args:\n            command: A list of command arguments, starting with 'git'.\n\n        Returns:\n            The standard output of the command as a string.\n\n        Raises:\n            subprocess.CalledProcessError: If the command returns a non-zero exit code.\n        \"\"\"\n        try:\n            result = subprocess.run(command, cwd=self.repo_path, check=True,\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True,\n                encoding='utf-8')\n            return result.stdout.strip()\n        except subprocess.CalledProcessError as e:\n            error_message = (\n                f\"Git command failed: {' '.join(command)}\\nError: {e.stderr.strip()}\"\n                )\n            raise subprocess.CalledProcessError(e.returncode, e.cmd, output\n                =e.stdout, stderr=error_message) from e\n\n    def get_status(self) ->str:\n        \"\"\"\n        Gets the repository status in a condensed format.\n\n        Uses `git status --porcelain` for a machine-readable output.\n\n        Returns:\n            A string representing the repository's status.\n        \"\"\"\n        return self._run_command(['git', 'status', '--porcelain'])\n        \n    def get_changed_files(self) -> List[str]:\n        \"\"\"\n        Gets a list of all changed (modified, added, deleted, untracked, renamed, or copied) files.\n\n        This parses the output of `git status --porcelain`, which provides a stable,\n        machine-readable format.\n\n        Returns:\n            A list of file paths relative to the repository root. For renamed or\n            copied files, it returns the new path.\n        \"\"\"\n        status_output = self.get_status()\n        if not status_output:\n            return []\n        \n        changed_files = []\n        for line in status_output.splitlines():\n            if len(line) < 3:  # Skip malformed lines\n                continue\n                \n            # Git status porcelain format: XY filename\n            # X = index status, Y = working tree status\n            index_status = line[0]\n            worktree_status = line[1]\n            \n            # The filename starts after the two status characters and a space\n            # But let's be more defensive about finding where the filename actually starts\n            filename_start = 2\n            while filename_start < len(line) and line[filename_start] == ' ':\n                filename_start += 1\n                \n            if filename_start >= len(line):\n                continue  # Skip if no filename found\n                \n            path_info = line[filename_start:]\n            \n            # Check if either index or working tree status indicates rename/copy\n            if index_status in ('R', 'C') or worktree_status in ('R', 'C'):\n                if ' -> ' in path_info:\n                    _, new_path = path_info.split(' -> ', 1)  # Use maxsplit=1 for safety\n                    changed_files.append(new_path.strip())\n                else:\n                    # Fallback if format is unexpected\n                    changed_files.append(path_info.strip())\n            else:\n                changed_files.append(path_info.strip())\n        \n        # Remove duplicates while preserving order\n        return list(dict.fromkeys(changed_files))\n\n    def get_diff(self, file_path: Optional[str]=None, staged: bool=False\n        ) ->str:\n        \"\"\"\n        Gets the diff of changes in the repository.\n\n        Args:\n            file_path: Optional. Path to a specific file to diff.\n            staged: If True, shows the diff for staged changes (`--cached`).\n                    Otherwise, shows the diff for unstaged changes.\n\n        Returns:\n            The git diff output as a string.\n        \"\"\"\n        cmd = ['git', 'diff']\n        if staged:\n            cmd.append('--cached')\n        if file_path:\n            cmd.append('--')\n            cmd.append(file_path)\n        return self._run_command(cmd)\n\n    def add(self, files: Union[str, List[str]]) ->None:\n        \"\"\"\n    Stages one or more files, handling each one individually for robustness.\n\n    This approach prevents a single invalid file path from causing the\n    entire 'git add' operation to fail. Warnings will be printed for any\n    files that could not be staged.\n\n    Args:\n        files: A single file path or a list of file paths to stage.\n               Can also be '.' to stage all changes.\n    \"\"\"\n        if isinstance(files, str):\n            files = [files]\n        for file_path in files:\n            try:\n                cmd = ['git', 'add', '--', file_path]\n                self._run_command(cmd)\n            except subprocess.CalledProcessError as e:\n                print(\n                    f\"Warning: Could not stage file '{file_path}'. Git reported: {e.stderr}\"\n                    )\n\n    def commit(self, message: str) ->str:\n        \"\"\"\n        Commits staged changes with a given message.\n\n        Args:\n            message: The commit message.\n\n        Returns:\n            The stdout from the git commit command.\n        \"\"\"\n        return self._run_command(['git', 'commit', '-m', message])\n\n    def push(self, remote: str='origin', branch: Optional[str]=None) ->str:\n        \"\"\"\n        Pushes commits to a remote repository.\n\n        Args:\n            remote: The name of the remote to push to (default: 'origin').\n            branch: The branch to push. If None, uses the current branch.\n\n        Returns:\n            The stdout from the git push command.\n        \"\"\"\n        if branch is None:\n            branch = self.get_current_branch()\n        return self._run_command(['git', 'push', remote, branch])\n\n    def get_current_branch(self) ->str:\n        \"\"\"\n        Determines the current active branch name.\n\n        Returns:\n            The name of the current branch.\n        \"\"\"\n        return self._run_command(['git', 'rev-parse', '--abbrev-ref', 'HEAD'])\n",
    "file": "/mnt/ProjectData/omni/git_manager.py"
  },
  {
    "id": 20,
    "hash": "31509b45a6fce6faa59ab9857bf02c0b",
    "content": "import json\nimport os\nfrom typing import List, Dict, Optional\nfrom rag_manager import RAGManager\n\n\nclass MemoryManager:\n    \"\"\"Manages persistent chat memory, look data, and RAG integration via JSON.\"\"\"\n\n    def __init__(self, memory_file: str):\n        self.memory_file = memory_file\n        self.memory: Dict[str, List] = self.load_memory()\n        self.rag_manager = RAGManager()\n\n    def load_memory(self) ->Dict[str, List]:\n        try:\n            with open(self.memory_file, 'r') as f:\n                return json.load(f)\n        except FileNotFoundError:\n            default = {'chat': [], 'look': []}\n            self.save_memory(default)\n            return default\n        except json.JSONDecodeError:\n            print('[yellow]Invalid memory file. Resetting.[/]')\n            return {'chat': [], 'look': []}\n\n    def save_memory(self, memory: Optional[Dict[str, List]]=None) ->None:\n        if memory is None:\n            memory = self.memory\n        with open(self.memory_file, 'w') as f:\n            json.dump(memory, f, indent=4)\n\n    def add_message(self, role: str, content: str) ->None:\n        self.memory['chat'].append({'role': role, 'content': content})\n        self.save_memory()\n\n    def add_look_data(self, file_path: str, content: str) ->None:\n        \"\"\"\n    Adds a watched item (directory or file) to memory, distinguishing its type.\n\n    This method stores structured data that differentiates between a project\n    directory (containing a manifest) and a single file (containing its content).\n    It also prevents duplicate entries by updating existing ones.\n\n    Args:\n        file_path: The path to the directory or file.\n        content: The manifest for a directory or the content for a file.\n    \"\"\"\n        item_type = 'directory' if os.path.isdir(file_path) else 'file'\n        for item in self.memory['look']:\n            if item.get('file') == file_path:\n                item['content'] = content\n                item['type'] = item_type\n                self.save_memory()\n                return\n        self.memory['look'].append({'type': item_type, 'file': file_path,\n            'content': content})\n        self.save_memory()\n        if item_type == 'file':\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    file_content = f.read()\n                self.rag_manager.add_documents([file_content], [{'file':\n                    file_path}])\n            except Exception as e:\n                print(\n                    f'[yellow]Warning: Could not add {file_path} to RAG index: {e}[/]'\n                    )\n\n    def get_project_root(self) -> Optional[str]:\n        \"\"\"\n        Finds the root directory of the project currently in memory.\n\n        The project root is defined as the first item in the 'look' memory\n        that is of type 'directory'.\n\n        Returns:\n            The absolute path to the project root directory, or None if not found.\n        \"\"\"\n        for item in self.memory.get('look', []):\n            if item.get('type') == 'directory':\n                return item.get('file')\n        return None\n\n    def get_memory_context(self) -> str:\n        \"\"\"\n        Dynamically builds the context using RAG and chat history.\n\n        It retrieves relevant file content from the RAG index based on the latest\n        user query, includes project manifests for directories, and appends the\n        recent chat history.\n        \"\"\"\n        context = ''\n        # 1. Add project manifests for any watched directories\n        for look in self.memory.get('look', []):\n            path = look.get('file')\n            if path and os.path.isdir(path):\n                content = look.get('content', '')\n                context += f'--- Project Manifest for {path} ---\\n{content}\\n\\n'\n\n        # 2. Find the last user message to use as a query for the RAG system\n        last_user_message = next((msg['content'] for msg in reversed(self.memory.get('chat', [])) if msg['role'] == 'user'), None)\n\n        # 3. If a user message exists, search the RAG index for relevant context\n        if last_user_message:\n            rag_results = self.search_rag(last_user_message, k=3)\n            if rag_results:\n                context += '--- Relevant context from RAG ---\\n'\n                # Format and add each RAG result to the context\n                for doc, score, meta in rag_results:\n                    file_path = meta.get('file', 'Unknown source')\n                    context += f'Source: {file_path} (Score: {score:.4f})\\n'\n                    context += f'Content: {doc}\\n---\\n'\n                context += '\\n'\n\n        # 4. Append the full chat history for conversational context\n        for msg in self.memory.get('chat', []):\n            context += f\"{msg['role'].capitalize()}: {msg['content']}\\n\"\n\n        return context.strip()\n\n    def clear_memory(self) ->None:\n        self.memory = {'chat': [], 'look': []}\n        self.save_memory()\n        self.rag_manager.clear_index()\n\n    def search_rag(self, query: str, k: int=3) ->List[tuple]:\n        \"\"\"\n        Search the RAG index for relevant documents.\n        \n        Args:\n            query: The search query\n            k: Number of results to return\n            \n        Returns:\n            List of (document_content, score, metadata) tuples\n        \"\"\"\n        return self.rag_manager.search(query, k)",
    "file": "/mnt/ProjectData/omni/memory_manager.py"
  },
  {
    "id": 21,
    "hash": "1b61704bafe182154c395ea08a3acb39",
    "content": "\"\"\"\nOmni - AI-powered code generation and project-aware editing CLI tool\n\nIntegrates modular UI, memory, personality, and AST-based code editing.\n\"\"\"\nimport os\nimport subprocess\nimport requests\nimport json\nimport sys\nimport re\nimport argparse\nimport ast\nfrom datetime import datetime\nimport threading\nimport queue as Queue\nimport time\nfrom typing import List, Dict, Optional\nfrom rich import print\nfrom rich.panel import Panel\nfrom rich.console import Console\nfrom rich.tree import Tree\nfrom ui_manager import UIManager\nfrom personality_manager import PersonalityManager\nfrom memory_manager import MemoryManager\nfrom code_editor import CodeEditor\nfrom file_creator import FileCreator\nfrom git_manager import GitManager\nimport traceback\nDEFAULT_BACKEND = 'openrouter'\nOLLAMA_MODEL = 'phi4-reasoning'\nOPENROUTER_MODEL = 'qwen/qwen3-coder'\nDEFAULT_SAVE_DIR = os.path.expanduser('/mnt/ProjectData/omni/omni_saves/')\nCONFIG_FILE = 'config.json'\nMEMORY_FILE = 'memory.json'\nOLLAMA_API_URL = 'http://localhost:11434/api/generate'\nOPENROUTER_API_URL = 'https://openrouter.ai/api/v1/chat/completions'\nOPENROUTER_MODELS_API_URL = 'https://openrouter.ai/api/v1/models'\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\ncurrent_backend = DEFAULT_BACKEND\ncurrent_model = (OLLAMA_MODEL if DEFAULT_BACKEND == 'ollama' else\n    OPENROUTER_MODEL)\nOLLAMA_MODELS = {'deepseek': 'deepseek-coder:6.7b', 'codellama':\n    'codellama:13b', 'mistral': 'mistral:latest', 'llama2': 'llama2:latest',\n    'phind': 'phind-codellama:34b'}\nos.makedirs(DEFAULT_SAVE_DIR, exist_ok=True)\nTEMPLATES = {'flask':\n    \"\"\"from flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/')\ndef home():\n    return '<h1>Hello, Flask!</h1>'\n\nif __name__ == '__main__':\n    app.run(debug=True)\"\"\"\n    , 'html5':\n    \"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>New Page</title>\n</head>\n<body>\n    <h1>Hello World</h1>\n</body>\n</html>\"\"\"\n    , 'scraper':\n    \"\"\"import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        print(soup.title.text)\n    except Exception as e:\n        print(f\"[bold red]Error scraping {url}:[/] {e}\")\n\nif __name__ == \"__main__\":\n    scrape(\"https://example.com\")\"\"\"\n    }\nconsole = Console()\npersonality_manager = PersonalityManager(CONFIG_FILE)\nmemory_manager = MemoryManager(MEMORY_FILE)\nui_manager = UIManager()\nlast_query: Optional[str] = None\nlast_response: Optional[str] = None\nlast_code: Optional[str] = None\n\n\ndef start_ollama_server() ->None:\n    if current_backend != 'ollama':\n        return\n    try:\n        requests.get('http://localhost:11434', timeout=1)\n    except requests.exceptions.ConnectionError:\n        print('[cyan]Starting Ollama server...[/]')\n        subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL)\n\n\ndef query_llm(prompt: str) ->str:\n    personality = personality_manager.get_current_personality()\n    system_prompt = personality.get('system_prompt', '') if personality else ''\n    memory_context = memory_manager.get_memory_context()\n    rag_context = ''\n    try:\n        from rag_manager import RAGManager\n        project_root = memory_manager.get_project_root()\n        if project_root:\n            rag_manager = RAGManager()\n            if rag_manager.get_document_count() > 0:\n                results = rag_manager.search(prompt, k=3)\n                if results:\n                    rag_context = '\\n\\nRelevant context from codebase:\\n'\n                    for i, (doc, score, meta) in enumerate(results, 1):\n                        file_path = meta.get('file', 'Unknown')\n                        rag_context += f'{i}. [{file_path}] {doc}\\n'\n    except Exception:\n        pass\n    full_prompt = (\n        f'{system_prompt}\\n\\n{memory_context}{rag_context}\\n\\nUser: {prompt}')\n    with ui_manager.show_spinner('AI is listening and thinking...'):\n        if current_backend == 'ollama':\n            response = query_ollama(full_prompt)\n        elif current_backend == 'openrouter':\n            response = query_openrouter(full_prompt)\n        else:\n            response = '[bold red]Error:[/] Unknown backend'\n    return response\n\n\ndef query_openrouter(prompt: str) ->str:\n    if not OPENROUTER_API_KEY:\n        return '[bold red]Error:[/] OPENROUTER_API_KEY not set.'\n    headers = {'Authorization': f'Bearer {OPENROUTER_API_KEY}',\n        'Content-Type': 'application/json'}\n    payload = {'model': current_model, 'messages': [{'role': 'user',\n        'content': prompt}]}\n    try:\n        response = requests.post(OPENROUTER_API_URL, headers=headers, json=\n            payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['choices'][0]['message']['content']\n    except Exception as e:\n        error_details = ''\n        try:\n            error_details = response.json()\n        except:\n            error_details = response.text if hasattr(response, 'text'\n                ) else str(e)\n        return (\n            f'[bold red]OpenRouter Error:[/] {e}\\n[dim]Details: {error_details}[/dim]'\n            )\n\n\ndef query_ollama(prompt: str) ->str:\n    payload = {'model': current_model, 'prompt': prompt, 'stream': False}\n    try:\n        response = requests.post(OLLAMA_API_URL, json=payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['response']\n    except Exception as e:\n        return f'[bold red]Ollama Error:[/] {e}'\n\n\ndef extract_code(text: str) ->List[tuple[str, str]]:\n    matches = re.findall('```(\\\\w*)\\\\n([\\\\s\\\\S]*?)```', text)\n    return [(lang or 'text', code.strip()) for lang, code in matches\n        ] if matches else []\n\n\ndef list_models(args: list=None) ->None:\n    if current_backend == 'ollama':\n        print('[bold cyan]Popular Ollama Models:[/]')\n        for name, model_id in OLLAMA_MODELS.items():\n            print(\n                f\"{'\u2b50' if model_id == current_model else '  '} [yellow]{name:12}[/] \u2192 {model_id}\"\n                )\n    elif current_backend == 'openrouter':\n        list_openrouter_models(args or [])\n\n\ndef list_openrouter_models(args: list):\n    try:\n        from simple_term_menu import TerminalMenu\n    except ImportError:\n        ui_manager.show_error(\n            \"'simple-term-menu' is required. `pip install simple-term-menu`\")\n        return\n    try:\n        with ui_manager.show_spinner('Fetching models...'):\n            response = requests.get(OPENROUTER_MODELS_API_URL)\n            response.raise_for_status()\n        api_models_data = response.json().get('data', [])\n    except requests.RequestException as e:\n        ui_manager.show_error(f'Error fetching models: {e}')\n        return\n    all_models, sources = [], set()\n    for model_data in api_models_data:\n        if (model_id := model_data.get('id')):\n            sources.add(model_id.split('/')[0])\n            pricing = model_data.get('pricing', {})\n            is_free = pricing.get('prompt') == '0' and pricing.get('completion'\n                ) == '0'\n            all_models.append({'id': model_id, 'name': model_data.get(\n                'name'), 'source': model_id.split('/')[0], 'is_free': is_free})\n    all_models.sort(key=lambda x: (x['source'], x['name']))\n    if args and args[0].lower() == 'sources':\n        print('[bold cyan]Available Model Sources:[/]')\n        [print(f'  [yellow]{s}[/]') for s in sorted(list(sources))]\n        return\n    models_to_display, title = all_models, 'Select an OpenRouter Model'\n    if args:\n        filter_keyword = args[0].lower()\n        title = f\"Select a Model from '{filter_keyword}'\"\n        models_to_display = [m for m in all_models if filter_keyword in m[\n            'source'].lower()]\n        if not models_to_display:\n            ui_manager.show_error(f\"No models for source: '{filter_keyword}'\")\n            return\n    menu_entries = [\n        f\"{'\u2b50' if m['id'] == current_model else '  '} {m['name']} [dim]({m['id']}){' [green](FREE)[/]' if m['is_free'] else ''}[/dim]\"\n         for m in models_to_display]\n    try:\n        cursor_idx = next((i for i, m in enumerate(models_to_display) if m[\n            'id'] == current_model), 0)\n        chosen_index = TerminalMenu(menu_entries, title=f'{title}',\n            cursor_index=cursor_idx, cycle_cursor=True, clear_screen=True\n            ).show()\n        if chosen_index is not None:\n            set_model(models_to_display[chosen_index]['id'])\n        else:\n            print('Model selection cancelled.')\n    except Exception as e:\n        ui_manager.show_error(f'Menu display error: {e}')\n\n\ndef set_model(model_id: str) ->None:\n    global current_model\n    current_model = model_id\n    ui_manager.show_success(f'Model set to: {current_model}')\n\n\ndef switch_backend(backend_name: str) ->None:\n    global current_backend, current_model\n    backend_name = backend_name.lower()\n    if backend_name not in ['ollama', 'openrouter']:\n        ui_manager.show_error(f'Unknown backend: {backend_name}')\n        return\n    current_backend = backend_name\n    current_model = (OLLAMA_MODEL if backend_name == 'ollama' else\n        OPENROUTER_MODEL)\n    ui_manager.show_success(\n        f'Switched to {backend_name} backend with model: {current_model}')\n    if backend_name == 'ollama':\n        start_ollama_server()\n\n\ndef generate_project_manifest(path: str) ->tuple[str, List[str]]:\n    manifest = ''\n    file_paths = []\n    tree = Tree(f'[bold cyan]Project: {os.path.basename(path)}[/]')\n    exclude_dirs = {'__pycache__', '.git', 'venv', 'node_modules', '.idea'}\n    for root, dirs, files in os.walk(path):\n        dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.\n            startswith('.')]\n        relative_path = os.path.relpath(root, path)\n        branch = tree\n        if relative_path != '.':\n            parts = relative_path.split(os.sep)\n            for part in parts:\n                child = next((c for c in branch.children if c.label ==\n                    f'[magenta]{part}[/]'), None)\n                if not child:\n                    child = branch.add(f'[magenta]{part}[/]')\n                branch = child\n        for fname in sorted(files):\n            ext = os.path.splitext(fname)[1]\n            if ext not in ('.py', '.js', '.html', '.css', '.md', '.txt'):\n                continue\n            rel_path = os.path.join(relative_path, fname\n                ) if relative_path != '.' else fname\n            file_paths.append(rel_path)\n            branch.add(f'[green]{fname}[/]' if ext == '.py' else\n                f'[dim]{fname}[/]')\n            manifest += f'File: {rel_path}\\n\\n'\n    console.print(tree)\n    return manifest.strip(), file_paths\n\n\ndef look_command(path: str) ->None:\n    \"\"\"\n    Scans a directory or file and loads it into memory. It can resolve paths\n    relative to the current working directory or the project root in memory.\n    If a new directory is scanned, the previous 'look' context is cleared\n    to ensure the context remains relevant.\n    \"\"\"\n    resolved_path = resolve_file_path(path)\n    if not resolved_path:\n        ui_manager.show_error(f'\u274c Path not found: {path}')\n        return\n    if resolved_path != os.path.abspath(path):\n        ui_manager.show_success(\n            f\"Found '{path}' in project. Using: {resolved_path}\")\n    if os.path.isdir(resolved_path):\n        ui_manager.show_success(\n            \"New project directory detected. Clearing previous 'look' context.\"\n            )\n        memory_manager.memory['look'] = []\n        with ui_manager.show_spinner('Generating project manifest...'):\n            manifest = generate_project_manifest(resolved_path)\n        memory_manager.add_look_data(resolved_path, manifest)\n        ui_manager.show_success('\u2705 Project manifest added to memory.')\n    else:\n        try:\n            with ui_manager.show_spinner('Loading file...'):\n                with open(resolved_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n            for item in memory_manager.memory['look']:\n                if item.get('file') == resolved_path:\n                    item['content'] = content\n                    memory_manager.save_memory()\n                    ui_manager.show_success(\n                        '\u2705 Refreshed file content in memory.')\n                    return\n            memory_manager.add_look_data(resolved_path, content)\n            ui_manager.show_success('\u2705 File content added to memory.')\n        except Exception as e:\n            ui_manager.show_error(f'\u274c Error reading file: {e}')\n\n\ndef resolve_file_path(path: str) ->Optional[str]:\n    \"\"\"Resolves a file path, checking CWD first, then against project root in memory.\"\"\"\n    if os.path.exists(path):\n        return os.path.abspath(path)\n    project_root = memory_manager.get_project_root()\n    if project_root:\n        full_path = os.path.join(project_root, path)\n        if os.path.exists(full_path):\n            return full_path\n    return None\n\n\ndef _create_prompt_for_file_creation(file_name: str, instruction: str) ->str:\n    \"\"\"\n    Generate a robust prompt for file creation that instructs the AI to act as an expert,\n    produce complete and clean code, and avoid any extra commentary.\n    \"\"\"\n    return f\"\"\"You are an expert programmer tasked with creating a new file. Your goal is to generate complete, production-ready content based on the user's instruction.\n\nIMPORTANT RULES:\n- Provide ONLY the raw file content - no explanations, notes, or commentary outside the file itself\n- Include all necessary imports, boilerplate, and complete implementations\n- If creating code, ensure it's syntactically correct and follows best practices\n- For configuration files, use appropriate formatting (JSON, YAML, etc.)\n- For documentation files, use proper markdown formatting\n\nFile to create: {file_name}\nUser instruction: {instruction}\n\nGenerate the complete file content now:\"\"\"\n\n\ndef handle_file_create_command(file_path: str, instruction: str):\n    \"\"\"\n    Uses the LLM to generate content for a new file based on an instruction.\n    \"\"\"\n    global last_code\n    if os.path.exists(file_path):\n        if ui_manager.get_user_input(\n            f\"File '{file_path}' already exists. Overwrite? (y/n): \").lower(\n            ) not in ['yes', 'y']:\n            ui_manager.show_error('File creation cancelled.')\n            return\n    prompt = _create_prompt_for_file_creation(os.path.basename(file_path),\n        instruction)\n    with ui_manager.show_spinner(\n        f\"AI is generating content for '{file_path}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    if code_blocks:\n        new_content = code_blocks[0][1]\n    else:\n        new_content = response.strip()\n    if not new_content:\n        ui_manager.show_error('AI did not return any content.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    print(Panel(new_content, title=\n        f'[bold yellow]Proposed content for {file_path}[/]', border_style=\n        'yellow'))\n    if ui_manager.get_user_input('Create this file? (y/n): ').lower() in ['yes'\n        , 'y']:\n        try:\n            FileCreator.create(file_path, new_content)\n            last_code = new_content\n            ui_manager.show_success(f'File created successfully: {file_path}')\n        except IOError as e:\n            ui_manager.show_error(f'Error creating file: {e}')\n    else:\n        ui_manager.show_error('File creation cancelled.')\n\n\ndef look_all_command() ->None:\n    \"\"\"\n    Finds the project manifest in memory, reads every file listed, and adds their content to memory.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first to generate a manifest.\"\n            )\n        return\n    manifest_data = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and item.get('type'\n            ) == 'directory':\n            manifest_data = item.get('content')\n            break\n    if not manifest_data or not isinstance(manifest_data, (list, tuple)\n        ) or len(manifest_data) != 2:\n        ui_manager.show_error(\n            \"Could not find a valid project manifest in memory. Please run 'look <directory>' again.\"\n            )\n        return\n    file_paths = manifest_data[1]\n    if not file_paths:\n        ui_manager.show_error('No files found in the project manifest.')\n        return\n    total_files = len(file_paths)\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Loading {total_files} files from project manifest...'):\n        for file_path_relative in file_paths:\n            full_path = os.path.join(project_root, file_path_relative)\n            if os.path.isfile(full_path):\n                try:\n                    with open(full_path, 'r', encoding='utf-8') as f:\n                        content = f.read().strip()\n                    if not any(look['file'] == full_path for look in\n                        memory_manager.memory['look']):\n                        memory_manager.add_look_data(full_path, content)\n                        loaded_count += 1\n                except Exception as e:\n                    print(\n                        f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\"\n                        )\n    ui_manager.show_success(\n        f'\u2705 Loaded content for {loaded_count} new files into memory.')\n\n\ndef _load_all_project_files_if_needed():\n    \"\"\"\n    Checks if a project is loaded and automatically loads any files from its\n    manifest that are not already in the 'look' memory. This ensures a\n    complete context for editing and refactoring commands.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        return\n    manifest_content = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and 'File:' in item.get('content',\n            ''):\n            manifest_content = item['content']\n            break\n    if not manifest_content:\n        return\n    existing_file_paths = {item['file'] for item in memory_manager.memory.\n        get('look', []) if item.get('type') == 'file'}\n    file_paths_relative = re.findall('File: (.*)', manifest_content)\n    files_to_load = []\n    for rel_path in file_paths_relative:\n        full_path = os.path.join(project_root, rel_path)\n        if full_path not in existing_file_paths and os.path.isfile(full_path):\n            files_to_load.append((full_path, rel_path))\n    if not files_to_load:\n        return\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Auto-loading {len(files_to_load)} project files for context...'):\n        for full_path, file_path_relative in files_to_load:\n            try:\n                with open(full_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n                memory_manager.add_look_data(full_path, content)\n                loaded_count += 1\n            except Exception as e:\n                print(f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\")\n    if loaded_count > 0:\n        ui_manager.show_success(\n            f'\u2705 Loaded {loaded_count} new file(s) into memory for full project context.'\n            )\n\n\ndef _create_prompt_for_element_selection(file_name: str, instruction: str,\n    elements: List[str], element_structures: Dict[str, Dict]) ->str:\n    \"\"\"\n    Create a helper for the first stage of the 'edit' command. This prompt asks the AI\n    to analyze the user's instruction and intelligently select the most relevant code element to modify.\n    \"\"\"\n    element_details = []\n    for elem in elements:\n        if elem in element_structures:\n            struct = element_structures[elem]\n            detail = (\n                f\"{elem} ({struct['type']}, lines {struct['line_start']}-{struct['line_end']})\"\n                )\n            element_details.append(detail)\n        else:\n            element_details.append(elem)\n    return f\"\"\"You are an expert code analyzer. Your task is to identify what should be modified based on the user's instruction.\n\nFile: {file_name}\nAvailable elements: {', '.join(element_details) if element_details else 'None'}\n\nUser instruction: {instruction}\n\nRESPONSE FORMAT:\nChoose one of these response types:\n1. \"ELEMENT: <element_name>\" - to edit an entire function/class\n2. \"PARTIAL: <element_name> LINES: <start>-<end>\" - to edit specific lines within an element\n3. \"FILE\" - to edit the entire file or multiple elements\n\nRULES:\n- If the instruction mentions specific line numbers or a specific part of a function, use PARTIAL\n- If the instruction targets an entire function/class, use ELEMENT\n- If the instruction requires changes to multiple elements or file structure, use FILE\n- For PARTIAL edits, provide absolute line numbers from the original file\n\nWhat should be edited?\"\"\"\n\n\ndef _create_prompt_for_element_rewrite(file_name: str, element_name: str,\n    instruction: str, original_code: str, is_full_file: bool=False) ->str:\n    \"\"\"\n    Create a helper for the second stage of the 'edit' command. This prompt instructs the AI\n    to rewrite a specific code element (or the whole file) based on the user's request,\n    demanding a complete and syntactically correct code block as output.\n    \"\"\"\n    if is_full_file:\n        return f\"\"\"You are an expert programmer. Rewrite the entire file to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the entire file\n- Ensure all syntax is correct and the code is ready to run\n- Preserve existing functionality unless explicitly asked to change it\n- Include all necessary imports and maintain the file's structure\n- Do NOT include any explanations or comments outside the code\n\nFile: {file_name}\nTask: {instruction}\n\nCurrent file content:\n```python\n{original_code}\n```\n\nGenerate the complete updated file now:\"\"\"\n    else:\n        return f\"\"\"You are an expert programmer. Rewrite the specified element to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the element\n- Include any necessary imports at the top of your code block\n- Ensure the code is syntactically correct and maintains the same interface\n- Do NOT include explanations or comments outside the code block\n- The code must be a drop-in replacement for the original element\n\nFile: {file_name}\nElement to modify: {element_name}\nTask: {instruction}\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the complete updated element now:\"\"\"\n\n\ndef _create_prompt_for_partial_edit(file_name: str, element_name: str,\n    instruction: str, original_snippet: str, line_start: int, line_end: int,\n    full_element_code: str) ->str:\n    \"\"\"\n    Create a prompt for partial edits within a function or class.\n    This allows surgical changes to specific parts of code.\n    \"\"\"\n    return f\"\"\"You are an expert programmer. Make a surgical edit to a specific part of a function/class.\n\nCONTEXT:\n- File: {file_name}\n- Element: {element_name}\n- Lines to modify: {line_start}-{line_end}\n- Task: {instruction}\n\nIMPORTANT RULES:\n- Provide ONLY the code that will replace lines {line_start}-{line_end}\n- Your code must fit seamlessly into the existing function\n- Maintain proper indentation (the code will be auto-indented)\n- Do NOT include the function definition or other parts\n- Do NOT include explanations outside the code\n\nFull element for context:\n```python\n{full_element_code}\n```\n\nCode section to replace (lines {line_start}-{line_end}):\n```python\n{original_snippet}\n```\n\nGenerate ONLY the replacement code for the specified lines:\"\"\"\n\n\ndef handle_file_edit_command(file_path: str, instruction: str):\n    \"\"\"\n    Handles the entire workflow for editing a single file, ensuring full\n    project context is loaded before the AI makes any decisions.\n    Now supports partial edits within functions.\n    \"\"\"\n    global last_code\n    _load_all_project_files_if_needed()\n    resolved_path = resolve_file_path(file_path)\n    if not resolved_path:\n        ui_manager.show_error(f'File not found: {file_path}')\n        return\n    if resolved_path != os.path.abspath(file_path):\n        ui_manager.show_success(\n            f\"Found '{file_path}' in project. Using: {resolved_path}\")\n    try:\n        editor = CodeEditor(resolved_path)\n    except (ValueError, FileNotFoundError) as e:\n        ui_manager.show_error(str(e))\n        return\n    elements = editor.list_elements()\n    element_structures = {}\n    for elem in elements:\n        struct = editor.get_element_structure(elem)\n        if struct:\n            element_structures[elem] = struct\n    prompt1 = _create_prompt_for_element_selection(os.path.basename(\n        resolved_path), instruction, elements, element_structures)\n    with ui_manager.show_spinner('AI is analyzing file...'):\n        ai_response = query_llm(prompt1).strip()\n    if ai_response.upper() == 'FILE':\n        ui_manager.show_success('AI has chosen to edit the entire file.')\n        original_snippet = editor.source_code\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), 'entire file', instruction, original_snippet,\n            is_full_file=True)\n        edit_type = 'FILE'\n        element_to_edit = None\n        line_range = None\n    elif ai_response.startswith('PARTIAL:'):\n        parts = ai_response.split()\n        element_to_edit = parts[1]\n        if 'LINES:' in ai_response:\n            line_part = ai_response.split('LINES:')[1].strip()\n            if '-' in line_part:\n                line_start, line_end = map(int, line_part.split('-'))\n                line_range = line_start, line_end\n            else:\n                ui_manager.show_error('Invalid line range format')\n                return\n        else:\n            ui_manager.show_error('Missing line range for partial edit')\n            return\n        if element_to_edit not in elements:\n            ui_manager.show_error(f\"Element '{element_to_edit}' not found\")\n            return\n        ui_manager.show_success(\n            f\"AI selected partial edit of '{element_to_edit}' (lines {line_start}-{line_end})\"\n            )\n        original_snippet = editor.get_element_body_snippet(element_to_edit,\n            line_start, line_end)\n        if not original_snippet:\n            original_snippet = editor.get_source_of(element_to_edit)\n        full_element_code = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_partial_edit(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet,\n            line_start, line_end, full_element_code)\n        edit_type = 'PARTIAL'\n    elif ai_response.startswith('ELEMENT:'):\n        element_to_edit = ai_response.split(':', 1)[1].strip()\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    else:\n        element_to_edit = ai_response.splitlines()[0]\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    with ui_manager.show_spinner(f'AI is editing...'):\n        response = query_llm(prompt2)\n    code_blocks = extract_code(response)\n    if not code_blocks:\n        ui_manager.show_error('AI did not return a valid code block.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    new_code = code_blocks[0][1]\n    success = False\n    if edit_type == 'FILE':\n        try:\n            editor.tree = ast.parse(new_code)\n            success = True\n        except SyntaxError as e:\n            ui_manager.show_error(f'AI returned invalid Python syntax: {e}')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    elif edit_type == 'PARTIAL':\n        success = editor.replace_partial(element_to_edit, new_code,\n            line_start=line_range[0], line_end=line_range[1])\n        if not success:\n            ui_manager.show_error('Failed to apply partial edit.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    else:\n        success = editor.replace_element(element_to_edit, new_code)\n        if not success:\n            ui_manager.show_error(\n                'AI returned invalid code; could not be parsed or applied.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    if not (diff := editor.get_diff()):\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(diff, title=\n        f'[bold yellow]Proposed Changes for {resolved_path}[/]'))\n    if ui_manager.get_user_input('Apply changes? (y/n): ').lower() in ['yes',\n        'y']:\n        editor.save_changes()\n        last_code = editor.get_modified_source()\n        ui_manager.show_success(f'Changes saved to {resolved_path}.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_plan(instruction: str, memory_context: str\n    ) ->str:\n    \"\"\"\n    Create a specialized prompt-generation function for the 'refactor' command.\n    This prompt will explicitly define the required JSON structure for the plan\n    and instruct the AI to act as an expert project manager.\n    \"\"\"\n    return f\"\"\"You are an expert project manager and software architect. Analyze the project context and create a detailed refactoring plan.\n\nYour plan must be a valid JSON object with this exact structure:\n{{\n    \"actions\": [\n        {{\n            \"type\": \"MODIFY\" | \"CREATE\" | \"DELETE\" | \"PARTIAL\",\n            \"file\": \"relative/path/to/file.py\",\n            \"element\": \"function_or_class_name\",  // For MODIFY/DELETE/PARTIAL\n            \"element_name\": \"new_element_name\",    // For CREATE\n            \"line_start\": 10,                      // For PARTIAL only\n            \"line_end\": 20,                        // For PARTIAL only\n            \"reason\": \"Clear explanation of why this change is needed\",\n            \"description\": \"What this action will accomplish\",\n            \"anchor_element\": \"optional_anchor\",   // Optional for CREATE\n            \"position\": \"before\" | \"after\"         // Optional for CREATE\n        }}\n    ]\n}}\n\nACTION TYPES:\n- MODIFY: Change an entire function, class, or method\n- PARTIAL: Change specific lines within a function/class (requires line_start and line_end)\n- CREATE: Add new functions, classes, or files\n- DELETE: Remove functions, classes, variables, or imports\n\nRULES FOR YOUR PLAN:\n- Use PARTIAL when you only need to change a small part of a function\n- Use MODIFY when restructuring an entire function or class\n- Each action must have all required fields based on its type\n- File paths must be relative to the project root\n- Be specific and surgical - avoid unnecessary changes\n- Consider dependencies between changes\n- Order actions logically (e.g., create dependencies before using them)\n\n### Project Context ###\n{memory_context}\n\n### Refactoring Request ###\n{instruction}\n\nGenerate ONLY the JSON plan - no explanations or markdown:\"\"\"\n\n\ndef _get_refactor_plan(instruction: str) ->Optional[List[Dict]]:\n    \"\"\"\n    Generates a refactoring plan from the LLM.\n\n    This function encapsulates the logic for checking project context,\n    constructing a prompt, querying the LLM, and parsing the resulting\n    JSON plan for a refactoring task.\n\n    Args:\n        instruction: The user's high-level refactoring instruction.\n\n    Returns:\n        A list of action dictionaries if a valid plan is generated,\n        otherwise None.\n    \"\"\"\n    if not memory_manager.get_project_root():\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return None\n    memory_context = memory_manager.get_memory_context()\n    plan_prompt = _create_prompt_for_refactor_plan(instruction, memory_context)\n    with ui_manager.show_spinner('AI is creating an execution plan...'):\n        plan_str = query_llm(plan_prompt)\n    try:\n        match = re.search('\\\\{.*\\\\}', plan_str, re.DOTALL)\n        if not match:\n            raise ValueError('No JSON object found in the response.')\n        plan = json.loads(match.group(0))\n        actions = plan.get('actions', [])\n        if not actions:\n            raise ValueError(\"No 'actions' key found in plan or plan is empty.\"\n                )\n        return actions\n    except (json.JSONDecodeError, ValueError) as e:\n        ui_manager.show_error(f'AI failed to generate a valid plan: {e}')\n        print(Panel(plan_str, title=\"[yellow]AI's Invalid Plan Response[/]\",\n            border_style='yellow'))\n        return None\n\n\ndef _display_and_confirm_plan(plan: Dict) ->bool:\n    \"\"\"\n    Displays the generated execution plan to the user and asks for confirmation.\n\n    This helper function separates the UI interaction of plan confirmation from\n    the main refactoring logic.\n\n    Args:\n        plan: A dictionary, expected to contain an 'actions' key with a list of action dicts.\n\n    Returns:\n        True if the user confirms the plan, False otherwise.\n    \"\"\"\n    actions = plan.get('actions', [])\n    if not actions:\n        ui_manager.show_error('The generated plan is empty. Aborting.')\n        return False\n    ui_manager.show_success('AI has created a plan:')\n    for i, action in enumerate(actions):\n        action_type = action.get('type', 'N/A')\n        element = action.get('element') or action.get('element_name', 'N/A')\n        reason = action.get('reason') or action.get('description', '')\n        file_path = action.get('file', '')\n        if action_type == 'PARTIAL':\n            line_start = action.get('line_start', '?')\n            line_end = action.get('line_end', '?')\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} (lines {line_start}-{line_end}) - {reason}'\n                )\n        else:\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} - {reason}'\n                )\n    if ui_manager.get_user_input('\\nProceed with this plan? (y/n): ').lower(\n        ) in ['yes', 'y']:\n        return True\n    else:\n        ui_manager.show_error('Execution aborted by user.')\n        return False\n\n\ndef _apply_refactor_changes(editors: Dict[str, CodeEditor]) ->None:\n    \"\"\"\n    Consolidates changes from multiple CodeEditor instances, shows a unified\n    diff, and prompts the user to apply them.\n    \n    This helper function abstracts the final step of a refactor, ensuring\n    all proposed modifications are presented to the user for a final review\n    before any files are written to disk.\n\n    Args:\n        editors: A dictionary mapping absolute file paths to their\n                 corresponding CodeEditor instances which hold the\n                 proposed changes in their AST.\n    \"\"\"\n    full_diff = ''\n    for editor in editors.values():\n        diff = editor.get_diff()\n        if diff:\n            full_diff += diff + '\\n'\n    if not full_diff.strip():\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(full_diff, title=\n        '[bold yellow]Proposed Project-Wide Changes[/]'))\n    if ui_manager.get_user_input('Apply all changes? (y/n): ').lower() in [\n        'yes', 'y']:\n        for editor in editors.values():\n            editor.save_changes()\n        ui_manager.show_success('\u2705 Project changes applied successfully.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_action(action_type: str, file_path: str,\n    action_details: Dict) ->str:\n    \"\"\"\n    Create a helper to generate prompts for individual 'CREATE' or 'MODIFY' steps\n    within a refactor plan. This ensures the AI produces code for the specific\n    sub-task in the correct context.\n    \"\"\"\n    if action_type == 'MODIFY':\n        element_name = action_details['element_name']\n        reason = action_details['reason']\n        original_code = action_details['original_code']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- Element: {element_name}\n- Reason for change: {reason}\n\nRULES:\n- Provide ONLY the complete updated code for the element\n- Include any necessary imports at the top\n- Ensure the code integrates properly with the rest of the file\n- Maintain the same function/class signature unless the change requires otherwise\n- No explanations outside the code block\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the updated element code:\"\"\"\n    elif action_type == 'CREATE':\n        element_name = action_details['element_name']\n        description = action_details['description']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- New element to create: {element_name}\n- Purpose: {description}\n\nRULES:\n- Provide ONLY the complete code for the new element\n- Include all necessary imports at the top\n- Follow the coding style and patterns used in the project\n- Ensure the code is production-ready and well-structured\n- For non-Python files, provide the complete file content\n- No explanations outside the code block\n\nGenerate the new element code:\"\"\"\n\n\ndef _process_refactor_action(action: Dict, project_base_path: str, editors:\n    Dict) ->bool:\n    \"\"\"\n    Processes a single refactoring action from the plan.\n\n    This function handles the execution of a single action from the refactoring plan,\n    including LLM code generation and applying changes to in-memory editors or files.\n\n    Args:\n        action: A dictionary containing action details (type, file, element, etc.)\n        project_base_path: The absolute path to the project root\n        editors: Dictionary mapping file paths to their CodeEditor instances\n\n    Returns:\n        True if the action was processed successfully, False otherwise\n    \"\"\"\n    file_path_relative = action.get('file')\n    if not file_path_relative:\n        ui_manager.show_error(\n            f\"Action is missing 'file' key. Skipping: {action}\")\n        return False\n    file_path_absolute = os.path.join(project_base_path, file_path_relative)\n    action_type = action.get('type', '').upper()\n    prompt, element_name = '', ''\n    if action_type == 'MODIFY':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_source_of(element_name)\n            if not original_snippet:\n                ui_manager.show_error(\n                    f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                    )\n                return False\n            action_details = {'element_name': element_name, 'reason':\n                reason, 'original_code': original_snippet}\n            prompt = _create_prompt_for_refactor_action('MODIFY',\n                file_path_relative, action_details)\n    elif action_type == 'PARTIAL':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        line_start = action.get('line_start')\n        line_end = action.get('line_end')\n        if not all([element_name, line_start, line_end]):\n            ui_manager.show_error(\n                f'PARTIAL action missing required fields. Skipping: {action}')\n            return False\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_element_body_snippet(element_name,\n                line_start, line_end)\n            if not original_snippet:\n                original_snippet = editor.get_source_of(element_name)\n                if not original_snippet:\n                    ui_manager.show_error(\n                        f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                        )\n                    return False\n            full_element_code = editor.get_source_of(element_name)\n            prompt = _create_prompt_for_partial_edit(file_path_relative,\n                element_name, reason, original_snippet, line_start,\n                line_end, full_element_code)\n    elif action_type == 'CREATE':\n        element_name = action.get('element_name')\n        description = action.get('description')\n        action_details = {'element_name': element_name, 'description':\n            description}\n        prompt = _create_prompt_for_refactor_action('CREATE',\n            file_path_relative, action_details)\n    else:\n        ui_manager.show_error(f\"Invalid action type '{action_type}'. Skipping.\"\n            )\n        return False\n    with ui_manager.show_spinner(\n        f\"AI: {action_type} on '{element_name or file_path_relative}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    new_content = code_blocks[0][1] if code_blocks else response.strip()\n    if not new_content:\n        ui_manager.show_error(\n            f'AI failed to generate content for action: {action}')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return False\n    if not file_path_relative.endswith('.py'):\n        try:\n            FileCreator.create(file_path_absolute, new_content)\n            ui_manager.show_success(\n                f\"File '{file_path_relative}' created/updated.\")\n            return True\n        except IOError as e:\n            ui_manager.show_error(\n                f\"Failed to create file '{file_path_relative}': {e}\")\n            return False\n    if file_path_absolute not in editors:\n        try:\n            if not os.path.exists(file_path_absolute):\n                os.makedirs(os.path.dirname(file_path_absolute), exist_ok=True)\n                with open(file_path_absolute, 'w') as f:\n                    f.write('')\n            editors[file_path_absolute] = CodeEditor(file_path_absolute)\n        except Exception as e:\n            ui_manager.show_error(\n                f'Error loading file {file_path_absolute}: {e}')\n            return False\n    editor = editors[file_path_absolute]\n    if action_type == 'MODIFY':\n        if not editor.replace_element(element_name, new_content):\n            ui_manager.show_error(\n                f\"Failed to apply MODIFY change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic MODIFY Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'PARTIAL':\n        if not editor.replace_partial(element_name, new_content, line_start,\n            line_end):\n            ui_manager.show_error(\n                f\"Failed to apply PARTIAL change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic PARTIAL Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'CREATE':\n        anchor = action.get('anchor_element')\n        position = action.get('position', 'after')\n        if not editor.add_element(new_content, anchor_name=anchor, before=\n            position == 'before'):\n            ui_manager.show_error(\n                f\"Failed to apply CREATE change for '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic CREATE Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    return True\n\n\ndef handle_project_refactor_command(instruction: str):\n    \"\"\"\n    Orchestrates a multi-file, multi-step code refactoring process.\n    \n    This function serves as a high-level orchestrator that delegates specific tasks\n    to helper functions, improving readability, modularity, and maintainability.\n    \"\"\"\n    _load_all_project_files_if_needed()\n    actions = _get_refactor_plan(instruction)\n    if not actions:\n        return\n    plan = {'actions': actions}\n    if not _display_and_confirm_plan(plan):\n        return\n    editors: Dict[str, CodeEditor] = {}\n    project_base_path = memory_manager.get_project_root()\n    successful_actions = 0\n    total_actions = len(actions)\n    for i, action in enumerate(actions, 1):\n        ui_manager.show_success(f'Processing action {i}/{total_actions}...')\n        action_type = action.get('type', '').upper()\n        file_path_relative = action.get('file')\n        if not file_path_relative:\n            ui_manager.show_error(\n                f\"Action is missing 'file' key. Skipping: {action}\")\n            continue\n        file_path_absolute = os.path.join(project_base_path, file_path_relative\n            )\n        if action_type == 'DELETE':\n            element_name = action.get('element')\n            if not element_name:\n                ui_manager.show_error(\n                    f\"DELETE action missing 'element' key. Skipping: {action}\")\n                continue\n            if not file_path_relative.endswith('.py'):\n                ui_manager.show_error(\n                    f'DELETE actions are only supported for Python files. Skipping.'\n                    )\n                continue\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    continue\n            editor = editors[file_path_absolute]\n            if editor.delete_element(element_name):\n                successful_actions += 1\n                ui_manager.show_success(\n                    f\"Successfully deleted '{element_name}' from '{file_path_relative}'.\"\n                    )\n            else:\n                ui_manager.show_error(\n                    f\"Failed to delete '{element_name}' from '{file_path_relative}'.\"\n                    )\n        elif _process_refactor_action(action, project_base_path, editors):\n            successful_actions += 1\n        else:\n            ui_manager.show_error(\n                f'Action {i} failed, continuing with remaining actions...')\n    if successful_actions == 0:\n        ui_manager.show_error('No actions were successfully executed.')\n        return\n    elif successful_actions < total_actions:\n        ui_manager.show_error(\n            f'Only {successful_actions}/{total_actions} actions completed successfully.'\n            )\n    else:\n        ui_manager.show_success(\n            f'All {total_actions} actions completed successfully.')\n    _apply_refactor_changes(editors)\n\n\ndef _create_prompt_for_commit_message(diff: str) ->str:\n    \"\"\"\n    Create a dedicated prompt function for the 'commit' command. This prompt will\n    instruct the AI to analyze a git diff and generate a concise commit message\n    following the Conventional Commits standard.\n    \"\"\"\n    return f\"\"\"You are an expert developer writing a Git commit message. Your task is to analyze the provided git diff and create a professional commit message.\n\nCOMMIT MESSAGE RULES:\n- Follow the Conventional Commits specification\n- Format: <type>(<optional scope>): <subject>\n- Types: feat, fix, docs, style, refactor, perf, test, build, ci, chore, revert\n- Subject line: max 50 characters, imperative mood, no period\n- Optional body: explain what and why (not how), wrap at 72 characters\n- Be specific and concise\n- Focus on the intent and impact of the changes\n\nEXAMPLES OF GOOD COMMIT MESSAGES:\n- feat(auth): add OAuth2 integration for Google login\n- fix(api): handle null response in user endpoint\n- refactor(database): optimize query performance for large datasets\n- docs(readme): update installation instructions for Windows\n\nRespond with ONLY the commit message - no markdown, quotes, or explanations.\n\n--- GIT DIFF TO ANALYZE ---\n{diff}\n\nGenerate the commit message:\"\"\"\n\n\ndef handle_commit_command():\n    \"\"\"\n    Orchestrates an AI-assisted Git commit workflow with improved error handling.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return\n    try:\n        git_manager = GitManager(project_root)\n    except ValueError as e:\n        ui_manager.show_error(str(e))\n        return\n    changed_files = git_manager.get_changed_files()\n    if not changed_files:\n        ui_manager.show_success(\n            'No changes to commit. Everything is up to date.')\n        return\n    staged_diff = git_manager.get_diff(staged=True)\n    unstaged_diff = git_manager.get_diff()\n    full_diff = f'{staged_diff}\\n{unstaged_diff}'.strip()\n    if not full_diff.strip():\n        ui_manager.show_success(\n            'No content changes detected (e.g., only file mode changes).')\n        return\n    prompt = _create_prompt_for_commit_message(full_diff)\n    commit_message = query_llm(prompt).strip()\n    if not commit_message:\n        ui_manager.show_error(\n            'AI failed to generate a commit message. Aborting.')\n        return\n    files_to_commit_str = '\\n'.join(f'- {f}' for f in changed_files)\n    plan_panel_content = f\"\"\"[bold]Files to be staged:[/]\n[yellow]{files_to_commit_str}[/]\n\n[bold]AI-Generated Commit Message:[/]\n[green]{commit_message}[/]\"\"\"\n    print(Panel(plan_panel_content, title='[bold cyan]Commit Plan[/]',\n        border_style='cyan'))\n    if ui_manager.get_user_input('\\nProceed with commit? (y/n): ').lower() in [\n        'yes', 'y']:\n        try:\n            git_manager.add(changed_files)\n            ui_manager.show_success('\u2705 Files staged.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Staging failed: {e.stderr}')\n            return\n        try:\n            git_manager.commit(commit_message)\n            ui_manager.show_success('\u2705 Commit successful.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Commit failed: {e.stderr}')\n            return\n        if ui_manager.get_user_input('Push changes to remote? (y/n): ').lower(\n            ) in ['yes', 'y']:\n            try:\n                git_manager.push()\n                ui_manager.show_success('\u2705 Push successful.')\n            except subprocess.CalledProcessError as e:\n                ui_manager.show_error(f'Push failed: {e.stderr}')\n        else:\n            ui_manager.show_error('Push cancelled.')\n    else:\n        ui_manager.show_error('Commit aborted by user.')\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef interactive_mode() ->None:\n    global last_query, last_response, last_code\n    try:\n        from Testing.overlay_engine import show_sequential_popup\n        gui_available = True\n    except ImportError:\n        gui_available = False\n    print(Panel(\n        \"\"\"[bold cyan]Omni Interactive Mode[/]\n[dim]Type 'help' for commands, 'exit' to quit.[/dim]\"\"\"\n        , border_style='cyan'))\n    personality_name = personality_manager.get_current_personality().get('name'\n        , 'Default')\n    gui_enabled = False\n    if gui_available:\n        try:\n            with open(CONFIG_FILE, 'r') as f:\n                config = json.load(f)\n                if config.get('gui_enabled', False):\n                    gui_enabled = True\n        except (FileNotFoundError, json.JSONDecodeError):\n            pass\n    refresh_status_panel(personality_name)\n    while True:\n        try:\n            user_input = ui_manager.get_user_input('\\n> ')\n            if not user_input:\n                continue\n            command, *args = user_input.split(maxsplit=1)\n            arg_str = args[0] if args else ''\n            if command == 'exit':\n                memory_manager.save_memory()\n                print('[bold cyan]Goodbye![/]')\n                break\n            elif command == 'help':\n                print(\n                    \"\"\"[bold]Commands:[/]\n\n  [bold cyan]Core & Project Commands[/]\n  [yellow]send <prompt>[/]        - Ask the LLM a question.\n  [yellow]look <path>[/]          - Read file or scan directory into memory.\n  [yellow]look_all[/]            - Recursively scan the project directory into memory.\n  [yellow]create <file> \"instr\"[/] - Create a new file using AI.\n  [yellow]edit <file> \"instr\"[/]   - Edit a specific file using AI.\n  [yellow]refactor \"instr\"[/]      - Refactor project in memory based on instruction.\n  [yellow]commit[/]               - Commit changes with an AI-generated message.\n  [yellow]rag <query>[/]         - Query the RAG system for context retrieval.\n\n  [bold cyan]File & Code Management[/]\n  [yellow]save <filename>[/]     - Save last AI response to a file.\n  [yellow]list[/]               - List saved files.\n  [yellow]run[/]                 - Run the last generated Python code.\n\n  [bold cyan]Session & Config[/]\n  [yellow]history[/]             - Show the full chat history.\n  [yellow]memory clear[/]        - Clear the chat and file memory.\n  [yellow]backend <name>[/]      - Switch AI backend (e.g., openrouter, ollama).\n  [yellow]models [src][/]        - Interactively list and select models.\n  [yellow]set model <id>[/]      - Set the model directly by its ID.\n  [yellow]personality <cmd>[/]   - Manage AI personalities ('list', 'set', 'add').\n\"\"\"\n                    )\n            elif command == 'send':\n                last_query = arg_str\n                response = query_llm(arg_str)\n                last_response = response\n                if gui_enabled:\n                    threading.Thread(target=show_sequential_popup, args=(\n                        100, 100, response, f'Omni - {personality_name}'),\n                        daemon=True).start()\n                print(Panel(response, title='[cyan]Response[/]'))\n                if (code_blocks := extract_code(response)):\n                    last_code = code_blocks[0][1]\n            elif command == 'look':\n                look_command(arg_str)\n            elif command == 'look_all':\n                look_all_command()\n            elif command == 'create':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_create_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: create <file_path> \"<instruction>\"')\n            elif command == 'edit':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_edit_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: edit <file_path> \"<instruction>\"')\n            elif command == 'refactor':\n                if not arg_str:\n                    ui_manager.show_error('Usage: refactor \"<instruction>\"')\n                else:\n                    handle_project_refactor_command(arg_str.strip('\"'))\n            elif command == 'commit':\n                handle_commit_command()\n            elif command == 'models':\n                list_models(arg_str.split())\n            elif command == 'set' and arg_str.startswith('model '):\n                set_model(arg_str[6:])\n            elif command == 'backend':\n                switch_backend(arg_str)\n            elif command == 'history':\n                ui_manager.display_history(memory_manager.get_memory_context())\n            elif command == 'memory' and arg_str == 'clear':\n                memory_manager.clear_memory()\n                ui_manager.show_success('\u2705 Memory cleared')\n            elif command == 'personality':\n                p_args = arg_str.split(maxsplit=1)\n                cmd = p_args[0] if p_args else ''\n                p_arg_str = p_args[1] if len(p_args) > 1 else ''\n                if cmd == 'list':\n                    for p in personality_manager.list_personalities():\n                        print(f\"- {p['name']}: {p['description']}\")\n                elif cmd == 'set' and p_arg_str:\n                    if personality_manager.set_current_personality(p_arg_str):\n                        personality_name = p_arg_str\n                        ui_manager.show_success(\n                            f'Set personality to {personality_name}')\n                    else:\n                        ui_manager.show_error('Personality not found.')\n                else:\n                    ui_manager.show_error(\n                        \"Invalid personality command. Use 'list' or 'set <name>'.\"\n                        )\n            elif command == 'run':\n                run_python_code()\n            elif command == 'save':\n                if last_response:\n                    save_code(last_response, arg_str or\n                        f\"omni_save_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n                        )\n                else:\n                    ui_manager.show_error('No response to save.')\n            elif command == 'list':\n                files = sorted(os.listdir(DEFAULT_SAVE_DIR))\n                print('\\n'.join(f'  - {f}' for f in files) if files else\n                    '[yellow]No saved files.[/]')\n            elif command == 'rag':\n                if not arg_str:\n                    ui_manager.show_error('Usage: rag \"<query>\"')\n                else:\n                    from rag_manager import RAGManager\n                    project_root = memory_manager.get_project_root()\n                    if not project_root:\n                        ui_manager.show_error(\n                            \"No project context in memory. Use 'look <directory>' first.\"\n                            )\n                        continue\n                    rag = RAGManager()\n                    if rag.get_document_count() == 0:\n                        ui_manager.show_error(\n                            'RAG index is empty. Please add documents first.')\n                        continue\n                    results = rag.search(arg_str, k=3)\n                    if not results:\n                        ui_manager.show_error('No relevant documents found.')\n                        continue\n                    print(Panel('[bold]RAG Results:[/]', title=\n                        '[cyan]Retrieval-Augmented Generation[/]'))\n                    for i, (content, score, metadata) in enumerate(results, 1):\n                        file_path = metadata.get('file', 'Unknown')\n                        print(\n                            f'[bold cyan]{i}. {file_path}[/] (Score: {score:.4f})'\n                            )\n                        print(Panel(content[:500] + '...' if len(content) >\n                            500 else content, border_style='dim'))\n                    follow_up = ui_manager.get_user_input(\n                        \"\"\"\nWould you like to ask a follow-up question with this context? (y/n): \"\"\"\n                        )\n                    if follow_up.lower() in ['y', 'yes']:\n                        follow_up_query = ui_manager.get_user_input(\n                            'Follow-up query: ')\n                        if follow_up_query:\n                            context_parts = [\n                                f'Document {i} (Score: {score:.4f}):\\n{content}'\n                                 for i, (content, score, _) in enumerate(\n                                results, 1)]\n                            context = '\\n\\n'.join(context_parts)\n                            rag_prompt = f\"\"\"Based on the following context, please answer the question.\n\nContext:\n{context}\n\nQuestion: {follow_up_query}\"\"\"\n                            response = query_llm(rag_prompt)\n                            print(Panel(response, title=\n                                '[cyan]RAG-Augmented Response[/]'))\n            else:\n                ui_manager.show_error(\"Unknown command. Type 'help'.\")\n            refresh_status_panel(personality_name)\n        except KeyboardInterrupt:\n            memory_manager.save_memory()\n            print('\\n[bold cyan]Goodbye![/]')\n            break\n        except Exception as e:\n            ui_manager.show_error(f'An unexpected error occurred: {e}')\n\n\ndef run_python_code() ->None:\n    global last_code\n    if not last_code:\n        ui_manager.show_error('No Python code in memory to run.')\n        return\n    temp_file = os.path.join(DEFAULT_SAVE_DIR, 'temp_run.py')\n    try:\n        with open(temp_file, 'w') as f:\n            f.write(last_code)\n        print('[bold cyan]\\n--- Running Code ---\\n[/]')\n        subprocess.run([sys.executable, temp_file], check=True)\n        print('[bold cyan]\\n--- Code Finished ---\\n[/]')\n    except Exception as e:\n        ui_manager.show_error(f'Error running code: {e}')\n    finally:\n        if os.path.exists(temp_file):\n            os.remove(temp_file)\n\n\ndef save_code(content: str, filename: str) ->None:\n    filepath = os.path.join(DEFAULT_SAVE_DIR, filename)\n    try:\n        with open(filepath, 'w') as f:\n            f.write(content)\n        ui_manager.show_success(f'Saved to: {filepath}')\n    except IOError as e:\n        ui_manager.show_error(f'Error saving file: {e}')\n\n\ndef main() ->None:\n    try:\n        import astor\n    except ImportError:\n        print(\"[bold red]Error:[/] 'astor' is required. `pip install astor`\")\n        sys.exit(1)\n    try:\n        import simple_term_menu\n    except ImportError:\n        print(\n            \"[bold red]Error:[/] 'simple-term-menu' is required. `pip install simple-term-menu`\"\n            )\n        sys.exit(1)\n    parser = argparse.ArgumentParser(description=\n        'Omni - AI-powered code tool', add_help=False)\n    parser.add_argument('command', nargs='?', help='Main command.')\n    parser.add_argument('args', nargs='*', help='Arguments for the command.')\n    parser.add_argument('-h', '--help', action='store_true')\n    args, _ = parser.parse_known_args()\n    if args.help or not args.command:\n        interactive_mode()\n    elif args.command == 'look' and args.args:\n        look_command(args.args[0])\n    elif args.command == 'edit' and len(args.args) >= 2:\n        handle_file_edit_command(args.args[0], ' '.join(args.args[1:]))\n    elif args.command == 'models':\n        list_models(args.args)\n    else:\n        interactive_mode()\n\n\ndef refresh_status_panel(personality_name: str) ->None:\n    ui_manager.display_status_panel(personality_name, current_backend,\n        current_model, len(memory_manager.memory.get('chat', [])), len(\n        memory_manager.memory.get('look', [])))\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/omni.py"
  },
  {
    "id": 22,
    "hash": "db1585da7840e9dc17f3ab8c0a19f6f2",
    "content": "import json\nfrom typing import Dict, List, Optional\n\nclass PersonalityManager:\n    \"\"\"Manages AI personalities via JSON config.\"\"\"\n\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.personalities: List[Dict[str, str]] = self.load_personalities()\n        self.current_personality: Optional[str] = \"default\"  # Default\n\n    def load_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"Load personalities from JSON; auto-create if missing.\"\"\"\n        default = [{\"name\": \"default\", \"description\": \"Helpful assistant\", \"system_prompt\": \"You are a helpful AI assistant.\"}]\n        default_gui = {\n            \"gui_enabled\": True,\n            \"wake_word\": \"Jarvis\",\n            \"overlay_opacity\": 0.8,\n            \"font_size\": 16\n        }\n        try:\n            with open(self.config_file, 'r') as f:\n                data = json.load(f)\n                if \"personalities\" not in data:\n                    data[\"personalities\"] = default\n                if \"gui_enabled\" not in data:\n                    data.update(default_gui)\n                    self.save_personalities(data[\"personalities\"])  # Save with defaults\n                \n                return data[\"personalities\"]\n        except FileNotFoundError:\n            self.save_personalities(default)\n            return default\n        except json.JSONDecodeError:\n            print(\"[yellow]Invalid config. Resetting to default.[/]\")\n            self.save_personalities(default)\n            return default\n\n    def save_personalities(self, personalities: List[Dict[str, str]]) -> None:\n        \"\"\"Save with GUI config.\"\"\"\n        data = {\"personalities\": personalities}\n        data.update({\"gui_enabled\": True, \"wake_word\": \"Jarvis\", \"overlay_opacity\": 0.8, \"font_size\": 16})  # Defaults\n        with open(self.config_file, 'w') as f:\n            json.dump(data, f, indent=4)\n\n    def add_personality(self, name: str, description: str, system_prompt: str) -> None:\n        \"\"\"Add a new personality.\"\"\"\n        self.personalities.append({\"name\": name, \"description\": description, \"system_prompt\": system_prompt})\n        self.save_personalities(self.personalities)\n\n    def list_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"List all personalities.\"\"\"\n        return self.personalities\n\n    def set_current_personality(self, name: str) -> bool:\n        \"\"\"Set the current personality.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == name:\n                self.current_personality = name\n                return True\n        return False\n\n    def get_current_personality(self) -> Dict[str, str]:\n        \"\"\"Get the current personality dict.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == self.current_personality:\n                return p\n        return {}  # Fallback",
    "file": "/mnt/ProjectData/omni/personality_manager.py"
  },
  {
    "id": 23,
    "hash": "2914352eefed9d60de098e021dd79b67",
    "content": "import os\nimport sys\nimport argparse\nfrom typing import List\nfrom rag_manager import RAGManager\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\ndef create_sample_data() ->List[str]:\n    \"\"\"Create sample documents for the RAG example.\"\"\"\n    return [\n        'RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with language generation.'\n        ,\n        'The RAG model retrieves relevant documents from a knowledge base and uses them to generate more accurate responses.'\n        ,\n        'FAISS is a library for efficient similarity search and clustering of dense vectors, often used in RAG systems.'\n        ,\n        'Sentence transformers are used to create embeddings for documents and queries in RAG systems.'\n        ,\n        'Retrieval-Augmented Generation improves language models by allowing them to access external knowledge sources.'\n        ,\n        'In RAG systems, documents are indexed and searchable by their semantic embeddings rather than just keywords.'\n        ,\n        'Python is a great language for implementing RAG systems due to libraries like sentence-transformers and faiss.'\n        ,\n        'The retrieval component of RAG is crucial for finding relevant information before generation.'\n        ]\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_cli_example.py"
  },
  {
    "id": 24,
    "hash": "c27b11d2eaa8e13cdf8e698417efb75e",
    "content": "import os\nimport sys\nfrom typing import List, Dict, Tuple\n\"\"\"\nExample script demonstrating RAG (Retrieval-Augmented Generation) usage.\n\nThis script shows how to use a simple RAG implementation to answer questions\nbased on a given context or knowledge base.\n\"\"\"\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\nclass SimpleRAG:\n    \"\"\"A simple RAG implementation for demonstration purposes.\"\"\"\n\n    def __init__(self, knowledge_base: List[str]):\n        \"\"\"\n        Initialize the RAG with a knowledge base.\n        \n        Args:\n            knowledge_base: A list of strings representing the knowledge base.\n        \"\"\"\n        self.knowledge_base = knowledge_base\n\n    def retrieve(self, query: str, top_k: int=3) ->List[str]:\n        \"\"\"\n        Retrieve relevant documents from the knowledge base.\n        \n        This is a simplified implementation using keyword matching.\n        In a real implementation, you would use embeddings and vector search.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            A list of relevant documents.\n        \"\"\"\n        query_words = set(query.lower().split())\n        scores = []\n        for doc in self.knowledge_base:\n            doc_words = set(doc.lower().split())\n            score = len(query_words.intersection(doc_words))\n            scores.append((score, doc))\n        scores.sort(reverse=True)\n        return [doc for score, doc in scores[:top_k]]\n\n    def generate(self, query: str, retrieved_docs: List[str]) ->str:\n        \"\"\"\n        Generate an answer based on the query and retrieved documents.\n        \n        In a real implementation, this would use an LLM to generate the response.\n        For this example, we'll create a simple template-based response.\n        \n        Args:\n            query: The query string.\n            retrieved_docs: The retrieved documents.\n            \n        Returns:\n            A generated answer.\n        \"\"\"\n        context = '\\n'.join(retrieved_docs)\n        prompt = f\"\"\"\n        Context information:\n        {context}\n        \n        Question: {query}\n        \n        Based on the context provided above, please answer the question.\n        If the context doesn't contain relevant information, say so.\n        \"\"\"\n        return self._simple_response_generator(query, retrieved_docs)\n\n    def _simple_response_generator(self, query: str, retrieved_docs: List[str]\n        ) ->str:\n        \"\"\"\n        A simple response generator for demonstration.\n        \"\"\"\n        for doc in retrieved_docs:\n            if 'example' in doc.lower():\n                return (\n                    f'Based on the context provided, I found information about examples. {query} relates to the examples in the knowledge base.'\n                    )\n        return (\n            f\"I couldn't find specific information about '{query}' in the provided context. Please provide more details or check the knowledge base.\"\n            )\n\n    def query(self, query: str, top_k: int=3) ->str:\n        \"\"\"\n        Process a query through the full RAG pipeline.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            The generated answer.\n        \"\"\"\n        retrieved_docs = self.retrieve(query, top_k)\n        answer = self.generate(query, retrieved_docs)\n        return answer\n\n\ndef main():\n    \"\"\"Main function demonstrating the RAG implementation.\"\"\"\n    knowledge_base = ['This is an example document about machine learning.',\n        'Natural language processing is a subfield of artificial intelligence.'\n        , 'Python is a popular programming language for data science.',\n        'The quick brown fox jumps over the lazy dog.',\n        'RAG stands for Retrieval-Augmented Generation.',\n        'Vector databases are used for similarity search in RAG systems.',\n        'Transformers are a type of neural network architecture.',\n        'This example shows how to implement a simple RAG system.']\n    rag = SimpleRAG(knowledge_base)\n    queries = ['What is RAG?', 'How is Python used in data science?',\n        'Tell me about machine learning']\n    print('Simple RAG Example')\n    print('=' * 50)\n    for query in queries:\n        print(f'\\nQuery: {query}')\n        answer = rag.query(query)\n        print(f'Answer: {answer}')\n        print('-' * 30)\n    print(\"\\nInteractive Mode (type 'quit' to exit):\")\n    while True:\n        try:\n            user_query = input('\\nEnter your question: ').strip()\n            if user_query.lower() in ['quit', 'exit', 'q']:\n                break\n            if user_query:\n                answer = rag.query(user_query)\n                print(f'Answer: {answer}')\n        except KeyboardInterrupt:\n            print('\\nGoodbye!')\n            break\n        except EOFError:\n            break\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_example.py"
  },
  {
    "id": 25,
    "hash": "f151986bf2efa7602242590a357fab83",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n    Initialize the RAG manager.\n\n    Args:\n        model_name: Name of the sentence transformer model to use\n        index_path: Path to save/load the FAISS index\n    \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the RAG manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n",
    "file": "/mnt/ProjectData/omni/rag_manager.py"
  },
  {
    "id": 26,
    "hash": "f59a27842056dbb0dc95d0f29c1c5de8",
    "content": "Hello! I'm OmniForge, an AI coding assistant. I can help you scan, understand, and refactor your codebase using local (Ollama) or remote (OpenRouter) LLMs.\n\nI see you've opened the OmniForge project directory. Some key things I can help with:\n\n1. **Project Analysis**: I can look at your files to understand the structure\n2. **Code Editing**: I can make precise edits to functions/classes using AST-based transformations\n3. **Refactoring**: I can perform multi-file architectural changes with a plan\n4. **File Creation**: I can generate new files based on instructions\n\nFor example:\n- `look .` to scan the project\n- `edit code_editor.py \"add docstrings to main methods\"`\n- `refactor \"extract git operations into a separate module\"`\n- `create new_module.py \"implement a simple HTTP client\"`\n\nWhat would you like to do with this project?",
    "file": "/mnt/ProjectData/omni/requirements.txt"
  },
  {
    "id": 27,
    "hash": "4b879b8e64b677ec78d27f19b384623a",
    "content": "from typing import List\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.text import Text\nfrom rich.status import Status\nfrom rich import box\nfrom contextlib import contextmanager\nfrom rich.markup import escape\nimport gc\n\ntry:\n    from prompt_toolkit import prompt\n    from prompt_toolkit.completion import WordCompleter\n    from prompt_toolkit.history import InMemoryHistory\n    from prompt_toolkit.styles import Style\nexcept ImportError:\n    print('[yellow]prompt_toolkit not installed. Falling back to basic input.[/]')\n    prompt = input\n\n\nclass UIManager:\n    \"\"\"Manages interactive text-based UI with rich for display and prompt_toolkit for input.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initializes the UI manager with a rich console and prompt_toolkit components.\"\"\"\n        self.console = Console()\n        self.history = InMemoryHistory()\n        self.completer = WordCompleter([\n            'send', 'look', 'look_all', 'create', 'edit', 'refactor', 'commit',\n            'save', 'list', 'run', 'history', 'memory', 'backend', 'models',\n            'set', 'personality', 'help', 'exit'\n        ], ignore_case=True)\n        self.prompt_style = Style.from_dict({'prompt': 'bold cyan'})\n\n    def get_user_input(self, prompt_text: str) -> str:\n        try:\n            return prompt(prompt_text, history=self.history, completer=self.completer, style=self.prompt_style)\n        except Exception:\n            self.console.print('[yellow]Warning: Falling back to basic input.[/]')\n            return input(prompt_text)\n\n    def display_history(self, history_text: str) -> None:\n        if not history_text.strip():\n            self.console.print('[dim]No history yet.[/]')\n            return\n        \n        lines = history_text.split('\\n')\n        colored_text = Text()\n        for line in lines:\n            if line.startswith('User:'):\n                colored_text.append(line + '\\n', style='bold blue')\n            elif line.startswith('AI:'):\n                colored_text.append(line + '\\n', style='bold green')\n            elif line.startswith('File '):\n                colored_text.append(line + '\\n', style='yellow')\n            else:\n                colored_text.append(line + '\\n')\n        \n        self.console.print(Panel(\n            colored_text, \n            title='[bold magenta]Chat History[/]', \n            border_style='magenta', \n            expand=False, \n            box=box.ROUNDED\n        ))\n\n    @contextmanager\n    def show_spinner(self, message: str):\n        \"\"\"\n        Context manager that displays a spinner with the given message.\n        Handles Rich LiveError by cleaning up stuck live displays and \n        ensuring proper cleanup on exceptions.\n        \n        Usage:\n            with ui_manager.show_spinner(\"Loading...\"):\n                # do work here\n        \"\"\"\n        # Initialize spinner state if not exists\n        if not hasattr(self, '_spinner_active'):\n            self._spinner_active = False\n        \n        # If spinner is already active, just yield without additional output\n        if self._spinner_active:\n            try:\n                yield\n            except Exception as e:\n                raise e\n            return\n        \n        # Clean up any stuck Rich live displays before starting\n        self._cleanup_stuck_rich_displays()\n        \n        # Mark spinner as active\n        self._spinner_active = True\n        status_context = None\n        \n        try:\n            # Try to use rich status, but with fallback\n            try:\n                status_context = self.console.status(f'[bold yellow]{message}[/]')\n                status_context.__enter__()\n            except Exception:\n                # If rich.status fails, fallback to static print\n                status_context = None\n                self.console.print(f'[bold yellow]{message}[/]')\n            \n            yield\n            \n        except Exception as e:\n            # Re-raise actual work errors\n            raise e\n            \n        finally:\n            # Always cleanup spinner state and rich display\n            self._spinner_active = False\n            if status_context is not None:\n                try:\n                    status_context.__exit__(None, None, None)\n                except:\n                    pass  # Suppress cleanup errors\n            \n            # Force cleanup any remaining rich displays\n            self._cleanup_stuck_rich_displays()\n\n    def _cleanup_stuck_rich_displays(self):\n        \"\"\"\n        Clean up stuck Rich live displays that prevent new ones from starting.\n        Based on solution from: https://github.com/DLR-RM/stable-baselines3/issues/1645\n        \"\"\"\n        try:\n            # Method 1: Reset console live display if exists\n            if hasattr(self.console, '_live') and self.console._live is not None:\n                try:\n                    self.console._live.stop()\n                    self.console._live = None\n                except:\n                    pass\n            \n            # Method 2: Find and close stuck rich/tqdm objects using garbage collection\n            rich_objects = [obj for obj in gc.get_objects() \n                        if hasattr(obj, '__class__') and \n                        ('live' in type(obj).__name__.lower() or \n                            'progress' in type(obj).__name__.lower() or\n                            'status' in type(obj).__name__.lower()) and\n                        hasattr(obj, 'stop')]\n            \n            for rich_obj in rich_objects:\n                try:\n                    if hasattr(rich_obj, 'stop'):\n                        rich_obj.stop()\n                    elif hasattr(rich_obj, 'close'):\n                        rich_obj.close()\n                except:\n                    pass  # Suppress cleanup errors\n                    \n        except:\n            pass  # Suppress all cleanup errors to avoid breaking the main flow\n\n    def display_status_panel(self, personality: str, backend: str, model: str, msg_count: int, look_count: int) -> None:\n        status_text = (\n            f'[bold]Personality:[/] [green]{personality}[/] | '\n            f'[bold]Backend:[/] [green]{backend}[/] | '\n            f'[bold]Model:[/] [green]{model}[/] | '\n            f'[bold]Memory:[/] {msg_count} messages, {look_count} files'\n        )\n        self.console.print(Panel(\n            status_text, \n            title='[bold cyan]Status[/]', \n            border_style='cyan', \n            expand=False, \n            box=box.MINIMAL\n        ))\n\n    def show_success(self, message: str) -> None:\n        self.console.print(f'[green]\u2705 {message}[/]')\n\n    def show_error(self, message: str) -> None:\n        \"\"\"\n        Displays an error message, escaping any markup in the message.\n        \"\"\"\n        safe_message = escape(str(message))\n        self.console.print(f'[red]\u274c {safe_message}[/]')",
    "file": "/mnt/ProjectData/omni/ui_manager.py"
  },
  {
    "id": 28,
    "hash": "dbd143839288b400cafdedb655258434",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n",
    "file": "/mnt/ProjectData/omni/vectordb_manager.py"
  },
  {
    "id": 29,
    "hash": "47a91d3ac272236378053b23515fc9b0",
    "content": "import tkinter as tk\nfrom tkinter import ttk\nfrom time import strftime\n\n\ndef update_time():\n    current_time = strftime('%H:%M:%S %p\\n%Y-%m-%d')\n    time_label.config(text=current_time)\n    time_label.after(1000, update_time)\n\n\ndef center_window(root):\n    root.update_idletasks()\n    screen_width = root.winfo_screenwidth()\n    screen_height = root.winfo_screenheight()\n    window_width = root.winfo_width() + 4\n    window_height = root.winfo_height() + 4\n    x = (screen_width - window_width) // 2\n    y = (screen_height - window_height) // 2\n    root.geometry(f'{window_width}x{window_height}+{x}+{y}')\n\n\ndef create_3d_border(parent):\n    border_frame = tk.Frame(parent, bg='#c0c0c0')\n    border_frame.pack(padx=2, pady=2, expand=True, fill=tk.BOTH)\n    tk.Frame(border_frame, height=1, bg='#808080').pack(side=tk.TOP, fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#808080').pack(side=tk.LEFT, fill=tk.Y)\n    tk.Frame(border_frame, height=1, bg='#ffffff').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#ffffff').pack(side=tk.RIGHT, fill=tk.Y\n        )\n    inner_container = tk.Frame(border_frame, bg='#c0c0c0')\n    inner_container.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1\n        )\n    tk.Frame(inner_container, height=1, bg='#ffffff').pack(side=tk.TOP,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#ffffff').pack(side=tk.LEFT,\n        fill=tk.Y)\n    tk.Frame(inner_container, height=1, bg='#808080').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#808080').pack(side=tk.RIGHT,\n        fill=tk.Y)\n    content_area = tk.Frame(inner_container, bg='#c0c0c0')\n    content_area.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1)\n    return content_area\n\n\nroot = tk.Tk()\nroot.title('Current Time')\nroot.configure(bg='#008080')\nmain_frame = create_3d_border(root)\nmain_frame.config(padx=4, pady=4)\ninner_frame = tk.Frame(main_frame, bg='#c0c0c0', padx=8, pady=8)\ninner_frame.pack()\ntime_label = tk.Label(inner_frame, bg='#c0c0c0', fg='#000000', font=(\n    'MS Sans Serif', 18, 'bold'), padx=12, pady=8)\ntime_label.pack()\nroot.after(100, lambda : center_window(root))\nupdate_time()\nroot.mainloop()\n",
    "file": "/mnt/ProjectData/omni/omni_saves/watch.py"
  },
  {
    "id": 30,
    "hash": "6774a805052356775d8c4f0367253dc1",
    "content": "# OmniForge\n\n**Project\u2011Aware AI CLI for AST\u2011Precise Edits (\u201cScalpel\u201d) & Multi\u2011File Refactors (\u201cBlueprint\u201d).**\n\n> *OmniForge (a.k.a. the \"DualForge\" engine) helps you **scan**, **understand**, and **reforge** your codebase with local (Ollama) or remote (OpenRouter) LLMs. It is an independent open\u2011source project not affiliated with other products using the name \u201cOmni.\u201d*\n\n---\n\n## Core Features\n\n* **Project\u2011Aware Refactoring (`refactor`)**: Provide a high\u2011level goal (e.g. *\u201cmove all DB logic into `db/` and centralize config\u201d*). OmniForge generates & shows a multi\u2011step plan before touching files.\n* **Surgical AST Editing (`edit`)**: Target a single function/class. OmniForge parses the file, locates the node, applies a structural change, and shows you a diff.\n* **Context Ingestion (`look`)**: Scan a directory or single file to build a project manifest (paths + hashes + size + language hints) that guides subsequent edits/refactors.\n* **Dual Backends**: Seamlessly switch between **`openrouter`** (remote models) and **`ollama`** (local models) via `backend <name>`.\n* **Interactive Model Picker (`models`)**: Filter by source/provider and select from an up\u2011to\u2011date model list inside the terminal.\n* **Session Memory & History**: `history` shows conversation / action log; `memory clear` resets the working context.\n* **Safe AST\u2011Based Transformations**: Reduces syntax breakage vs naive text substitution. New imports / dependencies are auto\u2011inserted when possible.\n* **Dry\u2011Run Transparency**: Every multi\u2011file refactor presents (1) a generated plan, (2) per\u2011file proposed changes, (3) a consolidated diff for confirmation.\n\n---\n\n## Conceptual Modes\n\n| Mode          | Command(s) | Purpose                                              | Analogy              |\n| ------------- | ---------- | ---------------------------------------------------- | -------------------- |\n| **Survey**    | `look`     | Index project / ingest context                       | Mapping the terrain  |\n| **Scalpel**   | `edit`     | Precise single\u2011file structural change                | Surgery              |\n| **Blueprint** | `refactor` | Multi\u2011file architectural transformation              | Architecture         |\n| **Cast**      | `run`      | Execute last generated runnable block (if supported) | Forging the artifact |\n\nYou can reference these terms in docs, help screens, or UI banners for clarity.\n\n---\n\n## Installation\n\n> Requires Python 3.10+ and a Unix\u2011like shell.\n\n```bash\n# 1. Clone\ngit clone https://github.com/Snawyyy/omniforge.git\ncd omniforge\n\n# 2. (Optional) Inspect requirements\ncat requirements.txt\n\n# 3. Run installer (creates venv + installs deps)\nchmod +x install.sh\n./install.sh\n\n# 4. Activate environment\nsource venv/bin/activate\n\n# 5. Run CLI (interactive shell)\n./omni        # or: python omni.py\n```\n\nIf you later package it, expose a script entry point named `omni` while keeping an internal package name like `omniforge` to avoid namespace collisions.\n\n---\n\n## Configuration\n\nCreate a `.env` file to supply secrets (e.g. OpenRouter API key).\n\n```bash\ncp .env.example .env   # if example exists; otherwise create manually\n```\n\nIn `.env`:\n\n```dotenv\nOPENROUTER_API_KEY=\"sk-or-...\"\n```\n\n(Do **not** commit real keys. Ensure `.env` is listed in `.gitignore`.)\n\nOptional future keys can include local model paths, default model name, or feature flags.\n\n---\n\n## Quick Start Workflow\n\n```text\n> look .\n(Index project: builds manifest)\n\n> refactor \"extract hardcoded API URL to config/settings.py and update all imports\"\n(Shows plan \u2192 ask for confirmation)\n\n> edit src/utils.py \"add a doctring for calculate_average explaining parameters and return value\"\n(Shows targeted diff \u2192 confirm or abort)\n\n> models openai\n(Choose a different model)\n\n> backend ollama\n(Switch to local inference)\n```\n\n---\n\n## Command Reference\n\n| Command               | Example                                         | Description                                                                 |\n| --------------------- | ----------------------------------------------- | --------------------------------------------------------------------------- |\n| `look <path>`         | `look .`                                        | Scan directory or file; update project context manifest.                    |\n| `edit <file> \"instr\"` | `edit utils.py \"add error handling\"`            | AST\u2011guided targeted modification of a single file element or whole file.    |\n| `refactor \"goal\"`     | `refactor \"split monolith api.py into package\"` | High\u2011level multi\u2011file transformation with plan + diff review.               |\n| `send <prompt>`       | `send summarize module layout`                  | Generic prompt to current model with current context summary.               |\n| `models [filter]`     | `models google`                                 | Interactive model selector (filter by provider/source).                     |\n| `backend <name>`      | `backend ollama`                                | Switch between `openrouter` / `ollama`.                                     |\n| `history`             | `history`                                       | Display session interaction log.                                            |\n| `memory clear`        | `memory clear`                                  | Clear internal AI context memory (project manifest may persist separately). |\n| `run`                 | `run`                                           | Execute the last generated runnable code snippet (if feature implemented).  |\n| `help`                | `help`                                          | Show help / usage summary.                                                  |\n\n---\n\n## How It Works (High Level)\n\n1. **Ingestion (`look`)**: Walks the directory (configurable ignore patterns), captures file metadata (path, size, language), optionally caches abbreviated content or hashes.\n2. **Prompt Construction**: Merges user instruction + contextual manifest + focused snippets (for `edit`) or diff summaries (for `refactor`).\n3. **AST Layer** (Python initially): Parses target file(s); identifies node(s) (function/class) based on name + heuristic similarity; applies transformations guided by model output (structured hints or patch templates) rather than raw blind overwrite.\n4. **Plan (Refactor)**: Model proposes steps (CREATE / MODIFY / RENAME / DELETE). User approves. Each step executed & validated; errors surface early.\n5. **Diff Presentation**: A unified colorized diff shown; user confirms to write changes.\n6. **Safety**: If AST parse fails or patch violates syntax, changes abort (or fallback to text patch with warning).\n\n---\n\n## Roadmap (Indicative)\n\n| Milestone | Features                                                                    |\n| --------- | --------------------------------------------------------------------------- |\n| 0.1.0     | Core commands (`look`, `edit`, `refactor`, `models`, `backend`, `history`). |\n| 0.2.0     | Config file (`omniforge.toml`), ignore patterns, improved diff viewer.      |\n| 0.3.0     | Multi-language AST adapters (JS/TS via `tree-sitter`).                      |\n| 0.4.0     | Test impact analysis & auto test file generation.                           |\n| 0.5.0     | Refactor preview metrics (LOC touched, complexity delta).                   |\n| 0.6.0     | Inline security / lint feedback integration.                                |\n| 0.7.0     | Partial GUI / TUI dashboard mode.                                           |\n\n(Adjust roadmap as project evolves.)\n\n---\n\n## Developer Notes\n\n* Keep `.env`, virtual environment dirs (`venv/`), caches, large artifacts in `.gitignore`.\n* Consider adding a thin `omniforge/` package directory now for future PyPI packaging.\n* Implement a pluggable *Model Adapter* layer to abstract provider differences (OpenRouter vs Ollama).\n* Logging: Provide `--verbose` or `OMNIFORGE_DEBUG=1` env flag.\n* Add a JSONL log of commands & decisions to enable replay or supervised improvements.\n\n---\n\n## Contributing\n\n1. Fork & create a feature branch: `git checkout -b feat/<short-name>`\n2. Run and add tests (if/when test harness exists in `tests/`).\n3. Ensure style/format (e.g. `ruff`, `black`) passes.\n4. Submit pull request with concise description + before/after examples.\n\nIssues / discussions welcome for architecture proposals, AST adapters, or performance improvements.\n\n---\n\n## License\n\nReleased under the **MIT License**. See `LICENSE` file for full text.\n\n---\n\n## Name & Trademark Disclaimer\n\n\u201cOmniForge\u201d is an independent open-source tool and not affiliated with The Omni Group or any other third-party products using similar names. If a future naming conflict arises, a soft alias strategy (keeping the `omni` CLI) will preserve user workflows.\n\n---\n\n## Example Session (Illustrative)\n\n```text\n$ ./omni\nOMNIFORGE 0.1.0  (backend=openrouter | model=anthropic/claude-3)\nType 'help' or 'look .' to begin.\n\n> look .\nIndexed 42 files (Python=30, Markdown=5, JSON=7)\n\n> refactor \"centralize logging into logging_util.py and update imports\"\nPlan:\n  [1] CREATE logging_util.py\n  [2] MODIFY app.py (replace inline log setup)\n  [3] MODIFY worker.py (import logging_util)\nProceed? (y/n) y\n... (diff preview) ...\nApply changes? (y/n) y\nRefactor complete in 3.2s.\n\n> edit worker.py \"add retry with exponential backoff to fetch_data\"\nParsed worker.py \u2713\nApplied modification (function: fetch_data)\nDiff shown. Accept? (y/n) y\nSaved.\n```\n\n---\n\n## Philosophy\n\n*The next wave of developer AI goes beyond paste\u2011in prompts.* OmniForge treats your repository as *structured material*, enabling incremental, auditable, and safer evolution rather than opaque code dumps. By combining **context scanning**, **AST precision**, and **human approval loops**, it aims to become a trustworthy co\u2011developer rather than an occasionally helpful code generator.\n\n---\n\n## Feedback / Support\n\nOpen a GitHub Issue for bugs & feature requests. For conceptual discussions (roadmap, design choices), use Discussions.\n\n---\n\nHappy forging!\n",
    "file": "/mnt/ProjectData/omni/README.md"
  },
  {
    "id": 31,
    "hash": "48f330cca4dc037b3ad4942e430e6393",
    "content": "# ast_adapter.py\n\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional, Dict, Any, Union\n\n# Define common types that adapters might use or return\n# This keeps the interface flexible without importing specific parser libraries\nASTNode = Any  # Generic type for a node in the AST/CST\nDiffContent = str # Type alias for the string output of a diff\n\nclass ASTAdapter(ABC):\n    \"\"\"\n    Abstract base class defining the interface for language-specific AST adapters.\n\n    This interface allows the CodeEditor to interact with the AST/CST of different\n    programming languages in a uniform way. Concrete implementations will handle\n    the specifics of parsing, traversing, and modifying the AST/CST for their\n    respective languages (e.g., Python's `ast`/`astor`, JavaScript's `tree-sitter`).\n\n    The adapter is responsible for holding the parsed tree structure and any\n    necessary metadata for operations.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the adapter by parsing the provided source code.\n\n        Args:\n            source_code: The string content of the source file to be parsed.\n\n        Raises:\n            ValueError: If the source code cannot be parsed due to syntax errors.\n        \"\"\"\n        self.source_code: str = source_code\n        self.tree: Optional[ASTNode] = None\n        self.nodes: Dict[str, ASTNode] = {} # A map for quick access to named elements\n        self._parse_and_map(source_code)\n\n    @abstractmethod\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Abstract method to parse the source code and populate `self.tree` and `self.nodes`.\n\n        This is the core method where language-specific parsing logic resides.\n        Implementations should:\n        1. Parse the `source_code` into an AST/CST representation.\n        2. Store the root of this representation in `self.tree`.\n        3. Identify key top-level elements (functions, classes, variables, imports)\n           and map their names to their nodes in `self.nodes`.\n\n        Args:\n            source_code: The string content to parse.\n\n        Raises:\n            ValueError: If the source code cannot be parsed.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_elements(self) -> List[str]:\n        \"\"\"\n        Abstract method to list the names of the main elements found in the code.\n\n        These are typically top-level functions, classes, variable assignments,\n        and imports that the adapter can identify and manipulate.\n\n        Returns:\n            A list of element names (strings).\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"\n        Abstract method to get the source code string for a specific element.\n\n        Args:\n            element_name: The name of the element (function, class, etc.).\n\n        Returns:\n            The source code string for the element, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"\n        Abstract method to get detailed structural information about an element.\n\n        This information can include type, line numbers, body items, etc., useful\n        for aiding the AI in understanding the code's layout.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            A dictionary containing structural details, or None if not found.\n            Example structure:\n            {\n                'name': 'func_name',\n                'type': 'FunctionDef', # or 'ClassDef', etc.\n                'line_start': 10,\n                'line_end': 25,\n                'body_items': [list of internal statement details...]\n            }\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"\n        Abstract method to extract a snippet of code from within an element's body.\n\n        Used for 'partial' edits where only a specific range of lines within\n        a function or class needs to be changed.\n\n        Args:\n            element_name: The name of the element containing the snippet.\n            line_start: The starting line number (1-based, absolute) of the snippet.\n            line_end: The ending line number (inclusive) of the snippet.\n\n        Returns:\n            The source code string for the specified lines within the element, or None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"\n        Abstract method to replace an entire named element.\n\n        This involves finding the old element in the tree and swapping it with\n        the representation of the `new_code`.\n\n        Args:\n            element_name: The name of the element to replace.\n            new_code: The new source code for the element (and potential helpers).\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"\n        Abstract method to add a new block of code (element) to the file.\n\n        This involves parsing the `new_code` and inserting its representation\n        into the tree at an appropriate location (e.g., end of file, near anchor).\n\n        Args:\n            new_code: The source code for the new element(s).\n            anchor_name: Optional name of an existing element to position relative to.\n            before: If True and `anchor_name` is provided, insert before the anchor.\n\n        Returns:\n            True if the element was added successfully, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"\n        Abstract method to delete a named element from the file.\n\n        This involves finding the element in the tree and removing its representation.\n\n        Args:\n            element_name: The name of the element to delete.\n\n        Returns:\n            True if the element was successfully deleted, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"\n        Abstract method for a 'surgical' edit within an element's body.\n\n        Replaces a specific statement or line range within the body of an element.\n\n        Args:\n            element_name: Name of the function/class to modify.\n            new_code: New code to insert (can be multiple statements).\n            line_start: Starting line number (absolute) within the element.\n            line_end: Ending line number (inclusive) within the element.\n            statement_index: Alternative to line numbers - replace the Nth statement.\n\n        Returns:\n            True if successful, False otherwise.\n        \"\"\"\n        pass\n\n    # --- Methods related to final output and change tracking ---\n\n    @abstractmethod\n    def get_modified_source(self) -> str:\n        \"\"\"\n        Abstract method to serialize the potentially modified AST/CST back to source code.\n\n        Returns:\n            The full source code string reflecting the current state of the tree.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_diff(self) -> str:\n        \"\"\"\n        Abstract method to generate a diff between the original source and the modified source.\n\n        Returns:\n            A string containing the unified diff.\n        \"\"\"\n        pass\n\n    # Internal helper methods (can be abstract or have common logic in base if needed)\n    # These are less critical for the interface but might be useful\n    # _add_imports(new_import_nodes) -> could be handled differently per language\n    # _find_statement_in_body(body, line_start, line_end) -> Tree-sitter needs different logic",
    "file": "/mnt/ProjectData/omni/ast_adapter.py"
  },
  {
    "id": 32,
    "hash": "17ef2c48d5827115cc9579bd067e6ec9",
    "content": "\"\"\"\nCodeEditor - Enhanced AST-based Python code manipulation tool\n\nThis module provides a class to programmatically parse, analyze,\nand edit Python source code using Abstract Syntax Trees (AST).\nIt supports both full element replacement and surgical partial edits\nwithin functions and classes using asttokens for precise source mapping.\n\"\"\"\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Union, Tuple\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n    print(\"Warning: asttokens not installed. Partial edits will be limited.\")\n\n\nclass CodeEditor:\n    \"\"\"An enhanced class to safely edit Python files using AST with partial edit support.\"\"\"\n\n    def __init__(self, file_path: str):\n        self.file_path = file_path\n        self.source_code = self._read_file()\n        self.tree: ast.AST = self._parse_source()\n        self.nodes: Dict[str, ast.AST] = self._map_nodes()\n        # Enhanced source tracking with asttokens\n        if ASTTOKENS_AVAILABLE:\n            self.atok = asttokens.ASTTokens(self.source_code, parse=True)\n        else:\n            self.atok = None\n\n    def _read_file(self) -> str:\n        try:\n            with open(self.file_path, 'r') as f:\n                return f.read()\n        except FileNotFoundError:\n            raise ValueError(f'File not found: {self.file_path}')\n\n    def _parse_source(self) -> ast.AST:\n        try:\n            return ast.parse(self.source_code)\n        except SyntaxError as e:\n            raise ValueError(f'Invalid Python syntax in {self.file_path}: {e}')\n\n    def _map_nodes(self) -> Dict[str, ast.AST]:\n        nodes = {}\n        for node in ast.walk(self.tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def list_elements(self) -> List[str]:\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        node = self.nodes.get(element_name)\n        return astor.to_source(node) if node else None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"\n        Get detailed structure information about an element including\n        line numbers and internal components.\n        \"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n        \n        structure = {\n            'name': element_name,\n            'type': node.__class__.__name__,\n            'line_start': node.lineno if hasattr(node, 'lineno') else None,\n            'line_end': node.end_lineno if hasattr(node, 'end_lineno') else None,\n            'body_items': []\n        }\n        \n        if hasattr(node, 'body'):\n            for i, item in enumerate(node.body):\n                item_info = {\n                    'index': i,\n                    'type': item.__class__.__name__,\n                    'line_start': item.lineno if hasattr(item, 'lineno') else None,\n                    'line_end': item.end_lineno if hasattr(item, 'end_lineno') else None\n                }\n                \n                # Add more details for common statement types\n                if isinstance(item, ast.Assign) and item.targets:\n                    target = item.targets[0]\n                    if isinstance(target, ast.Name):\n                        item_info['assigns'] = target.id\n                elif isinstance(item, (ast.If, ast.While, ast.For)):\n                    item_info['has_body'] = bool(item.body)\n                elif isinstance(item, ast.Return):\n                    item_info['returns'] = True\n                    \n                structure['body_items'].append(item_info)\n                \n        return structure\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int, line_end: Optional[int] = None) -> Optional[Tuple[int, ast.AST]]:\n        \"\"\"\n        Find a statement in a body by line number range.\n        Returns (index, statement) or None.\n        \"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = stmt.end_lineno if hasattr(stmt, 'end_lineno') else stmt.lineno\n                    if stmt.lineno <= line_start <= stmt_end or stmt.lineno <= line_end <= stmt_end:\n                        return (i, stmt)\n                else:\n                    if stmt.lineno == line_start:\n                        return (i, stmt)\n        return None\n\n    def replace_partial(self, element_name: str, new_code: str, \n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"\n        Replace a partial section of an element (function/class).\n        \n        Args:\n            element_name: Name of the function/class to modify\n            new_code: New code to insert (can be multiple statements)\n            line_start: Starting line number within the element (1-based, absolute)\n            line_end: Ending line number within the element (inclusive)\n            statement_index: Alternative to line numbers - replace the Nth statement\n            \n        Returns:\n            True if successful, False otherwise\n        \"\"\"\n        if element_name not in self.nodes:\n            return False\n            \n        node = self.nodes[element_name]\n        if not hasattr(node, 'body') or not isinstance(node.body, list):\n            return False\n            \n        try:\n            # Parse the new code\n            if new_code.strip().startswith('def ') or new_code.strip().startswith('class '):\n                # If it's a full function/class, extract just the body\n                new_ast = ast.parse(new_code)\n                new_statements = new_ast.body[0].body\n            else:\n                # Parse as a module and get all statements\n                new_ast = ast.parse(new_code)\n                new_statements = new_ast.body\n        except SyntaxError:\n            return False\n            \n        if not new_statements:\n            return False\n            \n        # Find what to replace\n        if statement_index is not None:\n            # Replace by index\n            if 0 <= statement_index < len(node.body):\n                node.body[statement_index:statement_index+1] = new_statements\n                return True\n        elif line_start is not None:\n            # Replace by line number\n            result = self._find_statement_in_body(node.body, line_start, line_end)\n            if result:\n                idx, _ = result\n                if line_end:\n                    # Find end index\n                    end_idx = idx\n                    for i in range(idx + 1, len(node.body)):\n                        stmt = node.body[i]\n                        if hasattr(stmt, 'end_lineno') and stmt.end_lineno <= line_end:\n                            end_idx = i\n                        else:\n                            break\n                    node.body[idx:end_idx+1] = new_statements\n                else:\n                    node.body[idx:idx+1] = new_statements\n                return True\n                \n        return False\n\n    def insert_in_element(self, element_name: str, new_code: str, \n                         position: str = 'end', \n                         after_line: Optional[int] = None,\n                         before_line: Optional[int] = None) -> bool:\n        \"\"\"\n        Insert new code into an element without replacing existing code.\n        \n        Args:\n            element_name: Name of the function/class\n            new_code: Code to insert\n            position: 'start', 'end', or use after_line/before_line\n            after_line: Insert after this line number\n            before_line: Insert before this line number\n            \n        Returns:\n            True if successful\n        \"\"\"\n        if element_name not in self.nodes:\n            return False\n            \n        node = self.nodes[element_name]\n        if not hasattr(node, 'body') or not isinstance(node.body, list):\n            return False\n            \n        try:\n            new_ast = ast.parse(new_code)\n            new_statements = new_ast.body\n        except SyntaxError:\n            return False\n            \n        if not new_statements:\n            return False\n            \n        if position == 'start':\n            node.body[0:0] = new_statements\n        elif position == 'end':\n            node.body.extend(new_statements)\n        elif after_line:\n            result = self._find_statement_in_body(node.body, after_line)\n            if result:\n                idx, _ = result\n                node.body[idx+1:idx+1] = new_statements\n            else:\n                return False\n        elif before_line:\n            result = self._find_statement_in_body(node.body, before_line)\n            if result:\n                idx, _ = result\n                node.body[idx:idx] = new_statements\n            else:\n                return False\n        else:\n            return False\n            \n        return True\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"\n        Get a specific snippet from within an element's body by line numbers.\n        \"\"\"\n        if not self.atok:\n            return None\n            \n        node = self.nodes.get(element_name)\n        if not node or not hasattr(node, 'body'):\n            return None\n            \n        # Find statements in the range\n        statements = []\n        for stmt in node.body:\n            if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                if line_start <= stmt.lineno <= line_end or line_start <= stmt.end_lineno <= line_end:\n                    statements.append(stmt)\n                    \n        if not statements:\n            return None\n            \n        # Generate source for the statements\n        return '\\n'.join(astor.to_source(stmt).strip() for stmt in statements)\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.ImportFrom]]) -> None:\n        \"\"\"Intelligently adds new import nodes to the top of the AST.\"\"\"\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                existing_imports_str.add(astor.to_source(node).strip())\n                last_import_index = i\n        for new_import in reversed(new_import_nodes):\n            new_import_str = astor.to_source(new_import).strip()\n            if new_import_str not in existing_imports_str:\n                self.tree.body.insert(last_import_index + 1, new_import)\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"\n        Replaces a target element with a new block of code.\n\n        This method is more robust than a simple node-for-node replacement.\n        It parses the `new_code`, separates imports (which are moved to the top\n        of the file) from the main code body (functions, classes, variables, etc.),\n        and then replaces the single original element node in the AST with the\n        entire new code body. This allows the AI to return code blocks that\n        include helper constants or other statements along with the primary\n        function or class definition.\n\n        Args:\n            element_name: The name of the function or class to replace.\n            new_code: A string containing the new Python code.\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        if element_name not in self.nodes:\n            return False\n        try:\n            new_ast_module = ast.parse(new_code)\n        except SyntaxError:\n            return False\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n        if not new_code_body:\n            return False\n        if new_imports:\n            self._add_imports(new_imports)\n        for node in ast.walk(self.tree):\n            if hasattr(node, 'body') and isinstance(node.body, list):\n                try:\n                    old_node = self.nodes[element_name]\n                    idx = node.body.index(old_node)\n                    node.body.pop(idx)\n                    for i, new_node in enumerate(new_code_body):\n                        node.body.insert(idx + i, new_node)\n                    del self.nodes[element_name]\n                    for n in new_code_body:\n                        if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                            self.nodes[n.name] = n\n                    return True\n                except (ValueError, KeyError):\n                    continue\n        return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None,\n                   before: bool = False) -> bool:\n        \"\"\"\n        Adds a new block of code (function, class, variables) to the file.\n\n        This method intelligently handles code snippets from the AI. It separates\n        any import statements and adds them to the top of the file. The rest of\n        the code block is inserted at an appropriate location, determined either\n        by an `anchor_name` or by placing it before the main execution block\n        (`if __name__ == '__main__'`).\n\n        Args:\n            new_code: The string containing the new function/class/variables.\n            anchor_name: The name of an existing element to insert relative to.\n            before: If True, insert before the anchor; otherwise, after.\n\n        Returns:\n            True if the element block was added successfully, False otherwise.\n        \"\"\"\n        try:\n            new_ast_module = ast.parse(new_code)\n        except (SyntaxError, IndexError):\n            return False\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n        if not new_code_body:\n            return False\n        if new_imports:\n            self._add_imports(new_imports)\n        insertion_index = -1\n        main_block_idx = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, ast.If) and isinstance(node.test, ast.Compare) and isinstance(node.test.left, ast.Name) and node.test.left.id == '__name__' and len(node.test.ops) == 1 and isinstance(node.test.ops[0], ast.Eq) and len(node.test.comparators) == 1:\n                comp = node.test.comparators[0]\n                if isinstance(comp, ast.Constant) and comp.value == '__main__' or isinstance(comp, ast.Str) and comp.s == '__main__':\n                    main_block_idx = i\n                    break\n        if anchor_name:\n            if anchor_name not in self.nodes:\n                return False\n            anchor_node = self.nodes[anchor_name]\n            try:\n                anchor_idx = self.tree.body.index(anchor_node)\n                proposed_index = anchor_idx if before else anchor_idx + 1\n                if main_block_idx != -1:\n                    insertion_index = min(proposed_index, main_block_idx)\n                else:\n                    insertion_index = proposed_index\n            except ValueError:\n                return False\n        elif main_block_idx != -1:\n            insertion_index = main_block_idx\n        if insertion_index == -1:\n            self.tree.body.extend(new_code_body)\n        else:\n            for i, new_node in enumerate(new_code_body):\n                self.tree.body.insert(insertion_index + i, new_node)\n        for node in new_code_body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                self.nodes[node.name] = node\n        return True\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"\n        Deletes a function, class, variable (ast.Assign), or import (ast.Import/ast.ImportFrom) by its name from the AST.\n        Handles top-level elements primarily, with walking for functions and classes.\n\n        Args:\n            element_name: The name of the element to delete (function, class, variable, or imported name).\n\n        Returns:\n            True if the element was successfully deleted, False otherwise.\n        \"\"\"\n        deleted = False\n        if element_name in self.nodes:\n            node_to_delete = self.nodes[element_name]\n            for node in ast.walk(self.tree):\n                if hasattr(node, 'body') and isinstance(node.body, list):\n                    try:\n                        node.body.remove(node_to_delete)\n                        deleted = True\n                        break\n                    except ValueError:\n                        continue\n            if deleted:\n                del self.nodes[element_name]\n                self.nodes = self._map_nodes()\n                return True\n        new_body = []\n        for node in self.tree.body:\n            if isinstance(node, ast.Assign):\n                match = False\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id == element_name:\n                        match = True\n                        break\n                if match:\n                    deleted = True\n                    continue\n            elif isinstance(node, ast.Import):\n                new_aliases = []\n                for alias in node.names:\n                    if (alias.name == element_name or alias.asname == element_name):\n                        deleted = True\n                    else:\n                        new_aliases.append(alias)\n                if new_aliases:\n                    node.names = new_aliases\n                elif deleted:\n                    continue\n            elif isinstance(node, ast.ImportFrom):\n                new_aliases = []\n                for alias in node.names:\n                    if (alias.name == element_name or alias.asname == element_name):\n                        deleted = True\n                    else:\n                        new_aliases.append(alias)\n                if new_aliases:\n                    node.names = new_aliases\n                elif deleted:\n                    continue\n            new_body.append(node)\n        self.tree.body = new_body\n        if deleted:\n            self.nodes = self._map_nodes()\n        return deleted\n\n    def apply_arbitrary_change(self, new_source_code: str) -> bool:\n        \"\"\"\n        Rewrites the entire file's AST from a new source string.\n\n        This method parses the provided new_source_code into a new AST.\n        If the code is syntactically valid, it replaces the class's internal\n        AST (`self.tree`), remaps the file's nodes, and returns True. If\n        parsing fails, it returns False.\n        \"\"\"\n        try:\n            new_tree = ast.parse(new_source_code)\n            self.tree = new_tree\n            self.nodes = self._map_nodes()\n            # Recreate asttokens if available\n            if ASTTOKENS_AVAILABLE:\n                self.source_code = new_source_code\n                self.atok = asttokens.ASTTokens(self.source_code, parse=True)\n            return True\n        except SyntaxError:\n            return False\n\n    def get_modified_source(self) -> str:\n        return astor.to_source(self.tree)\n\n    def get_diff(self) -> str:\n        modified_source = self.get_modified_source()\n        return ''.join(difflib.unified_diff(\n            self.source_code.splitlines(keepends=True), \n            modified_source.splitlines(keepends=True),\n            fromfile=f'{self.file_path} (original)', \n            tofile=f'{self.file_path} (modified)'\n        ))\n\n    def save_changes(self) -> None:\n        modified_source = self.get_modified_source()\n        with open(self.file_path, 'w') as f:\n            f.write(modified_source)",
    "file": "/mnt/ProjectData/omni/code_editor.py"
  },
  {
    "id": 33,
    "hash": "cc52aa524d0929867d5d2ea3697229e6",
    "content": "\"\"\"\nGenerated file.\n\"\"\"\nimport os\n\"\"\"\nFileCreator - A utility for creating files.\n\nThis module provides a simple, encapsulated way to create files,\nensuring that their parent directories exist before writing.\n\"\"\"\n\n\nclass FileCreator:\n    \"\"\"\n    A utility class to handle the creation of new files.\n    \"\"\"\n\n    @staticmethod\n    def create(file_path: str, content: str) ->None:\n        \"\"\"\n        Creates a file at the specified path with the given content.\n\n        This method will automatically create any necessary parent\n        directories for the file path.\n\n        Args:\n            file_path: The full path where the file should be created.\n            content: The string content to write to the file.\n\n        Raises:\n            IOError: If there is an error creating the directories or writing the file.\n        \"\"\"\n        try:\n            directory = os.path.dirname(file_path)\n            if directory:\n                os.makedirs(directory, exist_ok=True)\n            with open(file_path, 'w', encoding='utf-8') as f:\n                f.write(content)\n        except (IOError, OSError) as e:\n            raise IOError(f\"Failed to create file '{file_path}': {e}\") from e\n",
    "file": "/mnt/ProjectData/omni/file_creator.py"
  },
  {
    "id": 34,
    "hash": "04a24ceab008bd649d0530d309c72e42",
    "content": "import subprocess\nimport os\nfrom typing import List, Optional, Union\n\n\nclass GitManager:\n    \"\"\"\n    Encapsulates Git-related logic for a specific repository.\n\n    This class provides methods to perform common Git operations such as\n    checking status, getting diffs, staging, committing, and pushing changes.\n    It relies on the Git command-line tool being installed and accessible\n    in the system's PATH.\n    \"\"\"\n\n    def __init__(self, repo_path: str):\n        \"\"\"\n        Initializes the GitManager for a given repository path.\n\n        Args:\n            repo_path: The absolute or relative path to the Git repository.\n\n        Raises:\n            ValueError: If the provided path is not a valid Git repository.\n        \"\"\"\n        if not os.path.isdir(os.path.join(repo_path, '.git')):\n            raise ValueError(\n                f\"The path '{repo_path}' is not a valid Git repository.\")\n        self.repo_path = repo_path\n\n    def _run_command(self, command: List[str]) ->str:\n        \"\"\"\n        Executes a Git command in the repository's directory.\n\n        Args:\n            command: A list of command arguments, starting with 'git'.\n\n        Returns:\n            The standard output of the command as a string.\n\n        Raises:\n            subprocess.CalledProcessError: If the command returns a non-zero exit code.\n        \"\"\"\n        try:\n            result = subprocess.run(command, cwd=self.repo_path, check=True,\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True,\n                encoding='utf-8')\n            return result.stdout.strip()\n        except subprocess.CalledProcessError as e:\n            error_message = (\n                f\"Git command failed: {' '.join(command)}\\nError: {e.stderr.strip()}\"\n                )\n            raise subprocess.CalledProcessError(e.returncode, e.cmd, output\n                =e.stdout, stderr=error_message) from e\n\n    def get_status(self) ->str:\n        \"\"\"\n        Gets the repository status in a condensed format.\n\n        Uses `git status --porcelain` for a machine-readable output.\n\n        Returns:\n            A string representing the repository's status.\n        \"\"\"\n        return self._run_command(['git', 'status', '--porcelain'])\n        \n    def get_changed_files(self) -> List[str]:\n        \"\"\"\n        Gets a list of all changed (modified, added, deleted, untracked, renamed, or copied) files.\n\n        This parses the output of `git status --porcelain`, which provides a stable,\n        machine-readable format.\n\n        Returns:\n            A list of file paths relative to the repository root. For renamed or\n            copied files, it returns the new path.\n        \"\"\"\n        status_output = self.get_status()\n        if not status_output:\n            return []\n        \n        changed_files = []\n        for line in status_output.splitlines():\n            if len(line) < 3:  # Skip malformed lines\n                continue\n                \n            # Git status porcelain format: XY filename\n            # X = index status, Y = working tree status\n            index_status = line[0]\n            worktree_status = line[1]\n            \n            # The filename starts after the two status characters and a space\n            # But let's be more defensive about finding where the filename actually starts\n            filename_start = 2\n            while filename_start < len(line) and line[filename_start] == ' ':\n                filename_start += 1\n                \n            if filename_start >= len(line):\n                continue  # Skip if no filename found\n                \n            path_info = line[filename_start:]\n            \n            # Check if either index or working tree status indicates rename/copy\n            if index_status in ('R', 'C') or worktree_status in ('R', 'C'):\n                if ' -> ' in path_info:\n                    _, new_path = path_info.split(' -> ', 1)  # Use maxsplit=1 for safety\n                    changed_files.append(new_path.strip())\n                else:\n                    # Fallback if format is unexpected\n                    changed_files.append(path_info.strip())\n            else:\n                changed_files.append(path_info.strip())\n        \n        # Remove duplicates while preserving order\n        return list(dict.fromkeys(changed_files))\n\n    def get_diff(self, file_path: Optional[str]=None, staged: bool=False\n        ) ->str:\n        \"\"\"\n        Gets the diff of changes in the repository.\n\n        Args:\n            file_path: Optional. Path to a specific file to diff.\n            staged: If True, shows the diff for staged changes (`--cached`).\n                    Otherwise, shows the diff for unstaged changes.\n\n        Returns:\n            The git diff output as a string.\n        \"\"\"\n        cmd = ['git', 'diff']\n        if staged:\n            cmd.append('--cached')\n        if file_path:\n            cmd.append('--')\n            cmd.append(file_path)\n        return self._run_command(cmd)\n\n    def add(self, files: Union[str, List[str]]) ->None:\n        \"\"\"\n    Stages one or more files, handling each one individually for robustness.\n\n    This approach prevents a single invalid file path from causing the\n    entire 'git add' operation to fail. Warnings will be printed for any\n    files that could not be staged.\n\n    Args:\n        files: A single file path or a list of file paths to stage.\n               Can also be '.' to stage all changes.\n    \"\"\"\n        if isinstance(files, str):\n            files = [files]\n        for file_path in files:\n            try:\n                cmd = ['git', 'add', '--', file_path]\n                self._run_command(cmd)\n            except subprocess.CalledProcessError as e:\n                print(\n                    f\"Warning: Could not stage file '{file_path}'. Git reported: {e.stderr}\"\n                    )\n\n    def commit(self, message: str) ->str:\n        \"\"\"\n        Commits staged changes with a given message.\n\n        Args:\n            message: The commit message.\n\n        Returns:\n            The stdout from the git commit command.\n        \"\"\"\n        return self._run_command(['git', 'commit', '-m', message])\n\n    def push(self, remote: str='origin', branch: Optional[str]=None) ->str:\n        \"\"\"\n        Pushes commits to a remote repository.\n\n        Args:\n            remote: The name of the remote to push to (default: 'origin').\n            branch: The branch to push. If None, uses the current branch.\n\n        Returns:\n            The stdout from the git push command.\n        \"\"\"\n        if branch is None:\n            branch = self.get_current_branch()\n        return self._run_command(['git', 'push', remote, branch])\n\n    def get_current_branch(self) ->str:\n        \"\"\"\n        Determines the current active branch name.\n\n        Returns:\n            The name of the current branch.\n        \"\"\"\n        return self._run_command(['git', 'rev-parse', '--abbrev-ref', 'HEAD'])\n",
    "file": "/mnt/ProjectData/omni/git_manager.py"
  },
  {
    "id": 35,
    "hash": "89fa0c06ca34019316daa58ce8fa9a20",
    "content": "import json\nimport os\nfrom typing import List, Dict, Optional\nfrom rag_manager import RAGManager\n\n\nclass MemoryManager:\n    \"\"\"Manages persistent chat memory, look data, and RAG integration via JSON.\"\"\"\n\n    def __init__(self, memory_file: str):\n        self.memory_file = memory_file\n        self.memory: Dict[str, List] = self.load_memory()\n        self.rag_manager = RAGManager()\n\n    def load_memory(self) ->Dict[str, List]:\n        try:\n            with open(self.memory_file, 'r') as f:\n                return json.load(f)\n        except FileNotFoundError:\n            default = {'chat': [], 'look': []}\n            self.save_memory(default)\n            return default\n        except json.JSONDecodeError:\n            print('[yellow]Invalid memory file. Resetting.[/]')\n            return {'chat': [], 'look': []}\n\n    def save_memory(self, memory: Optional[Dict[str, List]]=None) ->None:\n        if memory is None:\n            memory = self.memory\n        with open(self.memory_file, 'w') as f:\n            json.dump(memory, f, indent=4)\n\n    def add_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.memory['chat'].append({'role': role, 'content': content})\n        self.save_memory()\n\n    def add_chat_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        This is an alias for add_message to maintain compatibility.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.add_message(role, content)\n\n    def add_look_data(self, file_path: str, content: str) ->None:\n        \"\"\"\n    Adds a watched item (directory or file) to memory, distinguishing its type.\n\n    This method stores structured data that differentiates between a project\n    directory (containing a manifest) and a single file (containing its content).\n    It also prevents duplicate entries by updating existing ones.\n\n    Args:\n        file_path: The path to the directory or file.\n        content: The manifest for a directory or the content for a file.\n    \"\"\"\n        item_type = 'directory' if os.path.isdir(file_path) else 'file'\n        for item in self.memory['look']:\n            if item.get('file') == file_path:\n                item['content'] = content\n                item['type'] = item_type\n                self.save_memory()\n                return\n        self.memory['look'].append({'type': item_type, 'file': file_path,\n            'content': content})\n        self.save_memory()\n        if item_type == 'file':\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    file_content = f.read()\n                self.rag_manager.add_documents([file_content], [{'file':\n                    file_path}])\n            except Exception as e:\n                print(\n                    f'[yellow]Warning: Could not add {file_path} to RAG index: {e}[/]'\n                    )\n\n    def get_project_root(self) ->Optional[str]:\n        \"\"\"\n        Finds the root directory of the project currently in memory.\n\n        The project root is defined as the first item in the 'look' memory\n        that is of type 'directory'.\n\n        Returns:\n            The absolute path to the project root directory, or None if not found.\n        \"\"\"\n        for item in self.memory.get('look', []):\n            if item.get('type') == 'directory':\n                return item.get('file')\n        return None\n\n    def get_memory_context(self) ->str:\n        \"\"\"\n        Dynamically builds the context using RAG and chat history.\n\n        It retrieves relevant file content from the RAG index based on the latest\n        user query, includes project manifests for directories, and appends the\n        recent chat history.\n        \"\"\"\n        context = ''\n        for look in self.memory.get('look', []):\n            path = look.get('file')\n            if path and os.path.isdir(path):\n                content = look.get('content', '')\n                context += (\n                    f'--- Project Manifest for {path} ---\\n{content}\\n\\n')\n        last_user_message = next((msg['content'] for msg in reversed(self.\n            memory.get('chat', [])) if msg['role'] == 'user'), None)\n        if last_user_message:\n            rag_results = self.search_rag(last_user_message, k=3)\n            if rag_results:\n                context += '--- Relevant context from RAG ---\\n'\n                for doc, score, meta in rag_results:\n                    file_path = meta.get('file', 'Unknown source')\n                    context += f'Source: {file_path} (Score: {score:.4f})\\n'\n                    context += f'Content: {doc}\\n---\\n'\n                context += '\\n'\n        for msg in self.memory.get('chat', []):\n            context += f\"{msg['role'].capitalize()}: {msg['content']}\\n\"\n        return context.strip()\n\n    def clear_memory(self) ->None:\n        self.memory = {'chat': [], 'look': []}\n        self.save_memory()\n        self.rag_manager.clear_index()\n\n    def search_rag(self, query: str, k: int=3) ->List[tuple]:\n        \"\"\"\n        Search the RAG index for relevant documents.\n        \n        Args:\n            query: The search query\n            k: Number of results to return\n            \n        Returns:\n            List of (document_content, score, metadata) tuples\n        \"\"\"\n        return self.rag_manager.search(query, k)\n",
    "file": "/mnt/ProjectData/omni/memory_manager.py"
  },
  {
    "id": 36,
    "hash": "1503715e21300d3433a383484d00a3cb",
    "content": "\"\"\"\nOmni - AI-powered code generation and project-aware editing CLI tool\n\nIntegrates modular UI, memory, personality, and AST-based code editing.\n\"\"\"\nimport os\nimport subprocess\nimport requests\nimport json\nimport sys\nimport re\nimport argparse\nimport ast\nfrom datetime import datetime\nimport threading\nimport queue as Queue\nimport time\nfrom typing import List, Dict, Optional\nfrom rich import print\nfrom rich.panel import Panel\nfrom rich.console import Console\nfrom rich.tree import Tree\nfrom ui_manager import UIManager\nfrom personality_manager import PersonalityManager\nfrom memory_manager import MemoryManager\nfrom code_editor import CodeEditor\nfrom file_creator import FileCreator\nfrom git_manager import GitManager\nimport traceback\nDEFAULT_BACKEND = 'openrouter'\nOLLAMA_MODEL = 'phi4-reasoning'\nOPENROUTER_MODEL = 'qwen/qwen3-coder'\nDEFAULT_SAVE_DIR = os.path.expanduser('/mnt/ProjectData/omni/omni_saves/')\nCONFIG_FILE = 'config.json'\nMEMORY_FILE = 'memory.json'\nOLLAMA_API_URL = 'http://localhost:11434/api/generate'\nOPENROUTER_API_URL = 'https://openrouter.ai/api/v1/chat/completions'\nOPENROUTER_MODELS_API_URL = 'https://openrouter.ai/api/v1/models'\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\ncurrent_backend = DEFAULT_BACKEND\ncurrent_model = (OLLAMA_MODEL if DEFAULT_BACKEND == 'ollama' else\n    OPENROUTER_MODEL)\nOLLAMA_MODELS = {'deepseek': 'deepseek-coder:6.7b', 'codellama':\n    'codellama:13b', 'mistral': 'mistral:latest', 'llama2': 'llama2:latest',\n    'phind': 'phind-codellama:34b'}\nos.makedirs(DEFAULT_SAVE_DIR, exist_ok=True)\nTEMPLATES = {'flask':\n    \"\"\"from flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/')\ndef home():\n    return '<h1>Hello, Flask!</h1>'\n\nif __name__ == '__main__':\n    app.run(debug=True)\"\"\"\n    , 'html5':\n    \"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>New Page</title>\n</head>\n<body>\n    <h1>Hello World</h1>\n</body>\n</html>\"\"\"\n    , 'scraper':\n    \"\"\"import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        print(soup.title.text)\n    except Exception as e:\n        print(f\"[bold red]Error scraping {url}:[/] {e}\")\n\nif __name__ == \"__main__\":\n    scrape(\"https://example.com\")\"\"\"\n    }\nconsole = Console()\npersonality_manager = PersonalityManager(CONFIG_FILE)\nmemory_manager = MemoryManager(MEMORY_FILE)\nui_manager = UIManager()\nlast_query: Optional[str] = None\nlast_response: Optional[str] = None\nlast_code: Optional[str] = None\n\n\ndef start_ollama_server() ->None:\n    if current_backend != 'ollama':\n        return\n    try:\n        requests.get('http://localhost:11434', timeout=1)\n    except requests.exceptions.ConnectionError:\n        print('[cyan]Starting Ollama server...[/]')\n        subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL)\n\n\ndef query_llm(prompt: str) ->str:\n    personality = personality_manager.get_current_personality()\n    system_prompt = personality.get('system_prompt', '') if personality else ''\n    memory_context = memory_manager.get_memory_context()\n    rag_context = ''\n    try:\n        from rag_manager import RAGManager\n        project_root = memory_manager.get_project_root()\n        if project_root:\n            rag_manager = RAGManager()\n            if rag_manager.get_document_count() > 0:\n                results = rag_manager.search(prompt, k=3)\n                if results:\n                    rag_context = '\\n\\nRelevant context from codebase:\\n'\n                    for i, (doc, score, meta) in enumerate(results, 1):\n                        file_path = meta.get('file', 'Unknown')\n                        rag_context += f'{i}. [{file_path}] {doc}\\n'\n    except Exception:\n        pass\n    full_prompt = (\n        f'{system_prompt}\\n\\n{memory_context}{rag_context}\\n\\nUser: {prompt}')\n    with ui_manager.show_spinner('AI is listening and thinking...'):\n        if current_backend == 'ollama':\n            response = query_ollama(full_prompt)\n        elif current_backend == 'openrouter':\n            response = query_openrouter(full_prompt)\n        else:\n            response = '[bold red]Error:[/] Unknown backend'\n    return response\n\n\ndef query_openrouter(prompt: str) ->str:\n    if not OPENROUTER_API_KEY:\n        return '[bold red]Error:[/] OPENROUTER_API_KEY not set.'\n    headers = {'Authorization': f'Bearer {OPENROUTER_API_KEY}',\n        'Content-Type': 'application/json'}\n    payload = {'model': current_model, 'messages': [{'role': 'user',\n        'content': prompt}]}\n    try:\n        response = requests.post(OPENROUTER_API_URL, headers=headers, json=\n            payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['choices'][0]['message']['content']\n    except Exception as e:\n        error_details = ''\n        try:\n            error_details = response.json()\n        except:\n            error_details = response.text if hasattr(response, 'text'\n                ) else str(e)\n        return (\n            f'[bold red]OpenRouter Error:[/] {e}\\n[dim]Details: {error_details}[/dim]'\n            )\n\n\ndef query_ollama(prompt: str) ->str:\n    payload = {'model': current_model, 'prompt': prompt, 'stream': False}\n    try:\n        response = requests.post(OLLAMA_API_URL, json=payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['response']\n    except Exception as e:\n        return f'[bold red]Ollama Error:[/] {e}'\n\n\ndef extract_code(text: str) ->List[tuple[str, str]]:\n    matches = re.findall('```(\\\\w*)\\\\n([\\\\s\\\\S]*?)```', text)\n    return [(lang or 'text', code.strip()) for lang, code in matches\n        ] if matches else []\n\n\ndef list_models(args: list=None) ->None:\n    if current_backend == 'ollama':\n        print('[bold cyan]Popular Ollama Models:[/]')\n        for name, model_id in OLLAMA_MODELS.items():\n            print(\n                f\"{'\u2b50' if model_id == current_model else '  '} [yellow]{name:12}[/] \u2192 {model_id}\"\n                )\n    elif current_backend == 'openrouter':\n        list_openrouter_models(args or [])\n\n\ndef list_openrouter_models(args: list):\n    try:\n        from simple_term_menu import TerminalMenu\n    except ImportError:\n        ui_manager.show_error(\n            \"'simple-term-menu' is required. `pip install simple-term-menu`\")\n        return\n    try:\n        with ui_manager.show_spinner('Fetching models...'):\n            response = requests.get(OPENROUTER_MODELS_API_URL)\n            response.raise_for_status()\n        api_models_data = response.json().get('data', [])\n    except requests.RequestException as e:\n        ui_manager.show_error(f'Error fetching models: {e}')\n        return\n    all_models, sources = [], set()\n    for model_data in api_models_data:\n        if (model_id := model_data.get('id')):\n            sources.add(model_id.split('/')[0])\n            pricing = model_data.get('pricing', {})\n            is_free = pricing.get('prompt') == '0' and pricing.get('completion'\n                ) == '0'\n            all_models.append({'id': model_id, 'name': model_data.get(\n                'name'), 'source': model_id.split('/')[0], 'is_free': is_free})\n    all_models.sort(key=lambda x: (x['source'], x['name']))\n    if args and args[0].lower() == 'sources':\n        print('[bold cyan]Available Model Sources:[/]')\n        [print(f'  [yellow]{s}[/]') for s in sorted(list(sources))]\n        return\n    models_to_display, title = all_models, 'Select an OpenRouter Model'\n    if args:\n        filter_keyword = args[0].lower()\n        title = f\"Select a Model from '{filter_keyword}'\"\n        models_to_display = [m for m in all_models if filter_keyword in m[\n            'source'].lower()]\n        if not models_to_display:\n            ui_manager.show_error(f\"No models for source: '{filter_keyword}'\")\n            return\n    menu_entries = [\n        f\"{'\u2b50' if m['id'] == current_model else '  '} {m['name']} [dim]({m['id']}){' [green](FREE)[/]' if m['is_free'] else ''}[/dim]\"\n         for m in models_to_display]\n    try:\n        cursor_idx = next((i for i, m in enumerate(models_to_display) if m[\n            'id'] == current_model), 0)\n        chosen_index = TerminalMenu(menu_entries, title=f'{title}',\n            cursor_index=cursor_idx, cycle_cursor=True, clear_screen=True\n            ).show()\n        if chosen_index is not None:\n            set_model(models_to_display[chosen_index]['id'])\n        else:\n            print('Model selection cancelled.')\n    except Exception as e:\n        ui_manager.show_error(f'Menu display error: {e}')\n\n\ndef set_model(model_id: str) ->None:\n    global current_model\n    current_model = model_id\n    ui_manager.show_success(f'Model set to: {current_model}')\n\n\ndef switch_backend(backend_name: str) ->None:\n    global current_backend, current_model\n    backend_name = backend_name.lower()\n    if backend_name not in ['ollama', 'openrouter']:\n        ui_manager.show_error(f'Unknown backend: {backend_name}')\n        return\n    current_backend = backend_name\n    current_model = (OLLAMA_MODEL if backend_name == 'ollama' else\n        OPENROUTER_MODEL)\n    ui_manager.show_success(\n        f'Switched to {backend_name} backend with model: {current_model}')\n    if backend_name == 'ollama':\n        start_ollama_server()\n\n\ndef generate_project_manifest(path: str) ->tuple[str, List[str]]:\n    manifest = ''\n    file_paths = []\n    tree = Tree(f'[bold cyan]Project: {os.path.basename(path)}[/]')\n    exclude_dirs = {'__pycache__', '.git', 'venv', 'node_modules', '.idea',\n        'ollama'}\n    for root, dirs, files in os.walk(path):\n        dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.\n            startswith('.')]\n        relative_path = os.path.relpath(root, path)\n        branch = tree\n        if relative_path != '.':\n            parts = relative_path.split(os.sep)\n            for part in parts:\n                child = next((c for c in branch.children if c.label ==\n                    f'[magenta]{part}[/]'), None)\n                if not child:\n                    child = branch.add(f'[magenta]{part}[/]')\n                branch = child\n        for fname in sorted(files):\n            ext = os.path.splitext(fname)[1]\n            if ext not in ('.py', '.js', '.html', '.css', '.md', '.txt'):\n                continue\n            rel_path = os.path.join(relative_path, fname\n                ) if relative_path != '.' else fname\n            file_paths.append(rel_path)\n            branch.add(f'[green]{fname}[/]' if ext == '.py' else\n                f'[dim]{fname}[/]')\n            manifest += f'File: {rel_path}\\n\\n'\n    console.print(tree)\n    return manifest.strip(), file_paths\n\n\ndef look_command(path: str) ->None:\n    \"\"\"\n    Scans a directory or file and loads it into memory. It can resolve paths\n    relative to the current working directory or the project root in memory.\n    If a new directory is scanned, the previous 'look' context is cleared\n    to ensure the context remains relevant.\n    \"\"\"\n    resolved_path = resolve_file_path(path)\n    if not resolved_path:\n        ui_manager.show_error(f'\u274c Path not found: {path}')\n        return\n    if resolved_path != os.path.abspath(path):\n        ui_manager.show_success(\n            f\"Found '{path}' in project. Using: {resolved_path}\")\n    if os.path.isdir(resolved_path):\n        ui_manager.show_success(\n            \"New project directory detected. Clearing previous 'look' context.\"\n            )\n        memory_manager.memory['look'] = []\n        with ui_manager.show_spinner('Generating project manifest...'):\n            manifest = generate_project_manifest(resolved_path)\n        memory_manager.add_look_data(resolved_path, manifest)\n        ui_manager.show_success('\u2705 Project manifest added to memory.')\n    else:\n        try:\n            with ui_manager.show_spinner('Loading file...'):\n                with open(resolved_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n            for item in memory_manager.memory['look']:\n                if item.get('file') == resolved_path:\n                    item['content'] = content\n                    memory_manager.save_memory()\n                    ui_manager.show_success(\n                        '\u2705 Refreshed file content in memory.')\n                    return\n            memory_manager.add_look_data(resolved_path, content)\n            ui_manager.show_success('\u2705 File content added to memory.')\n        except Exception as e:\n            ui_manager.show_error(f'\u274c Error reading file: {e}')\n\n\ndef resolve_file_path(path: str) ->Optional[str]:\n    \"\"\"Resolves a file path, checking CWD first, then against project root in memory.\"\"\"\n    if os.path.exists(path):\n        return os.path.abspath(path)\n    project_root = memory_manager.get_project_root()\n    if project_root:\n        full_path = os.path.join(project_root, path)\n        if os.path.exists(full_path):\n            return full_path\n    return None\n\n\ndef _create_prompt_for_file_creation(file_name: str, instruction: str) ->str:\n    \"\"\"\n    Generate a robust prompt for file creation that instructs the AI to act as an expert,\n    produce complete and clean code, and avoid any extra commentary.\n    \"\"\"\n    return f\"\"\"You are an expert programmer tasked with creating a new file. Your goal is to generate complete, production-ready content based on the user's instruction.\n\nIMPORTANT RULES:\n- Provide ONLY the raw file content - no explanations, notes, or commentary outside the file itself\n- Include all necessary imports, boilerplate, and complete implementations\n- If creating code, ensure it's syntactically correct and follows best practices\n- For configuration files, use appropriate formatting (JSON, YAML, etc.)\n- For documentation files, use proper markdown formatting\n\nFile to create: {file_name}\nUser instruction: {instruction}\n\nGenerate the complete file content now:\"\"\"\n\n\ndef handle_file_create_command(file_path: str, instruction: str):\n    \"\"\"\n    Uses the LLM to generate content for a new file based on an instruction.\n    \"\"\"\n    global last_code\n    if os.path.exists(file_path):\n        if ui_manager.get_user_input(\n            f\"File '{file_path}' already exists. Overwrite? (y/n): \").lower(\n            ) not in ['yes', 'y']:\n            ui_manager.show_error('File creation cancelled.')\n            return\n    prompt = _create_prompt_for_file_creation(os.path.basename(file_path),\n        instruction)\n    with ui_manager.show_spinner(\n        f\"AI is generating content for '{file_path}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    if code_blocks:\n        new_content = code_blocks[0][1]\n    else:\n        new_content = response.strip()\n    if not new_content:\n        ui_manager.show_error('AI did not return any content.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    print(Panel(new_content, title=\n        f'[bold yellow]Proposed content for {file_path}[/]', border_style=\n        'yellow'))\n    if ui_manager.get_user_input('Create this file? (y/n): ').lower() in ['yes'\n        , 'y']:\n        try:\n            FileCreator.create(file_path, new_content)\n            last_code = new_content\n            ui_manager.show_success(f'File created successfully: {file_path}')\n        except IOError as e:\n            ui_manager.show_error(f'Error creating file: {e}')\n    else:\n        ui_manager.show_error('File creation cancelled.')\n\n\ndef look_all_command() ->None:\n    \"\"\"\n    Finds the project manifest in memory, reads every file listed, and adds their content to memory.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first to generate a manifest.\"\n            )\n        return\n    manifest_data = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and item.get('type'\n            ) == 'directory':\n            manifest_data = item.get('content')\n            break\n    if not manifest_data or not isinstance(manifest_data, (list, tuple)\n        ) or len(manifest_data) != 2:\n        ui_manager.show_error(\n            \"Could not find a valid project manifest in memory. Please run 'look <directory>' again.\"\n            )\n        return\n    file_paths = manifest_data[1]\n    if not file_paths:\n        ui_manager.show_error('No files found in the project manifest.')\n        return\n    total_files = len(file_paths)\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Loading {total_files} files from project manifest...'):\n        for file_path_relative in file_paths:\n            full_path = os.path.join(project_root, file_path_relative)\n            if os.path.isfile(full_path):\n                try:\n                    with open(full_path, 'r', encoding='utf-8') as f:\n                        content = f.read().strip()\n                    if not any(look['file'] == full_path for look in\n                        memory_manager.memory['look']):\n                        memory_manager.add_look_data(full_path, content)\n                        loaded_count += 1\n                except Exception as e:\n                    print(\n                        f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\"\n                        )\n    ui_manager.show_success(\n        f'\u2705 Loaded content for {loaded_count} new files into memory.')\n\n\ndef _load_all_project_files_if_needed():\n    \"\"\"\n    Checks if a project is loaded and automatically loads any files from its\n    manifest that are not already in the 'look' memory. This ensures a\n    complete context for editing and refactoring commands.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        return\n    manifest_content = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and 'File:' in item.get('content',\n            ''):\n            manifest_content = item['content']\n            break\n    if not manifest_content:\n        return\n    existing_file_paths = {item['file'] for item in memory_manager.memory.\n        get('look', []) if item.get('type') == 'file'}\n    file_paths_relative = re.findall('File: (.*)', manifest_content)\n    files_to_load = []\n    for rel_path in file_paths_relative:\n        full_path = os.path.join(project_root, rel_path)\n        if full_path not in existing_file_paths and os.path.isfile(full_path):\n            files_to_load.append((full_path, rel_path))\n    if not files_to_load:\n        return\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Auto-loading {len(files_to_load)} project files for context...'):\n        for full_path, file_path_relative in files_to_load:\n            try:\n                with open(full_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n                memory_manager.add_look_data(full_path, content)\n                loaded_count += 1\n            except Exception as e:\n                print(f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\")\n    if loaded_count > 0:\n        ui_manager.show_success(\n            f'\u2705 Loaded {loaded_count} new file(s) into memory for full project context.'\n            )\n\n\ndef _create_prompt_for_element_selection(file_name: str, instruction: str,\n    elements: List[str], element_structures: Dict[str, Dict]) ->str:\n    \"\"\"\n    Create a helper for the first stage of the 'edit' command. This prompt asks the AI\n    to analyze the user's instruction and intelligently select the most relevant code element to modify.\n    \"\"\"\n    element_details = []\n    for elem in elements:\n        if elem in element_structures:\n            struct = element_structures[elem]\n            detail = (\n                f\"{elem} ({struct['type']}, lines {struct['line_start']}-{struct['line_end']})\"\n                )\n            element_details.append(detail)\n        else:\n            element_details.append(elem)\n    return f\"\"\"You are an expert code analyzer. Your task is to identify what should be modified based on the user's instruction.\n\nFile: {file_name}\nAvailable elements: {', '.join(element_details) if element_details else 'None'}\n\nUser instruction: {instruction}\n\nRESPONSE FORMAT:\nChoose one of these response types:\n1. \"ELEMENT: <element_name>\" - to edit an entire function/class\n2. \"PARTIAL: <element_name> LINES: <start>-<end>\" - to edit specific lines within an element\n3. \"FILE\" - to edit the entire file or multiple elements\n\nRULES:\n- If the instruction mentions specific line numbers or a specific part of a function, use PARTIAL\n- If the instruction targets an entire function/class, use ELEMENT\n- If the instruction requires changes to multiple elements or file structure, use FILE\n- For PARTIAL edits, provide absolute line numbers from the original file\n\nWhat should be edited?\"\"\"\n\n\ndef _create_prompt_for_element_rewrite(file_name: str, element_name: str,\n    instruction: str, original_code: str, is_full_file: bool=False) ->str:\n    \"\"\"\n    Create a helper for the second stage of the 'edit' command. This prompt instructs the AI\n    to rewrite a specific code element (or the whole file) based on the user's request,\n    demanding a complete and syntactically correct code block as output.\n    \"\"\"\n    if is_full_file:\n        return f\"\"\"You are an expert programmer. Rewrite the entire file to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the entire file\n- Ensure all syntax is correct and the code is ready to run\n- Preserve existing functionality unless explicitly asked to change it\n- Include all necessary imports and maintain the file's structure\n- Do NOT include any explanations or comments outside the code\n\nFile: {file_name}\nTask: {instruction}\n\nCurrent file content:\n```python\n{original_code}\n```\n\nGenerate the complete updated file now:\"\"\"\n    else:\n        return f\"\"\"You are an expert programmer. Rewrite the specified element to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the element\n- Include any necessary imports at the top of your code block\n- Ensure the code is syntactically correct and maintains the same interface\n- Do NOT include explanations or comments outside the code block\n- The code must be a drop-in replacement for the original element\n\nFile: {file_name}\nElement to modify: {element_name}\nTask: {instruction}\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the complete updated element now:\"\"\"\n\n\ndef _create_prompt_for_partial_edit(file_name: str, element_name: str,\n    instruction: str, original_snippet: str, line_start: int, line_end: int,\n    full_element_code: str) ->str:\n    \"\"\"\n    Create a prompt for partial edits within a function or class.\n    This allows surgical changes to specific parts of code.\n    \"\"\"\n    return f\"\"\"You are an expert programmer. Make a surgical edit to a specific part of a function/class.\n\nCONTEXT:\n- File: {file_name}\n- Element: {element_name}\n- Lines to modify: {line_start}-{line_end}\n- Task: {instruction}\n\nIMPORTANT RULES:\n- Provide ONLY the code that will replace lines {line_start}-{line_end}\n- Your code must fit seamlessly into the existing function\n- Maintain proper indentation (the code will be auto-indented)\n- Do NOT include the function definition or other parts\n- Do NOT include explanations outside the code\n\nFull element for context:\n```python\n{full_element_code}\n```\n\nCode section to replace (lines {line_start}-{line_end}):\n```python\n{original_snippet}\n```\n\nGenerate ONLY the replacement code for the specified lines:\"\"\"\n\n\ndef handle_file_edit_command(file_path: str, instruction: str):\n    \"\"\"\n    Handles the entire workflow for editing a single file, ensuring full\n    project context is loaded before the AI makes any decisions.\n    Now supports partial edits within functions.\n    \"\"\"\n    global last_code\n    _load_all_project_files_if_needed()\n    resolved_path = resolve_file_path(file_path)\n    if not resolved_path:\n        ui_manager.show_error(f'File not found: {file_path}')\n        return\n    if resolved_path != os.path.abspath(file_path):\n        ui_manager.show_success(\n            f\"Found '{file_path}' in project. Using: {resolved_path}\")\n    try:\n        editor = CodeEditor(resolved_path)\n    except (ValueError, FileNotFoundError) as e:\n        ui_manager.show_error(str(e))\n        return\n    elements = editor.list_elements()\n    element_structures = {}\n    for elem in elements:\n        struct = editor.get_element_structure(elem)\n        if struct:\n            element_structures[elem] = struct\n    prompt1 = _create_prompt_for_element_selection(os.path.basename(\n        resolved_path), instruction, elements, element_structures)\n    with ui_manager.show_spinner('AI is analyzing file...'):\n        ai_response = query_llm(prompt1).strip()\n    if ai_response.upper() == 'FILE':\n        ui_manager.show_success('AI has chosen to edit the entire file.')\n        original_snippet = editor.source_code\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), 'entire file', instruction, original_snippet,\n            is_full_file=True)\n        edit_type = 'FILE'\n        element_to_edit = None\n        line_range = None\n    elif ai_response.startswith('PARTIAL:'):\n        parts = ai_response.split()\n        element_to_edit = parts[1]\n        if 'LINES:' in ai_response:\n            line_part = ai_response.split('LINES:')[1].strip()\n            if '-' in line_part:\n                line_start, line_end = map(int, line_part.split('-'))\n                line_range = line_start, line_end\n            else:\n                ui_manager.show_error('Invalid line range format')\n                return\n        else:\n            ui_manager.show_error('Missing line range for partial edit')\n            return\n        if element_to_edit not in elements:\n            ui_manager.show_error(f\"Element '{element_to_edit}' not found\")\n            return\n        ui_manager.show_success(\n            f\"AI selected partial edit of '{element_to_edit}' (lines {line_start}-{line_end})\"\n            )\n        original_snippet = editor.get_element_body_snippet(element_to_edit,\n            line_start, line_end)\n        if not original_snippet:\n            original_snippet = editor.get_source_of(element_to_edit)\n        full_element_code = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_partial_edit(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet,\n            line_start, line_end, full_element_code)\n        edit_type = 'PARTIAL'\n    elif ai_response.startswith('ELEMENT:'):\n        element_to_edit = ai_response.split(':', 1)[1].strip()\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    else:\n        element_to_edit = ai_response.splitlines()[0]\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    with ui_manager.show_spinner(f'AI is editing...'):\n        response = query_llm(prompt2)\n    code_blocks = extract_code(response)\n    if not code_blocks:\n        ui_manager.show_error('AI did not return a valid code block.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    new_code = code_blocks[0][1]\n    success = False\n    if edit_type == 'FILE':\n        try:\n            editor.tree = ast.parse(new_code)\n            success = True\n        except SyntaxError as e:\n            ui_manager.show_error(f'AI returned invalid Python syntax: {e}')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    elif edit_type == 'PARTIAL':\n        success = editor.replace_partial(element_to_edit, new_code,\n            line_start=line_range[0], line_end=line_range[1])\n        if not success:\n            ui_manager.show_error('Failed to apply partial edit.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    else:\n        success = editor.replace_element(element_to_edit, new_code)\n        if not success:\n            ui_manager.show_error(\n                'AI returned invalid code; could not be parsed or applied.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    if not (diff := editor.get_diff()):\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(diff, title=\n        f'[bold yellow]Proposed Changes for {resolved_path}[/]'))\n    if ui_manager.get_user_input('Apply changes? (y/n): ').lower() in ['yes',\n        'y']:\n        editor.save_changes()\n        last_code = editor.get_modified_source()\n        ui_manager.show_success(f'Changes saved to {resolved_path}.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_plan(instruction: str, memory_context: str\n    ) ->str:\n    \"\"\"\n    Create a specialized prompt-generation function for the 'refactor' command.\n    This prompt will explicitly define the required JSON structure for the plan\n    and instruct the AI to act as an expert project manager.\n    \"\"\"\n    return f\"\"\"You are an expert project manager and software architect. Analyze the project context and create a detailed refactoring plan.\n\nYour plan must be a valid JSON object with this exact structure:\n{{\n    \"actions\": [\n        {{\n            \"type\": \"MODIFY\" | \"CREATE\" | \"DELETE\" | \"PARTIAL\",\n            \"file\": \"relative/path/to/file.py\",\n            \"element\": \"function_or_class_name\",  // For MODIFY/DELETE/PARTIAL\n            \"element_name\": \"new_element_name\",    // For CREATE\n            \"line_start\": 10,                      // For PARTIAL only\n            \"line_end\": 20,                        // For PARTIAL only\n            \"reason\": \"Clear explanation of why this change is needed\",\n            \"description\": \"What this action will accomplish\",\n            \"anchor_element\": \"optional_anchor\",   // Optional for CREATE\n            \"position\": \"before\" | \"after\"         // Optional for CREATE\n        }}\n    ]\n}}\n\nACTION TYPES:\n- MODIFY: Change an entire function, class, or method\n- PARTIAL: Change specific lines within a function/class (requires line_start and line_end)\n- CREATE: Add new functions, classes, or files\n- DELETE: Remove functions, classes, variables, or imports\n\nRULES FOR YOUR PLAN:\n- Use PARTIAL when you only need to change a small part of a function\n- Use MODIFY when restructuring an entire function or class\n- Each action must have all required fields based on its type\n- File paths must be relative to the project root\n- Be specific and surgical - avoid unnecessary changes\n- Consider dependencies between changes\n- Order actions logically (e.g., create dependencies before using them)\n\n### Project Context ###\n{memory_context}\n\n### Refactoring Request ###\n{instruction}\n\nGenerate ONLY the JSON plan - no explanations or markdown:\"\"\"\n\n\ndef _get_refactor_plan(instruction: str) ->Optional[List[Dict]]:\n    \"\"\"\n    Generates a refactoring plan from the LLM.\n\n    This function encapsulates the logic for checking project context,\n    constructing a prompt, querying the LLM, and parsing the resulting\n    JSON plan for a refactoring task.\n\n    Args:\n        instruction: The user's high-level refactoring instruction.\n\n    Returns:\n        A list of action dictionaries if a valid plan is generated,\n        otherwise None.\n    \"\"\"\n    if not memory_manager.get_project_root():\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return None\n    memory_context = memory_manager.get_memory_context()\n    plan_prompt = _create_prompt_for_refactor_plan(instruction, memory_context)\n    with ui_manager.show_spinner('AI is creating an execution plan...'):\n        plan_str = query_llm(plan_prompt)\n    try:\n        match = re.search('\\\\{.*\\\\}', plan_str, re.DOTALL)\n        if not match:\n            raise ValueError('No JSON object found in the response.')\n        plan = json.loads(match.group(0))\n        actions = plan.get('actions', [])\n        if not actions:\n            raise ValueError(\"No 'actions' key found in plan or plan is empty.\"\n                )\n        return actions\n    except (json.JSONDecodeError, ValueError) as e:\n        ui_manager.show_error(f'AI failed to generate a valid plan: {e}')\n        print(Panel(plan_str, title=\"[yellow]AI's Invalid Plan Response[/]\",\n            border_style='yellow'))\n        return None\n\n\ndef _display_and_confirm_plan(plan: Dict) ->bool:\n    \"\"\"\n    Displays the generated execution plan to the user and asks for confirmation.\n\n    This helper function separates the UI interaction of plan confirmation from\n    the main refactoring logic.\n\n    Args:\n        plan: A dictionary, expected to contain an 'actions' key with a list of action dicts.\n\n    Returns:\n        True if the user confirms the plan, False otherwise.\n    \"\"\"\n    actions = plan.get('actions', [])\n    if not actions:\n        ui_manager.show_error('The generated plan is empty. Aborting.')\n        return False\n    ui_manager.show_success('AI has created a plan:')\n    for i, action in enumerate(actions):\n        action_type = action.get('type', 'N/A')\n        element = action.get('element') or action.get('element_name', 'N/A')\n        reason = action.get('reason') or action.get('description', '')\n        file_path = action.get('file', '')\n        if action_type == 'PARTIAL':\n            line_start = action.get('line_start', '?')\n            line_end = action.get('line_end', '?')\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} (lines {line_start}-{line_end}) - {reason}'\n                )\n        else:\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} - {reason}'\n                )\n    if ui_manager.get_user_input('\\nProceed with this plan? (y/n): ').lower(\n        ) in ['yes', 'y']:\n        return True\n    else:\n        ui_manager.show_error('Execution aborted by user.')\n        return False\n\n\ndef _apply_refactor_changes(editors: Dict[str, CodeEditor]) ->None:\n    \"\"\"\n    Consolidates changes from multiple CodeEditor instances, shows a unified\n    diff, and prompts the user to apply them.\n    \n    This helper function abstracts the final step of a refactor, ensuring\n    all proposed modifications are presented to the user for a final review\n    before any files are written to disk.\n\n    Args:\n        editors: A dictionary mapping absolute file paths to their\n                 corresponding CodeEditor instances which hold the\n                 proposed changes in their AST.\n    \"\"\"\n    full_diff = ''\n    for editor in editors.values():\n        diff = editor.get_diff()\n        if diff:\n            full_diff += diff + '\\n'\n    if not full_diff.strip():\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(full_diff, title=\n        '[bold yellow]Proposed Project-Wide Changes[/]'))\n    if ui_manager.get_user_input('Apply all changes? (y/n): ').lower() in [\n        'yes', 'y']:\n        for editor in editors.values():\n            editor.save_changes()\n        ui_manager.show_success('\u2705 Project changes applied successfully.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_action(action_type: str, file_path: str,\n    action_details: Dict) ->str:\n    \"\"\"\n    Create a helper to generate prompts for individual 'CREATE' or 'MODIFY' steps\n    within a refactor plan. This ensures the AI produces code for the specific\n    sub-task in the correct context.\n    \"\"\"\n    if action_type == 'MODIFY':\n        element_name = action_details['element_name']\n        reason = action_details['reason']\n        original_code = action_details['original_code']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- Element: {element_name}\n- Reason for change: {reason}\n\nRULES:\n- Provide ONLY the complete updated code for the element\n- Include any necessary imports at the top\n- Ensure the code integrates properly with the rest of the file\n- Maintain the same function/class signature unless the change requires otherwise\n- No explanations outside the code block\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the updated element code:\"\"\"\n    elif action_type == 'CREATE':\n        element_name = action_details['element_name']\n        description = action_details['description']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- New element to create: {element_name}\n- Purpose: {description}\n\nRULES:\n- Provide ONLY the complete code for the new element\n- Include all necessary imports at the top\n- Follow the coding style and patterns used in the project\n- Ensure the code is production-ready and well-structured\n- For non-Python files, provide the complete file content\n- No explanations outside the code block\n\nGenerate the new element code:\"\"\"\n\n\ndef _process_refactor_action(action: Dict, project_base_path: str, editors:\n    Dict) ->bool:\n    \"\"\"\n    Processes a single refactoring action from the plan.\n\n    This function handles the execution of a single action from the refactoring plan,\n    including LLM code generation and applying changes to in-memory editors or files.\n\n    Args:\n        action: A dictionary containing action details (type, file, element, etc.)\n        project_base_path: The absolute path to the project root\n        editors: Dictionary mapping file paths to their CodeEditor instances\n\n    Returns:\n        True if the action was processed successfully, False otherwise\n    \"\"\"\n    file_path_relative = action.get('file')\n    if not file_path_relative:\n        ui_manager.show_error(\n            f\"Action is missing 'file' key. Skipping: {action}\")\n        return False\n    file_path_absolute = os.path.join(project_base_path, file_path_relative)\n    action_type = action.get('type', '').upper()\n    prompt, element_name = '', ''\n    if action_type == 'MODIFY':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_source_of(element_name)\n            if not original_snippet:\n                ui_manager.show_error(\n                    f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                    )\n                return False\n            action_details = {'element_name': element_name, 'reason':\n                reason, 'original_code': original_snippet}\n            prompt = _create_prompt_for_refactor_action('MODIFY',\n                file_path_relative, action_details)\n    elif action_type == 'PARTIAL':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        line_start = action.get('line_start')\n        line_end = action.get('line_end')\n        if not all([element_name, line_start, line_end]):\n            ui_manager.show_error(\n                f'PARTIAL action missing required fields. Skipping: {action}')\n            return False\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_element_body_snippet(element_name,\n                line_start, line_end)\n            if not original_snippet:\n                original_snippet = editor.get_source_of(element_name)\n                if not original_snippet:\n                    ui_manager.show_error(\n                        f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                        )\n                    return False\n            full_element_code = editor.get_source_of(element_name)\n            prompt = _create_prompt_for_partial_edit(file_path_relative,\n                element_name, reason, original_snippet, line_start,\n                line_end, full_element_code)\n    elif action_type == 'CREATE':\n        element_name = action.get('element_name')\n        description = action.get('description')\n        action_details = {'element_name': element_name, 'description':\n            description}\n        prompt = _create_prompt_for_refactor_action('CREATE',\n            file_path_relative, action_details)\n    else:\n        ui_manager.show_error(f\"Invalid action type '{action_type}'. Skipping.\"\n            )\n        return False\n    with ui_manager.show_spinner(\n        f\"AI: {action_type} on '{element_name or file_path_relative}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    new_content = code_blocks[0][1] if code_blocks else response.strip()\n    if not new_content:\n        ui_manager.show_error(\n            f'AI failed to generate content for action: {action}')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return False\n    if not file_path_relative.endswith('.py'):\n        try:\n            FileCreator.create(file_path_absolute, new_content)\n            ui_manager.show_success(\n                f\"File '{file_path_relative}' created/updated.\")\n            return True\n        except IOError as e:\n            ui_manager.show_error(\n                f\"Failed to create file '{file_path_relative}': {e}\")\n            return False\n    if file_path_absolute not in editors:\n        try:\n            if not os.path.exists(file_path_absolute):\n                os.makedirs(os.path.dirname(file_path_absolute), exist_ok=True)\n                with open(file_path_absolute, 'w') as f:\n                    f.write('')\n            editors[file_path_absolute] = CodeEditor(file_path_absolute)\n        except Exception as e:\n            ui_manager.show_error(\n                f'Error loading file {file_path_absolute}: {e}')\n            return False\n    editor = editors[file_path_absolute]\n    if action_type == 'MODIFY':\n        if not editor.replace_element(element_name, new_content):\n            ui_manager.show_error(\n                f\"Failed to apply MODIFY change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic MODIFY Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'PARTIAL':\n        if not editor.replace_partial(element_name, new_content, line_start,\n            line_end):\n            ui_manager.show_error(\n                f\"Failed to apply PARTIAL change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic PARTIAL Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'CREATE':\n        anchor = action.get('anchor_element')\n        position = action.get('position', 'after')\n        if not editor.add_element(new_content, anchor_name=anchor, before=\n            position == 'before'):\n            ui_manager.show_error(\n                f\"Failed to apply CREATE change for '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic CREATE Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    return True\n\n\ndef handle_project_refactor_command(instruction: str):\n    \"\"\"\n    Orchestrates a multi-file, multi-step code refactoring process.\n    \n    This function serves as a high-level orchestrator that delegates specific tasks\n    to helper functions, improving readability, modularity, and maintainability.\n    \"\"\"\n    _load_all_project_files_if_needed()\n    actions = _get_refactor_plan(instruction)\n    if not actions:\n        return\n    plan = {'actions': actions}\n    if not _display_and_confirm_plan(plan):\n        return\n    editors: Dict[str, CodeEditor] = {}\n    project_base_path = memory_manager.get_project_root()\n    successful_actions = 0\n    total_actions = len(actions)\n    for i, action in enumerate(actions, 1):\n        ui_manager.show_success(f'Processing action {i}/{total_actions}...')\n        action_type = action.get('type', '').upper()\n        file_path_relative = action.get('file')\n        if not file_path_relative:\n            ui_manager.show_error(\n                f\"Action is missing 'file' key. Skipping: {action}\")\n            continue\n        file_path_absolute = os.path.join(project_base_path, file_path_relative\n            )\n        if action_type == 'DELETE':\n            element_name = action.get('element')\n            if not element_name:\n                ui_manager.show_error(\n                    f\"DELETE action missing 'element' key. Skipping: {action}\")\n                continue\n            if not file_path_relative.endswith('.py'):\n                ui_manager.show_error(\n                    f'DELETE actions are only supported for Python files. Skipping.'\n                    )\n                continue\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    continue\n            editor = editors[file_path_absolute]\n            if editor.delete_element(element_name):\n                successful_actions += 1\n                ui_manager.show_success(\n                    f\"Successfully deleted '{element_name}' from '{file_path_relative}'.\"\n                    )\n            else:\n                ui_manager.show_error(\n                    f\"Failed to delete '{element_name}' from '{file_path_relative}'.\"\n                    )\n        elif _process_refactor_action(action, project_base_path, editors):\n            successful_actions += 1\n        else:\n            ui_manager.show_error(\n                f'Action {i} failed, continuing with remaining actions...')\n    if successful_actions == 0:\n        ui_manager.show_error('No actions were successfully executed.')\n        return\n    elif successful_actions < total_actions:\n        ui_manager.show_error(\n            f'Only {successful_actions}/{total_actions} actions completed successfully.'\n            )\n    else:\n        ui_manager.show_success(\n            f'All {total_actions} actions completed successfully.')\n    _apply_refactor_changes(editors)\n\n\ndef _create_prompt_for_commit_message(diff: str) ->str:\n    \"\"\"\n    Create a dedicated prompt function for the 'commit' command. This prompt will\n    instruct the AI to analyze a git diff and generate a concise commit message\n    following the Conventional Commits standard.\n    \"\"\"\n    return f\"\"\"You are an expert developer writing a Git commit message. Your task is to analyze the provided git diff and create a professional commit message.\n\nCOMMIT MESSAGE RULES:\n- Follow the Conventional Commits specification\n- Format: <type>(<optional scope>): <subject>\n- Types: feat, fix, docs, style, refactor, perf, test, build, ci, chore, revert\n- Subject line: max 50 characters, imperative mood, no period\n- Optional body: explain what and why (not how), wrap at 72 characters\n- Be specific and concise\n- Focus on the intent and impact of the changes\n\nEXAMPLES OF GOOD COMMIT MESSAGES:\n- feat(auth): add OAuth2 integration for Google login\n- fix(api): handle null response in user endpoint\n- refactor(database): optimize query performance for large datasets\n- docs(readme): update installation instructions for Windows\n\nRespond with ONLY the commit message - no markdown, quotes, or explanations.\n\n--- GIT DIFF TO ANALYZE ---\n{diff}\n\nGenerate the commit message:\"\"\"\n\n\ndef handle_commit_command():\n    \"\"\"\n    Orchestrates an AI-assisted Git commit workflow with improved error handling.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return\n    try:\n        git_manager = GitManager(project_root)\n    except ValueError as e:\n        ui_manager.show_error(str(e))\n        return\n    changed_files = git_manager.get_changed_files()\n    if not changed_files:\n        ui_manager.show_success(\n            'No changes to commit. Everything is up to date.')\n        return\n    staged_diff = git_manager.get_diff(staged=True)\n    unstaged_diff = git_manager.get_diff()\n    full_diff = f'{staged_diff}\\n{unstaged_diff}'.strip()\n    if not full_diff.strip():\n        ui_manager.show_success(\n            'No content changes detected (e.g., only file mode changes).')\n        return\n    prompt = _create_prompt_for_commit_message(full_diff)\n    commit_message = query_llm(prompt).strip()\n    if not commit_message:\n        ui_manager.show_error(\n            'AI failed to generate a commit message. Aborting.')\n        return\n    files_to_commit_str = '\\n'.join(f'- {f}' for f in changed_files)\n    plan_panel_content = f\"\"\"[bold]Files to be staged:[/]\n[yellow]{files_to_commit_str}[/]\n\n[bold]AI-Generated Commit Message:[/]\n[green]{commit_message}[/]\"\"\"\n    print(Panel(plan_panel_content, title='[bold cyan]Commit Plan[/]',\n        border_style='cyan'))\n    if ui_manager.get_user_input('\\nProceed with commit? (y/n): ').lower() in [\n        'yes', 'y']:\n        try:\n            git_manager.add(changed_files)\n            ui_manager.show_success('\u2705 Files staged.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Staging failed: {e.stderr}')\n            return\n        try:\n            git_manager.commit(commit_message)\n            ui_manager.show_success('\u2705 Commit successful.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Commit failed: {e.stderr}')\n            return\n        if ui_manager.get_user_input('Push changes to remote? (y/n): ').lower(\n            ) in ['yes', 'y']:\n            try:\n                git_manager.push()\n                ui_manager.show_success('\u2705 Push successful.')\n            except subprocess.CalledProcessError as e:\n                ui_manager.show_error(f'Push failed: {e.stderr}')\n        else:\n            ui_manager.show_error('Push cancelled.')\n    else:\n        ui_manager.show_error('Commit aborted by user.')\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef interactive_mode() ->None:\n    global last_query, last_response, last_code\n    try:\n        from Testing.overlay_engine import show_sequential_popup\n        gui_available = True\n    except ImportError:\n        gui_available = False\n    print(Panel(\n        \"\"\"[bold cyan]Omni Interactive Mode[/]\n[dim]Type 'help' for commands, 'exit' to quit.[/dim]\"\"\"\n        , border_style='cyan'))\n    personality_name = personality_manager.get_current_personality().get('name'\n        , 'Default')\n    gui_enabled = False\n    if gui_available:\n        try:\n            with open(CONFIG_FILE, 'r') as f:\n                config = json.load(f)\n                if config.get('gui_enabled', False):\n                    gui_enabled = True\n        except (FileNotFoundError, json.JSONDecodeError):\n            pass\n    refresh_status_panel(personality_name)\n    while True:\n        try:\n            user_input = ui_manager.get_user_input('\\n> ')\n            if not user_input:\n                continue\n            command, *args = user_input.split(maxsplit=1)\n            arg_str = args[0] if args else ''\n            if command == 'exit':\n                memory_manager.save_memory()\n                print('[bold cyan]Goodbye![/]')\n                break\n            elif command == 'help':\n                print(\n                    \"\"\"[bold]Commands:[/]\n\n  [bold cyan]Core & Project Commands[/]\n  [yellow]send <prompt>[/]        - Ask the LLM a question.\n  [yellow]look <path>[/]          - Read file or scan directory into memory.\n  [yellow]look_all[/]            - Recursively scan the project directory into memory.\n  [yellow]create <file> \"instr\"[/] - Create a new file using AI.\n  [yellow]edit <file> \"instr\"[/]   - Edit a specific file using AI.\n  [yellow]refactor \"instr\"[/]      - Refactor project in memory based on instruction.\n  [yellow]commit[/]               - Commit changes with an AI-generated message.\n  [yellow]rag <query>[/]         - Query the RAG system for context retrieval.\n\n  [bold cyan]File & Code Management[/]\n  [yellow]save <filename>[/]     - Save last AI response to a file.\n  [yellow]list[/]               - List saved files.\n  [yellow]run[/]                 - Run the last generated Python code.\n\n  [bold cyan]Session & Config[/]\n  [yellow]history[/]             - Show the full chat history.\n  [yellow]memory clear[/]        - Clear the chat and file memory.\n  [yellow]backend <name>[/]      - Switch AI backend (e.g., openrouter, ollama).\n  [yellow]models [src][/]        - Interactively list and select models.\n  [yellow]set model <id>[/]      - Set the model directly by its ID.\n  [yellow]personality <cmd>[/]   - Manage AI personalities ('list', 'set', 'add').\n\"\"\"\n                    )\n            elif command == 'send':\n                last_query = arg_str\n                response = query_llm(arg_str)\n                last_response = response\n                memory_manager.add_chat_message('user', last_query)\n                memory_manager.add_chat_message('assistant', last_response)\n                if gui_enabled:\n                    threading.Thread(target=show_sequential_popup, args=(\n                        100, 100, response, f'Omni - {personality_name}'),\n                        daemon=True).start()\n                print(Panel(response, title='[cyan]Response[/]'))\n                if (code_blocks := extract_code(response)):\n                    last_code = code_blocks[0][1]\n            elif command == 'look':\n                look_command(arg_str)\n            elif command == 'look_all':\n                look_all_command()\n            elif command == 'create':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_create_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: create <file_path> \"<instruction>\"')\n            elif command == 'edit':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_edit_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: edit <file_path> \"<instruction>\"')\n            elif command == 'refactor':\n                if not arg_str:\n                    ui_manager.show_error('Usage: refactor \"<instruction>\"')\n                else:\n                    handle_project_refactor_command(arg_str.strip('\"'))\n            elif command == 'commit':\n                handle_commit_command()\n            elif command == 'models':\n                list_models(arg_str.split())\n            elif command == 'set' and arg_str.startswith('model '):\n                set_model(arg_str[6:])\n            elif command == 'backend':\n                switch_backend(arg_str)\n            elif command == 'history':\n                ui_manager.display_history(memory_manager.get_memory_context())\n            elif command == 'memory' and arg_str == 'clear':\n                memory_manager.clear_memory()\n                ui_manager.show_success('\u2705 Memory cleared')\n            elif command == 'personality':\n                p_args = arg_str.split(maxsplit=1)\n                cmd = p_args[0] if p_args else ''\n                p_arg_str = p_args[1] if len(p_args) > 1 else ''\n                if cmd == 'list':\n                    for p in personality_manager.list_personalities():\n                        print(f\"- {p['name']}: {p['description']}\")\n                elif cmd == 'set' and p_arg_str:\n                    if personality_manager.set_current_personality(p_arg_str):\n                        personality_name = p_arg_str\n                        ui_manager.show_success(\n                            f'Set personality to {personality_name}')\n                    else:\n                        ui_manager.show_error('Personality not found.')\n                else:\n                    ui_manager.show_error(\n                        \"Invalid personality command. Use 'list' or 'set <name>'.\"\n                        )\n            elif command == 'run':\n                run_python_code()\n            elif command == 'save':\n                if last_response:\n                    save_code(last_response, arg_str or\n                        f\"omni_save_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n                        )\n                else:\n                    ui_manager.show_error('No response to save.')\n            elif command == 'list':\n                files = sorted(os.listdir(DEFAULT_SAVE_DIR))\n                print('\\n'.join(f'  - {f}' for f in files) if files else\n                    '[yellow]No saved files.[/]')\n            elif command == 'rag':\n                if not arg_str:\n                    ui_manager.show_error('Usage: rag \"<query>\"')\n                else:\n                    from rag_manager import RAGManager\n                    project_root = memory_manager.get_project_root()\n                    if not project_root:\n                        ui_manager.show_error(\n                            \"No project context in memory. Use 'look <directory>' first.\"\n                            )\n                        continue\n                    rag = RAGManager()\n                    if rag.get_document_count() == 0:\n                        ui_manager.show_error(\n                            'RAG index is empty. Please add documents first.')\n                        continue\n                    results = rag.search(arg_str, k=3)\n                    if not results:\n                        ui_manager.show_error('No relevant documents found.')\n                        continue\n                    print(Panel('[bold]RAG Results:[/]', title=\n                        '[cyan]Retrieval-Augmented Generation[/]'))\n                    for i, (content, score, metadata) in enumerate(results, 1):\n                        file_path = metadata.get('file', 'Unknown')\n                        print(\n                            f'[bold cyan]{i}. {file_path}[/] (Score: {score:.4f})'\n                            )\n                        print(Panel(content[:500] + '...' if len(content) >\n                            500 else content, border_style='dim'))\n                    follow_up = ui_manager.get_user_input(\n                        \"\"\"\nWould you like to ask a follow-up question with this context? (y/n): \"\"\"\n                        )\n                    if follow_up.lower() in ['y', 'yes']:\n                        follow_up_query = ui_manager.get_user_input(\n                            'Follow-up query: ')\n                        if follow_up_query:\n                            context_parts = [\n                                f'Document {i} (Score: {score:.4f}):\\n{content}'\n                                 for i, (content, score, _) in enumerate(\n                                results, 1)]\n                            context = '\\n\\n'.join(context_parts)\n                            rag_prompt = f\"\"\"Based on the following context, please answer the question.\n\nContext:\n{context}\n\nQuestion: {follow_up_query}\"\"\"\n                            response = query_llm(rag_prompt)\n                            print(Panel(response, title=\n                                '[cyan]RAG-Augmented Response[/]'))\n            else:\n                ui_manager.show_error(\"Unknown command. Type 'help'.\")\n            refresh_status_panel(personality_name)\n        except KeyboardInterrupt:\n            memory_manager.save_memory()\n            print('\\n[bold cyan]Goodbye![/]')\n            break\n        except Exception as e:\n            ui_manager.show_error(f'An unexpected error occurred: {e}')\n\n\ndef run_python_code() ->None:\n    global last_code\n    if not last_code:\n        ui_manager.show_error('No Python code in memory to run.')\n        return\n    temp_file = os.path.join(DEFAULT_SAVE_DIR, 'temp_run.py')\n    try:\n        with open(temp_file, 'w') as f:\n            f.write(last_code)\n        print('[bold cyan]\\n--- Running Code ---\\n[/]')\n        subprocess.run([sys.executable, temp_file], check=True)\n        print('[bold cyan]\\n--- Code Finished ---\\n[/]')\n    except Exception as e:\n        ui_manager.show_error(f'Error running code: {e}')\n    finally:\n        if os.path.exists(temp_file):\n            os.remove(temp_file)\n\n\ndef save_code(content: str, filename: str) ->None:\n    filepath = os.path.join(DEFAULT_SAVE_DIR, filename)\n    try:\n        with open(filepath, 'w') as f:\n            f.write(content)\n        ui_manager.show_success(f'Saved to: {filepath}')\n    except IOError as e:\n        ui_manager.show_error(f'Error saving file: {e}')\n\n\ndef main() ->None:\n    try:\n        import astor\n    except ImportError:\n        print(\"[bold red]Error:[/] 'astor' is required. `pip install astor`\")\n        sys.exit(1)\n    try:\n        import simple_term_menu\n    except ImportError:\n        print(\n            \"[bold red]Error:[/] 'simple-term-menu' is required. `pip install simple-term-menu`\"\n            )\n        sys.exit(1)\n    parser = argparse.ArgumentParser(description=\n        'Omni - AI-powered code tool', add_help=False)\n    parser.add_argument('command', nargs='?', help='Main command.')\n    parser.add_argument('args', nargs='*', help='Arguments for the command.')\n    parser.add_argument('-h', '--help', action='store_true')\n    args, _ = parser.parse_known_args()\n    if args.help or not args.command:\n        interactive_mode()\n    elif args.command == 'look' and args.args:\n        look_command(args.args[0])\n    elif args.command == 'edit' and len(args.args) >= 2:\n        handle_file_edit_command(args.args[0], ' '.join(args.args[1:]))\n    elif args.command == 'models':\n        list_models(args.args)\n    else:\n        interactive_mode()\n\n\ndef refresh_status_panel(personality_name: str) ->None:\n    ui_manager.display_status_panel(personality_name, current_backend,\n        current_model, len(memory_manager.memory.get('chat', [])), len(\n        memory_manager.memory.get('look', [])))\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/omni.py"
  },
  {
    "id": 37,
    "hash": "db1585da7840e9dc17f3ab8c0a19f6f2",
    "content": "import json\nfrom typing import Dict, List, Optional\n\nclass PersonalityManager:\n    \"\"\"Manages AI personalities via JSON config.\"\"\"\n\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.personalities: List[Dict[str, str]] = self.load_personalities()\n        self.current_personality: Optional[str] = \"default\"  # Default\n\n    def load_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"Load personalities from JSON; auto-create if missing.\"\"\"\n        default = [{\"name\": \"default\", \"description\": \"Helpful assistant\", \"system_prompt\": \"You are a helpful AI assistant.\"}]\n        default_gui = {\n            \"gui_enabled\": True,\n            \"wake_word\": \"Jarvis\",\n            \"overlay_opacity\": 0.8,\n            \"font_size\": 16\n        }\n        try:\n            with open(self.config_file, 'r') as f:\n                data = json.load(f)\n                if \"personalities\" not in data:\n                    data[\"personalities\"] = default\n                if \"gui_enabled\" not in data:\n                    data.update(default_gui)\n                    self.save_personalities(data[\"personalities\"])  # Save with defaults\n                \n                return data[\"personalities\"]\n        except FileNotFoundError:\n            self.save_personalities(default)\n            return default\n        except json.JSONDecodeError:\n            print(\"[yellow]Invalid config. Resetting to default.[/]\")\n            self.save_personalities(default)\n            return default\n\n    def save_personalities(self, personalities: List[Dict[str, str]]) -> None:\n        \"\"\"Save with GUI config.\"\"\"\n        data = {\"personalities\": personalities}\n        data.update({\"gui_enabled\": True, \"wake_word\": \"Jarvis\", \"overlay_opacity\": 0.8, \"font_size\": 16})  # Defaults\n        with open(self.config_file, 'w') as f:\n            json.dump(data, f, indent=4)\n\n    def add_personality(self, name: str, description: str, system_prompt: str) -> None:\n        \"\"\"Add a new personality.\"\"\"\n        self.personalities.append({\"name\": name, \"description\": description, \"system_prompt\": system_prompt})\n        self.save_personalities(self.personalities)\n\n    def list_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"List all personalities.\"\"\"\n        return self.personalities\n\n    def set_current_personality(self, name: str) -> bool:\n        \"\"\"Set the current personality.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == name:\n                self.current_personality = name\n                return True\n        return False\n\n    def get_current_personality(self) -> Dict[str, str]:\n        \"\"\"Get the current personality dict.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == self.current_personality:\n                return p\n        return {}  # Fallback",
    "file": "/mnt/ProjectData/omni/personality_manager.py"
  },
  {
    "id": 38,
    "hash": "2914352eefed9d60de098e021dd79b67",
    "content": "import os\nimport sys\nimport argparse\nfrom typing import List\nfrom rag_manager import RAGManager\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\ndef create_sample_data() ->List[str]:\n    \"\"\"Create sample documents for the RAG example.\"\"\"\n    return [\n        'RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with language generation.'\n        ,\n        'The RAG model retrieves relevant documents from a knowledge base and uses them to generate more accurate responses.'\n        ,\n        'FAISS is a library for efficient similarity search and clustering of dense vectors, often used in RAG systems.'\n        ,\n        'Sentence transformers are used to create embeddings for documents and queries in RAG systems.'\n        ,\n        'Retrieval-Augmented Generation improves language models by allowing them to access external knowledge sources.'\n        ,\n        'In RAG systems, documents are indexed and searchable by their semantic embeddings rather than just keywords.'\n        ,\n        'Python is a great language for implementing RAG systems due to libraries like sentence-transformers and faiss.'\n        ,\n        'The retrieval component of RAG is crucial for finding relevant information before generation.'\n        ]\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_cli_example.py"
  },
  {
    "id": 39,
    "hash": "c27b11d2eaa8e13cdf8e698417efb75e",
    "content": "import os\nimport sys\nfrom typing import List, Dict, Tuple\n\"\"\"\nExample script demonstrating RAG (Retrieval-Augmented Generation) usage.\n\nThis script shows how to use a simple RAG implementation to answer questions\nbased on a given context or knowledge base.\n\"\"\"\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\nclass SimpleRAG:\n    \"\"\"A simple RAG implementation for demonstration purposes.\"\"\"\n\n    def __init__(self, knowledge_base: List[str]):\n        \"\"\"\n        Initialize the RAG with a knowledge base.\n        \n        Args:\n            knowledge_base: A list of strings representing the knowledge base.\n        \"\"\"\n        self.knowledge_base = knowledge_base\n\n    def retrieve(self, query: str, top_k: int=3) ->List[str]:\n        \"\"\"\n        Retrieve relevant documents from the knowledge base.\n        \n        This is a simplified implementation using keyword matching.\n        In a real implementation, you would use embeddings and vector search.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            A list of relevant documents.\n        \"\"\"\n        query_words = set(query.lower().split())\n        scores = []\n        for doc in self.knowledge_base:\n            doc_words = set(doc.lower().split())\n            score = len(query_words.intersection(doc_words))\n            scores.append((score, doc))\n        scores.sort(reverse=True)\n        return [doc for score, doc in scores[:top_k]]\n\n    def generate(self, query: str, retrieved_docs: List[str]) ->str:\n        \"\"\"\n        Generate an answer based on the query and retrieved documents.\n        \n        In a real implementation, this would use an LLM to generate the response.\n        For this example, we'll create a simple template-based response.\n        \n        Args:\n            query: The query string.\n            retrieved_docs: The retrieved documents.\n            \n        Returns:\n            A generated answer.\n        \"\"\"\n        context = '\\n'.join(retrieved_docs)\n        prompt = f\"\"\"\n        Context information:\n        {context}\n        \n        Question: {query}\n        \n        Based on the context provided above, please answer the question.\n        If the context doesn't contain relevant information, say so.\n        \"\"\"\n        return self._simple_response_generator(query, retrieved_docs)\n\n    def _simple_response_generator(self, query: str, retrieved_docs: List[str]\n        ) ->str:\n        \"\"\"\n        A simple response generator for demonstration.\n        \"\"\"\n        for doc in retrieved_docs:\n            if 'example' in doc.lower():\n                return (\n                    f'Based on the context provided, I found information about examples. {query} relates to the examples in the knowledge base.'\n                    )\n        return (\n            f\"I couldn't find specific information about '{query}' in the provided context. Please provide more details or check the knowledge base.\"\n            )\n\n    def query(self, query: str, top_k: int=3) ->str:\n        \"\"\"\n        Process a query through the full RAG pipeline.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            The generated answer.\n        \"\"\"\n        retrieved_docs = self.retrieve(query, top_k)\n        answer = self.generate(query, retrieved_docs)\n        return answer\n\n\ndef main():\n    \"\"\"Main function demonstrating the RAG implementation.\"\"\"\n    knowledge_base = ['This is an example document about machine learning.',\n        'Natural language processing is a subfield of artificial intelligence.'\n        , 'Python is a popular programming language for data science.',\n        'The quick brown fox jumps over the lazy dog.',\n        'RAG stands for Retrieval-Augmented Generation.',\n        'Vector databases are used for similarity search in RAG systems.',\n        'Transformers are a type of neural network architecture.',\n        'This example shows how to implement a simple RAG system.']\n    rag = SimpleRAG(knowledge_base)\n    queries = ['What is RAG?', 'How is Python used in data science?',\n        'Tell me about machine learning']\n    print('Simple RAG Example')\n    print('=' * 50)\n    for query in queries:\n        print(f'\\nQuery: {query}')\n        answer = rag.query(query)\n        print(f'Answer: {answer}')\n        print('-' * 30)\n    print(\"\\nInteractive Mode (type 'quit' to exit):\")\n    while True:\n        try:\n            user_query = input('\\nEnter your question: ').strip()\n            if user_query.lower() in ['quit', 'exit', 'q']:\n                break\n            if user_query:\n                answer = rag.query(user_query)\n                print(f'Answer: {answer}')\n        except KeyboardInterrupt:\n            print('\\nGoodbye!')\n            break\n        except EOFError:\n            break\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_example.py"
  },
  {
    "id": 40,
    "hash": "f151986bf2efa7602242590a357fab83",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n    Initialize the RAG manager.\n\n    Args:\n        model_name: Name of the sentence transformer model to use\n        index_path: Path to save/load the FAISS index\n    \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the RAG manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n",
    "file": "/mnt/ProjectData/omni/rag_manager.py"
  },
  {
    "id": 41,
    "hash": "f59a27842056dbb0dc95d0f29c1c5de8",
    "content": "Hello! I'm OmniForge, an AI coding assistant. I can help you scan, understand, and refactor your codebase using local (Ollama) or remote (OpenRouter) LLMs.\n\nI see you've opened the OmniForge project directory. Some key things I can help with:\n\n1. **Project Analysis**: I can look at your files to understand the structure\n2. **Code Editing**: I can make precise edits to functions/classes using AST-based transformations\n3. **Refactoring**: I can perform multi-file architectural changes with a plan\n4. **File Creation**: I can generate new files based on instructions\n\nFor example:\n- `look .` to scan the project\n- `edit code_editor.py \"add docstrings to main methods\"`\n- `refactor \"extract git operations into a separate module\"`\n- `create new_module.py \"implement a simple HTTP client\"`\n\nWhat would you like to do with this project?",
    "file": "/mnt/ProjectData/omni/requirements.txt"
  },
  {
    "id": 42,
    "hash": "4b879b8e64b677ec78d27f19b384623a",
    "content": "from typing import List\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.text import Text\nfrom rich.status import Status\nfrom rich import box\nfrom contextlib import contextmanager\nfrom rich.markup import escape\nimport gc\n\ntry:\n    from prompt_toolkit import prompt\n    from prompt_toolkit.completion import WordCompleter\n    from prompt_toolkit.history import InMemoryHistory\n    from prompt_toolkit.styles import Style\nexcept ImportError:\n    print('[yellow]prompt_toolkit not installed. Falling back to basic input.[/]')\n    prompt = input\n\n\nclass UIManager:\n    \"\"\"Manages interactive text-based UI with rich for display and prompt_toolkit for input.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initializes the UI manager with a rich console and prompt_toolkit components.\"\"\"\n        self.console = Console()\n        self.history = InMemoryHistory()\n        self.completer = WordCompleter([\n            'send', 'look', 'look_all', 'create', 'edit', 'refactor', 'commit',\n            'save', 'list', 'run', 'history', 'memory', 'backend', 'models',\n            'set', 'personality', 'help', 'exit'\n        ], ignore_case=True)\n        self.prompt_style = Style.from_dict({'prompt': 'bold cyan'})\n\n    def get_user_input(self, prompt_text: str) -> str:\n        try:\n            return prompt(prompt_text, history=self.history, completer=self.completer, style=self.prompt_style)\n        except Exception:\n            self.console.print('[yellow]Warning: Falling back to basic input.[/]')\n            return input(prompt_text)\n\n    def display_history(self, history_text: str) -> None:\n        if not history_text.strip():\n            self.console.print('[dim]No history yet.[/]')\n            return\n        \n        lines = history_text.split('\\n')\n        colored_text = Text()\n        for line in lines:\n            if line.startswith('User:'):\n                colored_text.append(line + '\\n', style='bold blue')\n            elif line.startswith('AI:'):\n                colored_text.append(line + '\\n', style='bold green')\n            elif line.startswith('File '):\n                colored_text.append(line + '\\n', style='yellow')\n            else:\n                colored_text.append(line + '\\n')\n        \n        self.console.print(Panel(\n            colored_text, \n            title='[bold magenta]Chat History[/]', \n            border_style='magenta', \n            expand=False, \n            box=box.ROUNDED\n        ))\n\n    @contextmanager\n    def show_spinner(self, message: str):\n        \"\"\"\n        Context manager that displays a spinner with the given message.\n        Handles Rich LiveError by cleaning up stuck live displays and \n        ensuring proper cleanup on exceptions.\n        \n        Usage:\n            with ui_manager.show_spinner(\"Loading...\"):\n                # do work here\n        \"\"\"\n        # Initialize spinner state if not exists\n        if not hasattr(self, '_spinner_active'):\n            self._spinner_active = False\n        \n        # If spinner is already active, just yield without additional output\n        if self._spinner_active:\n            try:\n                yield\n            except Exception as e:\n                raise e\n            return\n        \n        # Clean up any stuck Rich live displays before starting\n        self._cleanup_stuck_rich_displays()\n        \n        # Mark spinner as active\n        self._spinner_active = True\n        status_context = None\n        \n        try:\n            # Try to use rich status, but with fallback\n            try:\n                status_context = self.console.status(f'[bold yellow]{message}[/]')\n                status_context.__enter__()\n            except Exception:\n                # If rich.status fails, fallback to static print\n                status_context = None\n                self.console.print(f'[bold yellow]{message}[/]')\n            \n            yield\n            \n        except Exception as e:\n            # Re-raise actual work errors\n            raise e\n            \n        finally:\n            # Always cleanup spinner state and rich display\n            self._spinner_active = False\n            if status_context is not None:\n                try:\n                    status_context.__exit__(None, None, None)\n                except:\n                    pass  # Suppress cleanup errors\n            \n            # Force cleanup any remaining rich displays\n            self._cleanup_stuck_rich_displays()\n\n    def _cleanup_stuck_rich_displays(self):\n        \"\"\"\n        Clean up stuck Rich live displays that prevent new ones from starting.\n        Based on solution from: https://github.com/DLR-RM/stable-baselines3/issues/1645\n        \"\"\"\n        try:\n            # Method 1: Reset console live display if exists\n            if hasattr(self.console, '_live') and self.console._live is not None:\n                try:\n                    self.console._live.stop()\n                    self.console._live = None\n                except:\n                    pass\n            \n            # Method 2: Find and close stuck rich/tqdm objects using garbage collection\n            rich_objects = [obj for obj in gc.get_objects() \n                        if hasattr(obj, '__class__') and \n                        ('live' in type(obj).__name__.lower() or \n                            'progress' in type(obj).__name__.lower() or\n                            'status' in type(obj).__name__.lower()) and\n                        hasattr(obj, 'stop')]\n            \n            for rich_obj in rich_objects:\n                try:\n                    if hasattr(rich_obj, 'stop'):\n                        rich_obj.stop()\n                    elif hasattr(rich_obj, 'close'):\n                        rich_obj.close()\n                except:\n                    pass  # Suppress cleanup errors\n                    \n        except:\n            pass  # Suppress all cleanup errors to avoid breaking the main flow\n\n    def display_status_panel(self, personality: str, backend: str, model: str, msg_count: int, look_count: int) -> None:\n        status_text = (\n            f'[bold]Personality:[/] [green]{personality}[/] | '\n            f'[bold]Backend:[/] [green]{backend}[/] | '\n            f'[bold]Model:[/] [green]{model}[/] | '\n            f'[bold]Memory:[/] {msg_count} messages, {look_count} files'\n        )\n        self.console.print(Panel(\n            status_text, \n            title='[bold cyan]Status[/]', \n            border_style='cyan', \n            expand=False, \n            box=box.MINIMAL\n        ))\n\n    def show_success(self, message: str) -> None:\n        self.console.print(f'[green]\u2705 {message}[/]')\n\n    def show_error(self, message: str) -> None:\n        \"\"\"\n        Displays an error message, escaping any markup in the message.\n        \"\"\"\n        safe_message = escape(str(message))\n        self.console.print(f'[red]\u274c {safe_message}[/]')",
    "file": "/mnt/ProjectData/omni/ui_manager.py"
  },
  {
    "id": 43,
    "hash": "dbd143839288b400cafdedb655258434",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n",
    "file": "/mnt/ProjectData/omni/vectordb_manager.py"
  },
  {
    "id": 44,
    "hash": "47a91d3ac272236378053b23515fc9b0",
    "content": "import tkinter as tk\nfrom tkinter import ttk\nfrom time import strftime\n\n\ndef update_time():\n    current_time = strftime('%H:%M:%S %p\\n%Y-%m-%d')\n    time_label.config(text=current_time)\n    time_label.after(1000, update_time)\n\n\ndef center_window(root):\n    root.update_idletasks()\n    screen_width = root.winfo_screenwidth()\n    screen_height = root.winfo_screenheight()\n    window_width = root.winfo_width() + 4\n    window_height = root.winfo_height() + 4\n    x = (screen_width - window_width) // 2\n    y = (screen_height - window_height) // 2\n    root.geometry(f'{window_width}x{window_height}+{x}+{y}')\n\n\ndef create_3d_border(parent):\n    border_frame = tk.Frame(parent, bg='#c0c0c0')\n    border_frame.pack(padx=2, pady=2, expand=True, fill=tk.BOTH)\n    tk.Frame(border_frame, height=1, bg='#808080').pack(side=tk.TOP, fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#808080').pack(side=tk.LEFT, fill=tk.Y)\n    tk.Frame(border_frame, height=1, bg='#ffffff').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#ffffff').pack(side=tk.RIGHT, fill=tk.Y\n        )\n    inner_container = tk.Frame(border_frame, bg='#c0c0c0')\n    inner_container.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1\n        )\n    tk.Frame(inner_container, height=1, bg='#ffffff').pack(side=tk.TOP,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#ffffff').pack(side=tk.LEFT,\n        fill=tk.Y)\n    tk.Frame(inner_container, height=1, bg='#808080').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#808080').pack(side=tk.RIGHT,\n        fill=tk.Y)\n    content_area = tk.Frame(inner_container, bg='#c0c0c0')\n    content_area.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1)\n    return content_area\n\n\nroot = tk.Tk()\nroot.title('Current Time')\nroot.configure(bg='#008080')\nmain_frame = create_3d_border(root)\nmain_frame.config(padx=4, pady=4)\ninner_frame = tk.Frame(main_frame, bg='#c0c0c0', padx=8, pady=8)\ninner_frame.pack()\ntime_label = tk.Label(inner_frame, bg='#c0c0c0', fg='#000000', font=(\n    'MS Sans Serif', 18, 'bold'), padx=12, pady=8)\ntime_label.pack()\nroot.after(100, lambda : center_window(root))\nupdate_time()\nroot.mainloop()\n",
    "file": "/mnt/ProjectData/omni/omni_saves/watch.py"
  },
  {
    "id": 45,
    "hash": "6774a805052356775d8c4f0367253dc1",
    "content": "# OmniForge\n\n**Project\u2011Aware AI CLI for AST\u2011Precise Edits (\u201cScalpel\u201d) & Multi\u2011File Refactors (\u201cBlueprint\u201d).**\n\n> *OmniForge (a.k.a. the \"DualForge\" engine) helps you **scan**, **understand**, and **reforge** your codebase with local (Ollama) or remote (OpenRouter) LLMs. It is an independent open\u2011source project not affiliated with other products using the name \u201cOmni.\u201d*\n\n---\n\n## Core Features\n\n* **Project\u2011Aware Refactoring (`refactor`)**: Provide a high\u2011level goal (e.g. *\u201cmove all DB logic into `db/` and centralize config\u201d*). OmniForge generates & shows a multi\u2011step plan before touching files.\n* **Surgical AST Editing (`edit`)**: Target a single function/class. OmniForge parses the file, locates the node, applies a structural change, and shows you a diff.\n* **Context Ingestion (`look`)**: Scan a directory or single file to build a project manifest (paths + hashes + size + language hints) that guides subsequent edits/refactors.\n* **Dual Backends**: Seamlessly switch between **`openrouter`** (remote models) and **`ollama`** (local models) via `backend <name>`.\n* **Interactive Model Picker (`models`)**: Filter by source/provider and select from an up\u2011to\u2011date model list inside the terminal.\n* **Session Memory & History**: `history` shows conversation / action log; `memory clear` resets the working context.\n* **Safe AST\u2011Based Transformations**: Reduces syntax breakage vs naive text substitution. New imports / dependencies are auto\u2011inserted when possible.\n* **Dry\u2011Run Transparency**: Every multi\u2011file refactor presents (1) a generated plan, (2) per\u2011file proposed changes, (3) a consolidated diff for confirmation.\n\n---\n\n## Conceptual Modes\n\n| Mode          | Command(s) | Purpose                                              | Analogy              |\n| ------------- | ---------- | ---------------------------------------------------- | -------------------- |\n| **Survey**    | `look`     | Index project / ingest context                       | Mapping the terrain  |\n| **Scalpel**   | `edit`     | Precise single\u2011file structural change                | Surgery              |\n| **Blueprint** | `refactor` | Multi\u2011file architectural transformation              | Architecture         |\n| **Cast**      | `run`      | Execute last generated runnable block (if supported) | Forging the artifact |\n\nYou can reference these terms in docs, help screens, or UI banners for clarity.\n\n---\n\n## Installation\n\n> Requires Python 3.10+ and a Unix\u2011like shell.\n\n```bash\n# 1. Clone\ngit clone https://github.com/Snawyyy/omniforge.git\ncd omniforge\n\n# 2. (Optional) Inspect requirements\ncat requirements.txt\n\n# 3. Run installer (creates venv + installs deps)\nchmod +x install.sh\n./install.sh\n\n# 4. Activate environment\nsource venv/bin/activate\n\n# 5. Run CLI (interactive shell)\n./omni        # or: python omni.py\n```\n\nIf you later package it, expose a script entry point named `omni` while keeping an internal package name like `omniforge` to avoid namespace collisions.\n\n---\n\n## Configuration\n\nCreate a `.env` file to supply secrets (e.g. OpenRouter API key).\n\n```bash\ncp .env.example .env   # if example exists; otherwise create manually\n```\n\nIn `.env`:\n\n```dotenv\nOPENROUTER_API_KEY=\"sk-or-...\"\n```\n\n(Do **not** commit real keys. Ensure `.env` is listed in `.gitignore`.)\n\nOptional future keys can include local model paths, default model name, or feature flags.\n\n---\n\n## Quick Start Workflow\n\n```text\n> look .\n(Index project: builds manifest)\n\n> refactor \"extract hardcoded API URL to config/settings.py and update all imports\"\n(Shows plan \u2192 ask for confirmation)\n\n> edit src/utils.py \"add a doctring for calculate_average explaining parameters and return value\"\n(Shows targeted diff \u2192 confirm or abort)\n\n> models openai\n(Choose a different model)\n\n> backend ollama\n(Switch to local inference)\n```\n\n---\n\n## Command Reference\n\n| Command               | Example                                         | Description                                                                 |\n| --------------------- | ----------------------------------------------- | --------------------------------------------------------------------------- |\n| `look <path>`         | `look .`                                        | Scan directory or file; update project context manifest.                    |\n| `edit <file> \"instr\"` | `edit utils.py \"add error handling\"`            | AST\u2011guided targeted modification of a single file element or whole file.    |\n| `refactor \"goal\"`     | `refactor \"split monolith api.py into package\"` | High\u2011level multi\u2011file transformation with plan + diff review.               |\n| `send <prompt>`       | `send summarize module layout`                  | Generic prompt to current model with current context summary.               |\n| `models [filter]`     | `models google`                                 | Interactive model selector (filter by provider/source).                     |\n| `backend <name>`      | `backend ollama`                                | Switch between `openrouter` / `ollama`.                                     |\n| `history`             | `history`                                       | Display session interaction log.                                            |\n| `memory clear`        | `memory clear`                                  | Clear internal AI context memory (project manifest may persist separately). |\n| `run`                 | `run`                                           | Execute the last generated runnable code snippet (if feature implemented).  |\n| `help`                | `help`                                          | Show help / usage summary.                                                  |\n\n---\n\n## How It Works (High Level)\n\n1. **Ingestion (`look`)**: Walks the directory (configurable ignore patterns), captures file metadata (path, size, language), optionally caches abbreviated content or hashes.\n2. **Prompt Construction**: Merges user instruction + contextual manifest + focused snippets (for `edit`) or diff summaries (for `refactor`).\n3. **AST Layer** (Python initially): Parses target file(s); identifies node(s) (function/class) based on name + heuristic similarity; applies transformations guided by model output (structured hints or patch templates) rather than raw blind overwrite.\n4. **Plan (Refactor)**: Model proposes steps (CREATE / MODIFY / RENAME / DELETE). User approves. Each step executed & validated; errors surface early.\n5. **Diff Presentation**: A unified colorized diff shown; user confirms to write changes.\n6. **Safety**: If AST parse fails or patch violates syntax, changes abort (or fallback to text patch with warning).\n\n---\n\n## Roadmap (Indicative)\n\n| Milestone | Features                                                                    |\n| --------- | --------------------------------------------------------------------------- |\n| 0.1.0     | Core commands (`look`, `edit`, `refactor`, `models`, `backend`, `history`). |\n| 0.2.0     | Config file (`omniforge.toml`), ignore patterns, improved diff viewer.      |\n| 0.3.0     | Multi-language AST adapters (JS/TS via `tree-sitter`).                      |\n| 0.4.0     | Test impact analysis & auto test file generation.                           |\n| 0.5.0     | Refactor preview metrics (LOC touched, complexity delta).                   |\n| 0.6.0     | Inline security / lint feedback integration.                                |\n| 0.7.0     | Partial GUI / TUI dashboard mode.                                           |\n\n(Adjust roadmap as project evolves.)\n\n---\n\n## Developer Notes\n\n* Keep `.env`, virtual environment dirs (`venv/`), caches, large artifacts in `.gitignore`.\n* Consider adding a thin `omniforge/` package directory now for future PyPI packaging.\n* Implement a pluggable *Model Adapter* layer to abstract provider differences (OpenRouter vs Ollama).\n* Logging: Provide `--verbose` or `OMNIFORGE_DEBUG=1` env flag.\n* Add a JSONL log of commands & decisions to enable replay or supervised improvements.\n\n---\n\n## Contributing\n\n1. Fork & create a feature branch: `git checkout -b feat/<short-name>`\n2. Run and add tests (if/when test harness exists in `tests/`).\n3. Ensure style/format (e.g. `ruff`, `black`) passes.\n4. Submit pull request with concise description + before/after examples.\n\nIssues / discussions welcome for architecture proposals, AST adapters, or performance improvements.\n\n---\n\n## License\n\nReleased under the **MIT License**. See `LICENSE` file for full text.\n\n---\n\n## Name & Trademark Disclaimer\n\n\u201cOmniForge\u201d is an independent open-source tool and not affiliated with The Omni Group or any other third-party products using similar names. If a future naming conflict arises, a soft alias strategy (keeping the `omni` CLI) will preserve user workflows.\n\n---\n\n## Example Session (Illustrative)\n\n```text\n$ ./omni\nOMNIFORGE 0.1.0  (backend=openrouter | model=anthropic/claude-3)\nType 'help' or 'look .' to begin.\n\n> look .\nIndexed 42 files (Python=30, Markdown=5, JSON=7)\n\n> refactor \"centralize logging into logging_util.py and update imports\"\nPlan:\n  [1] CREATE logging_util.py\n  [2] MODIFY app.py (replace inline log setup)\n  [3] MODIFY worker.py (import logging_util)\nProceed? (y/n) y\n... (diff preview) ...\nApply changes? (y/n) y\nRefactor complete in 3.2s.\n\n> edit worker.py \"add retry with exponential backoff to fetch_data\"\nParsed worker.py \u2713\nApplied modification (function: fetch_data)\nDiff shown. Accept? (y/n) y\nSaved.\n```\n\n---\n\n## Philosophy\n\n*The next wave of developer AI goes beyond paste\u2011in prompts.* OmniForge treats your repository as *structured material*, enabling incremental, auditable, and safer evolution rather than opaque code dumps. By combining **context scanning**, **AST precision**, and **human approval loops**, it aims to become a trustworthy co\u2011developer rather than an occasionally helpful code generator.\n\n---\n\n## Feedback / Support\n\nOpen a GitHub Issue for bugs & feature requests. For conceptual discussions (roadmap, design choices), use Discussions.\n\n---\n\nHappy forging!\n",
    "file": "/mnt/ProjectData/omni/README.md"
  },
  {
    "id": 46,
    "hash": "48f330cca4dc037b3ad4942e430e6393",
    "content": "# ast_adapter.py\n\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional, Dict, Any, Union\n\n# Define common types that adapters might use or return\n# This keeps the interface flexible without importing specific parser libraries\nASTNode = Any  # Generic type for a node in the AST/CST\nDiffContent = str # Type alias for the string output of a diff\n\nclass ASTAdapter(ABC):\n    \"\"\"\n    Abstract base class defining the interface for language-specific AST adapters.\n\n    This interface allows the CodeEditor to interact with the AST/CST of different\n    programming languages in a uniform way. Concrete implementations will handle\n    the specifics of parsing, traversing, and modifying the AST/CST for their\n    respective languages (e.g., Python's `ast`/`astor`, JavaScript's `tree-sitter`).\n\n    The adapter is responsible for holding the parsed tree structure and any\n    necessary metadata for operations.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the adapter by parsing the provided source code.\n\n        Args:\n            source_code: The string content of the source file to be parsed.\n\n        Raises:\n            ValueError: If the source code cannot be parsed due to syntax errors.\n        \"\"\"\n        self.source_code: str = source_code\n        self.tree: Optional[ASTNode] = None\n        self.nodes: Dict[str, ASTNode] = {} # A map for quick access to named elements\n        self._parse_and_map(source_code)\n\n    @abstractmethod\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Abstract method to parse the source code and populate `self.tree` and `self.nodes`.\n\n        This is the core method where language-specific parsing logic resides.\n        Implementations should:\n        1. Parse the `source_code` into an AST/CST representation.\n        2. Store the root of this representation in `self.tree`.\n        3. Identify key top-level elements (functions, classes, variables, imports)\n           and map their names to their nodes in `self.nodes`.\n\n        Args:\n            source_code: The string content to parse.\n\n        Raises:\n            ValueError: If the source code cannot be parsed.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_elements(self) -> List[str]:\n        \"\"\"\n        Abstract method to list the names of the main elements found in the code.\n\n        These are typically top-level functions, classes, variable assignments,\n        and imports that the adapter can identify and manipulate.\n\n        Returns:\n            A list of element names (strings).\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"\n        Abstract method to get the source code string for a specific element.\n\n        Args:\n            element_name: The name of the element (function, class, etc.).\n\n        Returns:\n            The source code string for the element, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"\n        Abstract method to get detailed structural information about an element.\n\n        This information can include type, line numbers, body items, etc., useful\n        for aiding the AI in understanding the code's layout.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            A dictionary containing structural details, or None if not found.\n            Example structure:\n            {\n                'name': 'func_name',\n                'type': 'FunctionDef', # or 'ClassDef', etc.\n                'line_start': 10,\n                'line_end': 25,\n                'body_items': [list of internal statement details...]\n            }\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"\n        Abstract method to extract a snippet of code from within an element's body.\n\n        Used for 'partial' edits where only a specific range of lines within\n        a function or class needs to be changed.\n\n        Args:\n            element_name: The name of the element containing the snippet.\n            line_start: The starting line number (1-based, absolute) of the snippet.\n            line_end: The ending line number (inclusive) of the snippet.\n\n        Returns:\n            The source code string for the specified lines within the element, or None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"\n        Abstract method to replace an entire named element.\n\n        This involves finding the old element in the tree and swapping it with\n        the representation of the `new_code`.\n\n        Args:\n            element_name: The name of the element to replace.\n            new_code: The new source code for the element (and potential helpers).\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"\n        Abstract method to add a new block of code (element) to the file.\n\n        This involves parsing the `new_code` and inserting its representation\n        into the tree at an appropriate location (e.g., end of file, near anchor).\n\n        Args:\n            new_code: The source code for the new element(s).\n            anchor_name: Optional name of an existing element to position relative to.\n            before: If True and `anchor_name` is provided, insert before the anchor.\n\n        Returns:\n            True if the element was added successfully, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"\n        Abstract method to delete a named element from the file.\n\n        This involves finding the element in the tree and removing its representation.\n\n        Args:\n            element_name: The name of the element to delete.\n\n        Returns:\n            True if the element was successfully deleted, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"\n        Abstract method for a 'surgical' edit within an element's body.\n\n        Replaces a specific statement or line range within the body of an element.\n\n        Args:\n            element_name: Name of the function/class to modify.\n            new_code: New code to insert (can be multiple statements).\n            line_start: Starting line number (absolute) within the element.\n            line_end: Ending line number (inclusive) within the element.\n            statement_index: Alternative to line numbers - replace the Nth statement.\n\n        Returns:\n            True if successful, False otherwise.\n        \"\"\"\n        pass\n\n    # --- Methods related to final output and change tracking ---\n\n    @abstractmethod\n    def get_modified_source(self) -> str:\n        \"\"\"\n        Abstract method to serialize the potentially modified AST/CST back to source code.\n\n        Returns:\n            The full source code string reflecting the current state of the tree.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_diff(self) -> str:\n        \"\"\"\n        Abstract method to generate a diff between the original source and the modified source.\n\n        Returns:\n            A string containing the unified diff.\n        \"\"\"\n        pass\n\n    # Internal helper methods (can be abstract or have common logic in base if needed)\n    # These are less critical for the interface but might be useful\n    # _add_imports(new_import_nodes) -> could be handled differently per language\n    # _find_statement_in_body(body, line_start, line_end) -> Tree-sitter needs different logic",
    "file": "/mnt/ProjectData/omni/ast_adapter.py"
  },
  {
    "id": 47,
    "hash": "40b50193cb04547cadce2d070870277a",
    "content": "\"\"\"\nCodeEditor - Enhanced AST-based code manipulation tool\n\nThis module provides a class to programmatically parse, analyze,\nand edit source code. It has been refactored to use a pluggable\nASTAdapter system, allowing it to support multiple languages.\nCurrently, it defaults to Python's built-in `ast` module via\nPythonASTAdapter for backward compatibility during the transition.\n\"\"\"\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Union, Tuple, Type, Any\nfrom ast_adapter import ASTAdapter\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n\n\nclass CodeEditor:\n    \"\"\"\n    An enhanced class to safely edit files using AST/CST with partial edit support.\n    The core logic for interacting with the code structure is now delegated to\n    a language-specific ASTAdapter.\n    \"\"\"\n\n    def __init__(self, file_path: str, adapter_class: Optional[Type[\n        ASTAdapter]]=None):\n        \"\"\"\n        Initializes the CodeEditor.\n\n        Args:\n            file_path: The path to the source file.\n            adapter_class: The ASTAdapter subclass to use. If None, defaults to\n                           PythonASTAdapter for .py files.\n        \"\"\"\n        self.file_path = file_path\n        self.source_code = self._read_file()\n        if adapter_class is None:\n            try:\n                from python_ast_adapter import PythonASTAdapter\n                self.adapter: Optional[ASTAdapter] = PythonASTAdapter(self.\n                    source_code)\n            except ImportError:\n                self.adapter = None\n                self.tree: ast.AST = self._parse_source()\n                self.nodes: Dict[str, ast.AST] = self._map_nodes()\n                if ASTTOKENS_AVAILABLE:\n                    self.atok = asttokens.ASTTokens(self.source_code, parse\n                        =True)\n                else:\n                    self.atok = None\n        else:\n            self.adapter = adapter_class(self.source_code)\n\n    def _read_file(self) ->str:\n        \"\"\"Reads the source file.\"\"\"\n        try:\n            with open(self.file_path, 'r', encoding='utf-8') as f:\n                return f.read()\n        except FileNotFoundError:\n            raise ValueError(f'File not found: {self.file_path}')\n\n    def _parse_source(self) ->ast.AST:\n        \"\"\"Fallback parsing logic.\"\"\"\n        try:\n            return ast.parse(self.source_code)\n        except SyntaxError as e:\n            raise ValueError(f'Invalid Python syntax in {self.file_path}: {e}')\n\n    def list_elements(self) ->List[str]:\n        \"\"\"Lists top-level elements in the code.\"\"\"\n        if self.adapter:\n            return self.adapter.list_elements()\n        else:\n            return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"Gets the source code for a specific element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_source_of(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            return astor.to_source(node) if node else None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"Gets detailed structure information about an element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_structure(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            if not node:\n                return None\n            structure = {'name': element_name, 'type': node.__class__.\n                __name__, 'line_start': node.lineno if hasattr(node,\n                'lineno') else None, 'line_end': node.end_lineno if hasattr\n                (node, 'end_lineno') else None, 'body_items': []}\n            if hasattr(node, 'body'):\n                for i, item in enumerate(node.body):\n                    item_info = {'index': i, 'type': item.__class__.\n                        __name__, 'line_start': item.lineno if hasattr(item,\n                        'lineno') else None, 'line_end': item.end_lineno if\n                        hasattr(item, 'end_lineno') else None}\n                    if isinstance(item, ast.Assign) and item.targets:\n                        target = item.targets[0]\n                        if isinstance(target, ast.Name):\n                            item_info['assigns'] = target.id\n                    elif isinstance(item, (ast.If, ast.While, ast.For)):\n                        item_info['has_body'] = bool(item.body)\n                    elif isinstance(item, ast.Return):\n                        item_info['returns'] = True\n                    structure['body_items'].append(item_info)\n            return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"Gets a snippet from within an element's body.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_body_snippet(element_name,\n                line_start, line_end)\n        else:\n            if not self.atok:\n                return None\n            node = self.nodes.get(element_name)\n            if not node or not hasattr(node, 'body'):\n                return None\n            statements = []\n            for stmt in node.body:\n                if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                    if (line_start <= stmt.lineno <= line_end or line_start <=\n                        stmt.end_lineno <= line_end):\n                        statements.append(stmt)\n            if not statements:\n                return None\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in\n                statements)\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"Replaces a partial section of an element.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_partial(element_name, new_code,\n                line_start, line_end, statement_index)\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                if new_code.strip().startswith('def ') or new_code.strip(\n                    ).startswith('class '):\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body[0].body\n                else:\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if statement_index is not None:\n                if 0 <= statement_index < len(node.body):\n                    node.body[statement_index:statement_index + 1\n                        ] = new_statements\n                    return True\n            elif line_start is not None:\n                result = self._find_statement_in_body(node.body, line_start,\n                    line_end)\n                if result:\n                    idx, _ = result\n                    if line_end:\n                        end_idx = idx\n                        for i in range(idx + 1, len(node.body)):\n                            stmt = node.body[i]\n                            if hasattr(stmt, 'end_lineno'\n                                ) and stmt.end_lineno <= line_end:\n                                end_idx = i\n                            else:\n                                break\n                        node.body[idx:end_idx + 1] = new_statements\n                    else:\n                        node.body[idx:idx + 1] = new_statements\n                    return True\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"Adds a new block of code to the file.\"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name, before)\n        else:\n            try:\n                new_ast_module = ast.parse(new_code)\n            except (SyntaxError, IndexError):\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            insertion_index = -1\n            main_block_idx = -1\n            for i, _node in enumerate(self.tree.body):\n                if isinstance(_node, ast.If) and isinstance(_node.test, ast\n                    .Compare) and isinstance(_node.test.left, ast.Name\n                    ) and _node.test.left.id == '__name__' and len(_node.\n                    test.ops) == 1 and isinstance(_node.test.ops[0], ast.Eq\n                    ) and len(_node.test.comparators) == 1:\n                    comp = _node.test.comparators[0]\n                    if isinstance(comp, ast.Constant\n                        ) and comp.value == '__main__' or isinstance(comp,\n                        ast.Str) and comp.s == '__main__':\n                        main_block_idx = i\n                        break\n            if anchor_name:\n                if anchor_name not in self.nodes:\n                    return False\n                anchor_node = self.nodes[anchor_name]\n                try:\n                    anchor_idx = self.tree.body.index(anchor_node)\n                    proposed_index = anchor_idx if before else anchor_idx + 1\n                    if main_block_idx != -1:\n                        insertion_index = min(proposed_index, main_block_idx)\n                    else:\n                        insertion_index = proposed_index\n                except ValueError:\n                    return False\n            elif main_block_idx != -1:\n                insertion_index = main_block_idx\n            if insertion_index == -1:\n                self.tree.body.extend(new_code_body)\n            else:\n                for i, new_node in enumerate(new_code_body):\n                    self.tree.body.insert(insertion_index + i, new_node)\n            for _node in new_code_body:\n                if isinstance(_node, (ast.FunctionDef, ast.AsyncFunctionDef,\n                    ast.ClassDef)):\n                    self.nodes[_node.name] = _node\n            return True\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"Deletes an element by name.\"\"\"\n        if self.adapter:\n            return self.adapter.delete_element(element_name)\n        else:\n            deleted = False\n            if element_name in self.nodes:\n                node_to_delete = self.nodes[element_name]\n                for _node in ast.walk(self.tree):\n                    if hasattr(_node, 'body') and isinstance(_node.body, list):\n                        try:\n                            _node.body.remove(node_to_delete)\n                            deleted = True\n                            break\n                        except ValueError:\n                            continue\n                if deleted:\n                    del self.nodes[element_name]\n                    self.nodes = self._map_nodes()\n                    return True\n            new_body = []\n            for _node in self.tree.body:\n                if isinstance(_node, ast.Assign):\n                    match = False\n                    for target in _node.targets:\n                        if isinstance(target, ast.Name\n                            ) and target.id == element_name:\n                            match = True\n                            break\n                    if match:\n                        deleted = True\n                        continue\n                elif isinstance(_node, ast.Import):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                elif isinstance(_node, ast.ImportFrom):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                new_body.append(_node)\n            self.tree.body = new_body\n            if deleted:\n                self.nodes = self._map_nodes()\n            return deleted\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"Replaces a target element with new code.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_element(element_name, new_code)\n        else:\n            if element_name not in self.nodes:\n                return False\n            try:\n                new_ast_module = ast.parse(new_code)\n            except SyntaxError:\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            for _node in ast.walk(self.tree):\n                if hasattr(_node, 'body') and isinstance(_node.body, list):\n                    try:\n                        old_node = self.nodes[element_name]\n                        idx = _node.body.index(old_node)\n                        _node.body.pop(idx)\n                        for i, new_node in enumerate(new_code_body):\n                            _node.body.insert(idx + i, new_node)\n                        del self.nodes[element_name]\n                        for n in new_code_body:\n                            if isinstance(n, (ast.FunctionDef, ast.\n                                AsyncFunctionDef, ast.ClassDef)):\n                                self.nodes[n.name] = n\n                        return True\n                    except (ValueError, KeyError):\n                        continue\n            return False\n\n    def insert_in_element(self, element_name: str, new_code: str, position:\n        str='end', after_line: Optional[int]=None, before_line: Optional[\n        int]=None) ->bool:\n        \"\"\"\n        Insert new code into an element without replacing existing code.\n        This is an internal/helper method, delegating to adapter OR using fallback.\n        \"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name=\n                element_name, before=position == 'start')\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                new_ast = ast.parse(new_code)\n                new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if position == 'start':\n                node.body[0:0] = new_statements\n            elif position == 'end':\n                node.body.extend(new_statements)\n            elif after_line:\n                result = self._find_statement_in_body(node.body, after_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx + 1:idx + 1] = new_statements\n                else:\n                    return False\n            elif before_line:\n                result = self._find_statement_in_body(node.body, before_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx:idx] = new_statements\n                else:\n                    return False\n            else:\n                return False\n            return True\n\n    def _map_nodes(self) ->Dict[str, ast.AST]:\n        \"\"\"Fallback node mapping logic for Python AST.\"\"\"\n        nodes = {}\n        for node in ast.walk(self.tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast\n                .ClassDef)):\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int,\n        line_end: Optional[int]=None) ->Optional[Tuple[int, ast.AST]]:\n        \"\"\"Fallback statement finding logic for Python AST.\"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = stmt.end_lineno if hasattr(stmt, 'end_lineno'\n                        ) else stmt.lineno\n                    if (stmt.lineno <= line_start <= stmt_end or stmt.\n                        lineno <= line_end <= stmt_end):\n                        return i, stmt\n                elif stmt.lineno == line_start:\n                    return i, stmt\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.\n        ImportFrom]]) ->None:\n        \"\"\"Fallback logic to add imports to the top of the Python AST.\"\"\"\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                existing_imports_str.add(astor.to_source(node).strip())\n                last_import_index = i\n        for new_import in reversed(new_import_nodes):\n            new_import_str = astor.to_source(new_import).strip()\n            if new_import_str not in existing_imports_str:\n                self.tree.body.insert(last_import_index + 1, new_import)\n\n    def apply_arbitrary_change(self, new_source_code: str) ->bool:\n        \"\"\"\n        Rewrites the entire file's AST from a new source string.\n        This method resets the adapter if one exists, or uses fallback.\n        \"\"\"\n        if self.adapter:\n            try:\n                adapter_class = type(self.adapter)\n                self.adapter = adapter_class(new_source_code)\n                return True\n            except Exception:\n                return False\n        else:\n            try:\n                new_tree = ast.parse(new_source_code)\n                self.tree = new_tree\n                self.nodes = self._map_nodes()\n                if ASTTOKENS_AVAILABLE:\n                    self.source_code = new_source_code\n                    self.atok = asttokens.ASTTokens(self.source_code, parse\n                        =True)\n                return True\n            except SyntaxError:\n                return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"Serializes the potentially modified code structure back to source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_modified_source()\n        else:\n            return astor.to_source(self.tree)\n\n    def get_diff(self) ->str:\n        \"\"\"Generates a diff between the original source and the modified source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_diff()\n        else:\n            modified_source = self.get_modified_source()\n            return ''.join(difflib.unified_diff(self.source_code.splitlines\n                (keepends=True), modified_source.splitlines(keepends=True),\n                fromfile=f'{self.file_path} (original)', tofile=\n                f'{self.file_path} (modified)'))\n\n    def save_changes(self) ->None:\n        \"\"\"Saves the modified source code back to the file.\"\"\"\n        modified_source = self.get_modified_source()\n        with open(self.file_path, 'w', encoding='utf-8') as f:\n            f.write(modified_source)\n",
    "file": "/mnt/ProjectData/omni/code_editor.py"
  },
  {
    "id": 48,
    "hash": "cc52aa524d0929867d5d2ea3697229e6",
    "content": "\"\"\"\nGenerated file.\n\"\"\"\nimport os\n\"\"\"\nFileCreator - A utility for creating files.\n\nThis module provides a simple, encapsulated way to create files,\nensuring that their parent directories exist before writing.\n\"\"\"\n\n\nclass FileCreator:\n    \"\"\"\n    A utility class to handle the creation of new files.\n    \"\"\"\n\n    @staticmethod\n    def create(file_path: str, content: str) ->None:\n        \"\"\"\n        Creates a file at the specified path with the given content.\n\n        This method will automatically create any necessary parent\n        directories for the file path.\n\n        Args:\n            file_path: The full path where the file should be created.\n            content: The string content to write to the file.\n\n        Raises:\n            IOError: If there is an error creating the directories or writing the file.\n        \"\"\"\n        try:\n            directory = os.path.dirname(file_path)\n            if directory:\n                os.makedirs(directory, exist_ok=True)\n            with open(file_path, 'w', encoding='utf-8') as f:\n                f.write(content)\n        except (IOError, OSError) as e:\n            raise IOError(f\"Failed to create file '{file_path}': {e}\") from e\n",
    "file": "/mnt/ProjectData/omni/file_creator.py"
  },
  {
    "id": 49,
    "hash": "04a24ceab008bd649d0530d309c72e42",
    "content": "import subprocess\nimport os\nfrom typing import List, Optional, Union\n\n\nclass GitManager:\n    \"\"\"\n    Encapsulates Git-related logic for a specific repository.\n\n    This class provides methods to perform common Git operations such as\n    checking status, getting diffs, staging, committing, and pushing changes.\n    It relies on the Git command-line tool being installed and accessible\n    in the system's PATH.\n    \"\"\"\n\n    def __init__(self, repo_path: str):\n        \"\"\"\n        Initializes the GitManager for a given repository path.\n\n        Args:\n            repo_path: The absolute or relative path to the Git repository.\n\n        Raises:\n            ValueError: If the provided path is not a valid Git repository.\n        \"\"\"\n        if not os.path.isdir(os.path.join(repo_path, '.git')):\n            raise ValueError(\n                f\"The path '{repo_path}' is not a valid Git repository.\")\n        self.repo_path = repo_path\n\n    def _run_command(self, command: List[str]) ->str:\n        \"\"\"\n        Executes a Git command in the repository's directory.\n\n        Args:\n            command: A list of command arguments, starting with 'git'.\n\n        Returns:\n            The standard output of the command as a string.\n\n        Raises:\n            subprocess.CalledProcessError: If the command returns a non-zero exit code.\n        \"\"\"\n        try:\n            result = subprocess.run(command, cwd=self.repo_path, check=True,\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True,\n                encoding='utf-8')\n            return result.stdout.strip()\n        except subprocess.CalledProcessError as e:\n            error_message = (\n                f\"Git command failed: {' '.join(command)}\\nError: {e.stderr.strip()}\"\n                )\n            raise subprocess.CalledProcessError(e.returncode, e.cmd, output\n                =e.stdout, stderr=error_message) from e\n\n    def get_status(self) ->str:\n        \"\"\"\n        Gets the repository status in a condensed format.\n\n        Uses `git status --porcelain` for a machine-readable output.\n\n        Returns:\n            A string representing the repository's status.\n        \"\"\"\n        return self._run_command(['git', 'status', '--porcelain'])\n        \n    def get_changed_files(self) -> List[str]:\n        \"\"\"\n        Gets a list of all changed (modified, added, deleted, untracked, renamed, or copied) files.\n\n        This parses the output of `git status --porcelain`, which provides a stable,\n        machine-readable format.\n\n        Returns:\n            A list of file paths relative to the repository root. For renamed or\n            copied files, it returns the new path.\n        \"\"\"\n        status_output = self.get_status()\n        if not status_output:\n            return []\n        \n        changed_files = []\n        for line in status_output.splitlines():\n            if len(line) < 3:  # Skip malformed lines\n                continue\n                \n            # Git status porcelain format: XY filename\n            # X = index status, Y = working tree status\n            index_status = line[0]\n            worktree_status = line[1]\n            \n            # The filename starts after the two status characters and a space\n            # But let's be more defensive about finding where the filename actually starts\n            filename_start = 2\n            while filename_start < len(line) and line[filename_start] == ' ':\n                filename_start += 1\n                \n            if filename_start >= len(line):\n                continue  # Skip if no filename found\n                \n            path_info = line[filename_start:]\n            \n            # Check if either index or working tree status indicates rename/copy\n            if index_status in ('R', 'C') or worktree_status in ('R', 'C'):\n                if ' -> ' in path_info:\n                    _, new_path = path_info.split(' -> ', 1)  # Use maxsplit=1 for safety\n                    changed_files.append(new_path.strip())\n                else:\n                    # Fallback if format is unexpected\n                    changed_files.append(path_info.strip())\n            else:\n                changed_files.append(path_info.strip())\n        \n        # Remove duplicates while preserving order\n        return list(dict.fromkeys(changed_files))\n\n    def get_diff(self, file_path: Optional[str]=None, staged: bool=False\n        ) ->str:\n        \"\"\"\n        Gets the diff of changes in the repository.\n\n        Args:\n            file_path: Optional. Path to a specific file to diff.\n            staged: If True, shows the diff for staged changes (`--cached`).\n                    Otherwise, shows the diff for unstaged changes.\n\n        Returns:\n            The git diff output as a string.\n        \"\"\"\n        cmd = ['git', 'diff']\n        if staged:\n            cmd.append('--cached')\n        if file_path:\n            cmd.append('--')\n            cmd.append(file_path)\n        return self._run_command(cmd)\n\n    def add(self, files: Union[str, List[str]]) ->None:\n        \"\"\"\n    Stages one or more files, handling each one individually for robustness.\n\n    This approach prevents a single invalid file path from causing the\n    entire 'git add' operation to fail. Warnings will be printed for any\n    files that could not be staged.\n\n    Args:\n        files: A single file path or a list of file paths to stage.\n               Can also be '.' to stage all changes.\n    \"\"\"\n        if isinstance(files, str):\n            files = [files]\n        for file_path in files:\n            try:\n                cmd = ['git', 'add', '--', file_path]\n                self._run_command(cmd)\n            except subprocess.CalledProcessError as e:\n                print(\n                    f\"Warning: Could not stage file '{file_path}'. Git reported: {e.stderr}\"\n                    )\n\n    def commit(self, message: str) ->str:\n        \"\"\"\n        Commits staged changes with a given message.\n\n        Args:\n            message: The commit message.\n\n        Returns:\n            The stdout from the git commit command.\n        \"\"\"\n        return self._run_command(['git', 'commit', '-m', message])\n\n    def push(self, remote: str='origin', branch: Optional[str]=None) ->str:\n        \"\"\"\n        Pushes commits to a remote repository.\n\n        Args:\n            remote: The name of the remote to push to (default: 'origin').\n            branch: The branch to push. If None, uses the current branch.\n\n        Returns:\n            The stdout from the git push command.\n        \"\"\"\n        if branch is None:\n            branch = self.get_current_branch()\n        return self._run_command(['git', 'push', remote, branch])\n\n    def get_current_branch(self) ->str:\n        \"\"\"\n        Determines the current active branch name.\n\n        Returns:\n            The name of the current branch.\n        \"\"\"\n        return self._run_command(['git', 'rev-parse', '--abbrev-ref', 'HEAD'])\n",
    "file": "/mnt/ProjectData/omni/git_manager.py"
  },
  {
    "id": 50,
    "hash": "89fa0c06ca34019316daa58ce8fa9a20",
    "content": "import json\nimport os\nfrom typing import List, Dict, Optional\nfrom rag_manager import RAGManager\n\n\nclass MemoryManager:\n    \"\"\"Manages persistent chat memory, look data, and RAG integration via JSON.\"\"\"\n\n    def __init__(self, memory_file: str):\n        self.memory_file = memory_file\n        self.memory: Dict[str, List] = self.load_memory()\n        self.rag_manager = RAGManager()\n\n    def load_memory(self) ->Dict[str, List]:\n        try:\n            with open(self.memory_file, 'r') as f:\n                return json.load(f)\n        except FileNotFoundError:\n            default = {'chat': [], 'look': []}\n            self.save_memory(default)\n            return default\n        except json.JSONDecodeError:\n            print('[yellow]Invalid memory file. Resetting.[/]')\n            return {'chat': [], 'look': []}\n\n    def save_memory(self, memory: Optional[Dict[str, List]]=None) ->None:\n        if memory is None:\n            memory = self.memory\n        with open(self.memory_file, 'w') as f:\n            json.dump(memory, f, indent=4)\n\n    def add_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.memory['chat'].append({'role': role, 'content': content})\n        self.save_memory()\n\n    def add_chat_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        This is an alias for add_message to maintain compatibility.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.add_message(role, content)\n\n    def add_look_data(self, file_path: str, content: str) ->None:\n        \"\"\"\n    Adds a watched item (directory or file) to memory, distinguishing its type.\n\n    This method stores structured data that differentiates between a project\n    directory (containing a manifest) and a single file (containing its content).\n    It also prevents duplicate entries by updating existing ones.\n\n    Args:\n        file_path: The path to the directory or file.\n        content: The manifest for a directory or the content for a file.\n    \"\"\"\n        item_type = 'directory' if os.path.isdir(file_path) else 'file'\n        for item in self.memory['look']:\n            if item.get('file') == file_path:\n                item['content'] = content\n                item['type'] = item_type\n                self.save_memory()\n                return\n        self.memory['look'].append({'type': item_type, 'file': file_path,\n            'content': content})\n        self.save_memory()\n        if item_type == 'file':\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    file_content = f.read()\n                self.rag_manager.add_documents([file_content], [{'file':\n                    file_path}])\n            except Exception as e:\n                print(\n                    f'[yellow]Warning: Could not add {file_path} to RAG index: {e}[/]'\n                    )\n\n    def get_project_root(self) ->Optional[str]:\n        \"\"\"\n        Finds the root directory of the project currently in memory.\n\n        The project root is defined as the first item in the 'look' memory\n        that is of type 'directory'.\n\n        Returns:\n            The absolute path to the project root directory, or None if not found.\n        \"\"\"\n        for item in self.memory.get('look', []):\n            if item.get('type') == 'directory':\n                return item.get('file')\n        return None\n\n    def get_memory_context(self) ->str:\n        \"\"\"\n        Dynamically builds the context using RAG and chat history.\n\n        It retrieves relevant file content from the RAG index based on the latest\n        user query, includes project manifests for directories, and appends the\n        recent chat history.\n        \"\"\"\n        context = ''\n        for look in self.memory.get('look', []):\n            path = look.get('file')\n            if path and os.path.isdir(path):\n                content = look.get('content', '')\n                context += (\n                    f'--- Project Manifest for {path} ---\\n{content}\\n\\n')\n        last_user_message = next((msg['content'] for msg in reversed(self.\n            memory.get('chat', [])) if msg['role'] == 'user'), None)\n        if last_user_message:\n            rag_results = self.search_rag(last_user_message, k=3)\n            if rag_results:\n                context += '--- Relevant context from RAG ---\\n'\n                for doc, score, meta in rag_results:\n                    file_path = meta.get('file', 'Unknown source')\n                    context += f'Source: {file_path} (Score: {score:.4f})\\n'\n                    context += f'Content: {doc}\\n---\\n'\n                context += '\\n'\n        for msg in self.memory.get('chat', []):\n            context += f\"{msg['role'].capitalize()}: {msg['content']}\\n\"\n        return context.strip()\n\n    def clear_memory(self) ->None:\n        self.memory = {'chat': [], 'look': []}\n        self.save_memory()\n        self.rag_manager.clear_index()\n\n    def search_rag(self, query: str, k: int=3) ->List[tuple]:\n        \"\"\"\n        Search the RAG index for relevant documents.\n        \n        Args:\n            query: The search query\n            k: Number of results to return\n            \n        Returns:\n            List of (document_content, score, metadata) tuples\n        \"\"\"\n        return self.rag_manager.search(query, k)\n",
    "file": "/mnt/ProjectData/omni/memory_manager.py"
  },
  {
    "id": 51,
    "hash": "1503715e21300d3433a383484d00a3cb",
    "content": "\"\"\"\nOmni - AI-powered code generation and project-aware editing CLI tool\n\nIntegrates modular UI, memory, personality, and AST-based code editing.\n\"\"\"\nimport os\nimport subprocess\nimport requests\nimport json\nimport sys\nimport re\nimport argparse\nimport ast\nfrom datetime import datetime\nimport threading\nimport queue as Queue\nimport time\nfrom typing import List, Dict, Optional\nfrom rich import print\nfrom rich.panel import Panel\nfrom rich.console import Console\nfrom rich.tree import Tree\nfrom ui_manager import UIManager\nfrom personality_manager import PersonalityManager\nfrom memory_manager import MemoryManager\nfrom code_editor import CodeEditor\nfrom file_creator import FileCreator\nfrom git_manager import GitManager\nimport traceback\nDEFAULT_BACKEND = 'openrouter'\nOLLAMA_MODEL = 'phi4-reasoning'\nOPENROUTER_MODEL = 'qwen/qwen3-coder'\nDEFAULT_SAVE_DIR = os.path.expanduser('/mnt/ProjectData/omni/omni_saves/')\nCONFIG_FILE = 'config.json'\nMEMORY_FILE = 'memory.json'\nOLLAMA_API_URL = 'http://localhost:11434/api/generate'\nOPENROUTER_API_URL = 'https://openrouter.ai/api/v1/chat/completions'\nOPENROUTER_MODELS_API_URL = 'https://openrouter.ai/api/v1/models'\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\ncurrent_backend = DEFAULT_BACKEND\ncurrent_model = (OLLAMA_MODEL if DEFAULT_BACKEND == 'ollama' else\n    OPENROUTER_MODEL)\nOLLAMA_MODELS = {'deepseek': 'deepseek-coder:6.7b', 'codellama':\n    'codellama:13b', 'mistral': 'mistral:latest', 'llama2': 'llama2:latest',\n    'phind': 'phind-codellama:34b'}\nos.makedirs(DEFAULT_SAVE_DIR, exist_ok=True)\nTEMPLATES = {'flask':\n    \"\"\"from flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/')\ndef home():\n    return '<h1>Hello, Flask!</h1>'\n\nif __name__ == '__main__':\n    app.run(debug=True)\"\"\"\n    , 'html5':\n    \"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>New Page</title>\n</head>\n<body>\n    <h1>Hello World</h1>\n</body>\n</html>\"\"\"\n    , 'scraper':\n    \"\"\"import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        print(soup.title.text)\n    except Exception as e:\n        print(f\"[bold red]Error scraping {url}:[/] {e}\")\n\nif __name__ == \"__main__\":\n    scrape(\"https://example.com\")\"\"\"\n    }\nconsole = Console()\npersonality_manager = PersonalityManager(CONFIG_FILE)\nmemory_manager = MemoryManager(MEMORY_FILE)\nui_manager = UIManager()\nlast_query: Optional[str] = None\nlast_response: Optional[str] = None\nlast_code: Optional[str] = None\n\n\ndef start_ollama_server() ->None:\n    if current_backend != 'ollama':\n        return\n    try:\n        requests.get('http://localhost:11434', timeout=1)\n    except requests.exceptions.ConnectionError:\n        print('[cyan]Starting Ollama server...[/]')\n        subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL)\n\n\ndef query_llm(prompt: str) ->str:\n    personality = personality_manager.get_current_personality()\n    system_prompt = personality.get('system_prompt', '') if personality else ''\n    memory_context = memory_manager.get_memory_context()\n    rag_context = ''\n    try:\n        from rag_manager import RAGManager\n        project_root = memory_manager.get_project_root()\n        if project_root:\n            rag_manager = RAGManager()\n            if rag_manager.get_document_count() > 0:\n                results = rag_manager.search(prompt, k=3)\n                if results:\n                    rag_context = '\\n\\nRelevant context from codebase:\\n'\n                    for i, (doc, score, meta) in enumerate(results, 1):\n                        file_path = meta.get('file', 'Unknown')\n                        rag_context += f'{i}. [{file_path}] {doc}\\n'\n    except Exception:\n        pass\n    full_prompt = (\n        f'{system_prompt}\\n\\n{memory_context}{rag_context}\\n\\nUser: {prompt}')\n    with ui_manager.show_spinner('AI is listening and thinking...'):\n        if current_backend == 'ollama':\n            response = query_ollama(full_prompt)\n        elif current_backend == 'openrouter':\n            response = query_openrouter(full_prompt)\n        else:\n            response = '[bold red]Error:[/] Unknown backend'\n    return response\n\n\ndef query_openrouter(prompt: str) ->str:\n    if not OPENROUTER_API_KEY:\n        return '[bold red]Error:[/] OPENROUTER_API_KEY not set.'\n    headers = {'Authorization': f'Bearer {OPENROUTER_API_KEY}',\n        'Content-Type': 'application/json'}\n    payload = {'model': current_model, 'messages': [{'role': 'user',\n        'content': prompt}]}\n    try:\n        response = requests.post(OPENROUTER_API_URL, headers=headers, json=\n            payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['choices'][0]['message']['content']\n    except Exception as e:\n        error_details = ''\n        try:\n            error_details = response.json()\n        except:\n            error_details = response.text if hasattr(response, 'text'\n                ) else str(e)\n        return (\n            f'[bold red]OpenRouter Error:[/] {e}\\n[dim]Details: {error_details}[/dim]'\n            )\n\n\ndef query_ollama(prompt: str) ->str:\n    payload = {'model': current_model, 'prompt': prompt, 'stream': False}\n    try:\n        response = requests.post(OLLAMA_API_URL, json=payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['response']\n    except Exception as e:\n        return f'[bold red]Ollama Error:[/] {e}'\n\n\ndef extract_code(text: str) ->List[tuple[str, str]]:\n    matches = re.findall('```(\\\\w*)\\\\n([\\\\s\\\\S]*?)```', text)\n    return [(lang or 'text', code.strip()) for lang, code in matches\n        ] if matches else []\n\n\ndef list_models(args: list=None) ->None:\n    if current_backend == 'ollama':\n        print('[bold cyan]Popular Ollama Models:[/]')\n        for name, model_id in OLLAMA_MODELS.items():\n            print(\n                f\"{'\u2b50' if model_id == current_model else '  '} [yellow]{name:12}[/] \u2192 {model_id}\"\n                )\n    elif current_backend == 'openrouter':\n        list_openrouter_models(args or [])\n\n\ndef list_openrouter_models(args: list):\n    try:\n        from simple_term_menu import TerminalMenu\n    except ImportError:\n        ui_manager.show_error(\n            \"'simple-term-menu' is required. `pip install simple-term-menu`\")\n        return\n    try:\n        with ui_manager.show_spinner('Fetching models...'):\n            response = requests.get(OPENROUTER_MODELS_API_URL)\n            response.raise_for_status()\n        api_models_data = response.json().get('data', [])\n    except requests.RequestException as e:\n        ui_manager.show_error(f'Error fetching models: {e}')\n        return\n    all_models, sources = [], set()\n    for model_data in api_models_data:\n        if (model_id := model_data.get('id')):\n            sources.add(model_id.split('/')[0])\n            pricing = model_data.get('pricing', {})\n            is_free = pricing.get('prompt') == '0' and pricing.get('completion'\n                ) == '0'\n            all_models.append({'id': model_id, 'name': model_data.get(\n                'name'), 'source': model_id.split('/')[0], 'is_free': is_free})\n    all_models.sort(key=lambda x: (x['source'], x['name']))\n    if args and args[0].lower() == 'sources':\n        print('[bold cyan]Available Model Sources:[/]')\n        [print(f'  [yellow]{s}[/]') for s in sorted(list(sources))]\n        return\n    models_to_display, title = all_models, 'Select an OpenRouter Model'\n    if args:\n        filter_keyword = args[0].lower()\n        title = f\"Select a Model from '{filter_keyword}'\"\n        models_to_display = [m for m in all_models if filter_keyword in m[\n            'source'].lower()]\n        if not models_to_display:\n            ui_manager.show_error(f\"No models for source: '{filter_keyword}'\")\n            return\n    menu_entries = [\n        f\"{'\u2b50' if m['id'] == current_model else '  '} {m['name']} [dim]({m['id']}){' [green](FREE)[/]' if m['is_free'] else ''}[/dim]\"\n         for m in models_to_display]\n    try:\n        cursor_idx = next((i for i, m in enumerate(models_to_display) if m[\n            'id'] == current_model), 0)\n        chosen_index = TerminalMenu(menu_entries, title=f'{title}',\n            cursor_index=cursor_idx, cycle_cursor=True, clear_screen=True\n            ).show()\n        if chosen_index is not None:\n            set_model(models_to_display[chosen_index]['id'])\n        else:\n            print('Model selection cancelled.')\n    except Exception as e:\n        ui_manager.show_error(f'Menu display error: {e}')\n\n\ndef set_model(model_id: str) ->None:\n    global current_model\n    current_model = model_id\n    ui_manager.show_success(f'Model set to: {current_model}')\n\n\ndef switch_backend(backend_name: str) ->None:\n    global current_backend, current_model\n    backend_name = backend_name.lower()\n    if backend_name not in ['ollama', 'openrouter']:\n        ui_manager.show_error(f'Unknown backend: {backend_name}')\n        return\n    current_backend = backend_name\n    current_model = (OLLAMA_MODEL if backend_name == 'ollama' else\n        OPENROUTER_MODEL)\n    ui_manager.show_success(\n        f'Switched to {backend_name} backend with model: {current_model}')\n    if backend_name == 'ollama':\n        start_ollama_server()\n\n\ndef generate_project_manifest(path: str) ->tuple[str, List[str]]:\n    manifest = ''\n    file_paths = []\n    tree = Tree(f'[bold cyan]Project: {os.path.basename(path)}[/]')\n    exclude_dirs = {'__pycache__', '.git', 'venv', 'node_modules', '.idea',\n        'ollama'}\n    for root, dirs, files in os.walk(path):\n        dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.\n            startswith('.')]\n        relative_path = os.path.relpath(root, path)\n        branch = tree\n        if relative_path != '.':\n            parts = relative_path.split(os.sep)\n            for part in parts:\n                child = next((c for c in branch.children if c.label ==\n                    f'[magenta]{part}[/]'), None)\n                if not child:\n                    child = branch.add(f'[magenta]{part}[/]')\n                branch = child\n        for fname in sorted(files):\n            ext = os.path.splitext(fname)[1]\n            if ext not in ('.py', '.js', '.html', '.css', '.md', '.txt'):\n                continue\n            rel_path = os.path.join(relative_path, fname\n                ) if relative_path != '.' else fname\n            file_paths.append(rel_path)\n            branch.add(f'[green]{fname}[/]' if ext == '.py' else\n                f'[dim]{fname}[/]')\n            manifest += f'File: {rel_path}\\n\\n'\n    console.print(tree)\n    return manifest.strip(), file_paths\n\n\ndef look_command(path: str) ->None:\n    \"\"\"\n    Scans a directory or file and loads it into memory. It can resolve paths\n    relative to the current working directory or the project root in memory.\n    If a new directory is scanned, the previous 'look' context is cleared\n    to ensure the context remains relevant.\n    \"\"\"\n    resolved_path = resolve_file_path(path)\n    if not resolved_path:\n        ui_manager.show_error(f'\u274c Path not found: {path}')\n        return\n    if resolved_path != os.path.abspath(path):\n        ui_manager.show_success(\n            f\"Found '{path}' in project. Using: {resolved_path}\")\n    if os.path.isdir(resolved_path):\n        ui_manager.show_success(\n            \"New project directory detected. Clearing previous 'look' context.\"\n            )\n        memory_manager.memory['look'] = []\n        with ui_manager.show_spinner('Generating project manifest...'):\n            manifest = generate_project_manifest(resolved_path)\n        memory_manager.add_look_data(resolved_path, manifest)\n        ui_manager.show_success('\u2705 Project manifest added to memory.')\n    else:\n        try:\n            with ui_manager.show_spinner('Loading file...'):\n                with open(resolved_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n            for item in memory_manager.memory['look']:\n                if item.get('file') == resolved_path:\n                    item['content'] = content\n                    memory_manager.save_memory()\n                    ui_manager.show_success(\n                        '\u2705 Refreshed file content in memory.')\n                    return\n            memory_manager.add_look_data(resolved_path, content)\n            ui_manager.show_success('\u2705 File content added to memory.')\n        except Exception as e:\n            ui_manager.show_error(f'\u274c Error reading file: {e}')\n\n\ndef resolve_file_path(path: str) ->Optional[str]:\n    \"\"\"Resolves a file path, checking CWD first, then against project root in memory.\"\"\"\n    if os.path.exists(path):\n        return os.path.abspath(path)\n    project_root = memory_manager.get_project_root()\n    if project_root:\n        full_path = os.path.join(project_root, path)\n        if os.path.exists(full_path):\n            return full_path\n    return None\n\n\ndef _create_prompt_for_file_creation(file_name: str, instruction: str) ->str:\n    \"\"\"\n    Generate a robust prompt for file creation that instructs the AI to act as an expert,\n    produce complete and clean code, and avoid any extra commentary.\n    \"\"\"\n    return f\"\"\"You are an expert programmer tasked with creating a new file. Your goal is to generate complete, production-ready content based on the user's instruction.\n\nIMPORTANT RULES:\n- Provide ONLY the raw file content - no explanations, notes, or commentary outside the file itself\n- Include all necessary imports, boilerplate, and complete implementations\n- If creating code, ensure it's syntactically correct and follows best practices\n- For configuration files, use appropriate formatting (JSON, YAML, etc.)\n- For documentation files, use proper markdown formatting\n\nFile to create: {file_name}\nUser instruction: {instruction}\n\nGenerate the complete file content now:\"\"\"\n\n\ndef handle_file_create_command(file_path: str, instruction: str):\n    \"\"\"\n    Uses the LLM to generate content for a new file based on an instruction.\n    \"\"\"\n    global last_code\n    if os.path.exists(file_path):\n        if ui_manager.get_user_input(\n            f\"File '{file_path}' already exists. Overwrite? (y/n): \").lower(\n            ) not in ['yes', 'y']:\n            ui_manager.show_error('File creation cancelled.')\n            return\n    prompt = _create_prompt_for_file_creation(os.path.basename(file_path),\n        instruction)\n    with ui_manager.show_spinner(\n        f\"AI is generating content for '{file_path}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    if code_blocks:\n        new_content = code_blocks[0][1]\n    else:\n        new_content = response.strip()\n    if not new_content:\n        ui_manager.show_error('AI did not return any content.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    print(Panel(new_content, title=\n        f'[bold yellow]Proposed content for {file_path}[/]', border_style=\n        'yellow'))\n    if ui_manager.get_user_input('Create this file? (y/n): ').lower() in ['yes'\n        , 'y']:\n        try:\n            FileCreator.create(file_path, new_content)\n            last_code = new_content\n            ui_manager.show_success(f'File created successfully: {file_path}')\n        except IOError as e:\n            ui_manager.show_error(f'Error creating file: {e}')\n    else:\n        ui_manager.show_error('File creation cancelled.')\n\n\ndef look_all_command() ->None:\n    \"\"\"\n    Finds the project manifest in memory, reads every file listed, and adds their content to memory.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first to generate a manifest.\"\n            )\n        return\n    manifest_data = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and item.get('type'\n            ) == 'directory':\n            manifest_data = item.get('content')\n            break\n    if not manifest_data or not isinstance(manifest_data, (list, tuple)\n        ) or len(manifest_data) != 2:\n        ui_manager.show_error(\n            \"Could not find a valid project manifest in memory. Please run 'look <directory>' again.\"\n            )\n        return\n    file_paths = manifest_data[1]\n    if not file_paths:\n        ui_manager.show_error('No files found in the project manifest.')\n        return\n    total_files = len(file_paths)\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Loading {total_files} files from project manifest...'):\n        for file_path_relative in file_paths:\n            full_path = os.path.join(project_root, file_path_relative)\n            if os.path.isfile(full_path):\n                try:\n                    with open(full_path, 'r', encoding='utf-8') as f:\n                        content = f.read().strip()\n                    if not any(look['file'] == full_path for look in\n                        memory_manager.memory['look']):\n                        memory_manager.add_look_data(full_path, content)\n                        loaded_count += 1\n                except Exception as e:\n                    print(\n                        f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\"\n                        )\n    ui_manager.show_success(\n        f'\u2705 Loaded content for {loaded_count} new files into memory.')\n\n\ndef _load_all_project_files_if_needed():\n    \"\"\"\n    Checks if a project is loaded and automatically loads any files from its\n    manifest that are not already in the 'look' memory. This ensures a\n    complete context for editing and refactoring commands.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        return\n    manifest_content = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and 'File:' in item.get('content',\n            ''):\n            manifest_content = item['content']\n            break\n    if not manifest_content:\n        return\n    existing_file_paths = {item['file'] for item in memory_manager.memory.\n        get('look', []) if item.get('type') == 'file'}\n    file_paths_relative = re.findall('File: (.*)', manifest_content)\n    files_to_load = []\n    for rel_path in file_paths_relative:\n        full_path = os.path.join(project_root, rel_path)\n        if full_path not in existing_file_paths and os.path.isfile(full_path):\n            files_to_load.append((full_path, rel_path))\n    if not files_to_load:\n        return\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Auto-loading {len(files_to_load)} project files for context...'):\n        for full_path, file_path_relative in files_to_load:\n            try:\n                with open(full_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n                memory_manager.add_look_data(full_path, content)\n                loaded_count += 1\n            except Exception as e:\n                print(f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\")\n    if loaded_count > 0:\n        ui_manager.show_success(\n            f'\u2705 Loaded {loaded_count} new file(s) into memory for full project context.'\n            )\n\n\ndef _create_prompt_for_element_selection(file_name: str, instruction: str,\n    elements: List[str], element_structures: Dict[str, Dict]) ->str:\n    \"\"\"\n    Create a helper for the first stage of the 'edit' command. This prompt asks the AI\n    to analyze the user's instruction and intelligently select the most relevant code element to modify.\n    \"\"\"\n    element_details = []\n    for elem in elements:\n        if elem in element_structures:\n            struct = element_structures[elem]\n            detail = (\n                f\"{elem} ({struct['type']}, lines {struct['line_start']}-{struct['line_end']})\"\n                )\n            element_details.append(detail)\n        else:\n            element_details.append(elem)\n    return f\"\"\"You are an expert code analyzer. Your task is to identify what should be modified based on the user's instruction.\n\nFile: {file_name}\nAvailable elements: {', '.join(element_details) if element_details else 'None'}\n\nUser instruction: {instruction}\n\nRESPONSE FORMAT:\nChoose one of these response types:\n1. \"ELEMENT: <element_name>\" - to edit an entire function/class\n2. \"PARTIAL: <element_name> LINES: <start>-<end>\" - to edit specific lines within an element\n3. \"FILE\" - to edit the entire file or multiple elements\n\nRULES:\n- If the instruction mentions specific line numbers or a specific part of a function, use PARTIAL\n- If the instruction targets an entire function/class, use ELEMENT\n- If the instruction requires changes to multiple elements or file structure, use FILE\n- For PARTIAL edits, provide absolute line numbers from the original file\n\nWhat should be edited?\"\"\"\n\n\ndef _create_prompt_for_element_rewrite(file_name: str, element_name: str,\n    instruction: str, original_code: str, is_full_file: bool=False) ->str:\n    \"\"\"\n    Create a helper for the second stage of the 'edit' command. This prompt instructs the AI\n    to rewrite a specific code element (or the whole file) based on the user's request,\n    demanding a complete and syntactically correct code block as output.\n    \"\"\"\n    if is_full_file:\n        return f\"\"\"You are an expert programmer. Rewrite the entire file to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the entire file\n- Ensure all syntax is correct and the code is ready to run\n- Preserve existing functionality unless explicitly asked to change it\n- Include all necessary imports and maintain the file's structure\n- Do NOT include any explanations or comments outside the code\n\nFile: {file_name}\nTask: {instruction}\n\nCurrent file content:\n```python\n{original_code}\n```\n\nGenerate the complete updated file now:\"\"\"\n    else:\n        return f\"\"\"You are an expert programmer. Rewrite the specified element to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the element\n- Include any necessary imports at the top of your code block\n- Ensure the code is syntactically correct and maintains the same interface\n- Do NOT include explanations or comments outside the code block\n- The code must be a drop-in replacement for the original element\n\nFile: {file_name}\nElement to modify: {element_name}\nTask: {instruction}\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the complete updated element now:\"\"\"\n\n\ndef _create_prompt_for_partial_edit(file_name: str, element_name: str,\n    instruction: str, original_snippet: str, line_start: int, line_end: int,\n    full_element_code: str) ->str:\n    \"\"\"\n    Create a prompt for partial edits within a function or class.\n    This allows surgical changes to specific parts of code.\n    \"\"\"\n    return f\"\"\"You are an expert programmer. Make a surgical edit to a specific part of a function/class.\n\nCONTEXT:\n- File: {file_name}\n- Element: {element_name}\n- Lines to modify: {line_start}-{line_end}\n- Task: {instruction}\n\nIMPORTANT RULES:\n- Provide ONLY the code that will replace lines {line_start}-{line_end}\n- Your code must fit seamlessly into the existing function\n- Maintain proper indentation (the code will be auto-indented)\n- Do NOT include the function definition or other parts\n- Do NOT include explanations outside the code\n\nFull element for context:\n```python\n{full_element_code}\n```\n\nCode section to replace (lines {line_start}-{line_end}):\n```python\n{original_snippet}\n```\n\nGenerate ONLY the replacement code for the specified lines:\"\"\"\n\n\ndef handle_file_edit_command(file_path: str, instruction: str):\n    \"\"\"\n    Handles the entire workflow for editing a single file, ensuring full\n    project context is loaded before the AI makes any decisions.\n    Now supports partial edits within functions.\n    \"\"\"\n    global last_code\n    _load_all_project_files_if_needed()\n    resolved_path = resolve_file_path(file_path)\n    if not resolved_path:\n        ui_manager.show_error(f'File not found: {file_path}')\n        return\n    if resolved_path != os.path.abspath(file_path):\n        ui_manager.show_success(\n            f\"Found '{file_path}' in project. Using: {resolved_path}\")\n    try:\n        editor = CodeEditor(resolved_path)\n    except (ValueError, FileNotFoundError) as e:\n        ui_manager.show_error(str(e))\n        return\n    elements = editor.list_elements()\n    element_structures = {}\n    for elem in elements:\n        struct = editor.get_element_structure(elem)\n        if struct:\n            element_structures[elem] = struct\n    prompt1 = _create_prompt_for_element_selection(os.path.basename(\n        resolved_path), instruction, elements, element_structures)\n    with ui_manager.show_spinner('AI is analyzing file...'):\n        ai_response = query_llm(prompt1).strip()\n    if ai_response.upper() == 'FILE':\n        ui_manager.show_success('AI has chosen to edit the entire file.')\n        original_snippet = editor.source_code\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), 'entire file', instruction, original_snippet,\n            is_full_file=True)\n        edit_type = 'FILE'\n        element_to_edit = None\n        line_range = None\n    elif ai_response.startswith('PARTIAL:'):\n        parts = ai_response.split()\n        element_to_edit = parts[1]\n        if 'LINES:' in ai_response:\n            line_part = ai_response.split('LINES:')[1].strip()\n            if '-' in line_part:\n                line_start, line_end = map(int, line_part.split('-'))\n                line_range = line_start, line_end\n            else:\n                ui_manager.show_error('Invalid line range format')\n                return\n        else:\n            ui_manager.show_error('Missing line range for partial edit')\n            return\n        if element_to_edit not in elements:\n            ui_manager.show_error(f\"Element '{element_to_edit}' not found\")\n            return\n        ui_manager.show_success(\n            f\"AI selected partial edit of '{element_to_edit}' (lines {line_start}-{line_end})\"\n            )\n        original_snippet = editor.get_element_body_snippet(element_to_edit,\n            line_start, line_end)\n        if not original_snippet:\n            original_snippet = editor.get_source_of(element_to_edit)\n        full_element_code = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_partial_edit(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet,\n            line_start, line_end, full_element_code)\n        edit_type = 'PARTIAL'\n    elif ai_response.startswith('ELEMENT:'):\n        element_to_edit = ai_response.split(':', 1)[1].strip()\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    else:\n        element_to_edit = ai_response.splitlines()[0]\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    with ui_manager.show_spinner(f'AI is editing...'):\n        response = query_llm(prompt2)\n    code_blocks = extract_code(response)\n    if not code_blocks:\n        ui_manager.show_error('AI did not return a valid code block.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    new_code = code_blocks[0][1]\n    success = False\n    if edit_type == 'FILE':\n        try:\n            editor.tree = ast.parse(new_code)\n            success = True\n        except SyntaxError as e:\n            ui_manager.show_error(f'AI returned invalid Python syntax: {e}')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    elif edit_type == 'PARTIAL':\n        success = editor.replace_partial(element_to_edit, new_code,\n            line_start=line_range[0], line_end=line_range[1])\n        if not success:\n            ui_manager.show_error('Failed to apply partial edit.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    else:\n        success = editor.replace_element(element_to_edit, new_code)\n        if not success:\n            ui_manager.show_error(\n                'AI returned invalid code; could not be parsed or applied.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    if not (diff := editor.get_diff()):\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(diff, title=\n        f'[bold yellow]Proposed Changes for {resolved_path}[/]'))\n    if ui_manager.get_user_input('Apply changes? (y/n): ').lower() in ['yes',\n        'y']:\n        editor.save_changes()\n        last_code = editor.get_modified_source()\n        ui_manager.show_success(f'Changes saved to {resolved_path}.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_plan(instruction: str, memory_context: str\n    ) ->str:\n    \"\"\"\n    Create a specialized prompt-generation function for the 'refactor' command.\n    This prompt will explicitly define the required JSON structure for the plan\n    and instruct the AI to act as an expert project manager.\n    \"\"\"\n    return f\"\"\"You are an expert project manager and software architect. Analyze the project context and create a detailed refactoring plan.\n\nYour plan must be a valid JSON object with this exact structure:\n{{\n    \"actions\": [\n        {{\n            \"type\": \"MODIFY\" | \"CREATE\" | \"DELETE\" | \"PARTIAL\",\n            \"file\": \"relative/path/to/file.py\",\n            \"element\": \"function_or_class_name\",  // For MODIFY/DELETE/PARTIAL\n            \"element_name\": \"new_element_name\",    // For CREATE\n            \"line_start\": 10,                      // For PARTIAL only\n            \"line_end\": 20,                        // For PARTIAL only\n            \"reason\": \"Clear explanation of why this change is needed\",\n            \"description\": \"What this action will accomplish\",\n            \"anchor_element\": \"optional_anchor\",   // Optional for CREATE\n            \"position\": \"before\" | \"after\"         // Optional for CREATE\n        }}\n    ]\n}}\n\nACTION TYPES:\n- MODIFY: Change an entire function, class, or method\n- PARTIAL: Change specific lines within a function/class (requires line_start and line_end)\n- CREATE: Add new functions, classes, or files\n- DELETE: Remove functions, classes, variables, or imports\n\nRULES FOR YOUR PLAN:\n- Use PARTIAL when you only need to change a small part of a function\n- Use MODIFY when restructuring an entire function or class\n- Each action must have all required fields based on its type\n- File paths must be relative to the project root\n- Be specific and surgical - avoid unnecessary changes\n- Consider dependencies between changes\n- Order actions logically (e.g., create dependencies before using them)\n\n### Project Context ###\n{memory_context}\n\n### Refactoring Request ###\n{instruction}\n\nGenerate ONLY the JSON plan - no explanations or markdown:\"\"\"\n\n\ndef _get_refactor_plan(instruction: str) ->Optional[List[Dict]]:\n    \"\"\"\n    Generates a refactoring plan from the LLM.\n\n    This function encapsulates the logic for checking project context,\n    constructing a prompt, querying the LLM, and parsing the resulting\n    JSON plan for a refactoring task.\n\n    Args:\n        instruction: The user's high-level refactoring instruction.\n\n    Returns:\n        A list of action dictionaries if a valid plan is generated,\n        otherwise None.\n    \"\"\"\n    if not memory_manager.get_project_root():\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return None\n    memory_context = memory_manager.get_memory_context()\n    plan_prompt = _create_prompt_for_refactor_plan(instruction, memory_context)\n    with ui_manager.show_spinner('AI is creating an execution plan...'):\n        plan_str = query_llm(plan_prompt)\n    try:\n        match = re.search('\\\\{.*\\\\}', plan_str, re.DOTALL)\n        if not match:\n            raise ValueError('No JSON object found in the response.')\n        plan = json.loads(match.group(0))\n        actions = plan.get('actions', [])\n        if not actions:\n            raise ValueError(\"No 'actions' key found in plan or plan is empty.\"\n                )\n        return actions\n    except (json.JSONDecodeError, ValueError) as e:\n        ui_manager.show_error(f'AI failed to generate a valid plan: {e}')\n        print(Panel(plan_str, title=\"[yellow]AI's Invalid Plan Response[/]\",\n            border_style='yellow'))\n        return None\n\n\ndef _display_and_confirm_plan(plan: Dict) ->bool:\n    \"\"\"\n    Displays the generated execution plan to the user and asks for confirmation.\n\n    This helper function separates the UI interaction of plan confirmation from\n    the main refactoring logic.\n\n    Args:\n        plan: A dictionary, expected to contain an 'actions' key with a list of action dicts.\n\n    Returns:\n        True if the user confirms the plan, False otherwise.\n    \"\"\"\n    actions = plan.get('actions', [])\n    if not actions:\n        ui_manager.show_error('The generated plan is empty. Aborting.')\n        return False\n    ui_manager.show_success('AI has created a plan:')\n    for i, action in enumerate(actions):\n        action_type = action.get('type', 'N/A')\n        element = action.get('element') or action.get('element_name', 'N/A')\n        reason = action.get('reason') or action.get('description', '')\n        file_path = action.get('file', '')\n        if action_type == 'PARTIAL':\n            line_start = action.get('line_start', '?')\n            line_end = action.get('line_end', '?')\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} (lines {line_start}-{line_end}) - {reason}'\n                )\n        else:\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} - {reason}'\n                )\n    if ui_manager.get_user_input('\\nProceed with this plan? (y/n): ').lower(\n        ) in ['yes', 'y']:\n        return True\n    else:\n        ui_manager.show_error('Execution aborted by user.')\n        return False\n\n\ndef _apply_refactor_changes(editors: Dict[str, CodeEditor]) ->None:\n    \"\"\"\n    Consolidates changes from multiple CodeEditor instances, shows a unified\n    diff, and prompts the user to apply them.\n    \n    This helper function abstracts the final step of a refactor, ensuring\n    all proposed modifications are presented to the user for a final review\n    before any files are written to disk.\n\n    Args:\n        editors: A dictionary mapping absolute file paths to their\n                 corresponding CodeEditor instances which hold the\n                 proposed changes in their AST.\n    \"\"\"\n    full_diff = ''\n    for editor in editors.values():\n        diff = editor.get_diff()\n        if diff:\n            full_diff += diff + '\\n'\n    if not full_diff.strip():\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(full_diff, title=\n        '[bold yellow]Proposed Project-Wide Changes[/]'))\n    if ui_manager.get_user_input('Apply all changes? (y/n): ').lower() in [\n        'yes', 'y']:\n        for editor in editors.values():\n            editor.save_changes()\n        ui_manager.show_success('\u2705 Project changes applied successfully.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_action(action_type: str, file_path: str,\n    action_details: Dict) ->str:\n    \"\"\"\n    Create a helper to generate prompts for individual 'CREATE' or 'MODIFY' steps\n    within a refactor plan. This ensures the AI produces code for the specific\n    sub-task in the correct context.\n    \"\"\"\n    if action_type == 'MODIFY':\n        element_name = action_details['element_name']\n        reason = action_details['reason']\n        original_code = action_details['original_code']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- Element: {element_name}\n- Reason for change: {reason}\n\nRULES:\n- Provide ONLY the complete updated code for the element\n- Include any necessary imports at the top\n- Ensure the code integrates properly with the rest of the file\n- Maintain the same function/class signature unless the change requires otherwise\n- No explanations outside the code block\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the updated element code:\"\"\"\n    elif action_type == 'CREATE':\n        element_name = action_details['element_name']\n        description = action_details['description']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- New element to create: {element_name}\n- Purpose: {description}\n\nRULES:\n- Provide ONLY the complete code for the new element\n- Include all necessary imports at the top\n- Follow the coding style and patterns used in the project\n- Ensure the code is production-ready and well-structured\n- For non-Python files, provide the complete file content\n- No explanations outside the code block\n\nGenerate the new element code:\"\"\"\n\n\ndef _process_refactor_action(action: Dict, project_base_path: str, editors:\n    Dict) ->bool:\n    \"\"\"\n    Processes a single refactoring action from the plan.\n\n    This function handles the execution of a single action from the refactoring plan,\n    including LLM code generation and applying changes to in-memory editors or files.\n\n    Args:\n        action: A dictionary containing action details (type, file, element, etc.)\n        project_base_path: The absolute path to the project root\n        editors: Dictionary mapping file paths to their CodeEditor instances\n\n    Returns:\n        True if the action was processed successfully, False otherwise\n    \"\"\"\n    file_path_relative = action.get('file')\n    if not file_path_relative:\n        ui_manager.show_error(\n            f\"Action is missing 'file' key. Skipping: {action}\")\n        return False\n    file_path_absolute = os.path.join(project_base_path, file_path_relative)\n    action_type = action.get('type', '').upper()\n    prompt, element_name = '', ''\n    if action_type == 'MODIFY':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_source_of(element_name)\n            if not original_snippet:\n                ui_manager.show_error(\n                    f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                    )\n                return False\n            action_details = {'element_name': element_name, 'reason':\n                reason, 'original_code': original_snippet}\n            prompt = _create_prompt_for_refactor_action('MODIFY',\n                file_path_relative, action_details)\n    elif action_type == 'PARTIAL':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        line_start = action.get('line_start')\n        line_end = action.get('line_end')\n        if not all([element_name, line_start, line_end]):\n            ui_manager.show_error(\n                f'PARTIAL action missing required fields. Skipping: {action}')\n            return False\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_element_body_snippet(element_name,\n                line_start, line_end)\n            if not original_snippet:\n                original_snippet = editor.get_source_of(element_name)\n                if not original_snippet:\n                    ui_manager.show_error(\n                        f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                        )\n                    return False\n            full_element_code = editor.get_source_of(element_name)\n            prompt = _create_prompt_for_partial_edit(file_path_relative,\n                element_name, reason, original_snippet, line_start,\n                line_end, full_element_code)\n    elif action_type == 'CREATE':\n        element_name = action.get('element_name')\n        description = action.get('description')\n        action_details = {'element_name': element_name, 'description':\n            description}\n        prompt = _create_prompt_for_refactor_action('CREATE',\n            file_path_relative, action_details)\n    else:\n        ui_manager.show_error(f\"Invalid action type '{action_type}'. Skipping.\"\n            )\n        return False\n    with ui_manager.show_spinner(\n        f\"AI: {action_type} on '{element_name or file_path_relative}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    new_content = code_blocks[0][1] if code_blocks else response.strip()\n    if not new_content:\n        ui_manager.show_error(\n            f'AI failed to generate content for action: {action}')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return False\n    if not file_path_relative.endswith('.py'):\n        try:\n            FileCreator.create(file_path_absolute, new_content)\n            ui_manager.show_success(\n                f\"File '{file_path_relative}' created/updated.\")\n            return True\n        except IOError as e:\n            ui_manager.show_error(\n                f\"Failed to create file '{file_path_relative}': {e}\")\n            return False\n    if file_path_absolute not in editors:\n        try:\n            if not os.path.exists(file_path_absolute):\n                os.makedirs(os.path.dirname(file_path_absolute), exist_ok=True)\n                with open(file_path_absolute, 'w') as f:\n                    f.write('')\n            editors[file_path_absolute] = CodeEditor(file_path_absolute)\n        except Exception as e:\n            ui_manager.show_error(\n                f'Error loading file {file_path_absolute}: {e}')\n            return False\n    editor = editors[file_path_absolute]\n    if action_type == 'MODIFY':\n        if not editor.replace_element(element_name, new_content):\n            ui_manager.show_error(\n                f\"Failed to apply MODIFY change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic MODIFY Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'PARTIAL':\n        if not editor.replace_partial(element_name, new_content, line_start,\n            line_end):\n            ui_manager.show_error(\n                f\"Failed to apply PARTIAL change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic PARTIAL Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'CREATE':\n        anchor = action.get('anchor_element')\n        position = action.get('position', 'after')\n        if not editor.add_element(new_content, anchor_name=anchor, before=\n            position == 'before'):\n            ui_manager.show_error(\n                f\"Failed to apply CREATE change for '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic CREATE Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    return True\n\n\ndef handle_project_refactor_command(instruction: str):\n    \"\"\"\n    Orchestrates a multi-file, multi-step code refactoring process.\n    \n    This function serves as a high-level orchestrator that delegates specific tasks\n    to helper functions, improving readability, modularity, and maintainability.\n    \"\"\"\n    _load_all_project_files_if_needed()\n    actions = _get_refactor_plan(instruction)\n    if not actions:\n        return\n    plan = {'actions': actions}\n    if not _display_and_confirm_plan(plan):\n        return\n    editors: Dict[str, CodeEditor] = {}\n    project_base_path = memory_manager.get_project_root()\n    successful_actions = 0\n    total_actions = len(actions)\n    for i, action in enumerate(actions, 1):\n        ui_manager.show_success(f'Processing action {i}/{total_actions}...')\n        action_type = action.get('type', '').upper()\n        file_path_relative = action.get('file')\n        if not file_path_relative:\n            ui_manager.show_error(\n                f\"Action is missing 'file' key. Skipping: {action}\")\n            continue\n        file_path_absolute = os.path.join(project_base_path, file_path_relative\n            )\n        if action_type == 'DELETE':\n            element_name = action.get('element')\n            if not element_name:\n                ui_manager.show_error(\n                    f\"DELETE action missing 'element' key. Skipping: {action}\")\n                continue\n            if not file_path_relative.endswith('.py'):\n                ui_manager.show_error(\n                    f'DELETE actions are only supported for Python files. Skipping.'\n                    )\n                continue\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    continue\n            editor = editors[file_path_absolute]\n            if editor.delete_element(element_name):\n                successful_actions += 1\n                ui_manager.show_success(\n                    f\"Successfully deleted '{element_name}' from '{file_path_relative}'.\"\n                    )\n            else:\n                ui_manager.show_error(\n                    f\"Failed to delete '{element_name}' from '{file_path_relative}'.\"\n                    )\n        elif _process_refactor_action(action, project_base_path, editors):\n            successful_actions += 1\n        else:\n            ui_manager.show_error(\n                f'Action {i} failed, continuing with remaining actions...')\n    if successful_actions == 0:\n        ui_manager.show_error('No actions were successfully executed.')\n        return\n    elif successful_actions < total_actions:\n        ui_manager.show_error(\n            f'Only {successful_actions}/{total_actions} actions completed successfully.'\n            )\n    else:\n        ui_manager.show_success(\n            f'All {total_actions} actions completed successfully.')\n    _apply_refactor_changes(editors)\n\n\ndef _create_prompt_for_commit_message(diff: str) ->str:\n    \"\"\"\n    Create a dedicated prompt function for the 'commit' command. This prompt will\n    instruct the AI to analyze a git diff and generate a concise commit message\n    following the Conventional Commits standard.\n    \"\"\"\n    return f\"\"\"You are an expert developer writing a Git commit message. Your task is to analyze the provided git diff and create a professional commit message.\n\nCOMMIT MESSAGE RULES:\n- Follow the Conventional Commits specification\n- Format: <type>(<optional scope>): <subject>\n- Types: feat, fix, docs, style, refactor, perf, test, build, ci, chore, revert\n- Subject line: max 50 characters, imperative mood, no period\n- Optional body: explain what and why (not how), wrap at 72 characters\n- Be specific and concise\n- Focus on the intent and impact of the changes\n\nEXAMPLES OF GOOD COMMIT MESSAGES:\n- feat(auth): add OAuth2 integration for Google login\n- fix(api): handle null response in user endpoint\n- refactor(database): optimize query performance for large datasets\n- docs(readme): update installation instructions for Windows\n\nRespond with ONLY the commit message - no markdown, quotes, or explanations.\n\n--- GIT DIFF TO ANALYZE ---\n{diff}\n\nGenerate the commit message:\"\"\"\n\n\ndef handle_commit_command():\n    \"\"\"\n    Orchestrates an AI-assisted Git commit workflow with improved error handling.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return\n    try:\n        git_manager = GitManager(project_root)\n    except ValueError as e:\n        ui_manager.show_error(str(e))\n        return\n    changed_files = git_manager.get_changed_files()\n    if not changed_files:\n        ui_manager.show_success(\n            'No changes to commit. Everything is up to date.')\n        return\n    staged_diff = git_manager.get_diff(staged=True)\n    unstaged_diff = git_manager.get_diff()\n    full_diff = f'{staged_diff}\\n{unstaged_diff}'.strip()\n    if not full_diff.strip():\n        ui_manager.show_success(\n            'No content changes detected (e.g., only file mode changes).')\n        return\n    prompt = _create_prompt_for_commit_message(full_diff)\n    commit_message = query_llm(prompt).strip()\n    if not commit_message:\n        ui_manager.show_error(\n            'AI failed to generate a commit message. Aborting.')\n        return\n    files_to_commit_str = '\\n'.join(f'- {f}' for f in changed_files)\n    plan_panel_content = f\"\"\"[bold]Files to be staged:[/]\n[yellow]{files_to_commit_str}[/]\n\n[bold]AI-Generated Commit Message:[/]\n[green]{commit_message}[/]\"\"\"\n    print(Panel(plan_panel_content, title='[bold cyan]Commit Plan[/]',\n        border_style='cyan'))\n    if ui_manager.get_user_input('\\nProceed with commit? (y/n): ').lower() in [\n        'yes', 'y']:\n        try:\n            git_manager.add(changed_files)\n            ui_manager.show_success('\u2705 Files staged.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Staging failed: {e.stderr}')\n            return\n        try:\n            git_manager.commit(commit_message)\n            ui_manager.show_success('\u2705 Commit successful.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Commit failed: {e.stderr}')\n            return\n        if ui_manager.get_user_input('Push changes to remote? (y/n): ').lower(\n            ) in ['yes', 'y']:\n            try:\n                git_manager.push()\n                ui_manager.show_success('\u2705 Push successful.')\n            except subprocess.CalledProcessError as e:\n                ui_manager.show_error(f'Push failed: {e.stderr}')\n        else:\n            ui_manager.show_error('Push cancelled.')\n    else:\n        ui_manager.show_error('Commit aborted by user.')\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef interactive_mode() ->None:\n    global last_query, last_response, last_code\n    try:\n        from Testing.overlay_engine import show_sequential_popup\n        gui_available = True\n    except ImportError:\n        gui_available = False\n    print(Panel(\n        \"\"\"[bold cyan]Omni Interactive Mode[/]\n[dim]Type 'help' for commands, 'exit' to quit.[/dim]\"\"\"\n        , border_style='cyan'))\n    personality_name = personality_manager.get_current_personality().get('name'\n        , 'Default')\n    gui_enabled = False\n    if gui_available:\n        try:\n            with open(CONFIG_FILE, 'r') as f:\n                config = json.load(f)\n                if config.get('gui_enabled', False):\n                    gui_enabled = True\n        except (FileNotFoundError, json.JSONDecodeError):\n            pass\n    refresh_status_panel(personality_name)\n    while True:\n        try:\n            user_input = ui_manager.get_user_input('\\n> ')\n            if not user_input:\n                continue\n            command, *args = user_input.split(maxsplit=1)\n            arg_str = args[0] if args else ''\n            if command == 'exit':\n                memory_manager.save_memory()\n                print('[bold cyan]Goodbye![/]')\n                break\n            elif command == 'help':\n                print(\n                    \"\"\"[bold]Commands:[/]\n\n  [bold cyan]Core & Project Commands[/]\n  [yellow]send <prompt>[/]        - Ask the LLM a question.\n  [yellow]look <path>[/]          - Read file or scan directory into memory.\n  [yellow]look_all[/]            - Recursively scan the project directory into memory.\n  [yellow]create <file> \"instr\"[/] - Create a new file using AI.\n  [yellow]edit <file> \"instr\"[/]   - Edit a specific file using AI.\n  [yellow]refactor \"instr\"[/]      - Refactor project in memory based on instruction.\n  [yellow]commit[/]               - Commit changes with an AI-generated message.\n  [yellow]rag <query>[/]         - Query the RAG system for context retrieval.\n\n  [bold cyan]File & Code Management[/]\n  [yellow]save <filename>[/]     - Save last AI response to a file.\n  [yellow]list[/]               - List saved files.\n  [yellow]run[/]                 - Run the last generated Python code.\n\n  [bold cyan]Session & Config[/]\n  [yellow]history[/]             - Show the full chat history.\n  [yellow]memory clear[/]        - Clear the chat and file memory.\n  [yellow]backend <name>[/]      - Switch AI backend (e.g., openrouter, ollama).\n  [yellow]models [src][/]        - Interactively list and select models.\n  [yellow]set model <id>[/]      - Set the model directly by its ID.\n  [yellow]personality <cmd>[/]   - Manage AI personalities ('list', 'set', 'add').\n\"\"\"\n                    )\n            elif command == 'send':\n                last_query = arg_str\n                response = query_llm(arg_str)\n                last_response = response\n                memory_manager.add_chat_message('user', last_query)\n                memory_manager.add_chat_message('assistant', last_response)\n                if gui_enabled:\n                    threading.Thread(target=show_sequential_popup, args=(\n                        100, 100, response, f'Omni - {personality_name}'),\n                        daemon=True).start()\n                print(Panel(response, title='[cyan]Response[/]'))\n                if (code_blocks := extract_code(response)):\n                    last_code = code_blocks[0][1]\n            elif command == 'look':\n                look_command(arg_str)\n            elif command == 'look_all':\n                look_all_command()\n            elif command == 'create':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_create_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: create <file_path> \"<instruction>\"')\n            elif command == 'edit':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_edit_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: edit <file_path> \"<instruction>\"')\n            elif command == 'refactor':\n                if not arg_str:\n                    ui_manager.show_error('Usage: refactor \"<instruction>\"')\n                else:\n                    handle_project_refactor_command(arg_str.strip('\"'))\n            elif command == 'commit':\n                handle_commit_command()\n            elif command == 'models':\n                list_models(arg_str.split())\n            elif command == 'set' and arg_str.startswith('model '):\n                set_model(arg_str[6:])\n            elif command == 'backend':\n                switch_backend(arg_str)\n            elif command == 'history':\n                ui_manager.display_history(memory_manager.get_memory_context())\n            elif command == 'memory' and arg_str == 'clear':\n                memory_manager.clear_memory()\n                ui_manager.show_success('\u2705 Memory cleared')\n            elif command == 'personality':\n                p_args = arg_str.split(maxsplit=1)\n                cmd = p_args[0] if p_args else ''\n                p_arg_str = p_args[1] if len(p_args) > 1 else ''\n                if cmd == 'list':\n                    for p in personality_manager.list_personalities():\n                        print(f\"- {p['name']}: {p['description']}\")\n                elif cmd == 'set' and p_arg_str:\n                    if personality_manager.set_current_personality(p_arg_str):\n                        personality_name = p_arg_str\n                        ui_manager.show_success(\n                            f'Set personality to {personality_name}')\n                    else:\n                        ui_manager.show_error('Personality not found.')\n                else:\n                    ui_manager.show_error(\n                        \"Invalid personality command. Use 'list' or 'set <name>'.\"\n                        )\n            elif command == 'run':\n                run_python_code()\n            elif command == 'save':\n                if last_response:\n                    save_code(last_response, arg_str or\n                        f\"omni_save_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n                        )\n                else:\n                    ui_manager.show_error('No response to save.')\n            elif command == 'list':\n                files = sorted(os.listdir(DEFAULT_SAVE_DIR))\n                print('\\n'.join(f'  - {f}' for f in files) if files else\n                    '[yellow]No saved files.[/]')\n            elif command == 'rag':\n                if not arg_str:\n                    ui_manager.show_error('Usage: rag \"<query>\"')\n                else:\n                    from rag_manager import RAGManager\n                    project_root = memory_manager.get_project_root()\n                    if not project_root:\n                        ui_manager.show_error(\n                            \"No project context in memory. Use 'look <directory>' first.\"\n                            )\n                        continue\n                    rag = RAGManager()\n                    if rag.get_document_count() == 0:\n                        ui_manager.show_error(\n                            'RAG index is empty. Please add documents first.')\n                        continue\n                    results = rag.search(arg_str, k=3)\n                    if not results:\n                        ui_manager.show_error('No relevant documents found.')\n                        continue\n                    print(Panel('[bold]RAG Results:[/]', title=\n                        '[cyan]Retrieval-Augmented Generation[/]'))\n                    for i, (content, score, metadata) in enumerate(results, 1):\n                        file_path = metadata.get('file', 'Unknown')\n                        print(\n                            f'[bold cyan]{i}. {file_path}[/] (Score: {score:.4f})'\n                            )\n                        print(Panel(content[:500] + '...' if len(content) >\n                            500 else content, border_style='dim'))\n                    follow_up = ui_manager.get_user_input(\n                        \"\"\"\nWould you like to ask a follow-up question with this context? (y/n): \"\"\"\n                        )\n                    if follow_up.lower() in ['y', 'yes']:\n                        follow_up_query = ui_manager.get_user_input(\n                            'Follow-up query: ')\n                        if follow_up_query:\n                            context_parts = [\n                                f'Document {i} (Score: {score:.4f}):\\n{content}'\n                                 for i, (content, score, _) in enumerate(\n                                results, 1)]\n                            context = '\\n\\n'.join(context_parts)\n                            rag_prompt = f\"\"\"Based on the following context, please answer the question.\n\nContext:\n{context}\n\nQuestion: {follow_up_query}\"\"\"\n                            response = query_llm(rag_prompt)\n                            print(Panel(response, title=\n                                '[cyan]RAG-Augmented Response[/]'))\n            else:\n                ui_manager.show_error(\"Unknown command. Type 'help'.\")\n            refresh_status_panel(personality_name)\n        except KeyboardInterrupt:\n            memory_manager.save_memory()\n            print('\\n[bold cyan]Goodbye![/]')\n            break\n        except Exception as e:\n            ui_manager.show_error(f'An unexpected error occurred: {e}')\n\n\ndef run_python_code() ->None:\n    global last_code\n    if not last_code:\n        ui_manager.show_error('No Python code in memory to run.')\n        return\n    temp_file = os.path.join(DEFAULT_SAVE_DIR, 'temp_run.py')\n    try:\n        with open(temp_file, 'w') as f:\n            f.write(last_code)\n        print('[bold cyan]\\n--- Running Code ---\\n[/]')\n        subprocess.run([sys.executable, temp_file], check=True)\n        print('[bold cyan]\\n--- Code Finished ---\\n[/]')\n    except Exception as e:\n        ui_manager.show_error(f'Error running code: {e}')\n    finally:\n        if os.path.exists(temp_file):\n            os.remove(temp_file)\n\n\ndef save_code(content: str, filename: str) ->None:\n    filepath = os.path.join(DEFAULT_SAVE_DIR, filename)\n    try:\n        with open(filepath, 'w') as f:\n            f.write(content)\n        ui_manager.show_success(f'Saved to: {filepath}')\n    except IOError as e:\n        ui_manager.show_error(f'Error saving file: {e}')\n\n\ndef main() ->None:\n    try:\n        import astor\n    except ImportError:\n        print(\"[bold red]Error:[/] 'astor' is required. `pip install astor`\")\n        sys.exit(1)\n    try:\n        import simple_term_menu\n    except ImportError:\n        print(\n            \"[bold red]Error:[/] 'simple-term-menu' is required. `pip install simple-term-menu`\"\n            )\n        sys.exit(1)\n    parser = argparse.ArgumentParser(description=\n        'Omni - AI-powered code tool', add_help=False)\n    parser.add_argument('command', nargs='?', help='Main command.')\n    parser.add_argument('args', nargs='*', help='Arguments for the command.')\n    parser.add_argument('-h', '--help', action='store_true')\n    args, _ = parser.parse_known_args()\n    if args.help or not args.command:\n        interactive_mode()\n    elif args.command == 'look' and args.args:\n        look_command(args.args[0])\n    elif args.command == 'edit' and len(args.args) >= 2:\n        handle_file_edit_command(args.args[0], ' '.join(args.args[1:]))\n    elif args.command == 'models':\n        list_models(args.args)\n    else:\n        interactive_mode()\n\n\ndef refresh_status_panel(personality_name: str) ->None:\n    ui_manager.display_status_panel(personality_name, current_backend,\n        current_model, len(memory_manager.memory.get('chat', [])), len(\n        memory_manager.memory.get('look', [])))\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/omni.py"
  },
  {
    "id": 52,
    "hash": "db1585da7840e9dc17f3ab8c0a19f6f2",
    "content": "import json\nfrom typing import Dict, List, Optional\n\nclass PersonalityManager:\n    \"\"\"Manages AI personalities via JSON config.\"\"\"\n\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.personalities: List[Dict[str, str]] = self.load_personalities()\n        self.current_personality: Optional[str] = \"default\"  # Default\n\n    def load_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"Load personalities from JSON; auto-create if missing.\"\"\"\n        default = [{\"name\": \"default\", \"description\": \"Helpful assistant\", \"system_prompt\": \"You are a helpful AI assistant.\"}]\n        default_gui = {\n            \"gui_enabled\": True,\n            \"wake_word\": \"Jarvis\",\n            \"overlay_opacity\": 0.8,\n            \"font_size\": 16\n        }\n        try:\n            with open(self.config_file, 'r') as f:\n                data = json.load(f)\n                if \"personalities\" not in data:\n                    data[\"personalities\"] = default\n                if \"gui_enabled\" not in data:\n                    data.update(default_gui)\n                    self.save_personalities(data[\"personalities\"])  # Save with defaults\n                \n                return data[\"personalities\"]\n        except FileNotFoundError:\n            self.save_personalities(default)\n            return default\n        except json.JSONDecodeError:\n            print(\"[yellow]Invalid config. Resetting to default.[/]\")\n            self.save_personalities(default)\n            return default\n\n    def save_personalities(self, personalities: List[Dict[str, str]]) -> None:\n        \"\"\"Save with GUI config.\"\"\"\n        data = {\"personalities\": personalities}\n        data.update({\"gui_enabled\": True, \"wake_word\": \"Jarvis\", \"overlay_opacity\": 0.8, \"font_size\": 16})  # Defaults\n        with open(self.config_file, 'w') as f:\n            json.dump(data, f, indent=4)\n\n    def add_personality(self, name: str, description: str, system_prompt: str) -> None:\n        \"\"\"Add a new personality.\"\"\"\n        self.personalities.append({\"name\": name, \"description\": description, \"system_prompt\": system_prompt})\n        self.save_personalities(self.personalities)\n\n    def list_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"List all personalities.\"\"\"\n        return self.personalities\n\n    def set_current_personality(self, name: str) -> bool:\n        \"\"\"Set the current personality.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == name:\n                self.current_personality = name\n                return True\n        return False\n\n    def get_current_personality(self) -> Dict[str, str]:\n        \"\"\"Get the current personality dict.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == self.current_personality:\n                return p\n        return {}  # Fallback",
    "file": "/mnt/ProjectData/omni/personality_manager.py"
  },
  {
    "id": 53,
    "hash": "da963f141c557fe12f1a26374f3e5ff4",
    "content": "# python_ast_adapter.py\n\n\"\"\"\nPythonASTAdapter - Concrete AST adapter for Python using built-in `ast` and `astor`.\n\nThis module implements the ASTAdapter interface specifically for Python,\nleveraging the standard library's `ast` module for parsing and\nmanipulation, and `astor` for code generation.\n\"\"\"\n\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for asttokens (for enhanced partial edits)\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n    # print(\"Warning: asttokens not installed. Partial edits will be limited.\")\n\n\nclass PythonASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for Python source code.\n\n    This adapter uses Python's built-in `ast` module to parse and manipulate\n    the code, and `astor` for code generation and source-to-source transformations.\n    It holds the parsed AST tree and provides methods to interact with it\n    according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the PythonASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The Python source code as a string.\n        \"\"\"\n        # Store source code for diffing and potential asttokens use\n        self.source_code: str = source_code\n        # Will hold the parsed AST tree\n        self.tree: Optional[ast.AST] = None\n        # Will hold a mapping of element names to their AST nodes\n        self.nodes: Dict[str, ast.AST] = {}\n        # asttokens instance for enhanced source mapping (if available)\n        self.atok: Optional[asttokens.ASTTokens] = None\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the Python source code and maps elements.\n\n        Args:\n            source_code: The Python source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid Python syntax.\n        \"\"\"\n        try:\n            self.tree = ast.parse(source_code)\n        except SyntaxError as e:\n            raise ValueError(f\"Invalid Python syntax: {e}\") from e\n\n        self.nodes = self._map_nodes()\n        if ASTTOKENS_AVAILABLE:\n            try:\n                self.atok = asttokens.ASTTokens(source_code, parse=True)\n            except Exception:\n                # If asttokens fails for any reason, continue without it\n                self.atok = None\n        else:\n            self.atok = None\n\n    def _map_nodes(self) -> Dict[str, ast.AST]:\n        \"\"\"\n        Walks the AST and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their AST nodes.\n        \"\"\"\n        nodes: Dict[str, ast.AST] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        for node in ast.walk(self.tree):\n            # Map functions and classes by name\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                # Use 'not in' to prioritize top-level definitions in case of conflicts\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            # Map assignments by target variable name(s)\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            # Map imports by their alias or original name\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int, line_end: Optional[int] = None) -> Optional[Tuple[int, ast.AST]]:\n        \"\"\"\n        Finds a statement within a body based on line numbers.\n\n        Args:\n            body: The list of AST nodes representing the body.\n            line_start: The starting line number to search for.\n            line_end: The optional ending line number.\n\n        Returns:\n            A tuple of (index, statement node) if found, otherwise None.\n        \"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = getattr(stmt, 'end_lineno', stmt.lineno)\n                    # Check for overlap or containment\n                    if (stmt.lineno <= line_start <= stmt_end) or (stmt.lineno <= line_end <= stmt_end) or \\\n                       (line_start <= stmt.lineno and line_end >= stmt_end):\n                        return (i, stmt)\n                else:\n                    if stmt.lineno == line_start:\n                        return (i, stmt)\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.ImportFrom]]) -> None:\n        \"\"\"\n        Adds new import nodes to the file's AST, typically at the top.\n\n        Args:\n            new_import_nodes: A list of ast.Import or ast.ImportFrom nodes.\n        \"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return # Cannot add imports without a valid module tree\n\n        # Get string representations of existing imports to avoid duplicates\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                try:\n                    existing_imports_str.add(astor.to_source(node).strip())\n                except Exception:\n                    # If astor fails, skip adding to set (might lead to potential duplicate, but safer)\n                    pass\n                last_import_index = i\n\n        # Insert new imports after the last existing import\n        # Reverse them so they are inserted in the correct order\n        for new_import in reversed(new_import_nodes):\n            try:\n                new_import_str = astor.to_source(new_import).strip()\n                if new_import_str not in existing_imports_str:\n                    self.tree.body.insert(last_import_index + 1, new_import)\n                    last_import_index += 1 # Update index for next insertion\n            except Exception:\n                # If we can't generate source, we can't check for duplicates, skip\n                self.tree.body.insert(last_import_index + 1, new_import)\n                last_import_index += 1\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return astor.to_source(node)\n            except Exception:\n                # Handle potential astor issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.__class__.__name__,\n            'line_start': getattr(node, 'lineno', None),\n            'line_end': getattr(node, 'end_lineno', None),\n            'body_items': []\n        }\n\n        if hasattr(node, 'body'):\n            for i, item in enumerate(node.body):\n                item_info = {\n                    'index': i,\n                    'type': item.__class__.__name__,\n                    'line_start': getattr(item, 'lineno', None),\n                    'line_end': getattr(item, 'end_lineno', None)\n                }\n\n                if isinstance(item, ast.Assign) and item.targets:\n                    target = item.targets[0]\n                    if isinstance(target, ast.Name):\n                        item_info['assigns'] = target.id\n                elif isinstance(item, (ast.If, ast.While, ast.For)):\n                    item_info['has_body'] = bool(getattr(item, 'body', None))\n                elif isinstance(item, ast.Return):\n                    item_info['returns'] = True\n\n                structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        if not self.atok:\n            return None # asttokens is required for precise original source retrieval\n\n        node = self.nodes.get(element_name)\n        if not node or not hasattr(node, 'body'):\n            return None\n\n        statements = []\n        for stmt in node.body:\n            if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                 # Check for overlap or containment of the statement within the requested range\n                stmt_start = stmt.lineno\n                stmt_end = stmt.end_lineno\n                if (stmt_start >= line_start and stmt_end <= line_end) or \\\n                   (stmt_start <= line_end and stmt_end >= line_start): # Overlap\n                    statements.append(stmt)\n\n        if not statements:\n            return None\n\n        # Use asttokens to get the original source text for accuracy\n        try:\n            # Combine text ranges of the found statements\n            combined_text = \"\"\n            last_end_pos = None\n            for stmt in sorted(statements, key=lambda s: s.lineno):\n                # Get the text range for the statement\n                stmt_text = self.atok.get_text_range(stmt)\n                if last_end_pos is not None and stmt_text[0] > last_end_pos:\n                     # Add the original whitespace/newlines between statements\n                    combined_text += self.source_code[last_end_pos:stmt_text[0]]\n                combined_text += self.atok.get_text(stmt)\n                last_end_pos = stmt_text[1]\n            return combined_text.strip()\n        except Exception:\n            # Fallback if asttokens text retrieval fails\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in statements)\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except SyntaxError:\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body: # Ensure there's actual code body to replace with\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # Walk the tree to find the parent node containing the element to replace\n        for parent_node in ast.walk(self.tree):\n            if hasattr(parent_node, 'body') and isinstance(parent_node.body, list):\n                try:\n                    old_node = self.nodes[element_name]\n                    idx = parent_node.body.index(old_node)\n                    # Remove the old node\n                    parent_node.body.pop(idx)\n                    # Insert the new nodes\n                    for i, new_node in enumerate(new_code_body):\n                        parent_node.body.insert(idx + i, new_node)\n\n                    # Update the nodes map: remove old, add new top-level definitions\n                    del self.nodes[element_name]\n                    for n in new_code_body:\n                        if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                            self.nodes[n.name] = n\n                    return True\n                except (ValueError, KeyError):\n                    # ValueError from index(), KeyError from accessing self.nodes\n                    continue\n        return False # Element not found in any body\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n             return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except (SyntaxError, IndexError):\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body:\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # --- Determine insertion index ---\n\n        # Find the `if __name__ == \"__main__\":` block index\n        main_block_idx = -1\n        for i, node in enumerate(self.tree.body):\n            if (isinstance(node, ast.If) and\n                isinstance(getattr(node, 'test', None), ast.Compare) and\n                isinstance(getattr(node.test, 'left', None), ast.Name) and\n                node.test.left.id == '__name__' and\n                len(getattr(node.test, 'ops', [])) == 1 and isinstance(node.test.ops[0], ast.Eq) and\n                len(getattr(node.test, 'comparators', [])) == 1):\n\n                comp = node.test.comparators[0]\n                # Check for both ast.Constant ('__main__') and older ast.Str ('__main__')\n                if ((isinstance(comp, ast.Constant) and comp.value == '__main__') or\n                    (isinstance(comp, ast.Str) and comp.s == '__main__')): # type: ignore\n                    main_block_idx = i\n                    break\n\n        insertion_index = -1\n        if anchor_name:\n            # If anchor is specified, find its index\n            if anchor_name not in self.nodes:\n                return False\n            anchor_node = self.nodes[anchor_name]\n            try:\n                anchor_idx = self.tree.body.index(anchor_node)\n                proposed_index = anchor_idx if before else anchor_idx + 1\n                # Prefer to stay before the main block if possible\n                if main_block_idx != -1:\n                    insertion_index = min(proposed_index, main_block_idx)\n                else:\n                    insertion_index = proposed_index\n            except ValueError:\n                return False # Anchor node not found in tree body\n        elif main_block_idx != -1:\n            # If no anchor, but there's a main block, insert before it\n            insertion_index = main_block_idx\n        # If no anchor and no main block, insertion_index remains -1\n\n        # --- Perform the insertion ---\n        if insertion_index == -1:\n            # Append to the end\n            self.tree.body.extend(new_code_body)\n        else:\n            # Insert at the calculated position\n            for i, new_node in enumerate(new_code_body):\n                self.tree.body.insert(insertion_index + i, new_node)\n\n        # Update the nodes map with any new top-level definitions\n        for node in new_code_body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                self.nodes[node.name] = node # This might overwrite if names clash\n\n        return True\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return False\n\n        deleted = False\n        if element_name in self.nodes:\n            node_to_delete = self.nodes[element_name]\n            # Walk the tree to find the parent node containing the element\n            for node in ast.walk(self.tree):\n                if hasattr(node, 'body') and isinstance(node.body, list):\n                    try:\n                        node.body.remove(node_to_delete)\n                        deleted = True\n                        break # Assume element appears only once at top level\n                    except ValueError:\n                        continue # This parent doesn't contain the node\n            if deleted:\n                del self.nodes[element_name]\n                # Although nodes map is passed by ref in base __init__, we should call _map_nodes\n                # to ensure consistency after a direct tree modification.\n                self.nodes = self._map_nodes()\n                return True\n\n        # If not found by node reference, try to find by name pattern matching (vars/imports)\n        new_body = []\n        for node in self.tree.body:\n            if isinstance(node, ast.Assign):\n                match = False\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id == element_name:\n                        match = True\n                        deleted = True\n                        break\n                if not match: # Keep the node if it doesn't match\n                    new_body.append(node)\n            elif isinstance(node, ast.Import):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                    # Keep the node if none of its aliases match (should theoretically be the same as above)\n                     new_body.append(node)\n                else:\n                    deleted = True # The import node is being completely removed\n            elif isinstance(node, ast.ImportFrom):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                     new_body.append(node)\n                else:\n                    deleted = True\n            else:\n                new_body.append(node)\n\n        if deleted:\n            self.tree.body = new_body\n            # Remap nodes after structural changes\n            self.nodes = self._map_nodes()\n\n        return deleted\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        if element_name not in self.nodes:\n            return False\n\n        node = self.nodes[element_name]\n        # Ensure the node has a body to modify\n        if not hasattr(node, 'body') or not isinstance(node.body, list):\n            return False\n\n        # Parse the new code to get AST nodes for the replacement\n        try:\n             # Heuristic: If new code looks like a def/class, extract its body.\n             # Otherwise, treat as standalone statements.\n            if new_code.strip().startswith(('def ', 'class ', 'async def ')):\n                # Parse as if it's a module with a single function/class\n                temp_module = ast.parse(new_code)\n                if temp_module.body and hasattr(temp_module.body[0], 'body'):\n                    new_statements = temp_module.body[0].body # Get the inner body\n                else:\n                    return False # Malformed attempt to define a func/class\n            else:\n                # Parse as a module and take its body\n                new_ast_module = ast.parse(new_code)\n                new_statements = new_ast_module.body\n        except SyntaxError:\n            return False # Invalid new code\n\n        if not new_statements: # Nothing to insert\n            return False\n\n        # --- Determine what to replace based on parameters ---\n        if statement_index is not None:\n            # Replace by statement index\n            if 0 <= statement_index < len(node.body):\n                # Replace the single statement at index with the list of new statements\n                node.body[statement_index:statement_index+1] = new_statements\n                return True\n        elif line_start is not None:\n            # Replace by line number(s)\n            result = self._find_statement_in_body(node.body, line_start, line_end)\n            if result:\n                idx, _ = result\n                if line_end:\n                    # Find the last statement within the specified range to replace multiple\n                    end_idx = idx\n                    # Iterate from the found index forward\n                    for i in range(idx, len(node.body)):\n                        stmt = node.body[i]\n                        stmt_s_ln = getattr(stmt, 'lineno', None)\n                        stmt_e_ln = getattr(stmt, 'end_lineno', stmt_s_ln)\n                        if stmt_s_ln is not None and stmt_e_ln is not None:\n                            # Check if the statement ends within the range or starts within the range\n                            # This handles overlapping ranges correctly\n                             if stmt_e_ln <= line_end or stmt_s_ln <= line_end:\n                                 end_idx = i\n                             else:\n                                 break # Statement is past the end range\n                        else:\n                            break # Can't determine statement range\n                    node.body[idx:end_idx+1] = new_statements\n                else:\n                    # line_end not specified, only replace the statement at line_start\n                    node.body[idx:idx+1] = new_statements\n                return True\n\n        # If none of the conditions were met to perform a replacement\n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        if self.tree:\n            try:\n                return astor.to_source(self.tree)\n            except Exception as e:\n                 # Fallback error handling, should ideally not happen if tree is valid\n                 return f\"# Error generating source: {e}\\n{self.source_code}\"\n        else:\n            # If somehow the tree is None, return the original source\n            return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        # Ensure line endings are consistent for diffing, keepends=True preserves them\n        # If source_code had different line endings, this might still cause issues,\n        # but this is a standard approach.\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/python_ast_adapter.py"
  },
  {
    "id": 54,
    "hash": "2914352eefed9d60de098e021dd79b67",
    "content": "import os\nimport sys\nimport argparse\nfrom typing import List\nfrom rag_manager import RAGManager\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\ndef create_sample_data() ->List[str]:\n    \"\"\"Create sample documents for the RAG example.\"\"\"\n    return [\n        'RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with language generation.'\n        ,\n        'The RAG model retrieves relevant documents from a knowledge base and uses them to generate more accurate responses.'\n        ,\n        'FAISS is a library for efficient similarity search and clustering of dense vectors, often used in RAG systems.'\n        ,\n        'Sentence transformers are used to create embeddings for documents and queries in RAG systems.'\n        ,\n        'Retrieval-Augmented Generation improves language models by allowing them to access external knowledge sources.'\n        ,\n        'In RAG systems, documents are indexed and searchable by their semantic embeddings rather than just keywords.'\n        ,\n        'Python is a great language for implementing RAG systems due to libraries like sentence-transformers and faiss.'\n        ,\n        'The retrieval component of RAG is crucial for finding relevant information before generation.'\n        ]\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_cli_example.py"
  },
  {
    "id": 55,
    "hash": "c27b11d2eaa8e13cdf8e698417efb75e",
    "content": "import os\nimport sys\nfrom typing import List, Dict, Tuple\n\"\"\"\nExample script demonstrating RAG (Retrieval-Augmented Generation) usage.\n\nThis script shows how to use a simple RAG implementation to answer questions\nbased on a given context or knowledge base.\n\"\"\"\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\nclass SimpleRAG:\n    \"\"\"A simple RAG implementation for demonstration purposes.\"\"\"\n\n    def __init__(self, knowledge_base: List[str]):\n        \"\"\"\n        Initialize the RAG with a knowledge base.\n        \n        Args:\n            knowledge_base: A list of strings representing the knowledge base.\n        \"\"\"\n        self.knowledge_base = knowledge_base\n\n    def retrieve(self, query: str, top_k: int=3) ->List[str]:\n        \"\"\"\n        Retrieve relevant documents from the knowledge base.\n        \n        This is a simplified implementation using keyword matching.\n        In a real implementation, you would use embeddings and vector search.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            A list of relevant documents.\n        \"\"\"\n        query_words = set(query.lower().split())\n        scores = []\n        for doc in self.knowledge_base:\n            doc_words = set(doc.lower().split())\n            score = len(query_words.intersection(doc_words))\n            scores.append((score, doc))\n        scores.sort(reverse=True)\n        return [doc for score, doc in scores[:top_k]]\n\n    def generate(self, query: str, retrieved_docs: List[str]) ->str:\n        \"\"\"\n        Generate an answer based on the query and retrieved documents.\n        \n        In a real implementation, this would use an LLM to generate the response.\n        For this example, we'll create a simple template-based response.\n        \n        Args:\n            query: The query string.\n            retrieved_docs: The retrieved documents.\n            \n        Returns:\n            A generated answer.\n        \"\"\"\n        context = '\\n'.join(retrieved_docs)\n        prompt = f\"\"\"\n        Context information:\n        {context}\n        \n        Question: {query}\n        \n        Based on the context provided above, please answer the question.\n        If the context doesn't contain relevant information, say so.\n        \"\"\"\n        return self._simple_response_generator(query, retrieved_docs)\n\n    def _simple_response_generator(self, query: str, retrieved_docs: List[str]\n        ) ->str:\n        \"\"\"\n        A simple response generator for demonstration.\n        \"\"\"\n        for doc in retrieved_docs:\n            if 'example' in doc.lower():\n                return (\n                    f'Based on the context provided, I found information about examples. {query} relates to the examples in the knowledge base.'\n                    )\n        return (\n            f\"I couldn't find specific information about '{query}' in the provided context. Please provide more details or check the knowledge base.\"\n            )\n\n    def query(self, query: str, top_k: int=3) ->str:\n        \"\"\"\n        Process a query through the full RAG pipeline.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            The generated answer.\n        \"\"\"\n        retrieved_docs = self.retrieve(query, top_k)\n        answer = self.generate(query, retrieved_docs)\n        return answer\n\n\ndef main():\n    \"\"\"Main function demonstrating the RAG implementation.\"\"\"\n    knowledge_base = ['This is an example document about machine learning.',\n        'Natural language processing is a subfield of artificial intelligence.'\n        , 'Python is a popular programming language for data science.',\n        'The quick brown fox jumps over the lazy dog.',\n        'RAG stands for Retrieval-Augmented Generation.',\n        'Vector databases are used for similarity search in RAG systems.',\n        'Transformers are a type of neural network architecture.',\n        'This example shows how to implement a simple RAG system.']\n    rag = SimpleRAG(knowledge_base)\n    queries = ['What is RAG?', 'How is Python used in data science?',\n        'Tell me about machine learning']\n    print('Simple RAG Example')\n    print('=' * 50)\n    for query in queries:\n        print(f'\\nQuery: {query}')\n        answer = rag.query(query)\n        print(f'Answer: {answer}')\n        print('-' * 30)\n    print(\"\\nInteractive Mode (type 'quit' to exit):\")\n    while True:\n        try:\n            user_query = input('\\nEnter your question: ').strip()\n            if user_query.lower() in ['quit', 'exit', 'q']:\n                break\n            if user_query:\n                answer = rag.query(user_query)\n                print(f'Answer: {answer}')\n        except KeyboardInterrupt:\n            print('\\nGoodbye!')\n            break\n        except EOFError:\n            break\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_example.py"
  },
  {
    "id": 56,
    "hash": "f151986bf2efa7602242590a357fab83",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n    Initialize the RAG manager.\n\n    Args:\n        model_name: Name of the sentence transformer model to use\n        index_path: Path to save/load the FAISS index\n    \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the RAG manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n",
    "file": "/mnt/ProjectData/omni/rag_manager.py"
  },
  {
    "id": 57,
    "hash": "f59a27842056dbb0dc95d0f29c1c5de8",
    "content": "Hello! I'm OmniForge, an AI coding assistant. I can help you scan, understand, and refactor your codebase using local (Ollama) or remote (OpenRouter) LLMs.\n\nI see you've opened the OmniForge project directory. Some key things I can help with:\n\n1. **Project Analysis**: I can look at your files to understand the structure\n2. **Code Editing**: I can make precise edits to functions/classes using AST-based transformations\n3. **Refactoring**: I can perform multi-file architectural changes with a plan\n4. **File Creation**: I can generate new files based on instructions\n\nFor example:\n- `look .` to scan the project\n- `edit code_editor.py \"add docstrings to main methods\"`\n- `refactor \"extract git operations into a separate module\"`\n- `create new_module.py \"implement a simple HTTP client\"`\n\nWhat would you like to do with this project?",
    "file": "/mnt/ProjectData/omni/requirements.txt"
  },
  {
    "id": 58,
    "hash": "4b879b8e64b677ec78d27f19b384623a",
    "content": "from typing import List\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.text import Text\nfrom rich.status import Status\nfrom rich import box\nfrom contextlib import contextmanager\nfrom rich.markup import escape\nimport gc\n\ntry:\n    from prompt_toolkit import prompt\n    from prompt_toolkit.completion import WordCompleter\n    from prompt_toolkit.history import InMemoryHistory\n    from prompt_toolkit.styles import Style\nexcept ImportError:\n    print('[yellow]prompt_toolkit not installed. Falling back to basic input.[/]')\n    prompt = input\n\n\nclass UIManager:\n    \"\"\"Manages interactive text-based UI with rich for display and prompt_toolkit for input.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initializes the UI manager with a rich console and prompt_toolkit components.\"\"\"\n        self.console = Console()\n        self.history = InMemoryHistory()\n        self.completer = WordCompleter([\n            'send', 'look', 'look_all', 'create', 'edit', 'refactor', 'commit',\n            'save', 'list', 'run', 'history', 'memory', 'backend', 'models',\n            'set', 'personality', 'help', 'exit'\n        ], ignore_case=True)\n        self.prompt_style = Style.from_dict({'prompt': 'bold cyan'})\n\n    def get_user_input(self, prompt_text: str) -> str:\n        try:\n            return prompt(prompt_text, history=self.history, completer=self.completer, style=self.prompt_style)\n        except Exception:\n            self.console.print('[yellow]Warning: Falling back to basic input.[/]')\n            return input(prompt_text)\n\n    def display_history(self, history_text: str) -> None:\n        if not history_text.strip():\n            self.console.print('[dim]No history yet.[/]')\n            return\n        \n        lines = history_text.split('\\n')\n        colored_text = Text()\n        for line in lines:\n            if line.startswith('User:'):\n                colored_text.append(line + '\\n', style='bold blue')\n            elif line.startswith('AI:'):\n                colored_text.append(line + '\\n', style='bold green')\n            elif line.startswith('File '):\n                colored_text.append(line + '\\n', style='yellow')\n            else:\n                colored_text.append(line + '\\n')\n        \n        self.console.print(Panel(\n            colored_text, \n            title='[bold magenta]Chat History[/]', \n            border_style='magenta', \n            expand=False, \n            box=box.ROUNDED\n        ))\n\n    @contextmanager\n    def show_spinner(self, message: str):\n        \"\"\"\n        Context manager that displays a spinner with the given message.\n        Handles Rich LiveError by cleaning up stuck live displays and \n        ensuring proper cleanup on exceptions.\n        \n        Usage:\n            with ui_manager.show_spinner(\"Loading...\"):\n                # do work here\n        \"\"\"\n        # Initialize spinner state if not exists\n        if not hasattr(self, '_spinner_active'):\n            self._spinner_active = False\n        \n        # If spinner is already active, just yield without additional output\n        if self._spinner_active:\n            try:\n                yield\n            except Exception as e:\n                raise e\n            return\n        \n        # Clean up any stuck Rich live displays before starting\n        self._cleanup_stuck_rich_displays()\n        \n        # Mark spinner as active\n        self._spinner_active = True\n        status_context = None\n        \n        try:\n            # Try to use rich status, but with fallback\n            try:\n                status_context = self.console.status(f'[bold yellow]{message}[/]')\n                status_context.__enter__()\n            except Exception:\n                # If rich.status fails, fallback to static print\n                status_context = None\n                self.console.print(f'[bold yellow]{message}[/]')\n            \n            yield\n            \n        except Exception as e:\n            # Re-raise actual work errors\n            raise e\n            \n        finally:\n            # Always cleanup spinner state and rich display\n            self._spinner_active = False\n            if status_context is not None:\n                try:\n                    status_context.__exit__(None, None, None)\n                except:\n                    pass  # Suppress cleanup errors\n            \n            # Force cleanup any remaining rich displays\n            self._cleanup_stuck_rich_displays()\n\n    def _cleanup_stuck_rich_displays(self):\n        \"\"\"\n        Clean up stuck Rich live displays that prevent new ones from starting.\n        Based on solution from: https://github.com/DLR-RM/stable-baselines3/issues/1645\n        \"\"\"\n        try:\n            # Method 1: Reset console live display if exists\n            if hasattr(self.console, '_live') and self.console._live is not None:\n                try:\n                    self.console._live.stop()\n                    self.console._live = None\n                except:\n                    pass\n            \n            # Method 2: Find and close stuck rich/tqdm objects using garbage collection\n            rich_objects = [obj for obj in gc.get_objects() \n                        if hasattr(obj, '__class__') and \n                        ('live' in type(obj).__name__.lower() or \n                            'progress' in type(obj).__name__.lower() or\n                            'status' in type(obj).__name__.lower()) and\n                        hasattr(obj, 'stop')]\n            \n            for rich_obj in rich_objects:\n                try:\n                    if hasattr(rich_obj, 'stop'):\n                        rich_obj.stop()\n                    elif hasattr(rich_obj, 'close'):\n                        rich_obj.close()\n                except:\n                    pass  # Suppress cleanup errors\n                    \n        except:\n            pass  # Suppress all cleanup errors to avoid breaking the main flow\n\n    def display_status_panel(self, personality: str, backend: str, model: str, msg_count: int, look_count: int) -> None:\n        status_text = (\n            f'[bold]Personality:[/] [green]{personality}[/] | '\n            f'[bold]Backend:[/] [green]{backend}[/] | '\n            f'[bold]Model:[/] [green]{model}[/] | '\n            f'[bold]Memory:[/] {msg_count} messages, {look_count} files'\n        )\n        self.console.print(Panel(\n            status_text, \n            title='[bold cyan]Status[/]', \n            border_style='cyan', \n            expand=False, \n            box=box.MINIMAL\n        ))\n\n    def show_success(self, message: str) -> None:\n        self.console.print(f'[green]\u2705 {message}[/]')\n\n    def show_error(self, message: str) -> None:\n        \"\"\"\n        Displays an error message, escaping any markup in the message.\n        \"\"\"\n        safe_message = escape(str(message))\n        self.console.print(f'[red]\u274c {safe_message}[/]')",
    "file": "/mnt/ProjectData/omni/ui_manager.py"
  },
  {
    "id": 59,
    "hash": "dbd143839288b400cafdedb655258434",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n",
    "file": "/mnt/ProjectData/omni/vectordb_manager.py"
  },
  {
    "id": 60,
    "hash": "47a91d3ac272236378053b23515fc9b0",
    "content": "import tkinter as tk\nfrom tkinter import ttk\nfrom time import strftime\n\n\ndef update_time():\n    current_time = strftime('%H:%M:%S %p\\n%Y-%m-%d')\n    time_label.config(text=current_time)\n    time_label.after(1000, update_time)\n\n\ndef center_window(root):\n    root.update_idletasks()\n    screen_width = root.winfo_screenwidth()\n    screen_height = root.winfo_screenheight()\n    window_width = root.winfo_width() + 4\n    window_height = root.winfo_height() + 4\n    x = (screen_width - window_width) // 2\n    y = (screen_height - window_height) // 2\n    root.geometry(f'{window_width}x{window_height}+{x}+{y}')\n\n\ndef create_3d_border(parent):\n    border_frame = tk.Frame(parent, bg='#c0c0c0')\n    border_frame.pack(padx=2, pady=2, expand=True, fill=tk.BOTH)\n    tk.Frame(border_frame, height=1, bg='#808080').pack(side=tk.TOP, fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#808080').pack(side=tk.LEFT, fill=tk.Y)\n    tk.Frame(border_frame, height=1, bg='#ffffff').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#ffffff').pack(side=tk.RIGHT, fill=tk.Y\n        )\n    inner_container = tk.Frame(border_frame, bg='#c0c0c0')\n    inner_container.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1\n        )\n    tk.Frame(inner_container, height=1, bg='#ffffff').pack(side=tk.TOP,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#ffffff').pack(side=tk.LEFT,\n        fill=tk.Y)\n    tk.Frame(inner_container, height=1, bg='#808080').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#808080').pack(side=tk.RIGHT,\n        fill=tk.Y)\n    content_area = tk.Frame(inner_container, bg='#c0c0c0')\n    content_area.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1)\n    return content_area\n\n\nroot = tk.Tk()\nroot.title('Current Time')\nroot.configure(bg='#008080')\nmain_frame = create_3d_border(root)\nmain_frame.config(padx=4, pady=4)\ninner_frame = tk.Frame(main_frame, bg='#c0c0c0', padx=8, pady=8)\ninner_frame.pack()\ntime_label = tk.Label(inner_frame, bg='#c0c0c0', fg='#000000', font=(\n    'MS Sans Serif', 18, 'bold'), padx=12, pady=8)\ntime_label.pack()\nroot.after(100, lambda : center_window(root))\nupdate_time()\nroot.mainloop()\n",
    "file": "/mnt/ProjectData/omni/omni_saves/watch.py"
  },
  {
    "id": 61,
    "hash": "6774a805052356775d8c4f0367253dc1",
    "content": "# OmniForge\n\n**Project\u2011Aware AI CLI for AST\u2011Precise Edits (\u201cScalpel\u201d) & Multi\u2011File Refactors (\u201cBlueprint\u201d).**\n\n> *OmniForge (a.k.a. the \"DualForge\" engine) helps you **scan**, **understand**, and **reforge** your codebase with local (Ollama) or remote (OpenRouter) LLMs. It is an independent open\u2011source project not affiliated with other products using the name \u201cOmni.\u201d*\n\n---\n\n## Core Features\n\n* **Project\u2011Aware Refactoring (`refactor`)**: Provide a high\u2011level goal (e.g. *\u201cmove all DB logic into `db/` and centralize config\u201d*). OmniForge generates & shows a multi\u2011step plan before touching files.\n* **Surgical AST Editing (`edit`)**: Target a single function/class. OmniForge parses the file, locates the node, applies a structural change, and shows you a diff.\n* **Context Ingestion (`look`)**: Scan a directory or single file to build a project manifest (paths + hashes + size + language hints) that guides subsequent edits/refactors.\n* **Dual Backends**: Seamlessly switch between **`openrouter`** (remote models) and **`ollama`** (local models) via `backend <name>`.\n* **Interactive Model Picker (`models`)**: Filter by source/provider and select from an up\u2011to\u2011date model list inside the terminal.\n* **Session Memory & History**: `history` shows conversation / action log; `memory clear` resets the working context.\n* **Safe AST\u2011Based Transformations**: Reduces syntax breakage vs naive text substitution. New imports / dependencies are auto\u2011inserted when possible.\n* **Dry\u2011Run Transparency**: Every multi\u2011file refactor presents (1) a generated plan, (2) per\u2011file proposed changes, (3) a consolidated diff for confirmation.\n\n---\n\n## Conceptual Modes\n\n| Mode          | Command(s) | Purpose                                              | Analogy              |\n| ------------- | ---------- | ---------------------------------------------------- | -------------------- |\n| **Survey**    | `look`     | Index project / ingest context                       | Mapping the terrain  |\n| **Scalpel**   | `edit`     | Precise single\u2011file structural change                | Surgery              |\n| **Blueprint** | `refactor` | Multi\u2011file architectural transformation              | Architecture         |\n| **Cast**      | `run`      | Execute last generated runnable block (if supported) | Forging the artifact |\n\nYou can reference these terms in docs, help screens, or UI banners for clarity.\n\n---\n\n## Installation\n\n> Requires Python 3.10+ and a Unix\u2011like shell.\n\n```bash\n# 1. Clone\ngit clone https://github.com/Snawyyy/omniforge.git\ncd omniforge\n\n# 2. (Optional) Inspect requirements\ncat requirements.txt\n\n# 3. Run installer (creates venv + installs deps)\nchmod +x install.sh\n./install.sh\n\n# 4. Activate environment\nsource venv/bin/activate\n\n# 5. Run CLI (interactive shell)\n./omni        # or: python omni.py\n```\n\nIf you later package it, expose a script entry point named `omni` while keeping an internal package name like `omniforge` to avoid namespace collisions.\n\n---\n\n## Configuration\n\nCreate a `.env` file to supply secrets (e.g. OpenRouter API key).\n\n```bash\ncp .env.example .env   # if example exists; otherwise create manually\n```\n\nIn `.env`:\n\n```dotenv\nOPENROUTER_API_KEY=\"sk-or-...\"\n```\n\n(Do **not** commit real keys. Ensure `.env` is listed in `.gitignore`.)\n\nOptional future keys can include local model paths, default model name, or feature flags.\n\n---\n\n## Quick Start Workflow\n\n```text\n> look .\n(Index project: builds manifest)\n\n> refactor \"extract hardcoded API URL to config/settings.py and update all imports\"\n(Shows plan \u2192 ask for confirmation)\n\n> edit src/utils.py \"add a doctring for calculate_average explaining parameters and return value\"\n(Shows targeted diff \u2192 confirm or abort)\n\n> models openai\n(Choose a different model)\n\n> backend ollama\n(Switch to local inference)\n```\n\n---\n\n## Command Reference\n\n| Command               | Example                                         | Description                                                                 |\n| --------------------- | ----------------------------------------------- | --------------------------------------------------------------------------- |\n| `look <path>`         | `look .`                                        | Scan directory or file; update project context manifest.                    |\n| `edit <file> \"instr\"` | `edit utils.py \"add error handling\"`            | AST\u2011guided targeted modification of a single file element or whole file.    |\n| `refactor \"goal\"`     | `refactor \"split monolith api.py into package\"` | High\u2011level multi\u2011file transformation with plan + diff review.               |\n| `send <prompt>`       | `send summarize module layout`                  | Generic prompt to current model with current context summary.               |\n| `models [filter]`     | `models google`                                 | Interactive model selector (filter by provider/source).                     |\n| `backend <name>`      | `backend ollama`                                | Switch between `openrouter` / `ollama`.                                     |\n| `history`             | `history`                                       | Display session interaction log.                                            |\n| `memory clear`        | `memory clear`                                  | Clear internal AI context memory (project manifest may persist separately). |\n| `run`                 | `run`                                           | Execute the last generated runnable code snippet (if feature implemented).  |\n| `help`                | `help`                                          | Show help / usage summary.                                                  |\n\n---\n\n## How It Works (High Level)\n\n1. **Ingestion (`look`)**: Walks the directory (configurable ignore patterns), captures file metadata (path, size, language), optionally caches abbreviated content or hashes.\n2. **Prompt Construction**: Merges user instruction + contextual manifest + focused snippets (for `edit`) or diff summaries (for `refactor`).\n3. **AST Layer** (Python initially): Parses target file(s); identifies node(s) (function/class) based on name + heuristic similarity; applies transformations guided by model output (structured hints or patch templates) rather than raw blind overwrite.\n4. **Plan (Refactor)**: Model proposes steps (CREATE / MODIFY / RENAME / DELETE). User approves. Each step executed & validated; errors surface early.\n5. **Diff Presentation**: A unified colorized diff shown; user confirms to write changes.\n6. **Safety**: If AST parse fails or patch violates syntax, changes abort (or fallback to text patch with warning).\n\n---\n\n## Roadmap (Indicative)\n\n| Milestone | Features                                                                    |\n| --------- | --------------------------------------------------------------------------- |\n| 0.1.0     | Core commands (`look`, `edit`, `refactor`, `models`, `backend`, `history`). |\n| 0.2.0     | Config file (`omniforge.toml`), ignore patterns, improved diff viewer.      |\n| 0.3.0     | Multi-language AST adapters (JS/TS via `tree-sitter`).                      |\n| 0.4.0     | Test impact analysis & auto test file generation.                           |\n| 0.5.0     | Refactor preview metrics (LOC touched, complexity delta).                   |\n| 0.6.0     | Inline security / lint feedback integration.                                |\n| 0.7.0     | Partial GUI / TUI dashboard mode.                                           |\n\n(Adjust roadmap as project evolves.)\n\n---\n\n## Developer Notes\n\n* Keep `.env`, virtual environment dirs (`venv/`), caches, large artifacts in `.gitignore`.\n* Consider adding a thin `omniforge/` package directory now for future PyPI packaging.\n* Implement a pluggable *Model Adapter* layer to abstract provider differences (OpenRouter vs Ollama).\n* Logging: Provide `--verbose` or `OMNIFORGE_DEBUG=1` env flag.\n* Add a JSONL log of commands & decisions to enable replay or supervised improvements.\n\n---\n\n## Contributing\n\n1. Fork & create a feature branch: `git checkout -b feat/<short-name>`\n2. Run and add tests (if/when test harness exists in `tests/`).\n3. Ensure style/format (e.g. `ruff`, `black`) passes.\n4. Submit pull request with concise description + before/after examples.\n\nIssues / discussions welcome for architecture proposals, AST adapters, or performance improvements.\n\n---\n\n## License\n\nReleased under the **MIT License**. See `LICENSE` file for full text.\n\n---\n\n## Name & Trademark Disclaimer\n\n\u201cOmniForge\u201d is an independent open-source tool and not affiliated with The Omni Group or any other third-party products using similar names. If a future naming conflict arises, a soft alias strategy (keeping the `omni` CLI) will preserve user workflows.\n\n---\n\n## Example Session (Illustrative)\n\n```text\n$ ./omni\nOMNIFORGE 0.1.0  (backend=openrouter | model=anthropic/claude-3)\nType 'help' or 'look .' to begin.\n\n> look .\nIndexed 42 files (Python=30, Markdown=5, JSON=7)\n\n> refactor \"centralize logging into logging_util.py and update imports\"\nPlan:\n  [1] CREATE logging_util.py\n  [2] MODIFY app.py (replace inline log setup)\n  [3] MODIFY worker.py (import logging_util)\nProceed? (y/n) y\n... (diff preview) ...\nApply changes? (y/n) y\nRefactor complete in 3.2s.\n\n> edit worker.py \"add retry with exponential backoff to fetch_data\"\nParsed worker.py \u2713\nApplied modification (function: fetch_data)\nDiff shown. Accept? (y/n) y\nSaved.\n```\n\n---\n\n## Philosophy\n\n*The next wave of developer AI goes beyond paste\u2011in prompts.* OmniForge treats your repository as *structured material*, enabling incremental, auditable, and safer evolution rather than opaque code dumps. By combining **context scanning**, **AST precision**, and **human approval loops**, it aims to become a trustworthy co\u2011developer rather than an occasionally helpful code generator.\n\n---\n\n## Feedback / Support\n\nOpen a GitHub Issue for bugs & feature requests. For conceptual discussions (roadmap, design choices), use Discussions.\n\n---\n\nHappy forging!\n",
    "file": "/mnt/ProjectData/omni/README.md"
  },
  {
    "id": 62,
    "hash": "48f330cca4dc037b3ad4942e430e6393",
    "content": "# ast_adapter.py\n\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional, Dict, Any, Union\n\n# Define common types that adapters might use or return\n# This keeps the interface flexible without importing specific parser libraries\nASTNode = Any  # Generic type for a node in the AST/CST\nDiffContent = str # Type alias for the string output of a diff\n\nclass ASTAdapter(ABC):\n    \"\"\"\n    Abstract base class defining the interface for language-specific AST adapters.\n\n    This interface allows the CodeEditor to interact with the AST/CST of different\n    programming languages in a uniform way. Concrete implementations will handle\n    the specifics of parsing, traversing, and modifying the AST/CST for their\n    respective languages (e.g., Python's `ast`/`astor`, JavaScript's `tree-sitter`).\n\n    The adapter is responsible for holding the parsed tree structure and any\n    necessary metadata for operations.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the adapter by parsing the provided source code.\n\n        Args:\n            source_code: The string content of the source file to be parsed.\n\n        Raises:\n            ValueError: If the source code cannot be parsed due to syntax errors.\n        \"\"\"\n        self.source_code: str = source_code\n        self.tree: Optional[ASTNode] = None\n        self.nodes: Dict[str, ASTNode] = {} # A map for quick access to named elements\n        self._parse_and_map(source_code)\n\n    @abstractmethod\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Abstract method to parse the source code and populate `self.tree` and `self.nodes`.\n\n        This is the core method where language-specific parsing logic resides.\n        Implementations should:\n        1. Parse the `source_code` into an AST/CST representation.\n        2. Store the root of this representation in `self.tree`.\n        3. Identify key top-level elements (functions, classes, variables, imports)\n           and map their names to their nodes in `self.nodes`.\n\n        Args:\n            source_code: The string content to parse.\n\n        Raises:\n            ValueError: If the source code cannot be parsed.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_elements(self) -> List[str]:\n        \"\"\"\n        Abstract method to list the names of the main elements found in the code.\n\n        These are typically top-level functions, classes, variable assignments,\n        and imports that the adapter can identify and manipulate.\n\n        Returns:\n            A list of element names (strings).\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"\n        Abstract method to get the source code string for a specific element.\n\n        Args:\n            element_name: The name of the element (function, class, etc.).\n\n        Returns:\n            The source code string for the element, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"\n        Abstract method to get detailed structural information about an element.\n\n        This information can include type, line numbers, body items, etc., useful\n        for aiding the AI in understanding the code's layout.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            A dictionary containing structural details, or None if not found.\n            Example structure:\n            {\n                'name': 'func_name',\n                'type': 'FunctionDef', # or 'ClassDef', etc.\n                'line_start': 10,\n                'line_end': 25,\n                'body_items': [list of internal statement details...]\n            }\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"\n        Abstract method to extract a snippet of code from within an element's body.\n\n        Used for 'partial' edits where only a specific range of lines within\n        a function or class needs to be changed.\n\n        Args:\n            element_name: The name of the element containing the snippet.\n            line_start: The starting line number (1-based, absolute) of the snippet.\n            line_end: The ending line number (inclusive) of the snippet.\n\n        Returns:\n            The source code string for the specified lines within the element, or None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"\n        Abstract method to replace an entire named element.\n\n        This involves finding the old element in the tree and swapping it with\n        the representation of the `new_code`.\n\n        Args:\n            element_name: The name of the element to replace.\n            new_code: The new source code for the element (and potential helpers).\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"\n        Abstract method to add a new block of code (element) to the file.\n\n        This involves parsing the `new_code` and inserting its representation\n        into the tree at an appropriate location (e.g., end of file, near anchor).\n\n        Args:\n            new_code: The source code for the new element(s).\n            anchor_name: Optional name of an existing element to position relative to.\n            before: If True and `anchor_name` is provided, insert before the anchor.\n\n        Returns:\n            True if the element was added successfully, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"\n        Abstract method to delete a named element from the file.\n\n        This involves finding the element in the tree and removing its representation.\n\n        Args:\n            element_name: The name of the element to delete.\n\n        Returns:\n            True if the element was successfully deleted, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"\n        Abstract method for a 'surgical' edit within an element's body.\n\n        Replaces a specific statement or line range within the body of an element.\n\n        Args:\n            element_name: Name of the function/class to modify.\n            new_code: New code to insert (can be multiple statements).\n            line_start: Starting line number (absolute) within the element.\n            line_end: Ending line number (inclusive) within the element.\n            statement_index: Alternative to line numbers - replace the Nth statement.\n\n        Returns:\n            True if successful, False otherwise.\n        \"\"\"\n        pass\n\n    # --- Methods related to final output and change tracking ---\n\n    @abstractmethod\n    def get_modified_source(self) -> str:\n        \"\"\"\n        Abstract method to serialize the potentially modified AST/CST back to source code.\n\n        Returns:\n            The full source code string reflecting the current state of the tree.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_diff(self) -> str:\n        \"\"\"\n        Abstract method to generate a diff between the original source and the modified source.\n\n        Returns:\n            A string containing the unified diff.\n        \"\"\"\n        pass\n\n    # Internal helper methods (can be abstract or have common logic in base if needed)\n    # These are less critical for the interface but might be useful\n    # _add_imports(new_import_nodes) -> could be handled differently per language\n    # _find_statement_in_body(body, line_start, line_end) -> Tree-sitter needs different logic",
    "file": "/mnt/ProjectData/omni/ast_adapter.py"
  },
  {
    "id": 63,
    "hash": "40b50193cb04547cadce2d070870277a",
    "content": "\"\"\"\nCodeEditor - Enhanced AST-based code manipulation tool\n\nThis module provides a class to programmatically parse, analyze,\nand edit source code. It has been refactored to use a pluggable\nASTAdapter system, allowing it to support multiple languages.\nCurrently, it defaults to Python's built-in `ast` module via\nPythonASTAdapter for backward compatibility during the transition.\n\"\"\"\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Union, Tuple, Type, Any\nfrom ast_adapter import ASTAdapter\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n\n\nclass CodeEditor:\n    \"\"\"\n    An enhanced class to safely edit files using AST/CST with partial edit support.\n    The core logic for interacting with the code structure is now delegated to\n    a language-specific ASTAdapter.\n    \"\"\"\n\n    def __init__(self, file_path: str, adapter_class: Optional[Type[\n        ASTAdapter]]=None):\n        \"\"\"\n        Initializes the CodeEditor.\n\n        Args:\n            file_path: The path to the source file.\n            adapter_class: The ASTAdapter subclass to use. If None, defaults to\n                           PythonASTAdapter for .py files.\n        \"\"\"\n        self.file_path = file_path\n        self.source_code = self._read_file()\n        if adapter_class is None:\n            try:\n                from python_ast_adapter import PythonASTAdapter\n                self.adapter: Optional[ASTAdapter] = PythonASTAdapter(self.\n                    source_code)\n            except ImportError:\n                self.adapter = None\n                self.tree: ast.AST = self._parse_source()\n                self.nodes: Dict[str, ast.AST] = self._map_nodes()\n                if ASTTOKENS_AVAILABLE:\n                    self.atok = asttokens.ASTTokens(self.source_code, parse\n                        =True)\n                else:\n                    self.atok = None\n        else:\n            self.adapter = adapter_class(self.source_code)\n\n    def _read_file(self) ->str:\n        \"\"\"Reads the source file.\"\"\"\n        try:\n            with open(self.file_path, 'r', encoding='utf-8') as f:\n                return f.read()\n        except FileNotFoundError:\n            raise ValueError(f'File not found: {self.file_path}')\n\n    def _parse_source(self) ->ast.AST:\n        \"\"\"Fallback parsing logic.\"\"\"\n        try:\n            return ast.parse(self.source_code)\n        except SyntaxError as e:\n            raise ValueError(f'Invalid Python syntax in {self.file_path}: {e}')\n\n    def list_elements(self) ->List[str]:\n        \"\"\"Lists top-level elements in the code.\"\"\"\n        if self.adapter:\n            return self.adapter.list_elements()\n        else:\n            return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"Gets the source code for a specific element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_source_of(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            return astor.to_source(node) if node else None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"Gets detailed structure information about an element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_structure(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            if not node:\n                return None\n            structure = {'name': element_name, 'type': node.__class__.\n                __name__, 'line_start': node.lineno if hasattr(node,\n                'lineno') else None, 'line_end': node.end_lineno if hasattr\n                (node, 'end_lineno') else None, 'body_items': []}\n            if hasattr(node, 'body'):\n                for i, item in enumerate(node.body):\n                    item_info = {'index': i, 'type': item.__class__.\n                        __name__, 'line_start': item.lineno if hasattr(item,\n                        'lineno') else None, 'line_end': item.end_lineno if\n                        hasattr(item, 'end_lineno') else None}\n                    if isinstance(item, ast.Assign) and item.targets:\n                        target = item.targets[0]\n                        if isinstance(target, ast.Name):\n                            item_info['assigns'] = target.id\n                    elif isinstance(item, (ast.If, ast.While, ast.For)):\n                        item_info['has_body'] = bool(item.body)\n                    elif isinstance(item, ast.Return):\n                        item_info['returns'] = True\n                    structure['body_items'].append(item_info)\n            return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"Gets a snippet from within an element's body.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_body_snippet(element_name,\n                line_start, line_end)\n        else:\n            if not self.atok:\n                return None\n            node = self.nodes.get(element_name)\n            if not node or not hasattr(node, 'body'):\n                return None\n            statements = []\n            for stmt in node.body:\n                if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                    if (line_start <= stmt.lineno <= line_end or line_start <=\n                        stmt.end_lineno <= line_end):\n                        statements.append(stmt)\n            if not statements:\n                return None\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in\n                statements)\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"Replaces a partial section of an element.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_partial(element_name, new_code,\n                line_start, line_end, statement_index)\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                if new_code.strip().startswith('def ') or new_code.strip(\n                    ).startswith('class '):\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body[0].body\n                else:\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if statement_index is not None:\n                if 0 <= statement_index < len(node.body):\n                    node.body[statement_index:statement_index + 1\n                        ] = new_statements\n                    return True\n            elif line_start is not None:\n                result = self._find_statement_in_body(node.body, line_start,\n                    line_end)\n                if result:\n                    idx, _ = result\n                    if line_end:\n                        end_idx = idx\n                        for i in range(idx + 1, len(node.body)):\n                            stmt = node.body[i]\n                            if hasattr(stmt, 'end_lineno'\n                                ) and stmt.end_lineno <= line_end:\n                                end_idx = i\n                            else:\n                                break\n                        node.body[idx:end_idx + 1] = new_statements\n                    else:\n                        node.body[idx:idx + 1] = new_statements\n                    return True\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"Adds a new block of code to the file.\"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name, before)\n        else:\n            try:\n                new_ast_module = ast.parse(new_code)\n            except (SyntaxError, IndexError):\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            insertion_index = -1\n            main_block_idx = -1\n            for i, _node in enumerate(self.tree.body):\n                if isinstance(_node, ast.If) and isinstance(_node.test, ast\n                    .Compare) and isinstance(_node.test.left, ast.Name\n                    ) and _node.test.left.id == '__name__' and len(_node.\n                    test.ops) == 1 and isinstance(_node.test.ops[0], ast.Eq\n                    ) and len(_node.test.comparators) == 1:\n                    comp = _node.test.comparators[0]\n                    if isinstance(comp, ast.Constant\n                        ) and comp.value == '__main__' or isinstance(comp,\n                        ast.Str) and comp.s == '__main__':\n                        main_block_idx = i\n                        break\n            if anchor_name:\n                if anchor_name not in self.nodes:\n                    return False\n                anchor_node = self.nodes[anchor_name]\n                try:\n                    anchor_idx = self.tree.body.index(anchor_node)\n                    proposed_index = anchor_idx if before else anchor_idx + 1\n                    if main_block_idx != -1:\n                        insertion_index = min(proposed_index, main_block_idx)\n                    else:\n                        insertion_index = proposed_index\n                except ValueError:\n                    return False\n            elif main_block_idx != -1:\n                insertion_index = main_block_idx\n            if insertion_index == -1:\n                self.tree.body.extend(new_code_body)\n            else:\n                for i, new_node in enumerate(new_code_body):\n                    self.tree.body.insert(insertion_index + i, new_node)\n            for _node in new_code_body:\n                if isinstance(_node, (ast.FunctionDef, ast.AsyncFunctionDef,\n                    ast.ClassDef)):\n                    self.nodes[_node.name] = _node\n            return True\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"Deletes an element by name.\"\"\"\n        if self.adapter:\n            return self.adapter.delete_element(element_name)\n        else:\n            deleted = False\n            if element_name in self.nodes:\n                node_to_delete = self.nodes[element_name]\n                for _node in ast.walk(self.tree):\n                    if hasattr(_node, 'body') and isinstance(_node.body, list):\n                        try:\n                            _node.body.remove(node_to_delete)\n                            deleted = True\n                            break\n                        except ValueError:\n                            continue\n                if deleted:\n                    del self.nodes[element_name]\n                    self.nodes = self._map_nodes()\n                    return True\n            new_body = []\n            for _node in self.tree.body:\n                if isinstance(_node, ast.Assign):\n                    match = False\n                    for target in _node.targets:\n                        if isinstance(target, ast.Name\n                            ) and target.id == element_name:\n                            match = True\n                            break\n                    if match:\n                        deleted = True\n                        continue\n                elif isinstance(_node, ast.Import):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                elif isinstance(_node, ast.ImportFrom):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                new_body.append(_node)\n            self.tree.body = new_body\n            if deleted:\n                self.nodes = self._map_nodes()\n            return deleted\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"Replaces a target element with new code.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_element(element_name, new_code)\n        else:\n            if element_name not in self.nodes:\n                return False\n            try:\n                new_ast_module = ast.parse(new_code)\n            except SyntaxError:\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            for _node in ast.walk(self.tree):\n                if hasattr(_node, 'body') and isinstance(_node.body, list):\n                    try:\n                        old_node = self.nodes[element_name]\n                        idx = _node.body.index(old_node)\n                        _node.body.pop(idx)\n                        for i, new_node in enumerate(new_code_body):\n                            _node.body.insert(idx + i, new_node)\n                        del self.nodes[element_name]\n                        for n in new_code_body:\n                            if isinstance(n, (ast.FunctionDef, ast.\n                                AsyncFunctionDef, ast.ClassDef)):\n                                self.nodes[n.name] = n\n                        return True\n                    except (ValueError, KeyError):\n                        continue\n            return False\n\n    def insert_in_element(self, element_name: str, new_code: str, position:\n        str='end', after_line: Optional[int]=None, before_line: Optional[\n        int]=None) ->bool:\n        \"\"\"\n        Insert new code into an element without replacing existing code.\n        This is an internal/helper method, delegating to adapter OR using fallback.\n        \"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name=\n                element_name, before=position == 'start')\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                new_ast = ast.parse(new_code)\n                new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if position == 'start':\n                node.body[0:0] = new_statements\n            elif position == 'end':\n                node.body.extend(new_statements)\n            elif after_line:\n                result = self._find_statement_in_body(node.body, after_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx + 1:idx + 1] = new_statements\n                else:\n                    return False\n            elif before_line:\n                result = self._find_statement_in_body(node.body, before_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx:idx] = new_statements\n                else:\n                    return False\n            else:\n                return False\n            return True\n\n    def _map_nodes(self) ->Dict[str, ast.AST]:\n        \"\"\"Fallback node mapping logic for Python AST.\"\"\"\n        nodes = {}\n        for node in ast.walk(self.tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast\n                .ClassDef)):\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int,\n        line_end: Optional[int]=None) ->Optional[Tuple[int, ast.AST]]:\n        \"\"\"Fallback statement finding logic for Python AST.\"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = stmt.end_lineno if hasattr(stmt, 'end_lineno'\n                        ) else stmt.lineno\n                    if (stmt.lineno <= line_start <= stmt_end or stmt.\n                        lineno <= line_end <= stmt_end):\n                        return i, stmt\n                elif stmt.lineno == line_start:\n                    return i, stmt\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.\n        ImportFrom]]) ->None:\n        \"\"\"Fallback logic to add imports to the top of the Python AST.\"\"\"\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                existing_imports_str.add(astor.to_source(node).strip())\n                last_import_index = i\n        for new_import in reversed(new_import_nodes):\n            new_import_str = astor.to_source(new_import).strip()\n            if new_import_str not in existing_imports_str:\n                self.tree.body.insert(last_import_index + 1, new_import)\n\n    def apply_arbitrary_change(self, new_source_code: str) ->bool:\n        \"\"\"\n        Rewrites the entire file's AST from a new source string.\n        This method resets the adapter if one exists, or uses fallback.\n        \"\"\"\n        if self.adapter:\n            try:\n                adapter_class = type(self.adapter)\n                self.adapter = adapter_class(new_source_code)\n                return True\n            except Exception:\n                return False\n        else:\n            try:\n                new_tree = ast.parse(new_source_code)\n                self.tree = new_tree\n                self.nodes = self._map_nodes()\n                if ASTTOKENS_AVAILABLE:\n                    self.source_code = new_source_code\n                    self.atok = asttokens.ASTTokens(self.source_code, parse\n                        =True)\n                return True\n            except SyntaxError:\n                return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"Serializes the potentially modified code structure back to source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_modified_source()\n        else:\n            return astor.to_source(self.tree)\n\n    def get_diff(self) ->str:\n        \"\"\"Generates a diff between the original source and the modified source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_diff()\n        else:\n            modified_source = self.get_modified_source()\n            return ''.join(difflib.unified_diff(self.source_code.splitlines\n                (keepends=True), modified_source.splitlines(keepends=True),\n                fromfile=f'{self.file_path} (original)', tofile=\n                f'{self.file_path} (modified)'))\n\n    def save_changes(self) ->None:\n        \"\"\"Saves the modified source code back to the file.\"\"\"\n        modified_source = self.get_modified_source()\n        with open(self.file_path, 'w', encoding='utf-8') as f:\n            f.write(modified_source)\n",
    "file": "/mnt/ProjectData/omni/code_editor.py"
  },
  {
    "id": 64,
    "hash": "cc52aa524d0929867d5d2ea3697229e6",
    "content": "\"\"\"\nGenerated file.\n\"\"\"\nimport os\n\"\"\"\nFileCreator - A utility for creating files.\n\nThis module provides a simple, encapsulated way to create files,\nensuring that their parent directories exist before writing.\n\"\"\"\n\n\nclass FileCreator:\n    \"\"\"\n    A utility class to handle the creation of new files.\n    \"\"\"\n\n    @staticmethod\n    def create(file_path: str, content: str) ->None:\n        \"\"\"\n        Creates a file at the specified path with the given content.\n\n        This method will automatically create any necessary parent\n        directories for the file path.\n\n        Args:\n            file_path: The full path where the file should be created.\n            content: The string content to write to the file.\n\n        Raises:\n            IOError: If there is an error creating the directories or writing the file.\n        \"\"\"\n        try:\n            directory = os.path.dirname(file_path)\n            if directory:\n                os.makedirs(directory, exist_ok=True)\n            with open(file_path, 'w', encoding='utf-8') as f:\n                f.write(content)\n        except (IOError, OSError) as e:\n            raise IOError(f\"Failed to create file '{file_path}': {e}\") from e\n",
    "file": "/mnt/ProjectData/omni/file_creator.py"
  },
  {
    "id": 65,
    "hash": "04a24ceab008bd649d0530d309c72e42",
    "content": "import subprocess\nimport os\nfrom typing import List, Optional, Union\n\n\nclass GitManager:\n    \"\"\"\n    Encapsulates Git-related logic for a specific repository.\n\n    This class provides methods to perform common Git operations such as\n    checking status, getting diffs, staging, committing, and pushing changes.\n    It relies on the Git command-line tool being installed and accessible\n    in the system's PATH.\n    \"\"\"\n\n    def __init__(self, repo_path: str):\n        \"\"\"\n        Initializes the GitManager for a given repository path.\n\n        Args:\n            repo_path: The absolute or relative path to the Git repository.\n\n        Raises:\n            ValueError: If the provided path is not a valid Git repository.\n        \"\"\"\n        if not os.path.isdir(os.path.join(repo_path, '.git')):\n            raise ValueError(\n                f\"The path '{repo_path}' is not a valid Git repository.\")\n        self.repo_path = repo_path\n\n    def _run_command(self, command: List[str]) ->str:\n        \"\"\"\n        Executes a Git command in the repository's directory.\n\n        Args:\n            command: A list of command arguments, starting with 'git'.\n\n        Returns:\n            The standard output of the command as a string.\n\n        Raises:\n            subprocess.CalledProcessError: If the command returns a non-zero exit code.\n        \"\"\"\n        try:\n            result = subprocess.run(command, cwd=self.repo_path, check=True,\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True,\n                encoding='utf-8')\n            return result.stdout.strip()\n        except subprocess.CalledProcessError as e:\n            error_message = (\n                f\"Git command failed: {' '.join(command)}\\nError: {e.stderr.strip()}\"\n                )\n            raise subprocess.CalledProcessError(e.returncode, e.cmd, output\n                =e.stdout, stderr=error_message) from e\n\n    def get_status(self) ->str:\n        \"\"\"\n        Gets the repository status in a condensed format.\n\n        Uses `git status --porcelain` for a machine-readable output.\n\n        Returns:\n            A string representing the repository's status.\n        \"\"\"\n        return self._run_command(['git', 'status', '--porcelain'])\n        \n    def get_changed_files(self) -> List[str]:\n        \"\"\"\n        Gets a list of all changed (modified, added, deleted, untracked, renamed, or copied) files.\n\n        This parses the output of `git status --porcelain`, which provides a stable,\n        machine-readable format.\n\n        Returns:\n            A list of file paths relative to the repository root. For renamed or\n            copied files, it returns the new path.\n        \"\"\"\n        status_output = self.get_status()\n        if not status_output:\n            return []\n        \n        changed_files = []\n        for line in status_output.splitlines():\n            if len(line) < 3:  # Skip malformed lines\n                continue\n                \n            # Git status porcelain format: XY filename\n            # X = index status, Y = working tree status\n            index_status = line[0]\n            worktree_status = line[1]\n            \n            # The filename starts after the two status characters and a space\n            # But let's be more defensive about finding where the filename actually starts\n            filename_start = 2\n            while filename_start < len(line) and line[filename_start] == ' ':\n                filename_start += 1\n                \n            if filename_start >= len(line):\n                continue  # Skip if no filename found\n                \n            path_info = line[filename_start:]\n            \n            # Check if either index or working tree status indicates rename/copy\n            if index_status in ('R', 'C') or worktree_status in ('R', 'C'):\n                if ' -> ' in path_info:\n                    _, new_path = path_info.split(' -> ', 1)  # Use maxsplit=1 for safety\n                    changed_files.append(new_path.strip())\n                else:\n                    # Fallback if format is unexpected\n                    changed_files.append(path_info.strip())\n            else:\n                changed_files.append(path_info.strip())\n        \n        # Remove duplicates while preserving order\n        return list(dict.fromkeys(changed_files))\n\n    def get_diff(self, file_path: Optional[str]=None, staged: bool=False\n        ) ->str:\n        \"\"\"\n        Gets the diff of changes in the repository.\n\n        Args:\n            file_path: Optional. Path to a specific file to diff.\n            staged: If True, shows the diff for staged changes (`--cached`).\n                    Otherwise, shows the diff for unstaged changes.\n\n        Returns:\n            The git diff output as a string.\n        \"\"\"\n        cmd = ['git', 'diff']\n        if staged:\n            cmd.append('--cached')\n        if file_path:\n            cmd.append('--')\n            cmd.append(file_path)\n        return self._run_command(cmd)\n\n    def add(self, files: Union[str, List[str]]) ->None:\n        \"\"\"\n    Stages one or more files, handling each one individually for robustness.\n\n    This approach prevents a single invalid file path from causing the\n    entire 'git add' operation to fail. Warnings will be printed for any\n    files that could not be staged.\n\n    Args:\n        files: A single file path or a list of file paths to stage.\n               Can also be '.' to stage all changes.\n    \"\"\"\n        if isinstance(files, str):\n            files = [files]\n        for file_path in files:\n            try:\n                cmd = ['git', 'add', '--', file_path]\n                self._run_command(cmd)\n            except subprocess.CalledProcessError as e:\n                print(\n                    f\"Warning: Could not stage file '{file_path}'. Git reported: {e.stderr}\"\n                    )\n\n    def commit(self, message: str) ->str:\n        \"\"\"\n        Commits staged changes with a given message.\n\n        Args:\n            message: The commit message.\n\n        Returns:\n            The stdout from the git commit command.\n        \"\"\"\n        return self._run_command(['git', 'commit', '-m', message])\n\n    def push(self, remote: str='origin', branch: Optional[str]=None) ->str:\n        \"\"\"\n        Pushes commits to a remote repository.\n\n        Args:\n            remote: The name of the remote to push to (default: 'origin').\n            branch: The branch to push. If None, uses the current branch.\n\n        Returns:\n            The stdout from the git push command.\n        \"\"\"\n        if branch is None:\n            branch = self.get_current_branch()\n        return self._run_command(['git', 'push', remote, branch])\n\n    def get_current_branch(self) ->str:\n        \"\"\"\n        Determines the current active branch name.\n\n        Returns:\n            The name of the current branch.\n        \"\"\"\n        return self._run_command(['git', 'rev-parse', '--abbrev-ref', 'HEAD'])\n",
    "file": "/mnt/ProjectData/omni/git_manager.py"
  },
  {
    "id": 66,
    "hash": "f3f7ab448ad3e233539c4e4bddcd64f4",
    "content": "# javascript_ast_adapter.py\n\n\"\"\"\nJavaScriptASTAdapter - Concrete AST adapter for JavaScript using tree-sitter.\n\nThis module implements the ASTAdapter interface specifically for JavaScript,\nleveraging the tree-sitter library for parsing and manipulation.\n\"\"\"\n\nimport difflib\nimport re\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for tree-sitter\ntry:\n    import tree_sitter\n    import tree_sitter_languages\n    TREETSITTER_AVAILABLE = True\nexcept ImportError:\n    TREETSITTER_AVAILABLE = False\n    # This will cause an error during initialization if the adapter is used\n\n\nclass JavaScriptASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for JavaScript source code.\n\n    This adapter uses tree-sitter to parse and manipulate JavaScript code.\n    It holds the parsed tree-sitter Tree and provides methods to interact\n    with it according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the JavaScriptASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The JavaScript source code as a string.\n\n        Raises:\n            ValueError: If tree-sitter libraries are not available or if\n                        the source code has invalid JavaScript syntax.\n        \"\"\"\n        if not TREETSITTER_AVAILABLE:\n            raise ValueError(\"tree-sitter and tree-sitter-languages are required for JavaScript support.\")\n            \n        # Store source code for diffing and manipulation\n        self.source_code: str = source_code\n        # Will hold the parsed tree-sitter tree\n        self.tree: Optional[tree_sitter.Tree] = None\n        # Will hold a mapping of element names to their tree-sitter nodes\n        self.nodes: Dict[str, tree_sitter.Node] = {}\n        # Tree-sitter language parser\n        self.language = tree_sitter_languages.get_language(\"javascript\")\n        self.parser = tree_sitter.Parser(self.language)\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the JavaScript source code and maps elements.\n\n        Args:\n            source_code: The JavaScript source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid JavaScript syntax.\n        \"\"\"\n        try:\n            # Encode the source code in bytes as required by tree-sitter\n            self.tree = self.parser.parse(bytes(source_code, \"utf-8\"))\n        except Exception as e:\n            raise ValueError(f\"Failed to parse JavaScript source: {e}\") from e\n\n        self.nodes = self._map_nodes()\n\n    def _map_nodes(self) -> Dict[str, tree_sitter.Node]:\n        \"\"\"\n        Walks the tree and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their tree-sitter nodes.\n        \"\"\"\n        nodes: Dict[str, tree_sitter.Node] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        # Define the types of nodes we're interested in\n        target_types = {\n            \"function_declaration\", \"class_declaration\", \n            \"variable_declarator\", \"import_statement\"\n        }\n        \n        # Walk the tree using a stack-based approach\n        stack = [self.tree.root_node]\n        while stack:\n            node = stack.pop()\n            \n            # Check if this is a target node type\n            if node.type in target_types:\n                # Extract the name for different node types\n                name = self._get_node_name(node)\n                if name and name not in nodes:\n                    nodes[name] = node\n            \n            # Add children to the stack for further processing\n            for child in reversed(node.children):  # Reverse to maintain order when popping\n                stack.append(child)\n                \n        return nodes\n    \n    def _get_node_name(self, node: tree_sitter.Node) -> Optional[str]:\n        \"\"\"\n        Extracts the name of a node based on its type.\n        \n        Args:\n            node: The tree-sitter node to extract the name from.\n            \n        Returns:\n            The name of the node, or None if no name could be found.\n        \"\"\"\n        if node.type == \"function_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"class_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"variable_declarator\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"import_statement\":\n            # This is a more complex case - for now, we'll use a simplified approach\n            # Extract the module name from the import statement\n            # e.g., in \"import foo from 'bar'\", we want \"foo\"\n            # This is a simplified implementation and might need refinement\n            import_clause = None\n            for child in node.children:\n                if child.type == \"import_clause\":\n                    import_clause = child\n                    break\n            \n            if import_clause:\n                # Check for a simple identifier\n                for child in import_clause.children:\n                    if child.type == \"identifier\":\n                        return child.text.decode(\"utf-8\")\n                    elif child.type == \"named_imports\":\n                        # Handle named imports like { foo, bar }\n                        # For simplicity, we'll just return a placeholder\n                        # A more complete implementation would extract all names\n                        return f\"import_from_{hash(node.text.decode('utf-8')) % 10000}\"\n        \n        return None\n\n    def _find_node_by_position(self, start_point: Tuple[int, int], \n                              end_point: Optional[Tuple[int, int]] = None) -> Optional[tree_sitter.Node]:\n        \"\"\"\n        Finds a node in the tree that corresponds to a given range.\n        \n        Args:\n            start_point: A (row, column) tuple indicating the start position.\n            end_point: A (row, column) tuple indicating the end position.\n            \n        Returns:\n            The tree-sitter node that corresponds to the range, or None if not found.\n        \"\"\"\n        if not self.tree:\n            return None\n            \n        # A simple approach: find the smallest node that contains the range\n        # This is a simplified implementation and might need refinement\n        def contains_range(node):\n            node_start = (node.start_point[0], node.start_point[1])\n            node_end = (node.end_point[0], node.end_point[1])\n            if end_point:\n                return (node_start <= start_point and node_end >= end_point)\n            else:\n                return node_start <= start_point <= node_end\n        \n        # Walk the tree to find matching nodes\n        stack = [self.tree.root_node]\n        candidates = []\n        \n        while stack:\n            current_node = stack.pop()\n            if contains_range(current_node):\n                candidates.append(current_node)\n                # Add children to continue searching for smaller nodes\n                stack.extend(current_node.children)\n        \n        # Return the smallest (last) candidate\n        return candidates[-1] if candidates else None\n    \n    def _get_line_info_from_point(self, point: Tuple[int, int]) -> Dict[str, Any]:\n        \"\"\"\n        Converts a tree-sitter point to line information.\n        \n        Args:\n            point: A (row, column) tuple from tree-sitter.\n            \n        Returns:\n            A dictionary with line_start and line_end information.\n        \"\"\"\n        # Tree-sitter uses 0-based indexing for rows\n        return {\n            'line_start': point[0] + 1,  # Convert to 1-based\n            'line_end': point[0] + 1\n        }\n\n    def _reparse_tree(self, new_source: str) -> None:\n        \"\"\"\n        Re-parses the tree with new source code.\n        \n        This is necessary because tree-sitter trees are immutable.\n        \n        Args:\n            new_source: The new source code to parse.\n        \"\"\"\n        self.source_code = new_source\n        self.tree = self.parser.parse(bytes(new_source, \"utf-8\"))\n        self.nodes = self._map_nodes()\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return node.text.decode(\"utf-8\")\n            except Exception:\n                # Handle potential decoding issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.type,\n            'line_start': node.start_point[0] + 1,  # Convert to 1-based\n            'line_end': node.end_point[0] + 1,\n            'body_items': []\n        }\n\n        # Add body items for functions and classes\n        if node.type in (\"function_declaration\", \"class_declaration\"):\n            # Find the body block\n            body_node = None\n            for child in node.children:\n                if child.type == \"statement_block\":\n                    body_node = child\n                    break\n            \n            if body_node:\n                # Process statements in the body\n                for i, item in enumerate(body_node.children):\n                    # Skip '{' and '}' tokens\n                    if item.type in (\"{\", \"}\"):\n                        continue\n                    \n                    item_info = {\n                        'index': i,\n                        'type': item.type,\n                        'line_start': item.start_point[0] + 1,\n                        'line_end': item.end_point[0] + 1\n                    }\n                    \n                    # Add more specific information based on type\n                    if item.type == \"variable_declaration\":\n                        item_info['declares'] = \"variable\"\n                    elif item.type == \"return_statement\":\n                        item_info['returns'] = True\n                    elif item.type in (\"if_statement\", \"for_statement\", \"while_statement\"):\n                        item_info['has_body'] = True\n                    \n                    structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n            \n        # A simplified approach to extracting a snippet by line numbers\n        # This would need to be more sophisticated for production use\n        source_lines = self.source_code.split('\\n')\n        # Adjust for 0-based indexing\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(source_lines), line_end)\n        \n        if start_idx < end_idx:\n            return '\\n'.join(source_lines[start_idx:end_idx])\n        \n        return None\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Replace the node's text in the source code\n        new_source = self.source_code[:start_byte] + new_code + self.source_code[end_byte:]\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass  # If we can't even re-parse the original, we're in trouble\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree:\n            return False\n            \n        # For simplicity, we'll add the new code at the end of the file\n        # A more sophisticated implementation would handle the anchor and positioning\n        new_source = self.source_code.rstrip() + \"\\n\\n\" + new_code + \"\\n\"\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Find the full lines that contain the node\n        # This is a simplified approach to avoid leaving partial lines\n        source_lines = self.source_code.split('\\n')\n        start_line = node.start_point[0]\n        end_line = node.end_point[0]\n        \n        # Create new source without those lines\n        new_lines = source_lines[:start_line] + source_lines[end_line+1:]\n        new_source = '\\n'.join(new_lines)\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        # This is a complex operation that would require more sophisticated\n        # tree navigation and manipulation than what's shown here.\n        # For now, we'll provide a basic implementation.\n        \n        node = self.nodes.get(element_name)\n        if not node:\n            return False\n            \n        # Handle line-based replacement\n        if line_start is not None:\n            # Convert to 0-based indexing\n            start_idx = max(0, line_start - 1)\n            end_idx = line_end if line_end is not None else start_idx + 1\n            \n            source_lines = self.source_code.split('\\n')\n            if start_idx < len(source_lines):\n                # Replace the specified lines\n                end_idx = min(end_idx, len(source_lines))\n                new_lines = source_lines[:start_idx] + [new_code] + source_lines[end_idx:]\n                new_source = '\\n'.join(new_lines)\n                \n                # Re-parse the tree with the new source\n                try:\n                    self._reparse_tree(new_source)\n                    return True\n                except Exception:\n                    # If parsing fails, revert to the original source\n                    try:\n                        self._reparse_tree(self.source_code)\n                    except Exception:\n                        pass\n        \n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        # For tree-sitter, the source code is already maintained separately\n        return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        \n        # Ensure line endings are consistent for diffing\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/javascript_ast_adapter.py"
  },
  {
    "id": 67,
    "hash": "89fa0c06ca34019316daa58ce8fa9a20",
    "content": "import json\nimport os\nfrom typing import List, Dict, Optional\nfrom rag_manager import RAGManager\n\n\nclass MemoryManager:\n    \"\"\"Manages persistent chat memory, look data, and RAG integration via JSON.\"\"\"\n\n    def __init__(self, memory_file: str):\n        self.memory_file = memory_file\n        self.memory: Dict[str, List] = self.load_memory()\n        self.rag_manager = RAGManager()\n\n    def load_memory(self) ->Dict[str, List]:\n        try:\n            with open(self.memory_file, 'r') as f:\n                return json.load(f)\n        except FileNotFoundError:\n            default = {'chat': [], 'look': []}\n            self.save_memory(default)\n            return default\n        except json.JSONDecodeError:\n            print('[yellow]Invalid memory file. Resetting.[/]')\n            return {'chat': [], 'look': []}\n\n    def save_memory(self, memory: Optional[Dict[str, List]]=None) ->None:\n        if memory is None:\n            memory = self.memory\n        with open(self.memory_file, 'w') as f:\n            json.dump(memory, f, indent=4)\n\n    def add_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.memory['chat'].append({'role': role, 'content': content})\n        self.save_memory()\n\n    def add_chat_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        This is an alias for add_message to maintain compatibility.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.add_message(role, content)\n\n    def add_look_data(self, file_path: str, content: str) ->None:\n        \"\"\"\n    Adds a watched item (directory or file) to memory, distinguishing its type.\n\n    This method stores structured data that differentiates between a project\n    directory (containing a manifest) and a single file (containing its content).\n    It also prevents duplicate entries by updating existing ones.\n\n    Args:\n        file_path: The path to the directory or file.\n        content: The manifest for a directory or the content for a file.\n    \"\"\"\n        item_type = 'directory' if os.path.isdir(file_path) else 'file'\n        for item in self.memory['look']:\n            if item.get('file') == file_path:\n                item['content'] = content\n                item['type'] = item_type\n                self.save_memory()\n                return\n        self.memory['look'].append({'type': item_type, 'file': file_path,\n            'content': content})\n        self.save_memory()\n        if item_type == 'file':\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    file_content = f.read()\n                self.rag_manager.add_documents([file_content], [{'file':\n                    file_path}])\n            except Exception as e:\n                print(\n                    f'[yellow]Warning: Could not add {file_path} to RAG index: {e}[/]'\n                    )\n\n    def get_project_root(self) ->Optional[str]:\n        \"\"\"\n        Finds the root directory of the project currently in memory.\n\n        The project root is defined as the first item in the 'look' memory\n        that is of type 'directory'.\n\n        Returns:\n            The absolute path to the project root directory, or None if not found.\n        \"\"\"\n        for item in self.memory.get('look', []):\n            if item.get('type') == 'directory':\n                return item.get('file')\n        return None\n\n    def get_memory_context(self) ->str:\n        \"\"\"\n        Dynamically builds the context using RAG and chat history.\n\n        It retrieves relevant file content from the RAG index based on the latest\n        user query, includes project manifests for directories, and appends the\n        recent chat history.\n        \"\"\"\n        context = ''\n        for look in self.memory.get('look', []):\n            path = look.get('file')\n            if path and os.path.isdir(path):\n                content = look.get('content', '')\n                context += (\n                    f'--- Project Manifest for {path} ---\\n{content}\\n\\n')\n        last_user_message = next((msg['content'] for msg in reversed(self.\n            memory.get('chat', [])) if msg['role'] == 'user'), None)\n        if last_user_message:\n            rag_results = self.search_rag(last_user_message, k=3)\n            if rag_results:\n                context += '--- Relevant context from RAG ---\\n'\n                for doc, score, meta in rag_results:\n                    file_path = meta.get('file', 'Unknown source')\n                    context += f'Source: {file_path} (Score: {score:.4f})\\n'\n                    context += f'Content: {doc}\\n---\\n'\n                context += '\\n'\n        for msg in self.memory.get('chat', []):\n            context += f\"{msg['role'].capitalize()}: {msg['content']}\\n\"\n        return context.strip()\n\n    def clear_memory(self) ->None:\n        self.memory = {'chat': [], 'look': []}\n        self.save_memory()\n        self.rag_manager.clear_index()\n\n    def search_rag(self, query: str, k: int=3) ->List[tuple]:\n        \"\"\"\n        Search the RAG index for relevant documents.\n        \n        Args:\n            query: The search query\n            k: Number of results to return\n            \n        Returns:\n            List of (document_content, score, metadata) tuples\n        \"\"\"\n        return self.rag_manager.search(query, k)\n",
    "file": "/mnt/ProjectData/omni/memory_manager.py"
  },
  {
    "id": 68,
    "hash": "1503715e21300d3433a383484d00a3cb",
    "content": "\"\"\"\nOmni - AI-powered code generation and project-aware editing CLI tool\n\nIntegrates modular UI, memory, personality, and AST-based code editing.\n\"\"\"\nimport os\nimport subprocess\nimport requests\nimport json\nimport sys\nimport re\nimport argparse\nimport ast\nfrom datetime import datetime\nimport threading\nimport queue as Queue\nimport time\nfrom typing import List, Dict, Optional\nfrom rich import print\nfrom rich.panel import Panel\nfrom rich.console import Console\nfrom rich.tree import Tree\nfrom ui_manager import UIManager\nfrom personality_manager import PersonalityManager\nfrom memory_manager import MemoryManager\nfrom code_editor import CodeEditor\nfrom file_creator import FileCreator\nfrom git_manager import GitManager\nimport traceback\nDEFAULT_BACKEND = 'openrouter'\nOLLAMA_MODEL = 'phi4-reasoning'\nOPENROUTER_MODEL = 'qwen/qwen3-coder'\nDEFAULT_SAVE_DIR = os.path.expanduser('/mnt/ProjectData/omni/omni_saves/')\nCONFIG_FILE = 'config.json'\nMEMORY_FILE = 'memory.json'\nOLLAMA_API_URL = 'http://localhost:11434/api/generate'\nOPENROUTER_API_URL = 'https://openrouter.ai/api/v1/chat/completions'\nOPENROUTER_MODELS_API_URL = 'https://openrouter.ai/api/v1/models'\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\ncurrent_backend = DEFAULT_BACKEND\ncurrent_model = (OLLAMA_MODEL if DEFAULT_BACKEND == 'ollama' else\n    OPENROUTER_MODEL)\nOLLAMA_MODELS = {'deepseek': 'deepseek-coder:6.7b', 'codellama':\n    'codellama:13b', 'mistral': 'mistral:latest', 'llama2': 'llama2:latest',\n    'phind': 'phind-codellama:34b'}\nos.makedirs(DEFAULT_SAVE_DIR, exist_ok=True)\nTEMPLATES = {'flask':\n    \"\"\"from flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/')\ndef home():\n    return '<h1>Hello, Flask!</h1>'\n\nif __name__ == '__main__':\n    app.run(debug=True)\"\"\"\n    , 'html5':\n    \"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>New Page</title>\n</head>\n<body>\n    <h1>Hello World</h1>\n</body>\n</html>\"\"\"\n    , 'scraper':\n    \"\"\"import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        print(soup.title.text)\n    except Exception as e:\n        print(f\"[bold red]Error scraping {url}:[/] {e}\")\n\nif __name__ == \"__main__\":\n    scrape(\"https://example.com\")\"\"\"\n    }\nconsole = Console()\npersonality_manager = PersonalityManager(CONFIG_FILE)\nmemory_manager = MemoryManager(MEMORY_FILE)\nui_manager = UIManager()\nlast_query: Optional[str] = None\nlast_response: Optional[str] = None\nlast_code: Optional[str] = None\n\n\ndef start_ollama_server() ->None:\n    if current_backend != 'ollama':\n        return\n    try:\n        requests.get('http://localhost:11434', timeout=1)\n    except requests.exceptions.ConnectionError:\n        print('[cyan]Starting Ollama server...[/]')\n        subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL)\n\n\ndef query_llm(prompt: str) ->str:\n    personality = personality_manager.get_current_personality()\n    system_prompt = personality.get('system_prompt', '') if personality else ''\n    memory_context = memory_manager.get_memory_context()\n    rag_context = ''\n    try:\n        from rag_manager import RAGManager\n        project_root = memory_manager.get_project_root()\n        if project_root:\n            rag_manager = RAGManager()\n            if rag_manager.get_document_count() > 0:\n                results = rag_manager.search(prompt, k=3)\n                if results:\n                    rag_context = '\\n\\nRelevant context from codebase:\\n'\n                    for i, (doc, score, meta) in enumerate(results, 1):\n                        file_path = meta.get('file', 'Unknown')\n                        rag_context += f'{i}. [{file_path}] {doc}\\n'\n    except Exception:\n        pass\n    full_prompt = (\n        f'{system_prompt}\\n\\n{memory_context}{rag_context}\\n\\nUser: {prompt}')\n    with ui_manager.show_spinner('AI is listening and thinking...'):\n        if current_backend == 'ollama':\n            response = query_ollama(full_prompt)\n        elif current_backend == 'openrouter':\n            response = query_openrouter(full_prompt)\n        else:\n            response = '[bold red]Error:[/] Unknown backend'\n    return response\n\n\ndef query_openrouter(prompt: str) ->str:\n    if not OPENROUTER_API_KEY:\n        return '[bold red]Error:[/] OPENROUTER_API_KEY not set.'\n    headers = {'Authorization': f'Bearer {OPENROUTER_API_KEY}',\n        'Content-Type': 'application/json'}\n    payload = {'model': current_model, 'messages': [{'role': 'user',\n        'content': prompt}]}\n    try:\n        response = requests.post(OPENROUTER_API_URL, headers=headers, json=\n            payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['choices'][0]['message']['content']\n    except Exception as e:\n        error_details = ''\n        try:\n            error_details = response.json()\n        except:\n            error_details = response.text if hasattr(response, 'text'\n                ) else str(e)\n        return (\n            f'[bold red]OpenRouter Error:[/] {e}\\n[dim]Details: {error_details}[/dim]'\n            )\n\n\ndef query_ollama(prompt: str) ->str:\n    payload = {'model': current_model, 'prompt': prompt, 'stream': False}\n    try:\n        response = requests.post(OLLAMA_API_URL, json=payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['response']\n    except Exception as e:\n        return f'[bold red]Ollama Error:[/] {e}'\n\n\ndef extract_code(text: str) ->List[tuple[str, str]]:\n    matches = re.findall('```(\\\\w*)\\\\n([\\\\s\\\\S]*?)```', text)\n    return [(lang or 'text', code.strip()) for lang, code in matches\n        ] if matches else []\n\n\ndef list_models(args: list=None) ->None:\n    if current_backend == 'ollama':\n        print('[bold cyan]Popular Ollama Models:[/]')\n        for name, model_id in OLLAMA_MODELS.items():\n            print(\n                f\"{'\u2b50' if model_id == current_model else '  '} [yellow]{name:12}[/] \u2192 {model_id}\"\n                )\n    elif current_backend == 'openrouter':\n        list_openrouter_models(args or [])\n\n\ndef list_openrouter_models(args: list):\n    try:\n        from simple_term_menu import TerminalMenu\n    except ImportError:\n        ui_manager.show_error(\n            \"'simple-term-menu' is required. `pip install simple-term-menu`\")\n        return\n    try:\n        with ui_manager.show_spinner('Fetching models...'):\n            response = requests.get(OPENROUTER_MODELS_API_URL)\n            response.raise_for_status()\n        api_models_data = response.json().get('data', [])\n    except requests.RequestException as e:\n        ui_manager.show_error(f'Error fetching models: {e}')\n        return\n    all_models, sources = [], set()\n    for model_data in api_models_data:\n        if (model_id := model_data.get('id')):\n            sources.add(model_id.split('/')[0])\n            pricing = model_data.get('pricing', {})\n            is_free = pricing.get('prompt') == '0' and pricing.get('completion'\n                ) == '0'\n            all_models.append({'id': model_id, 'name': model_data.get(\n                'name'), 'source': model_id.split('/')[0], 'is_free': is_free})\n    all_models.sort(key=lambda x: (x['source'], x['name']))\n    if args and args[0].lower() == 'sources':\n        print('[bold cyan]Available Model Sources:[/]')\n        [print(f'  [yellow]{s}[/]') for s in sorted(list(sources))]\n        return\n    models_to_display, title = all_models, 'Select an OpenRouter Model'\n    if args:\n        filter_keyword = args[0].lower()\n        title = f\"Select a Model from '{filter_keyword}'\"\n        models_to_display = [m for m in all_models if filter_keyword in m[\n            'source'].lower()]\n        if not models_to_display:\n            ui_manager.show_error(f\"No models for source: '{filter_keyword}'\")\n            return\n    menu_entries = [\n        f\"{'\u2b50' if m['id'] == current_model else '  '} {m['name']} [dim]({m['id']}){' [green](FREE)[/]' if m['is_free'] else ''}[/dim]\"\n         for m in models_to_display]\n    try:\n        cursor_idx = next((i for i, m in enumerate(models_to_display) if m[\n            'id'] == current_model), 0)\n        chosen_index = TerminalMenu(menu_entries, title=f'{title}',\n            cursor_index=cursor_idx, cycle_cursor=True, clear_screen=True\n            ).show()\n        if chosen_index is not None:\n            set_model(models_to_display[chosen_index]['id'])\n        else:\n            print('Model selection cancelled.')\n    except Exception as e:\n        ui_manager.show_error(f'Menu display error: {e}')\n\n\ndef set_model(model_id: str) ->None:\n    global current_model\n    current_model = model_id\n    ui_manager.show_success(f'Model set to: {current_model}')\n\n\ndef switch_backend(backend_name: str) ->None:\n    global current_backend, current_model\n    backend_name = backend_name.lower()\n    if backend_name not in ['ollama', 'openrouter']:\n        ui_manager.show_error(f'Unknown backend: {backend_name}')\n        return\n    current_backend = backend_name\n    current_model = (OLLAMA_MODEL if backend_name == 'ollama' else\n        OPENROUTER_MODEL)\n    ui_manager.show_success(\n        f'Switched to {backend_name} backend with model: {current_model}')\n    if backend_name == 'ollama':\n        start_ollama_server()\n\n\ndef generate_project_manifest(path: str) ->tuple[str, List[str]]:\n    manifest = ''\n    file_paths = []\n    tree = Tree(f'[bold cyan]Project: {os.path.basename(path)}[/]')\n    exclude_dirs = {'__pycache__', '.git', 'venv', 'node_modules', '.idea',\n        'ollama'}\n    for root, dirs, files in os.walk(path):\n        dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.\n            startswith('.')]\n        relative_path = os.path.relpath(root, path)\n        branch = tree\n        if relative_path != '.':\n            parts = relative_path.split(os.sep)\n            for part in parts:\n                child = next((c for c in branch.children if c.label ==\n                    f'[magenta]{part}[/]'), None)\n                if not child:\n                    child = branch.add(f'[magenta]{part}[/]')\n                branch = child\n        for fname in sorted(files):\n            ext = os.path.splitext(fname)[1]\n            if ext not in ('.py', '.js', '.html', '.css', '.md', '.txt'):\n                continue\n            rel_path = os.path.join(relative_path, fname\n                ) if relative_path != '.' else fname\n            file_paths.append(rel_path)\n            branch.add(f'[green]{fname}[/]' if ext == '.py' else\n                f'[dim]{fname}[/]')\n            manifest += f'File: {rel_path}\\n\\n'\n    console.print(tree)\n    return manifest.strip(), file_paths\n\n\ndef look_command(path: str) ->None:\n    \"\"\"\n    Scans a directory or file and loads it into memory. It can resolve paths\n    relative to the current working directory or the project root in memory.\n    If a new directory is scanned, the previous 'look' context is cleared\n    to ensure the context remains relevant.\n    \"\"\"\n    resolved_path = resolve_file_path(path)\n    if not resolved_path:\n        ui_manager.show_error(f'\u274c Path not found: {path}')\n        return\n    if resolved_path != os.path.abspath(path):\n        ui_manager.show_success(\n            f\"Found '{path}' in project. Using: {resolved_path}\")\n    if os.path.isdir(resolved_path):\n        ui_manager.show_success(\n            \"New project directory detected. Clearing previous 'look' context.\"\n            )\n        memory_manager.memory['look'] = []\n        with ui_manager.show_spinner('Generating project manifest...'):\n            manifest = generate_project_manifest(resolved_path)\n        memory_manager.add_look_data(resolved_path, manifest)\n        ui_manager.show_success('\u2705 Project manifest added to memory.')\n    else:\n        try:\n            with ui_manager.show_spinner('Loading file...'):\n                with open(resolved_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n            for item in memory_manager.memory['look']:\n                if item.get('file') == resolved_path:\n                    item['content'] = content\n                    memory_manager.save_memory()\n                    ui_manager.show_success(\n                        '\u2705 Refreshed file content in memory.')\n                    return\n            memory_manager.add_look_data(resolved_path, content)\n            ui_manager.show_success('\u2705 File content added to memory.')\n        except Exception as e:\n            ui_manager.show_error(f'\u274c Error reading file: {e}')\n\n\ndef resolve_file_path(path: str) ->Optional[str]:\n    \"\"\"Resolves a file path, checking CWD first, then against project root in memory.\"\"\"\n    if os.path.exists(path):\n        return os.path.abspath(path)\n    project_root = memory_manager.get_project_root()\n    if project_root:\n        full_path = os.path.join(project_root, path)\n        if os.path.exists(full_path):\n            return full_path\n    return None\n\n\ndef _create_prompt_for_file_creation(file_name: str, instruction: str) ->str:\n    \"\"\"\n    Generate a robust prompt for file creation that instructs the AI to act as an expert,\n    produce complete and clean code, and avoid any extra commentary.\n    \"\"\"\n    return f\"\"\"You are an expert programmer tasked with creating a new file. Your goal is to generate complete, production-ready content based on the user's instruction.\n\nIMPORTANT RULES:\n- Provide ONLY the raw file content - no explanations, notes, or commentary outside the file itself\n- Include all necessary imports, boilerplate, and complete implementations\n- If creating code, ensure it's syntactically correct and follows best practices\n- For configuration files, use appropriate formatting (JSON, YAML, etc.)\n- For documentation files, use proper markdown formatting\n\nFile to create: {file_name}\nUser instruction: {instruction}\n\nGenerate the complete file content now:\"\"\"\n\n\ndef handle_file_create_command(file_path: str, instruction: str):\n    \"\"\"\n    Uses the LLM to generate content for a new file based on an instruction.\n    \"\"\"\n    global last_code\n    if os.path.exists(file_path):\n        if ui_manager.get_user_input(\n            f\"File '{file_path}' already exists. Overwrite? (y/n): \").lower(\n            ) not in ['yes', 'y']:\n            ui_manager.show_error('File creation cancelled.')\n            return\n    prompt = _create_prompt_for_file_creation(os.path.basename(file_path),\n        instruction)\n    with ui_manager.show_spinner(\n        f\"AI is generating content for '{file_path}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    if code_blocks:\n        new_content = code_blocks[0][1]\n    else:\n        new_content = response.strip()\n    if not new_content:\n        ui_manager.show_error('AI did not return any content.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    print(Panel(new_content, title=\n        f'[bold yellow]Proposed content for {file_path}[/]', border_style=\n        'yellow'))\n    if ui_manager.get_user_input('Create this file? (y/n): ').lower() in ['yes'\n        , 'y']:\n        try:\n            FileCreator.create(file_path, new_content)\n            last_code = new_content\n            ui_manager.show_success(f'File created successfully: {file_path}')\n        except IOError as e:\n            ui_manager.show_error(f'Error creating file: {e}')\n    else:\n        ui_manager.show_error('File creation cancelled.')\n\n\ndef look_all_command() ->None:\n    \"\"\"\n    Finds the project manifest in memory, reads every file listed, and adds their content to memory.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first to generate a manifest.\"\n            )\n        return\n    manifest_data = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and item.get('type'\n            ) == 'directory':\n            manifest_data = item.get('content')\n            break\n    if not manifest_data or not isinstance(manifest_data, (list, tuple)\n        ) or len(manifest_data) != 2:\n        ui_manager.show_error(\n            \"Could not find a valid project manifest in memory. Please run 'look <directory>' again.\"\n            )\n        return\n    file_paths = manifest_data[1]\n    if not file_paths:\n        ui_manager.show_error('No files found in the project manifest.')\n        return\n    total_files = len(file_paths)\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Loading {total_files} files from project manifest...'):\n        for file_path_relative in file_paths:\n            full_path = os.path.join(project_root, file_path_relative)\n            if os.path.isfile(full_path):\n                try:\n                    with open(full_path, 'r', encoding='utf-8') as f:\n                        content = f.read().strip()\n                    if not any(look['file'] == full_path for look in\n                        memory_manager.memory['look']):\n                        memory_manager.add_look_data(full_path, content)\n                        loaded_count += 1\n                except Exception as e:\n                    print(\n                        f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\"\n                        )\n    ui_manager.show_success(\n        f'\u2705 Loaded content for {loaded_count} new files into memory.')\n\n\ndef _load_all_project_files_if_needed():\n    \"\"\"\n    Checks if a project is loaded and automatically loads any files from its\n    manifest that are not already in the 'look' memory. This ensures a\n    complete context for editing and refactoring commands.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        return\n    manifest_content = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and 'File:' in item.get('content',\n            ''):\n            manifest_content = item['content']\n            break\n    if not manifest_content:\n        return\n    existing_file_paths = {item['file'] for item in memory_manager.memory.\n        get('look', []) if item.get('type') == 'file'}\n    file_paths_relative = re.findall('File: (.*)', manifest_content)\n    files_to_load = []\n    for rel_path in file_paths_relative:\n        full_path = os.path.join(project_root, rel_path)\n        if full_path not in existing_file_paths and os.path.isfile(full_path):\n            files_to_load.append((full_path, rel_path))\n    if not files_to_load:\n        return\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Auto-loading {len(files_to_load)} project files for context...'):\n        for full_path, file_path_relative in files_to_load:\n            try:\n                with open(full_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n                memory_manager.add_look_data(full_path, content)\n                loaded_count += 1\n            except Exception as e:\n                print(f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\")\n    if loaded_count > 0:\n        ui_manager.show_success(\n            f'\u2705 Loaded {loaded_count} new file(s) into memory for full project context.'\n            )\n\n\ndef _create_prompt_for_element_selection(file_name: str, instruction: str,\n    elements: List[str], element_structures: Dict[str, Dict]) ->str:\n    \"\"\"\n    Create a helper for the first stage of the 'edit' command. This prompt asks the AI\n    to analyze the user's instruction and intelligently select the most relevant code element to modify.\n    \"\"\"\n    element_details = []\n    for elem in elements:\n        if elem in element_structures:\n            struct = element_structures[elem]\n            detail = (\n                f\"{elem} ({struct['type']}, lines {struct['line_start']}-{struct['line_end']})\"\n                )\n            element_details.append(detail)\n        else:\n            element_details.append(elem)\n    return f\"\"\"You are an expert code analyzer. Your task is to identify what should be modified based on the user's instruction.\n\nFile: {file_name}\nAvailable elements: {', '.join(element_details) if element_details else 'None'}\n\nUser instruction: {instruction}\n\nRESPONSE FORMAT:\nChoose one of these response types:\n1. \"ELEMENT: <element_name>\" - to edit an entire function/class\n2. \"PARTIAL: <element_name> LINES: <start>-<end>\" - to edit specific lines within an element\n3. \"FILE\" - to edit the entire file or multiple elements\n\nRULES:\n- If the instruction mentions specific line numbers or a specific part of a function, use PARTIAL\n- If the instruction targets an entire function/class, use ELEMENT\n- If the instruction requires changes to multiple elements or file structure, use FILE\n- For PARTIAL edits, provide absolute line numbers from the original file\n\nWhat should be edited?\"\"\"\n\n\ndef _create_prompt_for_element_rewrite(file_name: str, element_name: str,\n    instruction: str, original_code: str, is_full_file: bool=False) ->str:\n    \"\"\"\n    Create a helper for the second stage of the 'edit' command. This prompt instructs the AI\n    to rewrite a specific code element (or the whole file) based on the user's request,\n    demanding a complete and syntactically correct code block as output.\n    \"\"\"\n    if is_full_file:\n        return f\"\"\"You are an expert programmer. Rewrite the entire file to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the entire file\n- Ensure all syntax is correct and the code is ready to run\n- Preserve existing functionality unless explicitly asked to change it\n- Include all necessary imports and maintain the file's structure\n- Do NOT include any explanations or comments outside the code\n\nFile: {file_name}\nTask: {instruction}\n\nCurrent file content:\n```python\n{original_code}\n```\n\nGenerate the complete updated file now:\"\"\"\n    else:\n        return f\"\"\"You are an expert programmer. Rewrite the specified element to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the element\n- Include any necessary imports at the top of your code block\n- Ensure the code is syntactically correct and maintains the same interface\n- Do NOT include explanations or comments outside the code block\n- The code must be a drop-in replacement for the original element\n\nFile: {file_name}\nElement to modify: {element_name}\nTask: {instruction}\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the complete updated element now:\"\"\"\n\n\ndef _create_prompt_for_partial_edit(file_name: str, element_name: str,\n    instruction: str, original_snippet: str, line_start: int, line_end: int,\n    full_element_code: str) ->str:\n    \"\"\"\n    Create a prompt for partial edits within a function or class.\n    This allows surgical changes to specific parts of code.\n    \"\"\"\n    return f\"\"\"You are an expert programmer. Make a surgical edit to a specific part of a function/class.\n\nCONTEXT:\n- File: {file_name}\n- Element: {element_name}\n- Lines to modify: {line_start}-{line_end}\n- Task: {instruction}\n\nIMPORTANT RULES:\n- Provide ONLY the code that will replace lines {line_start}-{line_end}\n- Your code must fit seamlessly into the existing function\n- Maintain proper indentation (the code will be auto-indented)\n- Do NOT include the function definition or other parts\n- Do NOT include explanations outside the code\n\nFull element for context:\n```python\n{full_element_code}\n```\n\nCode section to replace (lines {line_start}-{line_end}):\n```python\n{original_snippet}\n```\n\nGenerate ONLY the replacement code for the specified lines:\"\"\"\n\n\ndef handle_file_edit_command(file_path: str, instruction: str):\n    \"\"\"\n    Handles the entire workflow for editing a single file, ensuring full\n    project context is loaded before the AI makes any decisions.\n    Now supports partial edits within functions.\n    \"\"\"\n    global last_code\n    _load_all_project_files_if_needed()\n    resolved_path = resolve_file_path(file_path)\n    if not resolved_path:\n        ui_manager.show_error(f'File not found: {file_path}')\n        return\n    if resolved_path != os.path.abspath(file_path):\n        ui_manager.show_success(\n            f\"Found '{file_path}' in project. Using: {resolved_path}\")\n    try:\n        editor = CodeEditor(resolved_path)\n    except (ValueError, FileNotFoundError) as e:\n        ui_manager.show_error(str(e))\n        return\n    elements = editor.list_elements()\n    element_structures = {}\n    for elem in elements:\n        struct = editor.get_element_structure(elem)\n        if struct:\n            element_structures[elem] = struct\n    prompt1 = _create_prompt_for_element_selection(os.path.basename(\n        resolved_path), instruction, elements, element_structures)\n    with ui_manager.show_spinner('AI is analyzing file...'):\n        ai_response = query_llm(prompt1).strip()\n    if ai_response.upper() == 'FILE':\n        ui_manager.show_success('AI has chosen to edit the entire file.')\n        original_snippet = editor.source_code\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), 'entire file', instruction, original_snippet,\n            is_full_file=True)\n        edit_type = 'FILE'\n        element_to_edit = None\n        line_range = None\n    elif ai_response.startswith('PARTIAL:'):\n        parts = ai_response.split()\n        element_to_edit = parts[1]\n        if 'LINES:' in ai_response:\n            line_part = ai_response.split('LINES:')[1].strip()\n            if '-' in line_part:\n                line_start, line_end = map(int, line_part.split('-'))\n                line_range = line_start, line_end\n            else:\n                ui_manager.show_error('Invalid line range format')\n                return\n        else:\n            ui_manager.show_error('Missing line range for partial edit')\n            return\n        if element_to_edit not in elements:\n            ui_manager.show_error(f\"Element '{element_to_edit}' not found\")\n            return\n        ui_manager.show_success(\n            f\"AI selected partial edit of '{element_to_edit}' (lines {line_start}-{line_end})\"\n            )\n        original_snippet = editor.get_element_body_snippet(element_to_edit,\n            line_start, line_end)\n        if not original_snippet:\n            original_snippet = editor.get_source_of(element_to_edit)\n        full_element_code = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_partial_edit(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet,\n            line_start, line_end, full_element_code)\n        edit_type = 'PARTIAL'\n    elif ai_response.startswith('ELEMENT:'):\n        element_to_edit = ai_response.split(':', 1)[1].strip()\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    else:\n        element_to_edit = ai_response.splitlines()[0]\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    with ui_manager.show_spinner(f'AI is editing...'):\n        response = query_llm(prompt2)\n    code_blocks = extract_code(response)\n    if not code_blocks:\n        ui_manager.show_error('AI did not return a valid code block.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    new_code = code_blocks[0][1]\n    success = False\n    if edit_type == 'FILE':\n        try:\n            editor.tree = ast.parse(new_code)\n            success = True\n        except SyntaxError as e:\n            ui_manager.show_error(f'AI returned invalid Python syntax: {e}')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    elif edit_type == 'PARTIAL':\n        success = editor.replace_partial(element_to_edit, new_code,\n            line_start=line_range[0], line_end=line_range[1])\n        if not success:\n            ui_manager.show_error('Failed to apply partial edit.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    else:\n        success = editor.replace_element(element_to_edit, new_code)\n        if not success:\n            ui_manager.show_error(\n                'AI returned invalid code; could not be parsed or applied.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    if not (diff := editor.get_diff()):\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(diff, title=\n        f'[bold yellow]Proposed Changes for {resolved_path}[/]'))\n    if ui_manager.get_user_input('Apply changes? (y/n): ').lower() in ['yes',\n        'y']:\n        editor.save_changes()\n        last_code = editor.get_modified_source()\n        ui_manager.show_success(f'Changes saved to {resolved_path}.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_plan(instruction: str, memory_context: str\n    ) ->str:\n    \"\"\"\n    Create a specialized prompt-generation function for the 'refactor' command.\n    This prompt will explicitly define the required JSON structure for the plan\n    and instruct the AI to act as an expert project manager.\n    \"\"\"\n    return f\"\"\"You are an expert project manager and software architect. Analyze the project context and create a detailed refactoring plan.\n\nYour plan must be a valid JSON object with this exact structure:\n{{\n    \"actions\": [\n        {{\n            \"type\": \"MODIFY\" | \"CREATE\" | \"DELETE\" | \"PARTIAL\",\n            \"file\": \"relative/path/to/file.py\",\n            \"element\": \"function_or_class_name\",  // For MODIFY/DELETE/PARTIAL\n            \"element_name\": \"new_element_name\",    // For CREATE\n            \"line_start\": 10,                      // For PARTIAL only\n            \"line_end\": 20,                        // For PARTIAL only\n            \"reason\": \"Clear explanation of why this change is needed\",\n            \"description\": \"What this action will accomplish\",\n            \"anchor_element\": \"optional_anchor\",   // Optional for CREATE\n            \"position\": \"before\" | \"after\"         // Optional for CREATE\n        }}\n    ]\n}}\n\nACTION TYPES:\n- MODIFY: Change an entire function, class, or method\n- PARTIAL: Change specific lines within a function/class (requires line_start and line_end)\n- CREATE: Add new functions, classes, or files\n- DELETE: Remove functions, classes, variables, or imports\n\nRULES FOR YOUR PLAN:\n- Use PARTIAL when you only need to change a small part of a function\n- Use MODIFY when restructuring an entire function or class\n- Each action must have all required fields based on its type\n- File paths must be relative to the project root\n- Be specific and surgical - avoid unnecessary changes\n- Consider dependencies between changes\n- Order actions logically (e.g., create dependencies before using them)\n\n### Project Context ###\n{memory_context}\n\n### Refactoring Request ###\n{instruction}\n\nGenerate ONLY the JSON plan - no explanations or markdown:\"\"\"\n\n\ndef _get_refactor_plan(instruction: str) ->Optional[List[Dict]]:\n    \"\"\"\n    Generates a refactoring plan from the LLM.\n\n    This function encapsulates the logic for checking project context,\n    constructing a prompt, querying the LLM, and parsing the resulting\n    JSON plan for a refactoring task.\n\n    Args:\n        instruction: The user's high-level refactoring instruction.\n\n    Returns:\n        A list of action dictionaries if a valid plan is generated,\n        otherwise None.\n    \"\"\"\n    if not memory_manager.get_project_root():\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return None\n    memory_context = memory_manager.get_memory_context()\n    plan_prompt = _create_prompt_for_refactor_plan(instruction, memory_context)\n    with ui_manager.show_spinner('AI is creating an execution plan...'):\n        plan_str = query_llm(plan_prompt)\n    try:\n        match = re.search('\\\\{.*\\\\}', plan_str, re.DOTALL)\n        if not match:\n            raise ValueError('No JSON object found in the response.')\n        plan = json.loads(match.group(0))\n        actions = plan.get('actions', [])\n        if not actions:\n            raise ValueError(\"No 'actions' key found in plan or plan is empty.\"\n                )\n        return actions\n    except (json.JSONDecodeError, ValueError) as e:\n        ui_manager.show_error(f'AI failed to generate a valid plan: {e}')\n        print(Panel(plan_str, title=\"[yellow]AI's Invalid Plan Response[/]\",\n            border_style='yellow'))\n        return None\n\n\ndef _display_and_confirm_plan(plan: Dict) ->bool:\n    \"\"\"\n    Displays the generated execution plan to the user and asks for confirmation.\n\n    This helper function separates the UI interaction of plan confirmation from\n    the main refactoring logic.\n\n    Args:\n        plan: A dictionary, expected to contain an 'actions' key with a list of action dicts.\n\n    Returns:\n        True if the user confirms the plan, False otherwise.\n    \"\"\"\n    actions = plan.get('actions', [])\n    if not actions:\n        ui_manager.show_error('The generated plan is empty. Aborting.')\n        return False\n    ui_manager.show_success('AI has created a plan:')\n    for i, action in enumerate(actions):\n        action_type = action.get('type', 'N/A')\n        element = action.get('element') or action.get('element_name', 'N/A')\n        reason = action.get('reason') or action.get('description', '')\n        file_path = action.get('file', '')\n        if action_type == 'PARTIAL':\n            line_start = action.get('line_start', '?')\n            line_end = action.get('line_end', '?')\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} (lines {line_start}-{line_end}) - {reason}'\n                )\n        else:\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} - {reason}'\n                )\n    if ui_manager.get_user_input('\\nProceed with this plan? (y/n): ').lower(\n        ) in ['yes', 'y']:\n        return True\n    else:\n        ui_manager.show_error('Execution aborted by user.')\n        return False\n\n\ndef _apply_refactor_changes(editors: Dict[str, CodeEditor]) ->None:\n    \"\"\"\n    Consolidates changes from multiple CodeEditor instances, shows a unified\n    diff, and prompts the user to apply them.\n    \n    This helper function abstracts the final step of a refactor, ensuring\n    all proposed modifications are presented to the user for a final review\n    before any files are written to disk.\n\n    Args:\n        editors: A dictionary mapping absolute file paths to their\n                 corresponding CodeEditor instances which hold the\n                 proposed changes in their AST.\n    \"\"\"\n    full_diff = ''\n    for editor in editors.values():\n        diff = editor.get_diff()\n        if diff:\n            full_diff += diff + '\\n'\n    if not full_diff.strip():\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(full_diff, title=\n        '[bold yellow]Proposed Project-Wide Changes[/]'))\n    if ui_manager.get_user_input('Apply all changes? (y/n): ').lower() in [\n        'yes', 'y']:\n        for editor in editors.values():\n            editor.save_changes()\n        ui_manager.show_success('\u2705 Project changes applied successfully.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_action(action_type: str, file_path: str,\n    action_details: Dict) ->str:\n    \"\"\"\n    Create a helper to generate prompts for individual 'CREATE' or 'MODIFY' steps\n    within a refactor plan. This ensures the AI produces code for the specific\n    sub-task in the correct context.\n    \"\"\"\n    if action_type == 'MODIFY':\n        element_name = action_details['element_name']\n        reason = action_details['reason']\n        original_code = action_details['original_code']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- Element: {element_name}\n- Reason for change: {reason}\n\nRULES:\n- Provide ONLY the complete updated code for the element\n- Include any necessary imports at the top\n- Ensure the code integrates properly with the rest of the file\n- Maintain the same function/class signature unless the change requires otherwise\n- No explanations outside the code block\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the updated element code:\"\"\"\n    elif action_type == 'CREATE':\n        element_name = action_details['element_name']\n        description = action_details['description']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- New element to create: {element_name}\n- Purpose: {description}\n\nRULES:\n- Provide ONLY the complete code for the new element\n- Include all necessary imports at the top\n- Follow the coding style and patterns used in the project\n- Ensure the code is production-ready and well-structured\n- For non-Python files, provide the complete file content\n- No explanations outside the code block\n\nGenerate the new element code:\"\"\"\n\n\ndef _process_refactor_action(action: Dict, project_base_path: str, editors:\n    Dict) ->bool:\n    \"\"\"\n    Processes a single refactoring action from the plan.\n\n    This function handles the execution of a single action from the refactoring plan,\n    including LLM code generation and applying changes to in-memory editors or files.\n\n    Args:\n        action: A dictionary containing action details (type, file, element, etc.)\n        project_base_path: The absolute path to the project root\n        editors: Dictionary mapping file paths to their CodeEditor instances\n\n    Returns:\n        True if the action was processed successfully, False otherwise\n    \"\"\"\n    file_path_relative = action.get('file')\n    if not file_path_relative:\n        ui_manager.show_error(\n            f\"Action is missing 'file' key. Skipping: {action}\")\n        return False\n    file_path_absolute = os.path.join(project_base_path, file_path_relative)\n    action_type = action.get('type', '').upper()\n    prompt, element_name = '', ''\n    if action_type == 'MODIFY':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_source_of(element_name)\n            if not original_snippet:\n                ui_manager.show_error(\n                    f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                    )\n                return False\n            action_details = {'element_name': element_name, 'reason':\n                reason, 'original_code': original_snippet}\n            prompt = _create_prompt_for_refactor_action('MODIFY',\n                file_path_relative, action_details)\n    elif action_type == 'PARTIAL':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        line_start = action.get('line_start')\n        line_end = action.get('line_end')\n        if not all([element_name, line_start, line_end]):\n            ui_manager.show_error(\n                f'PARTIAL action missing required fields. Skipping: {action}')\n            return False\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_element_body_snippet(element_name,\n                line_start, line_end)\n            if not original_snippet:\n                original_snippet = editor.get_source_of(element_name)\n                if not original_snippet:\n                    ui_manager.show_error(\n                        f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                        )\n                    return False\n            full_element_code = editor.get_source_of(element_name)\n            prompt = _create_prompt_for_partial_edit(file_path_relative,\n                element_name, reason, original_snippet, line_start,\n                line_end, full_element_code)\n    elif action_type == 'CREATE':\n        element_name = action.get('element_name')\n        description = action.get('description')\n        action_details = {'element_name': element_name, 'description':\n            description}\n        prompt = _create_prompt_for_refactor_action('CREATE',\n            file_path_relative, action_details)\n    else:\n        ui_manager.show_error(f\"Invalid action type '{action_type}'. Skipping.\"\n            )\n        return False\n    with ui_manager.show_spinner(\n        f\"AI: {action_type} on '{element_name or file_path_relative}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    new_content = code_blocks[0][1] if code_blocks else response.strip()\n    if not new_content:\n        ui_manager.show_error(\n            f'AI failed to generate content for action: {action}')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return False\n    if not file_path_relative.endswith('.py'):\n        try:\n            FileCreator.create(file_path_absolute, new_content)\n            ui_manager.show_success(\n                f\"File '{file_path_relative}' created/updated.\")\n            return True\n        except IOError as e:\n            ui_manager.show_error(\n                f\"Failed to create file '{file_path_relative}': {e}\")\n            return False\n    if file_path_absolute not in editors:\n        try:\n            if not os.path.exists(file_path_absolute):\n                os.makedirs(os.path.dirname(file_path_absolute), exist_ok=True)\n                with open(file_path_absolute, 'w') as f:\n                    f.write('')\n            editors[file_path_absolute] = CodeEditor(file_path_absolute)\n        except Exception as e:\n            ui_manager.show_error(\n                f'Error loading file {file_path_absolute}: {e}')\n            return False\n    editor = editors[file_path_absolute]\n    if action_type == 'MODIFY':\n        if not editor.replace_element(element_name, new_content):\n            ui_manager.show_error(\n                f\"Failed to apply MODIFY change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic MODIFY Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'PARTIAL':\n        if not editor.replace_partial(element_name, new_content, line_start,\n            line_end):\n            ui_manager.show_error(\n                f\"Failed to apply PARTIAL change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic PARTIAL Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'CREATE':\n        anchor = action.get('anchor_element')\n        position = action.get('position', 'after')\n        if not editor.add_element(new_content, anchor_name=anchor, before=\n            position == 'before'):\n            ui_manager.show_error(\n                f\"Failed to apply CREATE change for '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic CREATE Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    return True\n\n\ndef handle_project_refactor_command(instruction: str):\n    \"\"\"\n    Orchestrates a multi-file, multi-step code refactoring process.\n    \n    This function serves as a high-level orchestrator that delegates specific tasks\n    to helper functions, improving readability, modularity, and maintainability.\n    \"\"\"\n    _load_all_project_files_if_needed()\n    actions = _get_refactor_plan(instruction)\n    if not actions:\n        return\n    plan = {'actions': actions}\n    if not _display_and_confirm_plan(plan):\n        return\n    editors: Dict[str, CodeEditor] = {}\n    project_base_path = memory_manager.get_project_root()\n    successful_actions = 0\n    total_actions = len(actions)\n    for i, action in enumerate(actions, 1):\n        ui_manager.show_success(f'Processing action {i}/{total_actions}...')\n        action_type = action.get('type', '').upper()\n        file_path_relative = action.get('file')\n        if not file_path_relative:\n            ui_manager.show_error(\n                f\"Action is missing 'file' key. Skipping: {action}\")\n            continue\n        file_path_absolute = os.path.join(project_base_path, file_path_relative\n            )\n        if action_type == 'DELETE':\n            element_name = action.get('element')\n            if not element_name:\n                ui_manager.show_error(\n                    f\"DELETE action missing 'element' key. Skipping: {action}\")\n                continue\n            if not file_path_relative.endswith('.py'):\n                ui_manager.show_error(\n                    f'DELETE actions are only supported for Python files. Skipping.'\n                    )\n                continue\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    continue\n            editor = editors[file_path_absolute]\n            if editor.delete_element(element_name):\n                successful_actions += 1\n                ui_manager.show_success(\n                    f\"Successfully deleted '{element_name}' from '{file_path_relative}'.\"\n                    )\n            else:\n                ui_manager.show_error(\n                    f\"Failed to delete '{element_name}' from '{file_path_relative}'.\"\n                    )\n        elif _process_refactor_action(action, project_base_path, editors):\n            successful_actions += 1\n        else:\n            ui_manager.show_error(\n                f'Action {i} failed, continuing with remaining actions...')\n    if successful_actions == 0:\n        ui_manager.show_error('No actions were successfully executed.')\n        return\n    elif successful_actions < total_actions:\n        ui_manager.show_error(\n            f'Only {successful_actions}/{total_actions} actions completed successfully.'\n            )\n    else:\n        ui_manager.show_success(\n            f'All {total_actions} actions completed successfully.')\n    _apply_refactor_changes(editors)\n\n\ndef _create_prompt_for_commit_message(diff: str) ->str:\n    \"\"\"\n    Create a dedicated prompt function for the 'commit' command. This prompt will\n    instruct the AI to analyze a git diff and generate a concise commit message\n    following the Conventional Commits standard.\n    \"\"\"\n    return f\"\"\"You are an expert developer writing a Git commit message. Your task is to analyze the provided git diff and create a professional commit message.\n\nCOMMIT MESSAGE RULES:\n- Follow the Conventional Commits specification\n- Format: <type>(<optional scope>): <subject>\n- Types: feat, fix, docs, style, refactor, perf, test, build, ci, chore, revert\n- Subject line: max 50 characters, imperative mood, no period\n- Optional body: explain what and why (not how), wrap at 72 characters\n- Be specific and concise\n- Focus on the intent and impact of the changes\n\nEXAMPLES OF GOOD COMMIT MESSAGES:\n- feat(auth): add OAuth2 integration for Google login\n- fix(api): handle null response in user endpoint\n- refactor(database): optimize query performance for large datasets\n- docs(readme): update installation instructions for Windows\n\nRespond with ONLY the commit message - no markdown, quotes, or explanations.\n\n--- GIT DIFF TO ANALYZE ---\n{diff}\n\nGenerate the commit message:\"\"\"\n\n\ndef handle_commit_command():\n    \"\"\"\n    Orchestrates an AI-assisted Git commit workflow with improved error handling.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return\n    try:\n        git_manager = GitManager(project_root)\n    except ValueError as e:\n        ui_manager.show_error(str(e))\n        return\n    changed_files = git_manager.get_changed_files()\n    if not changed_files:\n        ui_manager.show_success(\n            'No changes to commit. Everything is up to date.')\n        return\n    staged_diff = git_manager.get_diff(staged=True)\n    unstaged_diff = git_manager.get_diff()\n    full_diff = f'{staged_diff}\\n{unstaged_diff}'.strip()\n    if not full_diff.strip():\n        ui_manager.show_success(\n            'No content changes detected (e.g., only file mode changes).')\n        return\n    prompt = _create_prompt_for_commit_message(full_diff)\n    commit_message = query_llm(prompt).strip()\n    if not commit_message:\n        ui_manager.show_error(\n            'AI failed to generate a commit message. Aborting.')\n        return\n    files_to_commit_str = '\\n'.join(f'- {f}' for f in changed_files)\n    plan_panel_content = f\"\"\"[bold]Files to be staged:[/]\n[yellow]{files_to_commit_str}[/]\n\n[bold]AI-Generated Commit Message:[/]\n[green]{commit_message}[/]\"\"\"\n    print(Panel(plan_panel_content, title='[bold cyan]Commit Plan[/]',\n        border_style='cyan'))\n    if ui_manager.get_user_input('\\nProceed with commit? (y/n): ').lower() in [\n        'yes', 'y']:\n        try:\n            git_manager.add(changed_files)\n            ui_manager.show_success('\u2705 Files staged.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Staging failed: {e.stderr}')\n            return\n        try:\n            git_manager.commit(commit_message)\n            ui_manager.show_success('\u2705 Commit successful.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Commit failed: {e.stderr}')\n            return\n        if ui_manager.get_user_input('Push changes to remote? (y/n): ').lower(\n            ) in ['yes', 'y']:\n            try:\n                git_manager.push()\n                ui_manager.show_success('\u2705 Push successful.')\n            except subprocess.CalledProcessError as e:\n                ui_manager.show_error(f'Push failed: {e.stderr}')\n        else:\n            ui_manager.show_error('Push cancelled.')\n    else:\n        ui_manager.show_error('Commit aborted by user.')\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef interactive_mode() ->None:\n    global last_query, last_response, last_code\n    try:\n        from Testing.overlay_engine import show_sequential_popup\n        gui_available = True\n    except ImportError:\n        gui_available = False\n    print(Panel(\n        \"\"\"[bold cyan]Omni Interactive Mode[/]\n[dim]Type 'help' for commands, 'exit' to quit.[/dim]\"\"\"\n        , border_style='cyan'))\n    personality_name = personality_manager.get_current_personality().get('name'\n        , 'Default')\n    gui_enabled = False\n    if gui_available:\n        try:\n            with open(CONFIG_FILE, 'r') as f:\n                config = json.load(f)\n                if config.get('gui_enabled', False):\n                    gui_enabled = True\n        except (FileNotFoundError, json.JSONDecodeError):\n            pass\n    refresh_status_panel(personality_name)\n    while True:\n        try:\n            user_input = ui_manager.get_user_input('\\n> ')\n            if not user_input:\n                continue\n            command, *args = user_input.split(maxsplit=1)\n            arg_str = args[0] if args else ''\n            if command == 'exit':\n                memory_manager.save_memory()\n                print('[bold cyan]Goodbye![/]')\n                break\n            elif command == 'help':\n                print(\n                    \"\"\"[bold]Commands:[/]\n\n  [bold cyan]Core & Project Commands[/]\n  [yellow]send <prompt>[/]        - Ask the LLM a question.\n  [yellow]look <path>[/]          - Read file or scan directory into memory.\n  [yellow]look_all[/]            - Recursively scan the project directory into memory.\n  [yellow]create <file> \"instr\"[/] - Create a new file using AI.\n  [yellow]edit <file> \"instr\"[/]   - Edit a specific file using AI.\n  [yellow]refactor \"instr\"[/]      - Refactor project in memory based on instruction.\n  [yellow]commit[/]               - Commit changes with an AI-generated message.\n  [yellow]rag <query>[/]         - Query the RAG system for context retrieval.\n\n  [bold cyan]File & Code Management[/]\n  [yellow]save <filename>[/]     - Save last AI response to a file.\n  [yellow]list[/]               - List saved files.\n  [yellow]run[/]                 - Run the last generated Python code.\n\n  [bold cyan]Session & Config[/]\n  [yellow]history[/]             - Show the full chat history.\n  [yellow]memory clear[/]        - Clear the chat and file memory.\n  [yellow]backend <name>[/]      - Switch AI backend (e.g., openrouter, ollama).\n  [yellow]models [src][/]        - Interactively list and select models.\n  [yellow]set model <id>[/]      - Set the model directly by its ID.\n  [yellow]personality <cmd>[/]   - Manage AI personalities ('list', 'set', 'add').\n\"\"\"\n                    )\n            elif command == 'send':\n                last_query = arg_str\n                response = query_llm(arg_str)\n                last_response = response\n                memory_manager.add_chat_message('user', last_query)\n                memory_manager.add_chat_message('assistant', last_response)\n                if gui_enabled:\n                    threading.Thread(target=show_sequential_popup, args=(\n                        100, 100, response, f'Omni - {personality_name}'),\n                        daemon=True).start()\n                print(Panel(response, title='[cyan]Response[/]'))\n                if (code_blocks := extract_code(response)):\n                    last_code = code_blocks[0][1]\n            elif command == 'look':\n                look_command(arg_str)\n            elif command == 'look_all':\n                look_all_command()\n            elif command == 'create':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_create_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: create <file_path> \"<instruction>\"')\n            elif command == 'edit':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_edit_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: edit <file_path> \"<instruction>\"')\n            elif command == 'refactor':\n                if not arg_str:\n                    ui_manager.show_error('Usage: refactor \"<instruction>\"')\n                else:\n                    handle_project_refactor_command(arg_str.strip('\"'))\n            elif command == 'commit':\n                handle_commit_command()\n            elif command == 'models':\n                list_models(arg_str.split())\n            elif command == 'set' and arg_str.startswith('model '):\n                set_model(arg_str[6:])\n            elif command == 'backend':\n                switch_backend(arg_str)\n            elif command == 'history':\n                ui_manager.display_history(memory_manager.get_memory_context())\n            elif command == 'memory' and arg_str == 'clear':\n                memory_manager.clear_memory()\n                ui_manager.show_success('\u2705 Memory cleared')\n            elif command == 'personality':\n                p_args = arg_str.split(maxsplit=1)\n                cmd = p_args[0] if p_args else ''\n                p_arg_str = p_args[1] if len(p_args) > 1 else ''\n                if cmd == 'list':\n                    for p in personality_manager.list_personalities():\n                        print(f\"- {p['name']}: {p['description']}\")\n                elif cmd == 'set' and p_arg_str:\n                    if personality_manager.set_current_personality(p_arg_str):\n                        personality_name = p_arg_str\n                        ui_manager.show_success(\n                            f'Set personality to {personality_name}')\n                    else:\n                        ui_manager.show_error('Personality not found.')\n                else:\n                    ui_manager.show_error(\n                        \"Invalid personality command. Use 'list' or 'set <name>'.\"\n                        )\n            elif command == 'run':\n                run_python_code()\n            elif command == 'save':\n                if last_response:\n                    save_code(last_response, arg_str or\n                        f\"omni_save_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n                        )\n                else:\n                    ui_manager.show_error('No response to save.')\n            elif command == 'list':\n                files = sorted(os.listdir(DEFAULT_SAVE_DIR))\n                print('\\n'.join(f'  - {f}' for f in files) if files else\n                    '[yellow]No saved files.[/]')\n            elif command == 'rag':\n                if not arg_str:\n                    ui_manager.show_error('Usage: rag \"<query>\"')\n                else:\n                    from rag_manager import RAGManager\n                    project_root = memory_manager.get_project_root()\n                    if not project_root:\n                        ui_manager.show_error(\n                            \"No project context in memory. Use 'look <directory>' first.\"\n                            )\n                        continue\n                    rag = RAGManager()\n                    if rag.get_document_count() == 0:\n                        ui_manager.show_error(\n                            'RAG index is empty. Please add documents first.')\n                        continue\n                    results = rag.search(arg_str, k=3)\n                    if not results:\n                        ui_manager.show_error('No relevant documents found.')\n                        continue\n                    print(Panel('[bold]RAG Results:[/]', title=\n                        '[cyan]Retrieval-Augmented Generation[/]'))\n                    for i, (content, score, metadata) in enumerate(results, 1):\n                        file_path = metadata.get('file', 'Unknown')\n                        print(\n                            f'[bold cyan]{i}. {file_path}[/] (Score: {score:.4f})'\n                            )\n                        print(Panel(content[:500] + '...' if len(content) >\n                            500 else content, border_style='dim'))\n                    follow_up = ui_manager.get_user_input(\n                        \"\"\"\nWould you like to ask a follow-up question with this context? (y/n): \"\"\"\n                        )\n                    if follow_up.lower() in ['y', 'yes']:\n                        follow_up_query = ui_manager.get_user_input(\n                            'Follow-up query: ')\n                        if follow_up_query:\n                            context_parts = [\n                                f'Document {i} (Score: {score:.4f}):\\n{content}'\n                                 for i, (content, score, _) in enumerate(\n                                results, 1)]\n                            context = '\\n\\n'.join(context_parts)\n                            rag_prompt = f\"\"\"Based on the following context, please answer the question.\n\nContext:\n{context}\n\nQuestion: {follow_up_query}\"\"\"\n                            response = query_llm(rag_prompt)\n                            print(Panel(response, title=\n                                '[cyan]RAG-Augmented Response[/]'))\n            else:\n                ui_manager.show_error(\"Unknown command. Type 'help'.\")\n            refresh_status_panel(personality_name)\n        except KeyboardInterrupt:\n            memory_manager.save_memory()\n            print('\\n[bold cyan]Goodbye![/]')\n            break\n        except Exception as e:\n            ui_manager.show_error(f'An unexpected error occurred: {e}')\n\n\ndef run_python_code() ->None:\n    global last_code\n    if not last_code:\n        ui_manager.show_error('No Python code in memory to run.')\n        return\n    temp_file = os.path.join(DEFAULT_SAVE_DIR, 'temp_run.py')\n    try:\n        with open(temp_file, 'w') as f:\n            f.write(last_code)\n        print('[bold cyan]\\n--- Running Code ---\\n[/]')\n        subprocess.run([sys.executable, temp_file], check=True)\n        print('[bold cyan]\\n--- Code Finished ---\\n[/]')\n    except Exception as e:\n        ui_manager.show_error(f'Error running code: {e}')\n    finally:\n        if os.path.exists(temp_file):\n            os.remove(temp_file)\n\n\ndef save_code(content: str, filename: str) ->None:\n    filepath = os.path.join(DEFAULT_SAVE_DIR, filename)\n    try:\n        with open(filepath, 'w') as f:\n            f.write(content)\n        ui_manager.show_success(f'Saved to: {filepath}')\n    except IOError as e:\n        ui_manager.show_error(f'Error saving file: {e}')\n\n\ndef main() ->None:\n    try:\n        import astor\n    except ImportError:\n        print(\"[bold red]Error:[/] 'astor' is required. `pip install astor`\")\n        sys.exit(1)\n    try:\n        import simple_term_menu\n    except ImportError:\n        print(\n            \"[bold red]Error:[/] 'simple-term-menu' is required. `pip install simple-term-menu`\"\n            )\n        sys.exit(1)\n    parser = argparse.ArgumentParser(description=\n        'Omni - AI-powered code tool', add_help=False)\n    parser.add_argument('command', nargs='?', help='Main command.')\n    parser.add_argument('args', nargs='*', help='Arguments for the command.')\n    parser.add_argument('-h', '--help', action='store_true')\n    args, _ = parser.parse_known_args()\n    if args.help or not args.command:\n        interactive_mode()\n    elif args.command == 'look' and args.args:\n        look_command(args.args[0])\n    elif args.command == 'edit' and len(args.args) >= 2:\n        handle_file_edit_command(args.args[0], ' '.join(args.args[1:]))\n    elif args.command == 'models':\n        list_models(args.args)\n    else:\n        interactive_mode()\n\n\ndef refresh_status_panel(personality_name: str) ->None:\n    ui_manager.display_status_panel(personality_name, current_backend,\n        current_model, len(memory_manager.memory.get('chat', [])), len(\n        memory_manager.memory.get('look', [])))\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/omni.py"
  },
  {
    "id": 69,
    "hash": "db1585da7840e9dc17f3ab8c0a19f6f2",
    "content": "import json\nfrom typing import Dict, List, Optional\n\nclass PersonalityManager:\n    \"\"\"Manages AI personalities via JSON config.\"\"\"\n\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.personalities: List[Dict[str, str]] = self.load_personalities()\n        self.current_personality: Optional[str] = \"default\"  # Default\n\n    def load_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"Load personalities from JSON; auto-create if missing.\"\"\"\n        default = [{\"name\": \"default\", \"description\": \"Helpful assistant\", \"system_prompt\": \"You are a helpful AI assistant.\"}]\n        default_gui = {\n            \"gui_enabled\": True,\n            \"wake_word\": \"Jarvis\",\n            \"overlay_opacity\": 0.8,\n            \"font_size\": 16\n        }\n        try:\n            with open(self.config_file, 'r') as f:\n                data = json.load(f)\n                if \"personalities\" not in data:\n                    data[\"personalities\"] = default\n                if \"gui_enabled\" not in data:\n                    data.update(default_gui)\n                    self.save_personalities(data[\"personalities\"])  # Save with defaults\n                \n                return data[\"personalities\"]\n        except FileNotFoundError:\n            self.save_personalities(default)\n            return default\n        except json.JSONDecodeError:\n            print(\"[yellow]Invalid config. Resetting to default.[/]\")\n            self.save_personalities(default)\n            return default\n\n    def save_personalities(self, personalities: List[Dict[str, str]]) -> None:\n        \"\"\"Save with GUI config.\"\"\"\n        data = {\"personalities\": personalities}\n        data.update({\"gui_enabled\": True, \"wake_word\": \"Jarvis\", \"overlay_opacity\": 0.8, \"font_size\": 16})  # Defaults\n        with open(self.config_file, 'w') as f:\n            json.dump(data, f, indent=4)\n\n    def add_personality(self, name: str, description: str, system_prompt: str) -> None:\n        \"\"\"Add a new personality.\"\"\"\n        self.personalities.append({\"name\": name, \"description\": description, \"system_prompt\": system_prompt})\n        self.save_personalities(self.personalities)\n\n    def list_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"List all personalities.\"\"\"\n        return self.personalities\n\n    def set_current_personality(self, name: str) -> bool:\n        \"\"\"Set the current personality.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == name:\n                self.current_personality = name\n                return True\n        return False\n\n    def get_current_personality(self) -> Dict[str, str]:\n        \"\"\"Get the current personality dict.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == self.current_personality:\n                return p\n        return {}  # Fallback",
    "file": "/mnt/ProjectData/omni/personality_manager.py"
  },
  {
    "id": 70,
    "hash": "da963f141c557fe12f1a26374f3e5ff4",
    "content": "# python_ast_adapter.py\n\n\"\"\"\nPythonASTAdapter - Concrete AST adapter for Python using built-in `ast` and `astor`.\n\nThis module implements the ASTAdapter interface specifically for Python,\nleveraging the standard library's `ast` module for parsing and\nmanipulation, and `astor` for code generation.\n\"\"\"\n\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for asttokens (for enhanced partial edits)\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n    # print(\"Warning: asttokens not installed. Partial edits will be limited.\")\n\n\nclass PythonASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for Python source code.\n\n    This adapter uses Python's built-in `ast` module to parse and manipulate\n    the code, and `astor` for code generation and source-to-source transformations.\n    It holds the parsed AST tree and provides methods to interact with it\n    according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the PythonASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The Python source code as a string.\n        \"\"\"\n        # Store source code for diffing and potential asttokens use\n        self.source_code: str = source_code\n        # Will hold the parsed AST tree\n        self.tree: Optional[ast.AST] = None\n        # Will hold a mapping of element names to their AST nodes\n        self.nodes: Dict[str, ast.AST] = {}\n        # asttokens instance for enhanced source mapping (if available)\n        self.atok: Optional[asttokens.ASTTokens] = None\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the Python source code and maps elements.\n\n        Args:\n            source_code: The Python source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid Python syntax.\n        \"\"\"\n        try:\n            self.tree = ast.parse(source_code)\n        except SyntaxError as e:\n            raise ValueError(f\"Invalid Python syntax: {e}\") from e\n\n        self.nodes = self._map_nodes()\n        if ASTTOKENS_AVAILABLE:\n            try:\n                self.atok = asttokens.ASTTokens(source_code, parse=True)\n            except Exception:\n                # If asttokens fails for any reason, continue without it\n                self.atok = None\n        else:\n            self.atok = None\n\n    def _map_nodes(self) -> Dict[str, ast.AST]:\n        \"\"\"\n        Walks the AST and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their AST nodes.\n        \"\"\"\n        nodes: Dict[str, ast.AST] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        for node in ast.walk(self.tree):\n            # Map functions and classes by name\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                # Use 'not in' to prioritize top-level definitions in case of conflicts\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            # Map assignments by target variable name(s)\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            # Map imports by their alias or original name\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int, line_end: Optional[int] = None) -> Optional[Tuple[int, ast.AST]]:\n        \"\"\"\n        Finds a statement within a body based on line numbers.\n\n        Args:\n            body: The list of AST nodes representing the body.\n            line_start: The starting line number to search for.\n            line_end: The optional ending line number.\n\n        Returns:\n            A tuple of (index, statement node) if found, otherwise None.\n        \"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = getattr(stmt, 'end_lineno', stmt.lineno)\n                    # Check for overlap or containment\n                    if (stmt.lineno <= line_start <= stmt_end) or (stmt.lineno <= line_end <= stmt_end) or \\\n                       (line_start <= stmt.lineno and line_end >= stmt_end):\n                        return (i, stmt)\n                else:\n                    if stmt.lineno == line_start:\n                        return (i, stmt)\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.ImportFrom]]) -> None:\n        \"\"\"\n        Adds new import nodes to the file's AST, typically at the top.\n\n        Args:\n            new_import_nodes: A list of ast.Import or ast.ImportFrom nodes.\n        \"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return # Cannot add imports without a valid module tree\n\n        # Get string representations of existing imports to avoid duplicates\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                try:\n                    existing_imports_str.add(astor.to_source(node).strip())\n                except Exception:\n                    # If astor fails, skip adding to set (might lead to potential duplicate, but safer)\n                    pass\n                last_import_index = i\n\n        # Insert new imports after the last existing import\n        # Reverse them so they are inserted in the correct order\n        for new_import in reversed(new_import_nodes):\n            try:\n                new_import_str = astor.to_source(new_import).strip()\n                if new_import_str not in existing_imports_str:\n                    self.tree.body.insert(last_import_index + 1, new_import)\n                    last_import_index += 1 # Update index for next insertion\n            except Exception:\n                # If we can't generate source, we can't check for duplicates, skip\n                self.tree.body.insert(last_import_index + 1, new_import)\n                last_import_index += 1\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return astor.to_source(node)\n            except Exception:\n                # Handle potential astor issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.__class__.__name__,\n            'line_start': getattr(node, 'lineno', None),\n            'line_end': getattr(node, 'end_lineno', None),\n            'body_items': []\n        }\n\n        if hasattr(node, 'body'):\n            for i, item in enumerate(node.body):\n                item_info = {\n                    'index': i,\n                    'type': item.__class__.__name__,\n                    'line_start': getattr(item, 'lineno', None),\n                    'line_end': getattr(item, 'end_lineno', None)\n                }\n\n                if isinstance(item, ast.Assign) and item.targets:\n                    target = item.targets[0]\n                    if isinstance(target, ast.Name):\n                        item_info['assigns'] = target.id\n                elif isinstance(item, (ast.If, ast.While, ast.For)):\n                    item_info['has_body'] = bool(getattr(item, 'body', None))\n                elif isinstance(item, ast.Return):\n                    item_info['returns'] = True\n\n                structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        if not self.atok:\n            return None # asttokens is required for precise original source retrieval\n\n        node = self.nodes.get(element_name)\n        if not node or not hasattr(node, 'body'):\n            return None\n\n        statements = []\n        for stmt in node.body:\n            if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                 # Check for overlap or containment of the statement within the requested range\n                stmt_start = stmt.lineno\n                stmt_end = stmt.end_lineno\n                if (stmt_start >= line_start and stmt_end <= line_end) or \\\n                   (stmt_start <= line_end and stmt_end >= line_start): # Overlap\n                    statements.append(stmt)\n\n        if not statements:\n            return None\n\n        # Use asttokens to get the original source text for accuracy\n        try:\n            # Combine text ranges of the found statements\n            combined_text = \"\"\n            last_end_pos = None\n            for stmt in sorted(statements, key=lambda s: s.lineno):\n                # Get the text range for the statement\n                stmt_text = self.atok.get_text_range(stmt)\n                if last_end_pos is not None and stmt_text[0] > last_end_pos:\n                     # Add the original whitespace/newlines between statements\n                    combined_text += self.source_code[last_end_pos:stmt_text[0]]\n                combined_text += self.atok.get_text(stmt)\n                last_end_pos = stmt_text[1]\n            return combined_text.strip()\n        except Exception:\n            # Fallback if asttokens text retrieval fails\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in statements)\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except SyntaxError:\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body: # Ensure there's actual code body to replace with\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # Walk the tree to find the parent node containing the element to replace\n        for parent_node in ast.walk(self.tree):\n            if hasattr(parent_node, 'body') and isinstance(parent_node.body, list):\n                try:\n                    old_node = self.nodes[element_name]\n                    idx = parent_node.body.index(old_node)\n                    # Remove the old node\n                    parent_node.body.pop(idx)\n                    # Insert the new nodes\n                    for i, new_node in enumerate(new_code_body):\n                        parent_node.body.insert(idx + i, new_node)\n\n                    # Update the nodes map: remove old, add new top-level definitions\n                    del self.nodes[element_name]\n                    for n in new_code_body:\n                        if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                            self.nodes[n.name] = n\n                    return True\n                except (ValueError, KeyError):\n                    # ValueError from index(), KeyError from accessing self.nodes\n                    continue\n        return False # Element not found in any body\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n             return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except (SyntaxError, IndexError):\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body:\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # --- Determine insertion index ---\n\n        # Find the `if __name__ == \"__main__\":` block index\n        main_block_idx = -1\n        for i, node in enumerate(self.tree.body):\n            if (isinstance(node, ast.If) and\n                isinstance(getattr(node, 'test', None), ast.Compare) and\n                isinstance(getattr(node.test, 'left', None), ast.Name) and\n                node.test.left.id == '__name__' and\n                len(getattr(node.test, 'ops', [])) == 1 and isinstance(node.test.ops[0], ast.Eq) and\n                len(getattr(node.test, 'comparators', [])) == 1):\n\n                comp = node.test.comparators[0]\n                # Check for both ast.Constant ('__main__') and older ast.Str ('__main__')\n                if ((isinstance(comp, ast.Constant) and comp.value == '__main__') or\n                    (isinstance(comp, ast.Str) and comp.s == '__main__')): # type: ignore\n                    main_block_idx = i\n                    break\n\n        insertion_index = -1\n        if anchor_name:\n            # If anchor is specified, find its index\n            if anchor_name not in self.nodes:\n                return False\n            anchor_node = self.nodes[anchor_name]\n            try:\n                anchor_idx = self.tree.body.index(anchor_node)\n                proposed_index = anchor_idx if before else anchor_idx + 1\n                # Prefer to stay before the main block if possible\n                if main_block_idx != -1:\n                    insertion_index = min(proposed_index, main_block_idx)\n                else:\n                    insertion_index = proposed_index\n            except ValueError:\n                return False # Anchor node not found in tree body\n        elif main_block_idx != -1:\n            # If no anchor, but there's a main block, insert before it\n            insertion_index = main_block_idx\n        # If no anchor and no main block, insertion_index remains -1\n\n        # --- Perform the insertion ---\n        if insertion_index == -1:\n            # Append to the end\n            self.tree.body.extend(new_code_body)\n        else:\n            # Insert at the calculated position\n            for i, new_node in enumerate(new_code_body):\n                self.tree.body.insert(insertion_index + i, new_node)\n\n        # Update the nodes map with any new top-level definitions\n        for node in new_code_body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                self.nodes[node.name] = node # This might overwrite if names clash\n\n        return True\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return False\n\n        deleted = False\n        if element_name in self.nodes:\n            node_to_delete = self.nodes[element_name]\n            # Walk the tree to find the parent node containing the element\n            for node in ast.walk(self.tree):\n                if hasattr(node, 'body') and isinstance(node.body, list):\n                    try:\n                        node.body.remove(node_to_delete)\n                        deleted = True\n                        break # Assume element appears only once at top level\n                    except ValueError:\n                        continue # This parent doesn't contain the node\n            if deleted:\n                del self.nodes[element_name]\n                # Although nodes map is passed by ref in base __init__, we should call _map_nodes\n                # to ensure consistency after a direct tree modification.\n                self.nodes = self._map_nodes()\n                return True\n\n        # If not found by node reference, try to find by name pattern matching (vars/imports)\n        new_body = []\n        for node in self.tree.body:\n            if isinstance(node, ast.Assign):\n                match = False\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id == element_name:\n                        match = True\n                        deleted = True\n                        break\n                if not match: # Keep the node if it doesn't match\n                    new_body.append(node)\n            elif isinstance(node, ast.Import):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                    # Keep the node if none of its aliases match (should theoretically be the same as above)\n                     new_body.append(node)\n                else:\n                    deleted = True # The import node is being completely removed\n            elif isinstance(node, ast.ImportFrom):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                     new_body.append(node)\n                else:\n                    deleted = True\n            else:\n                new_body.append(node)\n\n        if deleted:\n            self.tree.body = new_body\n            # Remap nodes after structural changes\n            self.nodes = self._map_nodes()\n\n        return deleted\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        if element_name not in self.nodes:\n            return False\n\n        node = self.nodes[element_name]\n        # Ensure the node has a body to modify\n        if not hasattr(node, 'body') or not isinstance(node.body, list):\n            return False\n\n        # Parse the new code to get AST nodes for the replacement\n        try:\n             # Heuristic: If new code looks like a def/class, extract its body.\n             # Otherwise, treat as standalone statements.\n            if new_code.strip().startswith(('def ', 'class ', 'async def ')):\n                # Parse as if it's a module with a single function/class\n                temp_module = ast.parse(new_code)\n                if temp_module.body and hasattr(temp_module.body[0], 'body'):\n                    new_statements = temp_module.body[0].body # Get the inner body\n                else:\n                    return False # Malformed attempt to define a func/class\n            else:\n                # Parse as a module and take its body\n                new_ast_module = ast.parse(new_code)\n                new_statements = new_ast_module.body\n        except SyntaxError:\n            return False # Invalid new code\n\n        if not new_statements: # Nothing to insert\n            return False\n\n        # --- Determine what to replace based on parameters ---\n        if statement_index is not None:\n            # Replace by statement index\n            if 0 <= statement_index < len(node.body):\n                # Replace the single statement at index with the list of new statements\n                node.body[statement_index:statement_index+1] = new_statements\n                return True\n        elif line_start is not None:\n            # Replace by line number(s)\n            result = self._find_statement_in_body(node.body, line_start, line_end)\n            if result:\n                idx, _ = result\n                if line_end:\n                    # Find the last statement within the specified range to replace multiple\n                    end_idx = idx\n                    # Iterate from the found index forward\n                    for i in range(idx, len(node.body)):\n                        stmt = node.body[i]\n                        stmt_s_ln = getattr(stmt, 'lineno', None)\n                        stmt_e_ln = getattr(stmt, 'end_lineno', stmt_s_ln)\n                        if stmt_s_ln is not None and stmt_e_ln is not None:\n                            # Check if the statement ends within the range or starts within the range\n                            # This handles overlapping ranges correctly\n                             if stmt_e_ln <= line_end or stmt_s_ln <= line_end:\n                                 end_idx = i\n                             else:\n                                 break # Statement is past the end range\n                        else:\n                            break # Can't determine statement range\n                    node.body[idx:end_idx+1] = new_statements\n                else:\n                    # line_end not specified, only replace the statement at line_start\n                    node.body[idx:idx+1] = new_statements\n                return True\n\n        # If none of the conditions were met to perform a replacement\n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        if self.tree:\n            try:\n                return astor.to_source(self.tree)\n            except Exception as e:\n                 # Fallback error handling, should ideally not happen if tree is valid\n                 return f\"# Error generating source: {e}\\n{self.source_code}\"\n        else:\n            # If somehow the tree is None, return the original source\n            return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        # Ensure line endings are consistent for diffing, keepends=True preserves them\n        # If source_code had different line endings, this might still cause issues,\n        # but this is a standard approach.\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/python_ast_adapter.py"
  },
  {
    "id": 71,
    "hash": "2914352eefed9d60de098e021dd79b67",
    "content": "import os\nimport sys\nimport argparse\nfrom typing import List\nfrom rag_manager import RAGManager\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\ndef create_sample_data() ->List[str]:\n    \"\"\"Create sample documents for the RAG example.\"\"\"\n    return [\n        'RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with language generation.'\n        ,\n        'The RAG model retrieves relevant documents from a knowledge base and uses them to generate more accurate responses.'\n        ,\n        'FAISS is a library for efficient similarity search and clustering of dense vectors, often used in RAG systems.'\n        ,\n        'Sentence transformers are used to create embeddings for documents and queries in RAG systems.'\n        ,\n        'Retrieval-Augmented Generation improves language models by allowing them to access external knowledge sources.'\n        ,\n        'In RAG systems, documents are indexed and searchable by their semantic embeddings rather than just keywords.'\n        ,\n        'Python is a great language for implementing RAG systems due to libraries like sentence-transformers and faiss.'\n        ,\n        'The retrieval component of RAG is crucial for finding relevant information before generation.'\n        ]\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_cli_example.py"
  },
  {
    "id": 72,
    "hash": "c27b11d2eaa8e13cdf8e698417efb75e",
    "content": "import os\nimport sys\nfrom typing import List, Dict, Tuple\n\"\"\"\nExample script demonstrating RAG (Retrieval-Augmented Generation) usage.\n\nThis script shows how to use a simple RAG implementation to answer questions\nbased on a given context or knowledge base.\n\"\"\"\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\nclass SimpleRAG:\n    \"\"\"A simple RAG implementation for demonstration purposes.\"\"\"\n\n    def __init__(self, knowledge_base: List[str]):\n        \"\"\"\n        Initialize the RAG with a knowledge base.\n        \n        Args:\n            knowledge_base: A list of strings representing the knowledge base.\n        \"\"\"\n        self.knowledge_base = knowledge_base\n\n    def retrieve(self, query: str, top_k: int=3) ->List[str]:\n        \"\"\"\n        Retrieve relevant documents from the knowledge base.\n        \n        This is a simplified implementation using keyword matching.\n        In a real implementation, you would use embeddings and vector search.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            A list of relevant documents.\n        \"\"\"\n        query_words = set(query.lower().split())\n        scores = []\n        for doc in self.knowledge_base:\n            doc_words = set(doc.lower().split())\n            score = len(query_words.intersection(doc_words))\n            scores.append((score, doc))\n        scores.sort(reverse=True)\n        return [doc for score, doc in scores[:top_k]]\n\n    def generate(self, query: str, retrieved_docs: List[str]) ->str:\n        \"\"\"\n        Generate an answer based on the query and retrieved documents.\n        \n        In a real implementation, this would use an LLM to generate the response.\n        For this example, we'll create a simple template-based response.\n        \n        Args:\n            query: The query string.\n            retrieved_docs: The retrieved documents.\n            \n        Returns:\n            A generated answer.\n        \"\"\"\n        context = '\\n'.join(retrieved_docs)\n        prompt = f\"\"\"\n        Context information:\n        {context}\n        \n        Question: {query}\n        \n        Based on the context provided above, please answer the question.\n        If the context doesn't contain relevant information, say so.\n        \"\"\"\n        return self._simple_response_generator(query, retrieved_docs)\n\n    def _simple_response_generator(self, query: str, retrieved_docs: List[str]\n        ) ->str:\n        \"\"\"\n        A simple response generator for demonstration.\n        \"\"\"\n        for doc in retrieved_docs:\n            if 'example' in doc.lower():\n                return (\n                    f'Based on the context provided, I found information about examples. {query} relates to the examples in the knowledge base.'\n                    )\n        return (\n            f\"I couldn't find specific information about '{query}' in the provided context. Please provide more details or check the knowledge base.\"\n            )\n\n    def query(self, query: str, top_k: int=3) ->str:\n        \"\"\"\n        Process a query through the full RAG pipeline.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            The generated answer.\n        \"\"\"\n        retrieved_docs = self.retrieve(query, top_k)\n        answer = self.generate(query, retrieved_docs)\n        return answer\n\n\ndef main():\n    \"\"\"Main function demonstrating the RAG implementation.\"\"\"\n    knowledge_base = ['This is an example document about machine learning.',\n        'Natural language processing is a subfield of artificial intelligence.'\n        , 'Python is a popular programming language for data science.',\n        'The quick brown fox jumps over the lazy dog.',\n        'RAG stands for Retrieval-Augmented Generation.',\n        'Vector databases are used for similarity search in RAG systems.',\n        'Transformers are a type of neural network architecture.',\n        'This example shows how to implement a simple RAG system.']\n    rag = SimpleRAG(knowledge_base)\n    queries = ['What is RAG?', 'How is Python used in data science?',\n        'Tell me about machine learning']\n    print('Simple RAG Example')\n    print('=' * 50)\n    for query in queries:\n        print(f'\\nQuery: {query}')\n        answer = rag.query(query)\n        print(f'Answer: {answer}')\n        print('-' * 30)\n    print(\"\\nInteractive Mode (type 'quit' to exit):\")\n    while True:\n        try:\n            user_query = input('\\nEnter your question: ').strip()\n            if user_query.lower() in ['quit', 'exit', 'q']:\n                break\n            if user_query:\n                answer = rag.query(user_query)\n                print(f'Answer: {answer}')\n        except KeyboardInterrupt:\n            print('\\nGoodbye!')\n            break\n        except EOFError:\n            break\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_example.py"
  },
  {
    "id": 73,
    "hash": "f151986bf2efa7602242590a357fab83",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n    Initialize the RAG manager.\n\n    Args:\n        model_name: Name of the sentence transformer model to use\n        index_path: Path to save/load the FAISS index\n    \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the RAG manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n",
    "file": "/mnt/ProjectData/omni/rag_manager.py"
  },
  {
    "id": 74,
    "hash": "f59a27842056dbb0dc95d0f29c1c5de8",
    "content": "Hello! I'm OmniForge, an AI coding assistant. I can help you scan, understand, and refactor your codebase using local (Ollama) or remote (OpenRouter) LLMs.\n\nI see you've opened the OmniForge project directory. Some key things I can help with:\n\n1. **Project Analysis**: I can look at your files to understand the structure\n2. **Code Editing**: I can make precise edits to functions/classes using AST-based transformations\n3. **Refactoring**: I can perform multi-file architectural changes with a plan\n4. **File Creation**: I can generate new files based on instructions\n\nFor example:\n- `look .` to scan the project\n- `edit code_editor.py \"add docstrings to main methods\"`\n- `refactor \"extract git operations into a separate module\"`\n- `create new_module.py \"implement a simple HTTP client\"`\n\nWhat would you like to do with this project?",
    "file": "/mnt/ProjectData/omni/requirements.txt"
  },
  {
    "id": 75,
    "hash": "4b879b8e64b677ec78d27f19b384623a",
    "content": "from typing import List\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.text import Text\nfrom rich.status import Status\nfrom rich import box\nfrom contextlib import contextmanager\nfrom rich.markup import escape\nimport gc\n\ntry:\n    from prompt_toolkit import prompt\n    from prompt_toolkit.completion import WordCompleter\n    from prompt_toolkit.history import InMemoryHistory\n    from prompt_toolkit.styles import Style\nexcept ImportError:\n    print('[yellow]prompt_toolkit not installed. Falling back to basic input.[/]')\n    prompt = input\n\n\nclass UIManager:\n    \"\"\"Manages interactive text-based UI with rich for display and prompt_toolkit for input.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initializes the UI manager with a rich console and prompt_toolkit components.\"\"\"\n        self.console = Console()\n        self.history = InMemoryHistory()\n        self.completer = WordCompleter([\n            'send', 'look', 'look_all', 'create', 'edit', 'refactor', 'commit',\n            'save', 'list', 'run', 'history', 'memory', 'backend', 'models',\n            'set', 'personality', 'help', 'exit'\n        ], ignore_case=True)\n        self.prompt_style = Style.from_dict({'prompt': 'bold cyan'})\n\n    def get_user_input(self, prompt_text: str) -> str:\n        try:\n            return prompt(prompt_text, history=self.history, completer=self.completer, style=self.prompt_style)\n        except Exception:\n            self.console.print('[yellow]Warning: Falling back to basic input.[/]')\n            return input(prompt_text)\n\n    def display_history(self, history_text: str) -> None:\n        if not history_text.strip():\n            self.console.print('[dim]No history yet.[/]')\n            return\n        \n        lines = history_text.split('\\n')\n        colored_text = Text()\n        for line in lines:\n            if line.startswith('User:'):\n                colored_text.append(line + '\\n', style='bold blue')\n            elif line.startswith('AI:'):\n                colored_text.append(line + '\\n', style='bold green')\n            elif line.startswith('File '):\n                colored_text.append(line + '\\n', style='yellow')\n            else:\n                colored_text.append(line + '\\n')\n        \n        self.console.print(Panel(\n            colored_text, \n            title='[bold magenta]Chat History[/]', \n            border_style='magenta', \n            expand=False, \n            box=box.ROUNDED\n        ))\n\n    @contextmanager\n    def show_spinner(self, message: str):\n        \"\"\"\n        Context manager that displays a spinner with the given message.\n        Handles Rich LiveError by cleaning up stuck live displays and \n        ensuring proper cleanup on exceptions.\n        \n        Usage:\n            with ui_manager.show_spinner(\"Loading...\"):\n                # do work here\n        \"\"\"\n        # Initialize spinner state if not exists\n        if not hasattr(self, '_spinner_active'):\n            self._spinner_active = False\n        \n        # If spinner is already active, just yield without additional output\n        if self._spinner_active:\n            try:\n                yield\n            except Exception as e:\n                raise e\n            return\n        \n        # Clean up any stuck Rich live displays before starting\n        self._cleanup_stuck_rich_displays()\n        \n        # Mark spinner as active\n        self._spinner_active = True\n        status_context = None\n        \n        try:\n            # Try to use rich status, but with fallback\n            try:\n                status_context = self.console.status(f'[bold yellow]{message}[/]')\n                status_context.__enter__()\n            except Exception:\n                # If rich.status fails, fallback to static print\n                status_context = None\n                self.console.print(f'[bold yellow]{message}[/]')\n            \n            yield\n            \n        except Exception as e:\n            # Re-raise actual work errors\n            raise e\n            \n        finally:\n            # Always cleanup spinner state and rich display\n            self._spinner_active = False\n            if status_context is not None:\n                try:\n                    status_context.__exit__(None, None, None)\n                except:\n                    pass  # Suppress cleanup errors\n            \n            # Force cleanup any remaining rich displays\n            self._cleanup_stuck_rich_displays()\n\n    def _cleanup_stuck_rich_displays(self):\n        \"\"\"\n        Clean up stuck Rich live displays that prevent new ones from starting.\n        Based on solution from: https://github.com/DLR-RM/stable-baselines3/issues/1645\n        \"\"\"\n        try:\n            # Method 1: Reset console live display if exists\n            if hasattr(self.console, '_live') and self.console._live is not None:\n                try:\n                    self.console._live.stop()\n                    self.console._live = None\n                except:\n                    pass\n            \n            # Method 2: Find and close stuck rich/tqdm objects using garbage collection\n            rich_objects = [obj for obj in gc.get_objects() \n                        if hasattr(obj, '__class__') and \n                        ('live' in type(obj).__name__.lower() or \n                            'progress' in type(obj).__name__.lower() or\n                            'status' in type(obj).__name__.lower()) and\n                        hasattr(obj, 'stop')]\n            \n            for rich_obj in rich_objects:\n                try:\n                    if hasattr(rich_obj, 'stop'):\n                        rich_obj.stop()\n                    elif hasattr(rich_obj, 'close'):\n                        rich_obj.close()\n                except:\n                    pass  # Suppress cleanup errors\n                    \n        except:\n            pass  # Suppress all cleanup errors to avoid breaking the main flow\n\n    def display_status_panel(self, personality: str, backend: str, model: str, msg_count: int, look_count: int) -> None:\n        status_text = (\n            f'[bold]Personality:[/] [green]{personality}[/] | '\n            f'[bold]Backend:[/] [green]{backend}[/] | '\n            f'[bold]Model:[/] [green]{model}[/] | '\n            f'[bold]Memory:[/] {msg_count} messages, {look_count} files'\n        )\n        self.console.print(Panel(\n            status_text, \n            title='[bold cyan]Status[/]', \n            border_style='cyan', \n            expand=False, \n            box=box.MINIMAL\n        ))\n\n    def show_success(self, message: str) -> None:\n        self.console.print(f'[green]\u2705 {message}[/]')\n\n    def show_error(self, message: str) -> None:\n        \"\"\"\n        Displays an error message, escaping any markup in the message.\n        \"\"\"\n        safe_message = escape(str(message))\n        self.console.print(f'[red]\u274c {safe_message}[/]')",
    "file": "/mnt/ProjectData/omni/ui_manager.py"
  },
  {
    "id": 76,
    "hash": "dbd143839288b400cafdedb655258434",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n",
    "file": "/mnt/ProjectData/omni/vectordb_manager.py"
  },
  {
    "id": 77,
    "hash": "47a91d3ac272236378053b23515fc9b0",
    "content": "import tkinter as tk\nfrom tkinter import ttk\nfrom time import strftime\n\n\ndef update_time():\n    current_time = strftime('%H:%M:%S %p\\n%Y-%m-%d')\n    time_label.config(text=current_time)\n    time_label.after(1000, update_time)\n\n\ndef center_window(root):\n    root.update_idletasks()\n    screen_width = root.winfo_screenwidth()\n    screen_height = root.winfo_screenheight()\n    window_width = root.winfo_width() + 4\n    window_height = root.winfo_height() + 4\n    x = (screen_width - window_width) // 2\n    y = (screen_height - window_height) // 2\n    root.geometry(f'{window_width}x{window_height}+{x}+{y}')\n\n\ndef create_3d_border(parent):\n    border_frame = tk.Frame(parent, bg='#c0c0c0')\n    border_frame.pack(padx=2, pady=2, expand=True, fill=tk.BOTH)\n    tk.Frame(border_frame, height=1, bg='#808080').pack(side=tk.TOP, fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#808080').pack(side=tk.LEFT, fill=tk.Y)\n    tk.Frame(border_frame, height=1, bg='#ffffff').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#ffffff').pack(side=tk.RIGHT, fill=tk.Y\n        )\n    inner_container = tk.Frame(border_frame, bg='#c0c0c0')\n    inner_container.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1\n        )\n    tk.Frame(inner_container, height=1, bg='#ffffff').pack(side=tk.TOP,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#ffffff').pack(side=tk.LEFT,\n        fill=tk.Y)\n    tk.Frame(inner_container, height=1, bg='#808080').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#808080').pack(side=tk.RIGHT,\n        fill=tk.Y)\n    content_area = tk.Frame(inner_container, bg='#c0c0c0')\n    content_area.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1)\n    return content_area\n\n\nroot = tk.Tk()\nroot.title('Current Time')\nroot.configure(bg='#008080')\nmain_frame = create_3d_border(root)\nmain_frame.config(padx=4, pady=4)\ninner_frame = tk.Frame(main_frame, bg='#c0c0c0', padx=8, pady=8)\ninner_frame.pack()\ntime_label = tk.Label(inner_frame, bg='#c0c0c0', fg='#000000', font=(\n    'MS Sans Serif', 18, 'bold'), padx=12, pady=8)\ntime_label.pack()\nroot.after(100, lambda : center_window(root))\nupdate_time()\nroot.mainloop()\n",
    "file": "/mnt/ProjectData/omni/omni_saves/watch.py"
  },
  {
    "id": 78,
    "hash": "6774a805052356775d8c4f0367253dc1",
    "content": "# OmniForge\n\n**Project\u2011Aware AI CLI for AST\u2011Precise Edits (\u201cScalpel\u201d) & Multi\u2011File Refactors (\u201cBlueprint\u201d).**\n\n> *OmniForge (a.k.a. the \"DualForge\" engine) helps you **scan**, **understand**, and **reforge** your codebase with local (Ollama) or remote (OpenRouter) LLMs. It is an independent open\u2011source project not affiliated with other products using the name \u201cOmni.\u201d*\n\n---\n\n## Core Features\n\n* **Project\u2011Aware Refactoring (`refactor`)**: Provide a high\u2011level goal (e.g. *\u201cmove all DB logic into `db/` and centralize config\u201d*). OmniForge generates & shows a multi\u2011step plan before touching files.\n* **Surgical AST Editing (`edit`)**: Target a single function/class. OmniForge parses the file, locates the node, applies a structural change, and shows you a diff.\n* **Context Ingestion (`look`)**: Scan a directory or single file to build a project manifest (paths + hashes + size + language hints) that guides subsequent edits/refactors.\n* **Dual Backends**: Seamlessly switch between **`openrouter`** (remote models) and **`ollama`** (local models) via `backend <name>`.\n* **Interactive Model Picker (`models`)**: Filter by source/provider and select from an up\u2011to\u2011date model list inside the terminal.\n* **Session Memory & History**: `history` shows conversation / action log; `memory clear` resets the working context.\n* **Safe AST\u2011Based Transformations**: Reduces syntax breakage vs naive text substitution. New imports / dependencies are auto\u2011inserted when possible.\n* **Dry\u2011Run Transparency**: Every multi\u2011file refactor presents (1) a generated plan, (2) per\u2011file proposed changes, (3) a consolidated diff for confirmation.\n\n---\n\n## Conceptual Modes\n\n| Mode          | Command(s) | Purpose                                              | Analogy              |\n| ------------- | ---------- | ---------------------------------------------------- | -------------------- |\n| **Survey**    | `look`     | Index project / ingest context                       | Mapping the terrain  |\n| **Scalpel**   | `edit`     | Precise single\u2011file structural change                | Surgery              |\n| **Blueprint** | `refactor` | Multi\u2011file architectural transformation              | Architecture         |\n| **Cast**      | `run`      | Execute last generated runnable block (if supported) | Forging the artifact |\n\nYou can reference these terms in docs, help screens, or UI banners for clarity.\n\n---\n\n## Installation\n\n> Requires Python 3.10+ and a Unix\u2011like shell.\n\n```bash\n# 1. Clone\ngit clone https://github.com/Snawyyy/omniforge.git\ncd omniforge\n\n# 2. (Optional) Inspect requirements\ncat requirements.txt\n\n# 3. Run installer (creates venv + installs deps)\nchmod +x install.sh\n./install.sh\n\n# 4. Activate environment\nsource venv/bin/activate\n\n# 5. Run CLI (interactive shell)\n./omni        # or: python omni.py\n```\n\nIf you later package it, expose a script entry point named `omni` while keeping an internal package name like `omniforge` to avoid namespace collisions.\n\n---\n\n## Configuration\n\nCreate a `.env` file to supply secrets (e.g. OpenRouter API key).\n\n```bash\ncp .env.example .env   # if example exists; otherwise create manually\n```\n\nIn `.env`:\n\n```dotenv\nOPENROUTER_API_KEY=\"sk-or-...\"\n```\n\n(Do **not** commit real keys. Ensure `.env` is listed in `.gitignore`.)\n\nOptional future keys can include local model paths, default model name, or feature flags.\n\n---\n\n## Quick Start Workflow\n\n```text\n> look .\n(Index project: builds manifest)\n\n> refactor \"extract hardcoded API URL to config/settings.py and update all imports\"\n(Shows plan \u2192 ask for confirmation)\n\n> edit src/utils.py \"add a doctring for calculate_average explaining parameters and return value\"\n(Shows targeted diff \u2192 confirm or abort)\n\n> models openai\n(Choose a different model)\n\n> backend ollama\n(Switch to local inference)\n```\n\n---\n\n## Command Reference\n\n| Command               | Example                                         | Description                                                                 |\n| --------------------- | ----------------------------------------------- | --------------------------------------------------------------------------- |\n| `look <path>`         | `look .`                                        | Scan directory or file; update project context manifest.                    |\n| `edit <file> \"instr\"` | `edit utils.py \"add error handling\"`            | AST\u2011guided targeted modification of a single file element or whole file.    |\n| `refactor \"goal\"`     | `refactor \"split monolith api.py into package\"` | High\u2011level multi\u2011file transformation with plan + diff review.               |\n| `send <prompt>`       | `send summarize module layout`                  | Generic prompt to current model with current context summary.               |\n| `models [filter]`     | `models google`                                 | Interactive model selector (filter by provider/source).                     |\n| `backend <name>`      | `backend ollama`                                | Switch between `openrouter` / `ollama`.                                     |\n| `history`             | `history`                                       | Display session interaction log.                                            |\n| `memory clear`        | `memory clear`                                  | Clear internal AI context memory (project manifest may persist separately). |\n| `run`                 | `run`                                           | Execute the last generated runnable code snippet (if feature implemented).  |\n| `help`                | `help`                                          | Show help / usage summary.                                                  |\n\n---\n\n## How It Works (High Level)\n\n1. **Ingestion (`look`)**: Walks the directory (configurable ignore patterns), captures file metadata (path, size, language), optionally caches abbreviated content or hashes.\n2. **Prompt Construction**: Merges user instruction + contextual manifest + focused snippets (for `edit`) or diff summaries (for `refactor`).\n3. **AST Layer** (Python initially): Parses target file(s); identifies node(s) (function/class) based on name + heuristic similarity; applies transformations guided by model output (structured hints or patch templates) rather than raw blind overwrite.\n4. **Plan (Refactor)**: Model proposes steps (CREATE / MODIFY / RENAME / DELETE). User approves. Each step executed & validated; errors surface early.\n5. **Diff Presentation**: A unified colorized diff shown; user confirms to write changes.\n6. **Safety**: If AST parse fails or patch violates syntax, changes abort (or fallback to text patch with warning).\n\n---\n\n## Roadmap (Indicative)\n\n| Milestone | Features                                                                    |\n| --------- | --------------------------------------------------------------------------- |\n| 0.1.0     | Core commands (`look`, `edit`, `refactor`, `models`, `backend`, `history`). |\n| 0.2.0     | Config file (`omniforge.toml`), ignore patterns, improved diff viewer.      |\n| 0.3.0     | Multi-language AST adapters (JS/TS via `tree-sitter`).                      |\n| 0.4.0     | Test impact analysis & auto test file generation.                           |\n| 0.5.0     | Refactor preview metrics (LOC touched, complexity delta).                   |\n| 0.6.0     | Inline security / lint feedback integration.                                |\n| 0.7.0     | Partial GUI / TUI dashboard mode.                                           |\n\n(Adjust roadmap as project evolves.)\n\n---\n\n## Developer Notes\n\n* Keep `.env`, virtual environment dirs (`venv/`), caches, large artifacts in `.gitignore`.\n* Consider adding a thin `omniforge/` package directory now for future PyPI packaging.\n* Implement a pluggable *Model Adapter* layer to abstract provider differences (OpenRouter vs Ollama).\n* Logging: Provide `--verbose` or `OMNIFORGE_DEBUG=1` env flag.\n* Add a JSONL log of commands & decisions to enable replay or supervised improvements.\n\n---\n\n## Contributing\n\n1. Fork & create a feature branch: `git checkout -b feat/<short-name>`\n2. Run and add tests (if/when test harness exists in `tests/`).\n3. Ensure style/format (e.g. `ruff`, `black`) passes.\n4. Submit pull request with concise description + before/after examples.\n\nIssues / discussions welcome for architecture proposals, AST adapters, or performance improvements.\n\n---\n\n## License\n\nReleased under the **MIT License**. See `LICENSE` file for full text.\n\n---\n\n## Name & Trademark Disclaimer\n\n\u201cOmniForge\u201d is an independent open-source tool and not affiliated with The Omni Group or any other third-party products using similar names. If a future naming conflict arises, a soft alias strategy (keeping the `omni` CLI) will preserve user workflows.\n\n---\n\n## Example Session (Illustrative)\n\n```text\n$ ./omni\nOMNIFORGE 0.1.0  (backend=openrouter | model=anthropic/claude-3)\nType 'help' or 'look .' to begin.\n\n> look .\nIndexed 42 files (Python=30, Markdown=5, JSON=7)\n\n> refactor \"centralize logging into logging_util.py and update imports\"\nPlan:\n  [1] CREATE logging_util.py\n  [2] MODIFY app.py (replace inline log setup)\n  [3] MODIFY worker.py (import logging_util)\nProceed? (y/n) y\n... (diff preview) ...\nApply changes? (y/n) y\nRefactor complete in 3.2s.\n\n> edit worker.py \"add retry with exponential backoff to fetch_data\"\nParsed worker.py \u2713\nApplied modification (function: fetch_data)\nDiff shown. Accept? (y/n) y\nSaved.\n```\n\n---\n\n## Philosophy\n\n*The next wave of developer AI goes beyond paste\u2011in prompts.* OmniForge treats your repository as *structured material*, enabling incremental, auditable, and safer evolution rather than opaque code dumps. By combining **context scanning**, **AST precision**, and **human approval loops**, it aims to become a trustworthy co\u2011developer rather than an occasionally helpful code generator.\n\n---\n\n## Feedback / Support\n\nOpen a GitHub Issue for bugs & feature requests. For conceptual discussions (roadmap, design choices), use Discussions.\n\n---\n\nHappy forging!\n",
    "file": "/mnt/ProjectData/omni/README.md"
  },
  {
    "id": 79,
    "hash": "48f330cca4dc037b3ad4942e430e6393",
    "content": "# ast_adapter.py\n\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional, Dict, Any, Union\n\n# Define common types that adapters might use or return\n# This keeps the interface flexible without importing specific parser libraries\nASTNode = Any  # Generic type for a node in the AST/CST\nDiffContent = str # Type alias for the string output of a diff\n\nclass ASTAdapter(ABC):\n    \"\"\"\n    Abstract base class defining the interface for language-specific AST adapters.\n\n    This interface allows the CodeEditor to interact with the AST/CST of different\n    programming languages in a uniform way. Concrete implementations will handle\n    the specifics of parsing, traversing, and modifying the AST/CST for their\n    respective languages (e.g., Python's `ast`/`astor`, JavaScript's `tree-sitter`).\n\n    The adapter is responsible for holding the parsed tree structure and any\n    necessary metadata for operations.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the adapter by parsing the provided source code.\n\n        Args:\n            source_code: The string content of the source file to be parsed.\n\n        Raises:\n            ValueError: If the source code cannot be parsed due to syntax errors.\n        \"\"\"\n        self.source_code: str = source_code\n        self.tree: Optional[ASTNode] = None\n        self.nodes: Dict[str, ASTNode] = {} # A map for quick access to named elements\n        self._parse_and_map(source_code)\n\n    @abstractmethod\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Abstract method to parse the source code and populate `self.tree` and `self.nodes`.\n\n        This is the core method where language-specific parsing logic resides.\n        Implementations should:\n        1. Parse the `source_code` into an AST/CST representation.\n        2. Store the root of this representation in `self.tree`.\n        3. Identify key top-level elements (functions, classes, variables, imports)\n           and map their names to their nodes in `self.nodes`.\n\n        Args:\n            source_code: The string content to parse.\n\n        Raises:\n            ValueError: If the source code cannot be parsed.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_elements(self) -> List[str]:\n        \"\"\"\n        Abstract method to list the names of the main elements found in the code.\n\n        These are typically top-level functions, classes, variable assignments,\n        and imports that the adapter can identify and manipulate.\n\n        Returns:\n            A list of element names (strings).\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"\n        Abstract method to get the source code string for a specific element.\n\n        Args:\n            element_name: The name of the element (function, class, etc.).\n\n        Returns:\n            The source code string for the element, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"\n        Abstract method to get detailed structural information about an element.\n\n        This information can include type, line numbers, body items, etc., useful\n        for aiding the AI in understanding the code's layout.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            A dictionary containing structural details, or None if not found.\n            Example structure:\n            {\n                'name': 'func_name',\n                'type': 'FunctionDef', # or 'ClassDef', etc.\n                'line_start': 10,\n                'line_end': 25,\n                'body_items': [list of internal statement details...]\n            }\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"\n        Abstract method to extract a snippet of code from within an element's body.\n\n        Used for 'partial' edits where only a specific range of lines within\n        a function or class needs to be changed.\n\n        Args:\n            element_name: The name of the element containing the snippet.\n            line_start: The starting line number (1-based, absolute) of the snippet.\n            line_end: The ending line number (inclusive) of the snippet.\n\n        Returns:\n            The source code string for the specified lines within the element, or None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"\n        Abstract method to replace an entire named element.\n\n        This involves finding the old element in the tree and swapping it with\n        the representation of the `new_code`.\n\n        Args:\n            element_name: The name of the element to replace.\n            new_code: The new source code for the element (and potential helpers).\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"\n        Abstract method to add a new block of code (element) to the file.\n\n        This involves parsing the `new_code` and inserting its representation\n        into the tree at an appropriate location (e.g., end of file, near anchor).\n\n        Args:\n            new_code: The source code for the new element(s).\n            anchor_name: Optional name of an existing element to position relative to.\n            before: If True and `anchor_name` is provided, insert before the anchor.\n\n        Returns:\n            True if the element was added successfully, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"\n        Abstract method to delete a named element from the file.\n\n        This involves finding the element in the tree and removing its representation.\n\n        Args:\n            element_name: The name of the element to delete.\n\n        Returns:\n            True if the element was successfully deleted, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"\n        Abstract method for a 'surgical' edit within an element's body.\n\n        Replaces a specific statement or line range within the body of an element.\n\n        Args:\n            element_name: Name of the function/class to modify.\n            new_code: New code to insert (can be multiple statements).\n            line_start: Starting line number (absolute) within the element.\n            line_end: Ending line number (inclusive) within the element.\n            statement_index: Alternative to line numbers - replace the Nth statement.\n\n        Returns:\n            True if successful, False otherwise.\n        \"\"\"\n        pass\n\n    # --- Methods related to final output and change tracking ---\n\n    @abstractmethod\n    def get_modified_source(self) -> str:\n        \"\"\"\n        Abstract method to serialize the potentially modified AST/CST back to source code.\n\n        Returns:\n            The full source code string reflecting the current state of the tree.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_diff(self) -> str:\n        \"\"\"\n        Abstract method to generate a diff between the original source and the modified source.\n\n        Returns:\n            A string containing the unified diff.\n        \"\"\"\n        pass\n\n    # Internal helper methods (can be abstract or have common logic in base if needed)\n    # These are less critical for the interface but might be useful\n    # _add_imports(new_import_nodes) -> could be handled differently per language\n    # _find_statement_in_body(body, line_start, line_end) -> Tree-sitter needs different logic",
    "file": "/mnt/ProjectData/omni/ast_adapter.py"
  },
  {
    "id": 80,
    "hash": "dfd2f8b26c415d967b6e2c15b1a0c7f3",
    "content": "\"\"\"\nCodeEditor - Enhanced AST-based code manipulation tool\n\nThis module provides a class to programmatically parse, analyze,\nand edit source code. It has been refactored to use a pluggable\nASTAdapter system, allowing it to support multiple languages.\nCurrently, it defaults to Python's built-in `ast` module via\nPythonASTAdapter for backward compatibility during the transition.\n\"\"\"\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Union, Tuple, Type, Any\nfrom ast_adapter import ASTAdapter\nfrom python_ast_adapter import PythonASTAdapter\nimport os\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n\n\nclass CodeEditor:\n    \"\"\"\n    An enhanced class to safely edit files using AST/CST with partial edit support.\n    The core logic for interacting with the code structure is now delegated to\n    a language-specific ASTAdapter.\n    \"\"\"\n\n    def __init__(self, file_path: str, adapter_class: Optional[Type[\n        ASTAdapter]]=None):\n        \"\"\"\n        Initializes the CodeEditor.\n\n        Args:\n            file_path: The path to the source file.\n            adapter_class: The ASTAdapter subclass to use. If None, defaults to\n                           PythonASTAdapter for .py files.\n        \"\"\"\n        self.file_path = file_path\n        self.source_code = self._read_file()\n        if adapter_class is None:\n            file_extension = os.path.splitext(self.file_path)[1].lower()\n            if file_extension == '.py':\n                self.adapter: Optional[ASTAdapter] = PythonASTAdapter(self.\n                    source_code)\n            elif file_extension == '.js':\n                raise NotImplementedError(\n                    'JavaScript support is not yet implemented')\n            else:\n                raise ValueError(\n                    f'Unsupported file type: {file_extension}. Supported types: .py, .js'\n                    )\n        else:\n            self.adapter = adapter_class(self.source_code)\n\n    def _read_file(self) ->str:\n        \"\"\"Reads the source file.\"\"\"\n        try:\n            with open(self.file_path, 'r', encoding='utf-8') as f:\n                return f.read()\n        except FileNotFoundError:\n            raise ValueError(f'File not found: {self.file_path}')\n\n    def _parse_source(self) ->ast.AST:\n        \"\"\"Fallback parsing logic.\"\"\"\n        try:\n            return ast.parse(self.source_code)\n        except SyntaxError as e:\n            raise ValueError(f'Invalid Python syntax in {self.file_path}: {e}')\n\n    def list_elements(self) ->List[str]:\n        \"\"\"Lists top-level elements in the code.\"\"\"\n        if self.adapter:\n            return self.adapter.list_elements()\n        else:\n            return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"Gets the source code for a specific element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_source_of(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            return astor.to_source(node) if node else None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"Gets detailed structure information about an element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_structure(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            if not node:\n                return None\n            structure = {'name': element_name, 'type': node.__class__.\n                __name__, 'line_start': node.lineno if hasattr(node,\n                'lineno') else None, 'line_end': node.end_lineno if hasattr\n                (node, 'end_lineno') else None, 'body_items': []}\n            if hasattr(node, 'body'):\n                for i, item in enumerate(node.body):\n                    item_info = {'index': i, 'type': item.__class__.\n                        __name__, 'line_start': item.lineno if hasattr(item,\n                        'lineno') else None, 'line_end': item.end_lineno if\n                        hasattr(item, 'end_lineno') else None}\n                    if isinstance(item, ast.Assign) and item.targets:\n                        target = item.targets[0]\n                        if isinstance(target, ast.Name):\n                            item_info['assigns'] = target.id\n                    elif isinstance(item, (ast.If, ast.While, ast.For)):\n                        item_info['has_body'] = bool(item.body)\n                    elif isinstance(item, ast.Return):\n                        item_info['returns'] = True\n                    structure['body_items'].append(item_info)\n            return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"Gets a snippet from within an element's body.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_body_snippet(element_name,\n                line_start, line_end)\n        else:\n            if not self.atok:\n                return None\n            node = self.nodes.get(element_name)\n            if not node or not hasattr(node, 'body'):\n                return None\n            statements = []\n            for stmt in node.body:\n                if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                    if (line_start <= stmt.lineno <= line_end or line_start <=\n                        stmt.end_lineno <= line_end):\n                        statements.append(stmt)\n            if not statements:\n                return None\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in\n                statements)\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"Replaces a partial section of an element.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_partial(element_name, new_code,\n                line_start, line_end, statement_index)\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                if new_code.strip().startswith('def ') or new_code.strip(\n                    ).startswith('class '):\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body[0].body\n                else:\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if statement_index is not None:\n                if 0 <= statement_index < len(node.body):\n                    node.body[statement_index:statement_index + 1\n                        ] = new_statements\n                    return True\n            elif line_start is not None:\n                result = self._find_statement_in_body(node.body, line_start,\n                    line_end)\n                if result:\n                    idx, _ = result\n                    if line_end:\n                        end_idx = idx\n                        for i in range(idx + 1, len(node.body)):\n                            stmt = node.body[i]\n                            if hasattr(stmt, 'end_lineno'\n                                ) and stmt.end_lineno <= line_end:\n                                end_idx = i\n                            else:\n                                break\n                        node.body[idx:end_idx + 1] = new_statements\n                    else:\n                        node.body[idx:idx + 1] = new_statements\n                    return True\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"Adds a new block of code to the file.\"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name, before)\n        else:\n            try:\n                new_ast_module = ast.parse(new_code)\n            except (SyntaxError, IndexError):\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            insertion_index = -1\n            main_block_idx = -1\n            for i, _node in enumerate(self.tree.body):\n                if isinstance(_node, ast.If) and isinstance(_node.test, ast\n                    .Compare) and isinstance(_node.test.left, ast.Name\n                    ) and _node.test.left.id == '__name__' and len(_node.\n                    test.ops) == 1 and isinstance(_node.test.ops[0], ast.Eq\n                    ) and len(_node.test.comparators) == 1:\n                    comp = _node.test.comparators[0]\n                    if isinstance(comp, ast.Constant\n                        ) and comp.value == '__main__' or isinstance(comp,\n                        ast.Str) and comp.s == '__main__':\n                        main_block_idx = i\n                        break\n            if anchor_name:\n                if anchor_name not in self.nodes:\n                    return False\n                anchor_node = self.nodes[anchor_name]\n                try:\n                    anchor_idx = self.tree.body.index(anchor_node)\n                    proposed_index = anchor_idx if before else anchor_idx + 1\n                    if main_block_idx != -1:\n                        insertion_index = min(proposed_index, main_block_idx)\n                    else:\n                        insertion_index = proposed_index\n                except ValueError:\n                    return False\n            elif main_block_idx != -1:\n                insertion_index = main_block_idx\n            if insertion_index == -1:\n                self.tree.body.extend(new_code_body)\n            else:\n                for i, new_node in enumerate(new_code_body):\n                    self.tree.body.insert(insertion_index + i, new_node)\n            for _node in new_code_body:\n                if isinstance(_node, (ast.FunctionDef, ast.AsyncFunctionDef,\n                    ast.ClassDef)):\n                    self.nodes[_node.name] = _node\n            return True\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"Deletes an element by name.\"\"\"\n        if self.adapter:\n            return self.adapter.delete_element(element_name)\n        else:\n            deleted = False\n            if element_name in self.nodes:\n                node_to_delete = self.nodes[element_name]\n                for _node in ast.walk(self.tree):\n                    if hasattr(_node, 'body') and isinstance(_node.body, list):\n                        try:\n                            _node.body.remove(node_to_delete)\n                            deleted = True\n                            break\n                        except ValueError:\n                            continue\n                if deleted:\n                    del self.nodes[element_name]\n                    self.nodes = self._map_nodes()\n                    return True\n            new_body = []\n            for _node in self.tree.body:\n                if isinstance(_node, ast.Assign):\n                    match = False\n                    for target in _node.targets:\n                        if isinstance(target, ast.Name\n                            ) and target.id == element_name:\n                            match = True\n                            break\n                    if match:\n                        deleted = True\n                        continue\n                elif isinstance(_node, ast.Import):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                elif isinstance(_node, ast.ImportFrom):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                new_body.append(_node)\n            self.tree.body = new_body\n            if deleted:\n                self.nodes = self._map_nodes()\n            return deleted\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"Replaces a target element with new code.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_element(element_name, new_code)\n        else:\n            if element_name not in self.nodes:\n                return False\n            try:\n                new_ast_module = ast.parse(new_code)\n            except SyntaxError:\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            for _node in ast.walk(self.tree):\n                if hasattr(_node, 'body') and isinstance(_node.body, list):\n                    try:\n                        old_node = self.nodes[element_name]\n                        idx = _node.body.index(old_node)\n                        _node.body.pop(idx)\n                        for i, new_node in enumerate(new_code_body):\n                            _node.body.insert(idx + i, new_node)\n                        del self.nodes[element_name]\n                        for n in new_code_body:\n                            if isinstance(n, (ast.FunctionDef, ast.\n                                AsyncFunctionDef, ast.ClassDef)):\n                                self.nodes[n.name] = n\n                        return True\n                    except (ValueError, KeyError):\n                        continue\n            return False\n\n    def insert_in_element(self, element_name: str, new_code: str, position:\n        str='end', after_line: Optional[int]=None, before_line: Optional[\n        int]=None) ->bool:\n        \"\"\"\n        Insert new code into an element without replacing existing code.\n        This is an internal/helper method, delegating to adapter OR using fallback.\n        \"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name=\n                element_name, before=position == 'start')\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                new_ast = ast.parse(new_code)\n                new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if position == 'start':\n                node.body[0:0] = new_statements\n            elif position == 'end':\n                node.body.extend(new_statements)\n            elif after_line:\n                result = self._find_statement_in_body(node.body, after_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx + 1:idx + 1] = new_statements\n                else:\n                    return False\n            elif before_line:\n                result = self._find_statement_in_body(node.body, before_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx:idx] = new_statements\n                else:\n                    return False\n            else:\n                return False\n            return True\n\n    def _map_nodes(self) ->Dict[str, ast.AST]:\n        \"\"\"Fallback node mapping logic for Python AST.\"\"\"\n        nodes = {}\n        for node in ast.walk(self.tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast\n                .ClassDef)):\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int,\n        line_end: Optional[int]=None) ->Optional[Tuple[int, ast.AST]]:\n        \"\"\"Fallback statement finding logic for Python AST.\"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = stmt.end_lineno if hasattr(stmt, 'end_lineno'\n                        ) else stmt.lineno\n                    if (stmt.lineno <= line_start <= stmt_end or stmt.\n                        lineno <= line_end <= stmt_end):\n                        return i, stmt\n                elif stmt.lineno == line_start:\n                    return i, stmt\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.\n        ImportFrom]]) ->None:\n        \"\"\"Fallback logic to add imports to the top of the Python AST.\"\"\"\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                existing_imports_str.add(astor.to_source(node).strip())\n                last_import_index = i\n        for new_import in reversed(new_import_nodes):\n            new_import_str = astor.to_source(new_import).strip()\n            if new_import_str not in existing_imports_str:\n                self.tree.body.insert(last_import_index + 1, new_import)\n\n    def apply_arbitrary_change(self, new_source_code: str) ->bool:\n        \"\"\"\n        Rewrites the entire file's AST from a new source string.\n        This method resets the adapter if one exists, or uses fallback.\n        \"\"\"\n        if self.adapter:\n            try:\n                adapter_class = type(self.adapter)\n                self.adapter = adapter_class(new_source_code)\n                return True\n            except Exception:\n                return False\n        else:\n            try:\n                new_tree = ast.parse(new_source_code)\n                self.tree = new_tree\n                self.nodes = self._map_nodes()\n                if ASTTOKENS_AVAILABLE:\n                    self.source_code = new_source_code\n                    self.atok = asttokens.ASTTokens(self.source_code, parse\n                        =True)\n                return True\n            except SyntaxError:\n                return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"Serializes the potentially modified code structure back to source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_modified_source()\n        else:\n            return astor.to_source(self.tree)\n\n    def get_diff(self) ->str:\n        \"\"\"Generates a diff between the original source and the modified source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_diff()\n        else:\n            modified_source = self.get_modified_source()\n            return ''.join(difflib.unified_diff(self.source_code.splitlines\n                (keepends=True), modified_source.splitlines(keepends=True),\n                fromfile=f'{self.file_path} (original)', tofile=\n                f'{self.file_path} (modified)'))\n\n    def save_changes(self) ->None:\n        \"\"\"Saves the modified source code back to the file.\"\"\"\n        modified_source = self.get_modified_source()\n        with open(self.file_path, 'w', encoding='utf-8') as f:\n            f.write(modified_source)\n",
    "file": "/mnt/ProjectData/omni/code_editor.py"
  },
  {
    "id": 81,
    "hash": "cc52aa524d0929867d5d2ea3697229e6",
    "content": "\"\"\"\nGenerated file.\n\"\"\"\nimport os\n\"\"\"\nFileCreator - A utility for creating files.\n\nThis module provides a simple, encapsulated way to create files,\nensuring that their parent directories exist before writing.\n\"\"\"\n\n\nclass FileCreator:\n    \"\"\"\n    A utility class to handle the creation of new files.\n    \"\"\"\n\n    @staticmethod\n    def create(file_path: str, content: str) ->None:\n        \"\"\"\n        Creates a file at the specified path with the given content.\n\n        This method will automatically create any necessary parent\n        directories for the file path.\n\n        Args:\n            file_path: The full path where the file should be created.\n            content: The string content to write to the file.\n\n        Raises:\n            IOError: If there is an error creating the directories or writing the file.\n        \"\"\"\n        try:\n            directory = os.path.dirname(file_path)\n            if directory:\n                os.makedirs(directory, exist_ok=True)\n            with open(file_path, 'w', encoding='utf-8') as f:\n                f.write(content)\n        except (IOError, OSError) as e:\n            raise IOError(f\"Failed to create file '{file_path}': {e}\") from e\n",
    "file": "/mnt/ProjectData/omni/file_creator.py"
  },
  {
    "id": 82,
    "hash": "04a24ceab008bd649d0530d309c72e42",
    "content": "import subprocess\nimport os\nfrom typing import List, Optional, Union\n\n\nclass GitManager:\n    \"\"\"\n    Encapsulates Git-related logic for a specific repository.\n\n    This class provides methods to perform common Git operations such as\n    checking status, getting diffs, staging, committing, and pushing changes.\n    It relies on the Git command-line tool being installed and accessible\n    in the system's PATH.\n    \"\"\"\n\n    def __init__(self, repo_path: str):\n        \"\"\"\n        Initializes the GitManager for a given repository path.\n\n        Args:\n            repo_path: The absolute or relative path to the Git repository.\n\n        Raises:\n            ValueError: If the provided path is not a valid Git repository.\n        \"\"\"\n        if not os.path.isdir(os.path.join(repo_path, '.git')):\n            raise ValueError(\n                f\"The path '{repo_path}' is not a valid Git repository.\")\n        self.repo_path = repo_path\n\n    def _run_command(self, command: List[str]) ->str:\n        \"\"\"\n        Executes a Git command in the repository's directory.\n\n        Args:\n            command: A list of command arguments, starting with 'git'.\n\n        Returns:\n            The standard output of the command as a string.\n\n        Raises:\n            subprocess.CalledProcessError: If the command returns a non-zero exit code.\n        \"\"\"\n        try:\n            result = subprocess.run(command, cwd=self.repo_path, check=True,\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True,\n                encoding='utf-8')\n            return result.stdout.strip()\n        except subprocess.CalledProcessError as e:\n            error_message = (\n                f\"Git command failed: {' '.join(command)}\\nError: {e.stderr.strip()}\"\n                )\n            raise subprocess.CalledProcessError(e.returncode, e.cmd, output\n                =e.stdout, stderr=error_message) from e\n\n    def get_status(self) ->str:\n        \"\"\"\n        Gets the repository status in a condensed format.\n\n        Uses `git status --porcelain` for a machine-readable output.\n\n        Returns:\n            A string representing the repository's status.\n        \"\"\"\n        return self._run_command(['git', 'status', '--porcelain'])\n        \n    def get_changed_files(self) -> List[str]:\n        \"\"\"\n        Gets a list of all changed (modified, added, deleted, untracked, renamed, or copied) files.\n\n        This parses the output of `git status --porcelain`, which provides a stable,\n        machine-readable format.\n\n        Returns:\n            A list of file paths relative to the repository root. For renamed or\n            copied files, it returns the new path.\n        \"\"\"\n        status_output = self.get_status()\n        if not status_output:\n            return []\n        \n        changed_files = []\n        for line in status_output.splitlines():\n            if len(line) < 3:  # Skip malformed lines\n                continue\n                \n            # Git status porcelain format: XY filename\n            # X = index status, Y = working tree status\n            index_status = line[0]\n            worktree_status = line[1]\n            \n            # The filename starts after the two status characters and a space\n            # But let's be more defensive about finding where the filename actually starts\n            filename_start = 2\n            while filename_start < len(line) and line[filename_start] == ' ':\n                filename_start += 1\n                \n            if filename_start >= len(line):\n                continue  # Skip if no filename found\n                \n            path_info = line[filename_start:]\n            \n            # Check if either index or working tree status indicates rename/copy\n            if index_status in ('R', 'C') or worktree_status in ('R', 'C'):\n                if ' -> ' in path_info:\n                    _, new_path = path_info.split(' -> ', 1)  # Use maxsplit=1 for safety\n                    changed_files.append(new_path.strip())\n                else:\n                    # Fallback if format is unexpected\n                    changed_files.append(path_info.strip())\n            else:\n                changed_files.append(path_info.strip())\n        \n        # Remove duplicates while preserving order\n        return list(dict.fromkeys(changed_files))\n\n    def get_diff(self, file_path: Optional[str]=None, staged: bool=False\n        ) ->str:\n        \"\"\"\n        Gets the diff of changes in the repository.\n\n        Args:\n            file_path: Optional. Path to a specific file to diff.\n            staged: If True, shows the diff for staged changes (`--cached`).\n                    Otherwise, shows the diff for unstaged changes.\n\n        Returns:\n            The git diff output as a string.\n        \"\"\"\n        cmd = ['git', 'diff']\n        if staged:\n            cmd.append('--cached')\n        if file_path:\n            cmd.append('--')\n            cmd.append(file_path)\n        return self._run_command(cmd)\n\n    def add(self, files: Union[str, List[str]]) ->None:\n        \"\"\"\n    Stages one or more files, handling each one individually for robustness.\n\n    This approach prevents a single invalid file path from causing the\n    entire 'git add' operation to fail. Warnings will be printed for any\n    files that could not be staged.\n\n    Args:\n        files: A single file path or a list of file paths to stage.\n               Can also be '.' to stage all changes.\n    \"\"\"\n        if isinstance(files, str):\n            files = [files]\n        for file_path in files:\n            try:\n                cmd = ['git', 'add', '--', file_path]\n                self._run_command(cmd)\n            except subprocess.CalledProcessError as e:\n                print(\n                    f\"Warning: Could not stage file '{file_path}'. Git reported: {e.stderr}\"\n                    )\n\n    def commit(self, message: str) ->str:\n        \"\"\"\n        Commits staged changes with a given message.\n\n        Args:\n            message: The commit message.\n\n        Returns:\n            The stdout from the git commit command.\n        \"\"\"\n        return self._run_command(['git', 'commit', '-m', message])\n\n    def push(self, remote: str='origin', branch: Optional[str]=None) ->str:\n        \"\"\"\n        Pushes commits to a remote repository.\n\n        Args:\n            remote: The name of the remote to push to (default: 'origin').\n            branch: The branch to push. If None, uses the current branch.\n\n        Returns:\n            The stdout from the git push command.\n        \"\"\"\n        if branch is None:\n            branch = self.get_current_branch()\n        return self._run_command(['git', 'push', remote, branch])\n\n    def get_current_branch(self) ->str:\n        \"\"\"\n        Determines the current active branch name.\n\n        Returns:\n            The name of the current branch.\n        \"\"\"\n        return self._run_command(['git', 'rev-parse', '--abbrev-ref', 'HEAD'])\n",
    "file": "/mnt/ProjectData/omni/git_manager.py"
  },
  {
    "id": 83,
    "hash": "f3f7ab448ad3e233539c4e4bddcd64f4",
    "content": "# javascript_ast_adapter.py\n\n\"\"\"\nJavaScriptASTAdapter - Concrete AST adapter for JavaScript using tree-sitter.\n\nThis module implements the ASTAdapter interface specifically for JavaScript,\nleveraging the tree-sitter library for parsing and manipulation.\n\"\"\"\n\nimport difflib\nimport re\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for tree-sitter\ntry:\n    import tree_sitter\n    import tree_sitter_languages\n    TREETSITTER_AVAILABLE = True\nexcept ImportError:\n    TREETSITTER_AVAILABLE = False\n    # This will cause an error during initialization if the adapter is used\n\n\nclass JavaScriptASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for JavaScript source code.\n\n    This adapter uses tree-sitter to parse and manipulate JavaScript code.\n    It holds the parsed tree-sitter Tree and provides methods to interact\n    with it according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the JavaScriptASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The JavaScript source code as a string.\n\n        Raises:\n            ValueError: If tree-sitter libraries are not available or if\n                        the source code has invalid JavaScript syntax.\n        \"\"\"\n        if not TREETSITTER_AVAILABLE:\n            raise ValueError(\"tree-sitter and tree-sitter-languages are required for JavaScript support.\")\n            \n        # Store source code for diffing and manipulation\n        self.source_code: str = source_code\n        # Will hold the parsed tree-sitter tree\n        self.tree: Optional[tree_sitter.Tree] = None\n        # Will hold a mapping of element names to their tree-sitter nodes\n        self.nodes: Dict[str, tree_sitter.Node] = {}\n        # Tree-sitter language parser\n        self.language = tree_sitter_languages.get_language(\"javascript\")\n        self.parser = tree_sitter.Parser(self.language)\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the JavaScript source code and maps elements.\n\n        Args:\n            source_code: The JavaScript source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid JavaScript syntax.\n        \"\"\"\n        try:\n            # Encode the source code in bytes as required by tree-sitter\n            self.tree = self.parser.parse(bytes(source_code, \"utf-8\"))\n        except Exception as e:\n            raise ValueError(f\"Failed to parse JavaScript source: {e}\") from e\n\n        self.nodes = self._map_nodes()\n\n    def _map_nodes(self) -> Dict[str, tree_sitter.Node]:\n        \"\"\"\n        Walks the tree and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their tree-sitter nodes.\n        \"\"\"\n        nodes: Dict[str, tree_sitter.Node] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        # Define the types of nodes we're interested in\n        target_types = {\n            \"function_declaration\", \"class_declaration\", \n            \"variable_declarator\", \"import_statement\"\n        }\n        \n        # Walk the tree using a stack-based approach\n        stack = [self.tree.root_node]\n        while stack:\n            node = stack.pop()\n            \n            # Check if this is a target node type\n            if node.type in target_types:\n                # Extract the name for different node types\n                name = self._get_node_name(node)\n                if name and name not in nodes:\n                    nodes[name] = node\n            \n            # Add children to the stack for further processing\n            for child in reversed(node.children):  # Reverse to maintain order when popping\n                stack.append(child)\n                \n        return nodes\n    \n    def _get_node_name(self, node: tree_sitter.Node) -> Optional[str]:\n        \"\"\"\n        Extracts the name of a node based on its type.\n        \n        Args:\n            node: The tree-sitter node to extract the name from.\n            \n        Returns:\n            The name of the node, or None if no name could be found.\n        \"\"\"\n        if node.type == \"function_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"class_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"variable_declarator\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"import_statement\":\n            # This is a more complex case - for now, we'll use a simplified approach\n            # Extract the module name from the import statement\n            # e.g., in \"import foo from 'bar'\", we want \"foo\"\n            # This is a simplified implementation and might need refinement\n            import_clause = None\n            for child in node.children:\n                if child.type == \"import_clause\":\n                    import_clause = child\n                    break\n            \n            if import_clause:\n                # Check for a simple identifier\n                for child in import_clause.children:\n                    if child.type == \"identifier\":\n                        return child.text.decode(\"utf-8\")\n                    elif child.type == \"named_imports\":\n                        # Handle named imports like { foo, bar }\n                        # For simplicity, we'll just return a placeholder\n                        # A more complete implementation would extract all names\n                        return f\"import_from_{hash(node.text.decode('utf-8')) % 10000}\"\n        \n        return None\n\n    def _find_node_by_position(self, start_point: Tuple[int, int], \n                              end_point: Optional[Tuple[int, int]] = None) -> Optional[tree_sitter.Node]:\n        \"\"\"\n        Finds a node in the tree that corresponds to a given range.\n        \n        Args:\n            start_point: A (row, column) tuple indicating the start position.\n            end_point: A (row, column) tuple indicating the end position.\n            \n        Returns:\n            The tree-sitter node that corresponds to the range, or None if not found.\n        \"\"\"\n        if not self.tree:\n            return None\n            \n        # A simple approach: find the smallest node that contains the range\n        # This is a simplified implementation and might need refinement\n        def contains_range(node):\n            node_start = (node.start_point[0], node.start_point[1])\n            node_end = (node.end_point[0], node.end_point[1])\n            if end_point:\n                return (node_start <= start_point and node_end >= end_point)\n            else:\n                return node_start <= start_point <= node_end\n        \n        # Walk the tree to find matching nodes\n        stack = [self.tree.root_node]\n        candidates = []\n        \n        while stack:\n            current_node = stack.pop()\n            if contains_range(current_node):\n                candidates.append(current_node)\n                # Add children to continue searching for smaller nodes\n                stack.extend(current_node.children)\n        \n        # Return the smallest (last) candidate\n        return candidates[-1] if candidates else None\n    \n    def _get_line_info_from_point(self, point: Tuple[int, int]) -> Dict[str, Any]:\n        \"\"\"\n        Converts a tree-sitter point to line information.\n        \n        Args:\n            point: A (row, column) tuple from tree-sitter.\n            \n        Returns:\n            A dictionary with line_start and line_end information.\n        \"\"\"\n        # Tree-sitter uses 0-based indexing for rows\n        return {\n            'line_start': point[0] + 1,  # Convert to 1-based\n            'line_end': point[0] + 1\n        }\n\n    def _reparse_tree(self, new_source: str) -> None:\n        \"\"\"\n        Re-parses the tree with new source code.\n        \n        This is necessary because tree-sitter trees are immutable.\n        \n        Args:\n            new_source: The new source code to parse.\n        \"\"\"\n        self.source_code = new_source\n        self.tree = self.parser.parse(bytes(new_source, \"utf-8\"))\n        self.nodes = self._map_nodes()\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return node.text.decode(\"utf-8\")\n            except Exception:\n                # Handle potential decoding issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.type,\n            'line_start': node.start_point[0] + 1,  # Convert to 1-based\n            'line_end': node.end_point[0] + 1,\n            'body_items': []\n        }\n\n        # Add body items for functions and classes\n        if node.type in (\"function_declaration\", \"class_declaration\"):\n            # Find the body block\n            body_node = None\n            for child in node.children:\n                if child.type == \"statement_block\":\n                    body_node = child\n                    break\n            \n            if body_node:\n                # Process statements in the body\n                for i, item in enumerate(body_node.children):\n                    # Skip '{' and '}' tokens\n                    if item.type in (\"{\", \"}\"):\n                        continue\n                    \n                    item_info = {\n                        'index': i,\n                        'type': item.type,\n                        'line_start': item.start_point[0] + 1,\n                        'line_end': item.end_point[0] + 1\n                    }\n                    \n                    # Add more specific information based on type\n                    if item.type == \"variable_declaration\":\n                        item_info['declares'] = \"variable\"\n                    elif item.type == \"return_statement\":\n                        item_info['returns'] = True\n                    elif item.type in (\"if_statement\", \"for_statement\", \"while_statement\"):\n                        item_info['has_body'] = True\n                    \n                    structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n            \n        # A simplified approach to extracting a snippet by line numbers\n        # This would need to be more sophisticated for production use\n        source_lines = self.source_code.split('\\n')\n        # Adjust for 0-based indexing\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(source_lines), line_end)\n        \n        if start_idx < end_idx:\n            return '\\n'.join(source_lines[start_idx:end_idx])\n        \n        return None\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Replace the node's text in the source code\n        new_source = self.source_code[:start_byte] + new_code + self.source_code[end_byte:]\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass  # If we can't even re-parse the original, we're in trouble\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree:\n            return False\n            \n        # For simplicity, we'll add the new code at the end of the file\n        # A more sophisticated implementation would handle the anchor and positioning\n        new_source = self.source_code.rstrip() + \"\\n\\n\" + new_code + \"\\n\"\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Find the full lines that contain the node\n        # This is a simplified approach to avoid leaving partial lines\n        source_lines = self.source_code.split('\\n')\n        start_line = node.start_point[0]\n        end_line = node.end_point[0]\n        \n        # Create new source without those lines\n        new_lines = source_lines[:start_line] + source_lines[end_line+1:]\n        new_source = '\\n'.join(new_lines)\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        # This is a complex operation that would require more sophisticated\n        # tree navigation and manipulation than what's shown here.\n        # For now, we'll provide a basic implementation.\n        \n        node = self.nodes.get(element_name)\n        if not node:\n            return False\n            \n        # Handle line-based replacement\n        if line_start is not None:\n            # Convert to 0-based indexing\n            start_idx = max(0, line_start - 1)\n            end_idx = line_end if line_end is not None else start_idx + 1\n            \n            source_lines = self.source_code.split('\\n')\n            if start_idx < len(source_lines):\n                # Replace the specified lines\n                end_idx = min(end_idx, len(source_lines))\n                new_lines = source_lines[:start_idx] + [new_code] + source_lines[end_idx:]\n                new_source = '\\n'.join(new_lines)\n                \n                # Re-parse the tree with the new source\n                try:\n                    self._reparse_tree(new_source)\n                    return True\n                except Exception:\n                    # If parsing fails, revert to the original source\n                    try:\n                        self._reparse_tree(self.source_code)\n                    except Exception:\n                        pass\n        \n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        # For tree-sitter, the source code is already maintained separately\n        return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        \n        # Ensure line endings are consistent for diffing\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/javascript_ast_adapter.py"
  },
  {
    "id": 84,
    "hash": "89fa0c06ca34019316daa58ce8fa9a20",
    "content": "import json\nimport os\nfrom typing import List, Dict, Optional\nfrom rag_manager import RAGManager\n\n\nclass MemoryManager:\n    \"\"\"Manages persistent chat memory, look data, and RAG integration via JSON.\"\"\"\n\n    def __init__(self, memory_file: str):\n        self.memory_file = memory_file\n        self.memory: Dict[str, List] = self.load_memory()\n        self.rag_manager = RAGManager()\n\n    def load_memory(self) ->Dict[str, List]:\n        try:\n            with open(self.memory_file, 'r') as f:\n                return json.load(f)\n        except FileNotFoundError:\n            default = {'chat': [], 'look': []}\n            self.save_memory(default)\n            return default\n        except json.JSONDecodeError:\n            print('[yellow]Invalid memory file. Resetting.[/]')\n            return {'chat': [], 'look': []}\n\n    def save_memory(self, memory: Optional[Dict[str, List]]=None) ->None:\n        if memory is None:\n            memory = self.memory\n        with open(self.memory_file, 'w') as f:\n            json.dump(memory, f, indent=4)\n\n    def add_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.memory['chat'].append({'role': role, 'content': content})\n        self.save_memory()\n\n    def add_chat_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        This is an alias for add_message to maintain compatibility.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.add_message(role, content)\n\n    def add_look_data(self, file_path: str, content: str) ->None:\n        \"\"\"\n    Adds a watched item (directory or file) to memory, distinguishing its type.\n\n    This method stores structured data that differentiates between a project\n    directory (containing a manifest) and a single file (containing its content).\n    It also prevents duplicate entries by updating existing ones.\n\n    Args:\n        file_path: The path to the directory or file.\n        content: The manifest for a directory or the content for a file.\n    \"\"\"\n        item_type = 'directory' if os.path.isdir(file_path) else 'file'\n        for item in self.memory['look']:\n            if item.get('file') == file_path:\n                item['content'] = content\n                item['type'] = item_type\n                self.save_memory()\n                return\n        self.memory['look'].append({'type': item_type, 'file': file_path,\n            'content': content})\n        self.save_memory()\n        if item_type == 'file':\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    file_content = f.read()\n                self.rag_manager.add_documents([file_content], [{'file':\n                    file_path}])\n            except Exception as e:\n                print(\n                    f'[yellow]Warning: Could not add {file_path} to RAG index: {e}[/]'\n                    )\n\n    def get_project_root(self) ->Optional[str]:\n        \"\"\"\n        Finds the root directory of the project currently in memory.\n\n        The project root is defined as the first item in the 'look' memory\n        that is of type 'directory'.\n\n        Returns:\n            The absolute path to the project root directory, or None if not found.\n        \"\"\"\n        for item in self.memory.get('look', []):\n            if item.get('type') == 'directory':\n                return item.get('file')\n        return None\n\n    def get_memory_context(self) ->str:\n        \"\"\"\n        Dynamically builds the context using RAG and chat history.\n\n        It retrieves relevant file content from the RAG index based on the latest\n        user query, includes project manifests for directories, and appends the\n        recent chat history.\n        \"\"\"\n        context = ''\n        for look in self.memory.get('look', []):\n            path = look.get('file')\n            if path and os.path.isdir(path):\n                content = look.get('content', '')\n                context += (\n                    f'--- Project Manifest for {path} ---\\n{content}\\n\\n')\n        last_user_message = next((msg['content'] for msg in reversed(self.\n            memory.get('chat', [])) if msg['role'] == 'user'), None)\n        if last_user_message:\n            rag_results = self.search_rag(last_user_message, k=3)\n            if rag_results:\n                context += '--- Relevant context from RAG ---\\n'\n                for doc, score, meta in rag_results:\n                    file_path = meta.get('file', 'Unknown source')\n                    context += f'Source: {file_path} (Score: {score:.4f})\\n'\n                    context += f'Content: {doc}\\n---\\n'\n                context += '\\n'\n        for msg in self.memory.get('chat', []):\n            context += f\"{msg['role'].capitalize()}: {msg['content']}\\n\"\n        return context.strip()\n\n    def clear_memory(self) ->None:\n        self.memory = {'chat': [], 'look': []}\n        self.save_memory()\n        self.rag_manager.clear_index()\n\n    def search_rag(self, query: str, k: int=3) ->List[tuple]:\n        \"\"\"\n        Search the RAG index for relevant documents.\n        \n        Args:\n            query: The search query\n            k: Number of results to return\n            \n        Returns:\n            List of (document_content, score, metadata) tuples\n        \"\"\"\n        return self.rag_manager.search(query, k)\n",
    "file": "/mnt/ProjectData/omni/memory_manager.py"
  },
  {
    "id": 85,
    "hash": "1503715e21300d3433a383484d00a3cb",
    "content": "\"\"\"\nOmni - AI-powered code generation and project-aware editing CLI tool\n\nIntegrates modular UI, memory, personality, and AST-based code editing.\n\"\"\"\nimport os\nimport subprocess\nimport requests\nimport json\nimport sys\nimport re\nimport argparse\nimport ast\nfrom datetime import datetime\nimport threading\nimport queue as Queue\nimport time\nfrom typing import List, Dict, Optional\nfrom rich import print\nfrom rich.panel import Panel\nfrom rich.console import Console\nfrom rich.tree import Tree\nfrom ui_manager import UIManager\nfrom personality_manager import PersonalityManager\nfrom memory_manager import MemoryManager\nfrom code_editor import CodeEditor\nfrom file_creator import FileCreator\nfrom git_manager import GitManager\nimport traceback\nDEFAULT_BACKEND = 'openrouter'\nOLLAMA_MODEL = 'phi4-reasoning'\nOPENROUTER_MODEL = 'qwen/qwen3-coder'\nDEFAULT_SAVE_DIR = os.path.expanduser('/mnt/ProjectData/omni/omni_saves/')\nCONFIG_FILE = 'config.json'\nMEMORY_FILE = 'memory.json'\nOLLAMA_API_URL = 'http://localhost:11434/api/generate'\nOPENROUTER_API_URL = 'https://openrouter.ai/api/v1/chat/completions'\nOPENROUTER_MODELS_API_URL = 'https://openrouter.ai/api/v1/models'\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\ncurrent_backend = DEFAULT_BACKEND\ncurrent_model = (OLLAMA_MODEL if DEFAULT_BACKEND == 'ollama' else\n    OPENROUTER_MODEL)\nOLLAMA_MODELS = {'deepseek': 'deepseek-coder:6.7b', 'codellama':\n    'codellama:13b', 'mistral': 'mistral:latest', 'llama2': 'llama2:latest',\n    'phind': 'phind-codellama:34b'}\nos.makedirs(DEFAULT_SAVE_DIR, exist_ok=True)\nTEMPLATES = {'flask':\n    \"\"\"from flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/')\ndef home():\n    return '<h1>Hello, Flask!</h1>'\n\nif __name__ == '__main__':\n    app.run(debug=True)\"\"\"\n    , 'html5':\n    \"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>New Page</title>\n</head>\n<body>\n    <h1>Hello World</h1>\n</body>\n</html>\"\"\"\n    , 'scraper':\n    \"\"\"import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        print(soup.title.text)\n    except Exception as e:\n        print(f\"[bold red]Error scraping {url}:[/] {e}\")\n\nif __name__ == \"__main__\":\n    scrape(\"https://example.com\")\"\"\"\n    }\nconsole = Console()\npersonality_manager = PersonalityManager(CONFIG_FILE)\nmemory_manager = MemoryManager(MEMORY_FILE)\nui_manager = UIManager()\nlast_query: Optional[str] = None\nlast_response: Optional[str] = None\nlast_code: Optional[str] = None\n\n\ndef start_ollama_server() ->None:\n    if current_backend != 'ollama':\n        return\n    try:\n        requests.get('http://localhost:11434', timeout=1)\n    except requests.exceptions.ConnectionError:\n        print('[cyan]Starting Ollama server...[/]')\n        subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL)\n\n\ndef query_llm(prompt: str) ->str:\n    personality = personality_manager.get_current_personality()\n    system_prompt = personality.get('system_prompt', '') if personality else ''\n    memory_context = memory_manager.get_memory_context()\n    rag_context = ''\n    try:\n        from rag_manager import RAGManager\n        project_root = memory_manager.get_project_root()\n        if project_root:\n            rag_manager = RAGManager()\n            if rag_manager.get_document_count() > 0:\n                results = rag_manager.search(prompt, k=3)\n                if results:\n                    rag_context = '\\n\\nRelevant context from codebase:\\n'\n                    for i, (doc, score, meta) in enumerate(results, 1):\n                        file_path = meta.get('file', 'Unknown')\n                        rag_context += f'{i}. [{file_path}] {doc}\\n'\n    except Exception:\n        pass\n    full_prompt = (\n        f'{system_prompt}\\n\\n{memory_context}{rag_context}\\n\\nUser: {prompt}')\n    with ui_manager.show_spinner('AI is listening and thinking...'):\n        if current_backend == 'ollama':\n            response = query_ollama(full_prompt)\n        elif current_backend == 'openrouter':\n            response = query_openrouter(full_prompt)\n        else:\n            response = '[bold red]Error:[/] Unknown backend'\n    return response\n\n\ndef query_openrouter(prompt: str) ->str:\n    if not OPENROUTER_API_KEY:\n        return '[bold red]Error:[/] OPENROUTER_API_KEY not set.'\n    headers = {'Authorization': f'Bearer {OPENROUTER_API_KEY}',\n        'Content-Type': 'application/json'}\n    payload = {'model': current_model, 'messages': [{'role': 'user',\n        'content': prompt}]}\n    try:\n        response = requests.post(OPENROUTER_API_URL, headers=headers, json=\n            payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['choices'][0]['message']['content']\n    except Exception as e:\n        error_details = ''\n        try:\n            error_details = response.json()\n        except:\n            error_details = response.text if hasattr(response, 'text'\n                ) else str(e)\n        return (\n            f'[bold red]OpenRouter Error:[/] {e}\\n[dim]Details: {error_details}[/dim]'\n            )\n\n\ndef query_ollama(prompt: str) ->str:\n    payload = {'model': current_model, 'prompt': prompt, 'stream': False}\n    try:\n        response = requests.post(OLLAMA_API_URL, json=payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['response']\n    except Exception as e:\n        return f'[bold red]Ollama Error:[/] {e}'\n\n\ndef extract_code(text: str) ->List[tuple[str, str]]:\n    matches = re.findall('```(\\\\w*)\\\\n([\\\\s\\\\S]*?)```', text)\n    return [(lang or 'text', code.strip()) for lang, code in matches\n        ] if matches else []\n\n\ndef list_models(args: list=None) ->None:\n    if current_backend == 'ollama':\n        print('[bold cyan]Popular Ollama Models:[/]')\n        for name, model_id in OLLAMA_MODELS.items():\n            print(\n                f\"{'\u2b50' if model_id == current_model else '  '} [yellow]{name:12}[/] \u2192 {model_id}\"\n                )\n    elif current_backend == 'openrouter':\n        list_openrouter_models(args or [])\n\n\ndef list_openrouter_models(args: list):\n    try:\n        from simple_term_menu import TerminalMenu\n    except ImportError:\n        ui_manager.show_error(\n            \"'simple-term-menu' is required. `pip install simple-term-menu`\")\n        return\n    try:\n        with ui_manager.show_spinner('Fetching models...'):\n            response = requests.get(OPENROUTER_MODELS_API_URL)\n            response.raise_for_status()\n        api_models_data = response.json().get('data', [])\n    except requests.RequestException as e:\n        ui_manager.show_error(f'Error fetching models: {e}')\n        return\n    all_models, sources = [], set()\n    for model_data in api_models_data:\n        if (model_id := model_data.get('id')):\n            sources.add(model_id.split('/')[0])\n            pricing = model_data.get('pricing', {})\n            is_free = pricing.get('prompt') == '0' and pricing.get('completion'\n                ) == '0'\n            all_models.append({'id': model_id, 'name': model_data.get(\n                'name'), 'source': model_id.split('/')[0], 'is_free': is_free})\n    all_models.sort(key=lambda x: (x['source'], x['name']))\n    if args and args[0].lower() == 'sources':\n        print('[bold cyan]Available Model Sources:[/]')\n        [print(f'  [yellow]{s}[/]') for s in sorted(list(sources))]\n        return\n    models_to_display, title = all_models, 'Select an OpenRouter Model'\n    if args:\n        filter_keyword = args[0].lower()\n        title = f\"Select a Model from '{filter_keyword}'\"\n        models_to_display = [m for m in all_models if filter_keyword in m[\n            'source'].lower()]\n        if not models_to_display:\n            ui_manager.show_error(f\"No models for source: '{filter_keyword}'\")\n            return\n    menu_entries = [\n        f\"{'\u2b50' if m['id'] == current_model else '  '} {m['name']} [dim]({m['id']}){' [green](FREE)[/]' if m['is_free'] else ''}[/dim]\"\n         for m in models_to_display]\n    try:\n        cursor_idx = next((i for i, m in enumerate(models_to_display) if m[\n            'id'] == current_model), 0)\n        chosen_index = TerminalMenu(menu_entries, title=f'{title}',\n            cursor_index=cursor_idx, cycle_cursor=True, clear_screen=True\n            ).show()\n        if chosen_index is not None:\n            set_model(models_to_display[chosen_index]['id'])\n        else:\n            print('Model selection cancelled.')\n    except Exception as e:\n        ui_manager.show_error(f'Menu display error: {e}')\n\n\ndef set_model(model_id: str) ->None:\n    global current_model\n    current_model = model_id\n    ui_manager.show_success(f'Model set to: {current_model}')\n\n\ndef switch_backend(backend_name: str) ->None:\n    global current_backend, current_model\n    backend_name = backend_name.lower()\n    if backend_name not in ['ollama', 'openrouter']:\n        ui_manager.show_error(f'Unknown backend: {backend_name}')\n        return\n    current_backend = backend_name\n    current_model = (OLLAMA_MODEL if backend_name == 'ollama' else\n        OPENROUTER_MODEL)\n    ui_manager.show_success(\n        f'Switched to {backend_name} backend with model: {current_model}')\n    if backend_name == 'ollama':\n        start_ollama_server()\n\n\ndef generate_project_manifest(path: str) ->tuple[str, List[str]]:\n    manifest = ''\n    file_paths = []\n    tree = Tree(f'[bold cyan]Project: {os.path.basename(path)}[/]')\n    exclude_dirs = {'__pycache__', '.git', 'venv', 'node_modules', '.idea',\n        'ollama'}\n    for root, dirs, files in os.walk(path):\n        dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.\n            startswith('.')]\n        relative_path = os.path.relpath(root, path)\n        branch = tree\n        if relative_path != '.':\n            parts = relative_path.split(os.sep)\n            for part in parts:\n                child = next((c for c in branch.children if c.label ==\n                    f'[magenta]{part}[/]'), None)\n                if not child:\n                    child = branch.add(f'[magenta]{part}[/]')\n                branch = child\n        for fname in sorted(files):\n            ext = os.path.splitext(fname)[1]\n            if ext not in ('.py', '.js', '.html', '.css', '.md', '.txt'):\n                continue\n            rel_path = os.path.join(relative_path, fname\n                ) if relative_path != '.' else fname\n            file_paths.append(rel_path)\n            branch.add(f'[green]{fname}[/]' if ext == '.py' else\n                f'[dim]{fname}[/]')\n            manifest += f'File: {rel_path}\\n\\n'\n    console.print(tree)\n    return manifest.strip(), file_paths\n\n\ndef look_command(path: str) ->None:\n    \"\"\"\n    Scans a directory or file and loads it into memory. It can resolve paths\n    relative to the current working directory or the project root in memory.\n    If a new directory is scanned, the previous 'look' context is cleared\n    to ensure the context remains relevant.\n    \"\"\"\n    resolved_path = resolve_file_path(path)\n    if not resolved_path:\n        ui_manager.show_error(f'\u274c Path not found: {path}')\n        return\n    if resolved_path != os.path.abspath(path):\n        ui_manager.show_success(\n            f\"Found '{path}' in project. Using: {resolved_path}\")\n    if os.path.isdir(resolved_path):\n        ui_manager.show_success(\n            \"New project directory detected. Clearing previous 'look' context.\"\n            )\n        memory_manager.memory['look'] = []\n        with ui_manager.show_spinner('Generating project manifest...'):\n            manifest = generate_project_manifest(resolved_path)\n        memory_manager.add_look_data(resolved_path, manifest)\n        ui_manager.show_success('\u2705 Project manifest added to memory.')\n    else:\n        try:\n            with ui_manager.show_spinner('Loading file...'):\n                with open(resolved_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n            for item in memory_manager.memory['look']:\n                if item.get('file') == resolved_path:\n                    item['content'] = content\n                    memory_manager.save_memory()\n                    ui_manager.show_success(\n                        '\u2705 Refreshed file content in memory.')\n                    return\n            memory_manager.add_look_data(resolved_path, content)\n            ui_manager.show_success('\u2705 File content added to memory.')\n        except Exception as e:\n            ui_manager.show_error(f'\u274c Error reading file: {e}')\n\n\ndef resolve_file_path(path: str) ->Optional[str]:\n    \"\"\"Resolves a file path, checking CWD first, then against project root in memory.\"\"\"\n    if os.path.exists(path):\n        return os.path.abspath(path)\n    project_root = memory_manager.get_project_root()\n    if project_root:\n        full_path = os.path.join(project_root, path)\n        if os.path.exists(full_path):\n            return full_path\n    return None\n\n\ndef _create_prompt_for_file_creation(file_name: str, instruction: str) ->str:\n    \"\"\"\n    Generate a robust prompt for file creation that instructs the AI to act as an expert,\n    produce complete and clean code, and avoid any extra commentary.\n    \"\"\"\n    return f\"\"\"You are an expert programmer tasked with creating a new file. Your goal is to generate complete, production-ready content based on the user's instruction.\n\nIMPORTANT RULES:\n- Provide ONLY the raw file content - no explanations, notes, or commentary outside the file itself\n- Include all necessary imports, boilerplate, and complete implementations\n- If creating code, ensure it's syntactically correct and follows best practices\n- For configuration files, use appropriate formatting (JSON, YAML, etc.)\n- For documentation files, use proper markdown formatting\n\nFile to create: {file_name}\nUser instruction: {instruction}\n\nGenerate the complete file content now:\"\"\"\n\n\ndef handle_file_create_command(file_path: str, instruction: str):\n    \"\"\"\n    Uses the LLM to generate content for a new file based on an instruction.\n    \"\"\"\n    global last_code\n    if os.path.exists(file_path):\n        if ui_manager.get_user_input(\n            f\"File '{file_path}' already exists. Overwrite? (y/n): \").lower(\n            ) not in ['yes', 'y']:\n            ui_manager.show_error('File creation cancelled.')\n            return\n    prompt = _create_prompt_for_file_creation(os.path.basename(file_path),\n        instruction)\n    with ui_manager.show_spinner(\n        f\"AI is generating content for '{file_path}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    if code_blocks:\n        new_content = code_blocks[0][1]\n    else:\n        new_content = response.strip()\n    if not new_content:\n        ui_manager.show_error('AI did not return any content.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    print(Panel(new_content, title=\n        f'[bold yellow]Proposed content for {file_path}[/]', border_style=\n        'yellow'))\n    if ui_manager.get_user_input('Create this file? (y/n): ').lower() in ['yes'\n        , 'y']:\n        try:\n            FileCreator.create(file_path, new_content)\n            last_code = new_content\n            ui_manager.show_success(f'File created successfully: {file_path}')\n        except IOError as e:\n            ui_manager.show_error(f'Error creating file: {e}')\n    else:\n        ui_manager.show_error('File creation cancelled.')\n\n\ndef look_all_command() ->None:\n    \"\"\"\n    Finds the project manifest in memory, reads every file listed, and adds their content to memory.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first to generate a manifest.\"\n            )\n        return\n    manifest_data = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and item.get('type'\n            ) == 'directory':\n            manifest_data = item.get('content')\n            break\n    if not manifest_data or not isinstance(manifest_data, (list, tuple)\n        ) or len(manifest_data) != 2:\n        ui_manager.show_error(\n            \"Could not find a valid project manifest in memory. Please run 'look <directory>' again.\"\n            )\n        return\n    file_paths = manifest_data[1]\n    if not file_paths:\n        ui_manager.show_error('No files found in the project manifest.')\n        return\n    total_files = len(file_paths)\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Loading {total_files} files from project manifest...'):\n        for file_path_relative in file_paths:\n            full_path = os.path.join(project_root, file_path_relative)\n            if os.path.isfile(full_path):\n                try:\n                    with open(full_path, 'r', encoding='utf-8') as f:\n                        content = f.read().strip()\n                    if not any(look['file'] == full_path for look in\n                        memory_manager.memory['look']):\n                        memory_manager.add_look_data(full_path, content)\n                        loaded_count += 1\n                except Exception as e:\n                    print(\n                        f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\"\n                        )\n    ui_manager.show_success(\n        f'\u2705 Loaded content for {loaded_count} new files into memory.')\n\n\ndef _load_all_project_files_if_needed():\n    \"\"\"\n    Checks if a project is loaded and automatically loads any files from its\n    manifest that are not already in the 'look' memory. This ensures a\n    complete context for editing and refactoring commands.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        return\n    manifest_content = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and 'File:' in item.get('content',\n            ''):\n            manifest_content = item['content']\n            break\n    if not manifest_content:\n        return\n    existing_file_paths = {item['file'] for item in memory_manager.memory.\n        get('look', []) if item.get('type') == 'file'}\n    file_paths_relative = re.findall('File: (.*)', manifest_content)\n    files_to_load = []\n    for rel_path in file_paths_relative:\n        full_path = os.path.join(project_root, rel_path)\n        if full_path not in existing_file_paths and os.path.isfile(full_path):\n            files_to_load.append((full_path, rel_path))\n    if not files_to_load:\n        return\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Auto-loading {len(files_to_load)} project files for context...'):\n        for full_path, file_path_relative in files_to_load:\n            try:\n                with open(full_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n                memory_manager.add_look_data(full_path, content)\n                loaded_count += 1\n            except Exception as e:\n                print(f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\")\n    if loaded_count > 0:\n        ui_manager.show_success(\n            f'\u2705 Loaded {loaded_count} new file(s) into memory for full project context.'\n            )\n\n\ndef _create_prompt_for_element_selection(file_name: str, instruction: str,\n    elements: List[str], element_structures: Dict[str, Dict]) ->str:\n    \"\"\"\n    Create a helper for the first stage of the 'edit' command. This prompt asks the AI\n    to analyze the user's instruction and intelligently select the most relevant code element to modify.\n    \"\"\"\n    element_details = []\n    for elem in elements:\n        if elem in element_structures:\n            struct = element_structures[elem]\n            detail = (\n                f\"{elem} ({struct['type']}, lines {struct['line_start']}-{struct['line_end']})\"\n                )\n            element_details.append(detail)\n        else:\n            element_details.append(elem)\n    return f\"\"\"You are an expert code analyzer. Your task is to identify what should be modified based on the user's instruction.\n\nFile: {file_name}\nAvailable elements: {', '.join(element_details) if element_details else 'None'}\n\nUser instruction: {instruction}\n\nRESPONSE FORMAT:\nChoose one of these response types:\n1. \"ELEMENT: <element_name>\" - to edit an entire function/class\n2. \"PARTIAL: <element_name> LINES: <start>-<end>\" - to edit specific lines within an element\n3. \"FILE\" - to edit the entire file or multiple elements\n\nRULES:\n- If the instruction mentions specific line numbers or a specific part of a function, use PARTIAL\n- If the instruction targets an entire function/class, use ELEMENT\n- If the instruction requires changes to multiple elements or file structure, use FILE\n- For PARTIAL edits, provide absolute line numbers from the original file\n\nWhat should be edited?\"\"\"\n\n\ndef _create_prompt_for_element_rewrite(file_name: str, element_name: str,\n    instruction: str, original_code: str, is_full_file: bool=False) ->str:\n    \"\"\"\n    Create a helper for the second stage of the 'edit' command. This prompt instructs the AI\n    to rewrite a specific code element (or the whole file) based on the user's request,\n    demanding a complete and syntactically correct code block as output.\n    \"\"\"\n    if is_full_file:\n        return f\"\"\"You are an expert programmer. Rewrite the entire file to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the entire file\n- Ensure all syntax is correct and the code is ready to run\n- Preserve existing functionality unless explicitly asked to change it\n- Include all necessary imports and maintain the file's structure\n- Do NOT include any explanations or comments outside the code\n\nFile: {file_name}\nTask: {instruction}\n\nCurrent file content:\n```python\n{original_code}\n```\n\nGenerate the complete updated file now:\"\"\"\n    else:\n        return f\"\"\"You are an expert programmer. Rewrite the specified element to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the element\n- Include any necessary imports at the top of your code block\n- Ensure the code is syntactically correct and maintains the same interface\n- Do NOT include explanations or comments outside the code block\n- The code must be a drop-in replacement for the original element\n\nFile: {file_name}\nElement to modify: {element_name}\nTask: {instruction}\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the complete updated element now:\"\"\"\n\n\ndef _create_prompt_for_partial_edit(file_name: str, element_name: str,\n    instruction: str, original_snippet: str, line_start: int, line_end: int,\n    full_element_code: str) ->str:\n    \"\"\"\n    Create a prompt for partial edits within a function or class.\n    This allows surgical changes to specific parts of code.\n    \"\"\"\n    return f\"\"\"You are an expert programmer. Make a surgical edit to a specific part of a function/class.\n\nCONTEXT:\n- File: {file_name}\n- Element: {element_name}\n- Lines to modify: {line_start}-{line_end}\n- Task: {instruction}\n\nIMPORTANT RULES:\n- Provide ONLY the code that will replace lines {line_start}-{line_end}\n- Your code must fit seamlessly into the existing function\n- Maintain proper indentation (the code will be auto-indented)\n- Do NOT include the function definition or other parts\n- Do NOT include explanations outside the code\n\nFull element for context:\n```python\n{full_element_code}\n```\n\nCode section to replace (lines {line_start}-{line_end}):\n```python\n{original_snippet}\n```\n\nGenerate ONLY the replacement code for the specified lines:\"\"\"\n\n\ndef handle_file_edit_command(file_path: str, instruction: str):\n    \"\"\"\n    Handles the entire workflow for editing a single file, ensuring full\n    project context is loaded before the AI makes any decisions.\n    Now supports partial edits within functions.\n    \"\"\"\n    global last_code\n    _load_all_project_files_if_needed()\n    resolved_path = resolve_file_path(file_path)\n    if not resolved_path:\n        ui_manager.show_error(f'File not found: {file_path}')\n        return\n    if resolved_path != os.path.abspath(file_path):\n        ui_manager.show_success(\n            f\"Found '{file_path}' in project. Using: {resolved_path}\")\n    try:\n        editor = CodeEditor(resolved_path)\n    except (ValueError, FileNotFoundError) as e:\n        ui_manager.show_error(str(e))\n        return\n    elements = editor.list_elements()\n    element_structures = {}\n    for elem in elements:\n        struct = editor.get_element_structure(elem)\n        if struct:\n            element_structures[elem] = struct\n    prompt1 = _create_prompt_for_element_selection(os.path.basename(\n        resolved_path), instruction, elements, element_structures)\n    with ui_manager.show_spinner('AI is analyzing file...'):\n        ai_response = query_llm(prompt1).strip()\n    if ai_response.upper() == 'FILE':\n        ui_manager.show_success('AI has chosen to edit the entire file.')\n        original_snippet = editor.source_code\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), 'entire file', instruction, original_snippet,\n            is_full_file=True)\n        edit_type = 'FILE'\n        element_to_edit = None\n        line_range = None\n    elif ai_response.startswith('PARTIAL:'):\n        parts = ai_response.split()\n        element_to_edit = parts[1]\n        if 'LINES:' in ai_response:\n            line_part = ai_response.split('LINES:')[1].strip()\n            if '-' in line_part:\n                line_start, line_end = map(int, line_part.split('-'))\n                line_range = line_start, line_end\n            else:\n                ui_manager.show_error('Invalid line range format')\n                return\n        else:\n            ui_manager.show_error('Missing line range for partial edit')\n            return\n        if element_to_edit not in elements:\n            ui_manager.show_error(f\"Element '{element_to_edit}' not found\")\n            return\n        ui_manager.show_success(\n            f\"AI selected partial edit of '{element_to_edit}' (lines {line_start}-{line_end})\"\n            )\n        original_snippet = editor.get_element_body_snippet(element_to_edit,\n            line_start, line_end)\n        if not original_snippet:\n            original_snippet = editor.get_source_of(element_to_edit)\n        full_element_code = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_partial_edit(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet,\n            line_start, line_end, full_element_code)\n        edit_type = 'PARTIAL'\n    elif ai_response.startswith('ELEMENT:'):\n        element_to_edit = ai_response.split(':', 1)[1].strip()\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    else:\n        element_to_edit = ai_response.splitlines()[0]\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    with ui_manager.show_spinner(f'AI is editing...'):\n        response = query_llm(prompt2)\n    code_blocks = extract_code(response)\n    if not code_blocks:\n        ui_manager.show_error('AI did not return a valid code block.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    new_code = code_blocks[0][1]\n    success = False\n    if edit_type == 'FILE':\n        try:\n            editor.tree = ast.parse(new_code)\n            success = True\n        except SyntaxError as e:\n            ui_manager.show_error(f'AI returned invalid Python syntax: {e}')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    elif edit_type == 'PARTIAL':\n        success = editor.replace_partial(element_to_edit, new_code,\n            line_start=line_range[0], line_end=line_range[1])\n        if not success:\n            ui_manager.show_error('Failed to apply partial edit.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    else:\n        success = editor.replace_element(element_to_edit, new_code)\n        if not success:\n            ui_manager.show_error(\n                'AI returned invalid code; could not be parsed or applied.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    if not (diff := editor.get_diff()):\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(diff, title=\n        f'[bold yellow]Proposed Changes for {resolved_path}[/]'))\n    if ui_manager.get_user_input('Apply changes? (y/n): ').lower() in ['yes',\n        'y']:\n        editor.save_changes()\n        last_code = editor.get_modified_source()\n        ui_manager.show_success(f'Changes saved to {resolved_path}.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_plan(instruction: str, memory_context: str\n    ) ->str:\n    \"\"\"\n    Create a specialized prompt-generation function for the 'refactor' command.\n    This prompt will explicitly define the required JSON structure for the plan\n    and instruct the AI to act as an expert project manager.\n    \"\"\"\n    return f\"\"\"You are an expert project manager and software architect. Analyze the project context and create a detailed refactoring plan.\n\nYour plan must be a valid JSON object with this exact structure:\n{{\n    \"actions\": [\n        {{\n            \"type\": \"MODIFY\" | \"CREATE\" | \"DELETE\" | \"PARTIAL\",\n            \"file\": \"relative/path/to/file.py\",\n            \"element\": \"function_or_class_name\",  // For MODIFY/DELETE/PARTIAL\n            \"element_name\": \"new_element_name\",    // For CREATE\n            \"line_start\": 10,                      // For PARTIAL only\n            \"line_end\": 20,                        // For PARTIAL only\n            \"reason\": \"Clear explanation of why this change is needed\",\n            \"description\": \"What this action will accomplish\",\n            \"anchor_element\": \"optional_anchor\",   // Optional for CREATE\n            \"position\": \"before\" | \"after\"         // Optional for CREATE\n        }}\n    ]\n}}\n\nACTION TYPES:\n- MODIFY: Change an entire function, class, or method\n- PARTIAL: Change specific lines within a function/class (requires line_start and line_end)\n- CREATE: Add new functions, classes, or files\n- DELETE: Remove functions, classes, variables, or imports\n\nRULES FOR YOUR PLAN:\n- Use PARTIAL when you only need to change a small part of a function\n- Use MODIFY when restructuring an entire function or class\n- Each action must have all required fields based on its type\n- File paths must be relative to the project root\n- Be specific and surgical - avoid unnecessary changes\n- Consider dependencies between changes\n- Order actions logically (e.g., create dependencies before using them)\n\n### Project Context ###\n{memory_context}\n\n### Refactoring Request ###\n{instruction}\n\nGenerate ONLY the JSON plan - no explanations or markdown:\"\"\"\n\n\ndef _get_refactor_plan(instruction: str) ->Optional[List[Dict]]:\n    \"\"\"\n    Generates a refactoring plan from the LLM.\n\n    This function encapsulates the logic for checking project context,\n    constructing a prompt, querying the LLM, and parsing the resulting\n    JSON plan for a refactoring task.\n\n    Args:\n        instruction: The user's high-level refactoring instruction.\n\n    Returns:\n        A list of action dictionaries if a valid plan is generated,\n        otherwise None.\n    \"\"\"\n    if not memory_manager.get_project_root():\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return None\n    memory_context = memory_manager.get_memory_context()\n    plan_prompt = _create_prompt_for_refactor_plan(instruction, memory_context)\n    with ui_manager.show_spinner('AI is creating an execution plan...'):\n        plan_str = query_llm(plan_prompt)\n    try:\n        match = re.search('\\\\{.*\\\\}', plan_str, re.DOTALL)\n        if not match:\n            raise ValueError('No JSON object found in the response.')\n        plan = json.loads(match.group(0))\n        actions = plan.get('actions', [])\n        if not actions:\n            raise ValueError(\"No 'actions' key found in plan or plan is empty.\"\n                )\n        return actions\n    except (json.JSONDecodeError, ValueError) as e:\n        ui_manager.show_error(f'AI failed to generate a valid plan: {e}')\n        print(Panel(plan_str, title=\"[yellow]AI's Invalid Plan Response[/]\",\n            border_style='yellow'))\n        return None\n\n\ndef _display_and_confirm_plan(plan: Dict) ->bool:\n    \"\"\"\n    Displays the generated execution plan to the user and asks for confirmation.\n\n    This helper function separates the UI interaction of plan confirmation from\n    the main refactoring logic.\n\n    Args:\n        plan: A dictionary, expected to contain an 'actions' key with a list of action dicts.\n\n    Returns:\n        True if the user confirms the plan, False otherwise.\n    \"\"\"\n    actions = plan.get('actions', [])\n    if not actions:\n        ui_manager.show_error('The generated plan is empty. Aborting.')\n        return False\n    ui_manager.show_success('AI has created a plan:')\n    for i, action in enumerate(actions):\n        action_type = action.get('type', 'N/A')\n        element = action.get('element') or action.get('element_name', 'N/A')\n        reason = action.get('reason') or action.get('description', '')\n        file_path = action.get('file', '')\n        if action_type == 'PARTIAL':\n            line_start = action.get('line_start', '?')\n            line_end = action.get('line_end', '?')\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} (lines {line_start}-{line_end}) - {reason}'\n                )\n        else:\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} - {reason}'\n                )\n    if ui_manager.get_user_input('\\nProceed with this plan? (y/n): ').lower(\n        ) in ['yes', 'y']:\n        return True\n    else:\n        ui_manager.show_error('Execution aborted by user.')\n        return False\n\n\ndef _apply_refactor_changes(editors: Dict[str, CodeEditor]) ->None:\n    \"\"\"\n    Consolidates changes from multiple CodeEditor instances, shows a unified\n    diff, and prompts the user to apply them.\n    \n    This helper function abstracts the final step of a refactor, ensuring\n    all proposed modifications are presented to the user for a final review\n    before any files are written to disk.\n\n    Args:\n        editors: A dictionary mapping absolute file paths to their\n                 corresponding CodeEditor instances which hold the\n                 proposed changes in their AST.\n    \"\"\"\n    full_diff = ''\n    for editor in editors.values():\n        diff = editor.get_diff()\n        if diff:\n            full_diff += diff + '\\n'\n    if not full_diff.strip():\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(full_diff, title=\n        '[bold yellow]Proposed Project-Wide Changes[/]'))\n    if ui_manager.get_user_input('Apply all changes? (y/n): ').lower() in [\n        'yes', 'y']:\n        for editor in editors.values():\n            editor.save_changes()\n        ui_manager.show_success('\u2705 Project changes applied successfully.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_action(action_type: str, file_path: str,\n    action_details: Dict) ->str:\n    \"\"\"\n    Create a helper to generate prompts for individual 'CREATE' or 'MODIFY' steps\n    within a refactor plan. This ensures the AI produces code for the specific\n    sub-task in the correct context.\n    \"\"\"\n    if action_type == 'MODIFY':\n        element_name = action_details['element_name']\n        reason = action_details['reason']\n        original_code = action_details['original_code']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- Element: {element_name}\n- Reason for change: {reason}\n\nRULES:\n- Provide ONLY the complete updated code for the element\n- Include any necessary imports at the top\n- Ensure the code integrates properly with the rest of the file\n- Maintain the same function/class signature unless the change requires otherwise\n- No explanations outside the code block\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the updated element code:\"\"\"\n    elif action_type == 'CREATE':\n        element_name = action_details['element_name']\n        description = action_details['description']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- New element to create: {element_name}\n- Purpose: {description}\n\nRULES:\n- Provide ONLY the complete code for the new element\n- Include all necessary imports at the top\n- Follow the coding style and patterns used in the project\n- Ensure the code is production-ready and well-structured\n- For non-Python files, provide the complete file content\n- No explanations outside the code block\n\nGenerate the new element code:\"\"\"\n\n\ndef _process_refactor_action(action: Dict, project_base_path: str, editors:\n    Dict) ->bool:\n    \"\"\"\n    Processes a single refactoring action from the plan.\n\n    This function handles the execution of a single action from the refactoring plan,\n    including LLM code generation and applying changes to in-memory editors or files.\n\n    Args:\n        action: A dictionary containing action details (type, file, element, etc.)\n        project_base_path: The absolute path to the project root\n        editors: Dictionary mapping file paths to their CodeEditor instances\n\n    Returns:\n        True if the action was processed successfully, False otherwise\n    \"\"\"\n    file_path_relative = action.get('file')\n    if not file_path_relative:\n        ui_manager.show_error(\n            f\"Action is missing 'file' key. Skipping: {action}\")\n        return False\n    file_path_absolute = os.path.join(project_base_path, file_path_relative)\n    action_type = action.get('type', '').upper()\n    prompt, element_name = '', ''\n    if action_type == 'MODIFY':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_source_of(element_name)\n            if not original_snippet:\n                ui_manager.show_error(\n                    f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                    )\n                return False\n            action_details = {'element_name': element_name, 'reason':\n                reason, 'original_code': original_snippet}\n            prompt = _create_prompt_for_refactor_action('MODIFY',\n                file_path_relative, action_details)\n    elif action_type == 'PARTIAL':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        line_start = action.get('line_start')\n        line_end = action.get('line_end')\n        if not all([element_name, line_start, line_end]):\n            ui_manager.show_error(\n                f'PARTIAL action missing required fields. Skipping: {action}')\n            return False\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_element_body_snippet(element_name,\n                line_start, line_end)\n            if not original_snippet:\n                original_snippet = editor.get_source_of(element_name)\n                if not original_snippet:\n                    ui_manager.show_error(\n                        f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                        )\n                    return False\n            full_element_code = editor.get_source_of(element_name)\n            prompt = _create_prompt_for_partial_edit(file_path_relative,\n                element_name, reason, original_snippet, line_start,\n                line_end, full_element_code)\n    elif action_type == 'CREATE':\n        element_name = action.get('element_name')\n        description = action.get('description')\n        action_details = {'element_name': element_name, 'description':\n            description}\n        prompt = _create_prompt_for_refactor_action('CREATE',\n            file_path_relative, action_details)\n    else:\n        ui_manager.show_error(f\"Invalid action type '{action_type}'. Skipping.\"\n            )\n        return False\n    with ui_manager.show_spinner(\n        f\"AI: {action_type} on '{element_name or file_path_relative}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    new_content = code_blocks[0][1] if code_blocks else response.strip()\n    if not new_content:\n        ui_manager.show_error(\n            f'AI failed to generate content for action: {action}')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return False\n    if not file_path_relative.endswith('.py'):\n        try:\n            FileCreator.create(file_path_absolute, new_content)\n            ui_manager.show_success(\n                f\"File '{file_path_relative}' created/updated.\")\n            return True\n        except IOError as e:\n            ui_manager.show_error(\n                f\"Failed to create file '{file_path_relative}': {e}\")\n            return False\n    if file_path_absolute not in editors:\n        try:\n            if not os.path.exists(file_path_absolute):\n                os.makedirs(os.path.dirname(file_path_absolute), exist_ok=True)\n                with open(file_path_absolute, 'w') as f:\n                    f.write('')\n            editors[file_path_absolute] = CodeEditor(file_path_absolute)\n        except Exception as e:\n            ui_manager.show_error(\n                f'Error loading file {file_path_absolute}: {e}')\n            return False\n    editor = editors[file_path_absolute]\n    if action_type == 'MODIFY':\n        if not editor.replace_element(element_name, new_content):\n            ui_manager.show_error(\n                f\"Failed to apply MODIFY change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic MODIFY Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'PARTIAL':\n        if not editor.replace_partial(element_name, new_content, line_start,\n            line_end):\n            ui_manager.show_error(\n                f\"Failed to apply PARTIAL change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic PARTIAL Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'CREATE':\n        anchor = action.get('anchor_element')\n        position = action.get('position', 'after')\n        if not editor.add_element(new_content, anchor_name=anchor, before=\n            position == 'before'):\n            ui_manager.show_error(\n                f\"Failed to apply CREATE change for '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic CREATE Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    return True\n\n\ndef handle_project_refactor_command(instruction: str):\n    \"\"\"\n    Orchestrates a multi-file, multi-step code refactoring process.\n    \n    This function serves as a high-level orchestrator that delegates specific tasks\n    to helper functions, improving readability, modularity, and maintainability.\n    \"\"\"\n    _load_all_project_files_if_needed()\n    actions = _get_refactor_plan(instruction)\n    if not actions:\n        return\n    plan = {'actions': actions}\n    if not _display_and_confirm_plan(plan):\n        return\n    editors: Dict[str, CodeEditor] = {}\n    project_base_path = memory_manager.get_project_root()\n    successful_actions = 0\n    total_actions = len(actions)\n    for i, action in enumerate(actions, 1):\n        ui_manager.show_success(f'Processing action {i}/{total_actions}...')\n        action_type = action.get('type', '').upper()\n        file_path_relative = action.get('file')\n        if not file_path_relative:\n            ui_manager.show_error(\n                f\"Action is missing 'file' key. Skipping: {action}\")\n            continue\n        file_path_absolute = os.path.join(project_base_path, file_path_relative\n            )\n        if action_type == 'DELETE':\n            element_name = action.get('element')\n            if not element_name:\n                ui_manager.show_error(\n                    f\"DELETE action missing 'element' key. Skipping: {action}\")\n                continue\n            if not file_path_relative.endswith('.py'):\n                ui_manager.show_error(\n                    f'DELETE actions are only supported for Python files. Skipping.'\n                    )\n                continue\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    continue\n            editor = editors[file_path_absolute]\n            if editor.delete_element(element_name):\n                successful_actions += 1\n                ui_manager.show_success(\n                    f\"Successfully deleted '{element_name}' from '{file_path_relative}'.\"\n                    )\n            else:\n                ui_manager.show_error(\n                    f\"Failed to delete '{element_name}' from '{file_path_relative}'.\"\n                    )\n        elif _process_refactor_action(action, project_base_path, editors):\n            successful_actions += 1\n        else:\n            ui_manager.show_error(\n                f'Action {i} failed, continuing with remaining actions...')\n    if successful_actions == 0:\n        ui_manager.show_error('No actions were successfully executed.')\n        return\n    elif successful_actions < total_actions:\n        ui_manager.show_error(\n            f'Only {successful_actions}/{total_actions} actions completed successfully.'\n            )\n    else:\n        ui_manager.show_success(\n            f'All {total_actions} actions completed successfully.')\n    _apply_refactor_changes(editors)\n\n\ndef _create_prompt_for_commit_message(diff: str) ->str:\n    \"\"\"\n    Create a dedicated prompt function for the 'commit' command. This prompt will\n    instruct the AI to analyze a git diff and generate a concise commit message\n    following the Conventional Commits standard.\n    \"\"\"\n    return f\"\"\"You are an expert developer writing a Git commit message. Your task is to analyze the provided git diff and create a professional commit message.\n\nCOMMIT MESSAGE RULES:\n- Follow the Conventional Commits specification\n- Format: <type>(<optional scope>): <subject>\n- Types: feat, fix, docs, style, refactor, perf, test, build, ci, chore, revert\n- Subject line: max 50 characters, imperative mood, no period\n- Optional body: explain what and why (not how), wrap at 72 characters\n- Be specific and concise\n- Focus on the intent and impact of the changes\n\nEXAMPLES OF GOOD COMMIT MESSAGES:\n- feat(auth): add OAuth2 integration for Google login\n- fix(api): handle null response in user endpoint\n- refactor(database): optimize query performance for large datasets\n- docs(readme): update installation instructions for Windows\n\nRespond with ONLY the commit message - no markdown, quotes, or explanations.\n\n--- GIT DIFF TO ANALYZE ---\n{diff}\n\nGenerate the commit message:\"\"\"\n\n\ndef handle_commit_command():\n    \"\"\"\n    Orchestrates an AI-assisted Git commit workflow with improved error handling.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return\n    try:\n        git_manager = GitManager(project_root)\n    except ValueError as e:\n        ui_manager.show_error(str(e))\n        return\n    changed_files = git_manager.get_changed_files()\n    if not changed_files:\n        ui_manager.show_success(\n            'No changes to commit. Everything is up to date.')\n        return\n    staged_diff = git_manager.get_diff(staged=True)\n    unstaged_diff = git_manager.get_diff()\n    full_diff = f'{staged_diff}\\n{unstaged_diff}'.strip()\n    if not full_diff.strip():\n        ui_manager.show_success(\n            'No content changes detected (e.g., only file mode changes).')\n        return\n    prompt = _create_prompt_for_commit_message(full_diff)\n    commit_message = query_llm(prompt).strip()\n    if not commit_message:\n        ui_manager.show_error(\n            'AI failed to generate a commit message. Aborting.')\n        return\n    files_to_commit_str = '\\n'.join(f'- {f}' for f in changed_files)\n    plan_panel_content = f\"\"\"[bold]Files to be staged:[/]\n[yellow]{files_to_commit_str}[/]\n\n[bold]AI-Generated Commit Message:[/]\n[green]{commit_message}[/]\"\"\"\n    print(Panel(plan_panel_content, title='[bold cyan]Commit Plan[/]',\n        border_style='cyan'))\n    if ui_manager.get_user_input('\\nProceed with commit? (y/n): ').lower() in [\n        'yes', 'y']:\n        try:\n            git_manager.add(changed_files)\n            ui_manager.show_success('\u2705 Files staged.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Staging failed: {e.stderr}')\n            return\n        try:\n            git_manager.commit(commit_message)\n            ui_manager.show_success('\u2705 Commit successful.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Commit failed: {e.stderr}')\n            return\n        if ui_manager.get_user_input('Push changes to remote? (y/n): ').lower(\n            ) in ['yes', 'y']:\n            try:\n                git_manager.push()\n                ui_manager.show_success('\u2705 Push successful.')\n            except subprocess.CalledProcessError as e:\n                ui_manager.show_error(f'Push failed: {e.stderr}')\n        else:\n            ui_manager.show_error('Push cancelled.')\n    else:\n        ui_manager.show_error('Commit aborted by user.')\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef interactive_mode() ->None:\n    global last_query, last_response, last_code\n    try:\n        from Testing.overlay_engine import show_sequential_popup\n        gui_available = True\n    except ImportError:\n        gui_available = False\n    print(Panel(\n        \"\"\"[bold cyan]Omni Interactive Mode[/]\n[dim]Type 'help' for commands, 'exit' to quit.[/dim]\"\"\"\n        , border_style='cyan'))\n    personality_name = personality_manager.get_current_personality().get('name'\n        , 'Default')\n    gui_enabled = False\n    if gui_available:\n        try:\n            with open(CONFIG_FILE, 'r') as f:\n                config = json.load(f)\n                if config.get('gui_enabled', False):\n                    gui_enabled = True\n        except (FileNotFoundError, json.JSONDecodeError):\n            pass\n    refresh_status_panel(personality_name)\n    while True:\n        try:\n            user_input = ui_manager.get_user_input('\\n> ')\n            if not user_input:\n                continue\n            command, *args = user_input.split(maxsplit=1)\n            arg_str = args[0] if args else ''\n            if command == 'exit':\n                memory_manager.save_memory()\n                print('[bold cyan]Goodbye![/]')\n                break\n            elif command == 'help':\n                print(\n                    \"\"\"[bold]Commands:[/]\n\n  [bold cyan]Core & Project Commands[/]\n  [yellow]send <prompt>[/]        - Ask the LLM a question.\n  [yellow]look <path>[/]          - Read file or scan directory into memory.\n  [yellow]look_all[/]            - Recursively scan the project directory into memory.\n  [yellow]create <file> \"instr\"[/] - Create a new file using AI.\n  [yellow]edit <file> \"instr\"[/]   - Edit a specific file using AI.\n  [yellow]refactor \"instr\"[/]      - Refactor project in memory based on instruction.\n  [yellow]commit[/]               - Commit changes with an AI-generated message.\n  [yellow]rag <query>[/]         - Query the RAG system for context retrieval.\n\n  [bold cyan]File & Code Management[/]\n  [yellow]save <filename>[/]     - Save last AI response to a file.\n  [yellow]list[/]               - List saved files.\n  [yellow]run[/]                 - Run the last generated Python code.\n\n  [bold cyan]Session & Config[/]\n  [yellow]history[/]             - Show the full chat history.\n  [yellow]memory clear[/]        - Clear the chat and file memory.\n  [yellow]backend <name>[/]      - Switch AI backend (e.g., openrouter, ollama).\n  [yellow]models [src][/]        - Interactively list and select models.\n  [yellow]set model <id>[/]      - Set the model directly by its ID.\n  [yellow]personality <cmd>[/]   - Manage AI personalities ('list', 'set', 'add').\n\"\"\"\n                    )\n            elif command == 'send':\n                last_query = arg_str\n                response = query_llm(arg_str)\n                last_response = response\n                memory_manager.add_chat_message('user', last_query)\n                memory_manager.add_chat_message('assistant', last_response)\n                if gui_enabled:\n                    threading.Thread(target=show_sequential_popup, args=(\n                        100, 100, response, f'Omni - {personality_name}'),\n                        daemon=True).start()\n                print(Panel(response, title='[cyan]Response[/]'))\n                if (code_blocks := extract_code(response)):\n                    last_code = code_blocks[0][1]\n            elif command == 'look':\n                look_command(arg_str)\n            elif command == 'look_all':\n                look_all_command()\n            elif command == 'create':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_create_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: create <file_path> \"<instruction>\"')\n            elif command == 'edit':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_edit_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: edit <file_path> \"<instruction>\"')\n            elif command == 'refactor':\n                if not arg_str:\n                    ui_manager.show_error('Usage: refactor \"<instruction>\"')\n                else:\n                    handle_project_refactor_command(arg_str.strip('\"'))\n            elif command == 'commit':\n                handle_commit_command()\n            elif command == 'models':\n                list_models(arg_str.split())\n            elif command == 'set' and arg_str.startswith('model '):\n                set_model(arg_str[6:])\n            elif command == 'backend':\n                switch_backend(arg_str)\n            elif command == 'history':\n                ui_manager.display_history(memory_manager.get_memory_context())\n            elif command == 'memory' and arg_str == 'clear':\n                memory_manager.clear_memory()\n                ui_manager.show_success('\u2705 Memory cleared')\n            elif command == 'personality':\n                p_args = arg_str.split(maxsplit=1)\n                cmd = p_args[0] if p_args else ''\n                p_arg_str = p_args[1] if len(p_args) > 1 else ''\n                if cmd == 'list':\n                    for p in personality_manager.list_personalities():\n                        print(f\"- {p['name']}: {p['description']}\")\n                elif cmd == 'set' and p_arg_str:\n                    if personality_manager.set_current_personality(p_arg_str):\n                        personality_name = p_arg_str\n                        ui_manager.show_success(\n                            f'Set personality to {personality_name}')\n                    else:\n                        ui_manager.show_error('Personality not found.')\n                else:\n                    ui_manager.show_error(\n                        \"Invalid personality command. Use 'list' or 'set <name>'.\"\n                        )\n            elif command == 'run':\n                run_python_code()\n            elif command == 'save':\n                if last_response:\n                    save_code(last_response, arg_str or\n                        f\"omni_save_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n                        )\n                else:\n                    ui_manager.show_error('No response to save.')\n            elif command == 'list':\n                files = sorted(os.listdir(DEFAULT_SAVE_DIR))\n                print('\\n'.join(f'  - {f}' for f in files) if files else\n                    '[yellow]No saved files.[/]')\n            elif command == 'rag':\n                if not arg_str:\n                    ui_manager.show_error('Usage: rag \"<query>\"')\n                else:\n                    from rag_manager import RAGManager\n                    project_root = memory_manager.get_project_root()\n                    if not project_root:\n                        ui_manager.show_error(\n                            \"No project context in memory. Use 'look <directory>' first.\"\n                            )\n                        continue\n                    rag = RAGManager()\n                    if rag.get_document_count() == 0:\n                        ui_manager.show_error(\n                            'RAG index is empty. Please add documents first.')\n                        continue\n                    results = rag.search(arg_str, k=3)\n                    if not results:\n                        ui_manager.show_error('No relevant documents found.')\n                        continue\n                    print(Panel('[bold]RAG Results:[/]', title=\n                        '[cyan]Retrieval-Augmented Generation[/]'))\n                    for i, (content, score, metadata) in enumerate(results, 1):\n                        file_path = metadata.get('file', 'Unknown')\n                        print(\n                            f'[bold cyan]{i}. {file_path}[/] (Score: {score:.4f})'\n                            )\n                        print(Panel(content[:500] + '...' if len(content) >\n                            500 else content, border_style='dim'))\n                    follow_up = ui_manager.get_user_input(\n                        \"\"\"\nWould you like to ask a follow-up question with this context? (y/n): \"\"\"\n                        )\n                    if follow_up.lower() in ['y', 'yes']:\n                        follow_up_query = ui_manager.get_user_input(\n                            'Follow-up query: ')\n                        if follow_up_query:\n                            context_parts = [\n                                f'Document {i} (Score: {score:.4f}):\\n{content}'\n                                 for i, (content, score, _) in enumerate(\n                                results, 1)]\n                            context = '\\n\\n'.join(context_parts)\n                            rag_prompt = f\"\"\"Based on the following context, please answer the question.\n\nContext:\n{context}\n\nQuestion: {follow_up_query}\"\"\"\n                            response = query_llm(rag_prompt)\n                            print(Panel(response, title=\n                                '[cyan]RAG-Augmented Response[/]'))\n            else:\n                ui_manager.show_error(\"Unknown command. Type 'help'.\")\n            refresh_status_panel(personality_name)\n        except KeyboardInterrupt:\n            memory_manager.save_memory()\n            print('\\n[bold cyan]Goodbye![/]')\n            break\n        except Exception as e:\n            ui_manager.show_error(f'An unexpected error occurred: {e}')\n\n\ndef run_python_code() ->None:\n    global last_code\n    if not last_code:\n        ui_manager.show_error('No Python code in memory to run.')\n        return\n    temp_file = os.path.join(DEFAULT_SAVE_DIR, 'temp_run.py')\n    try:\n        with open(temp_file, 'w') as f:\n            f.write(last_code)\n        print('[bold cyan]\\n--- Running Code ---\\n[/]')\n        subprocess.run([sys.executable, temp_file], check=True)\n        print('[bold cyan]\\n--- Code Finished ---\\n[/]')\n    except Exception as e:\n        ui_manager.show_error(f'Error running code: {e}')\n    finally:\n        if os.path.exists(temp_file):\n            os.remove(temp_file)\n\n\ndef save_code(content: str, filename: str) ->None:\n    filepath = os.path.join(DEFAULT_SAVE_DIR, filename)\n    try:\n        with open(filepath, 'w') as f:\n            f.write(content)\n        ui_manager.show_success(f'Saved to: {filepath}')\n    except IOError as e:\n        ui_manager.show_error(f'Error saving file: {e}')\n\n\ndef main() ->None:\n    try:\n        import astor\n    except ImportError:\n        print(\"[bold red]Error:[/] 'astor' is required. `pip install astor`\")\n        sys.exit(1)\n    try:\n        import simple_term_menu\n    except ImportError:\n        print(\n            \"[bold red]Error:[/] 'simple-term-menu' is required. `pip install simple-term-menu`\"\n            )\n        sys.exit(1)\n    parser = argparse.ArgumentParser(description=\n        'Omni - AI-powered code tool', add_help=False)\n    parser.add_argument('command', nargs='?', help='Main command.')\n    parser.add_argument('args', nargs='*', help='Arguments for the command.')\n    parser.add_argument('-h', '--help', action='store_true')\n    args, _ = parser.parse_known_args()\n    if args.help or not args.command:\n        interactive_mode()\n    elif args.command == 'look' and args.args:\n        look_command(args.args[0])\n    elif args.command == 'edit' and len(args.args) >= 2:\n        handle_file_edit_command(args.args[0], ' '.join(args.args[1:]))\n    elif args.command == 'models':\n        list_models(args.args)\n    else:\n        interactive_mode()\n\n\ndef refresh_status_panel(personality_name: str) ->None:\n    ui_manager.display_status_panel(personality_name, current_backend,\n        current_model, len(memory_manager.memory.get('chat', [])), len(\n        memory_manager.memory.get('look', [])))\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/omni.py"
  },
  {
    "id": 86,
    "hash": "db1585da7840e9dc17f3ab8c0a19f6f2",
    "content": "import json\nfrom typing import Dict, List, Optional\n\nclass PersonalityManager:\n    \"\"\"Manages AI personalities via JSON config.\"\"\"\n\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.personalities: List[Dict[str, str]] = self.load_personalities()\n        self.current_personality: Optional[str] = \"default\"  # Default\n\n    def load_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"Load personalities from JSON; auto-create if missing.\"\"\"\n        default = [{\"name\": \"default\", \"description\": \"Helpful assistant\", \"system_prompt\": \"You are a helpful AI assistant.\"}]\n        default_gui = {\n            \"gui_enabled\": True,\n            \"wake_word\": \"Jarvis\",\n            \"overlay_opacity\": 0.8,\n            \"font_size\": 16\n        }\n        try:\n            with open(self.config_file, 'r') as f:\n                data = json.load(f)\n                if \"personalities\" not in data:\n                    data[\"personalities\"] = default\n                if \"gui_enabled\" not in data:\n                    data.update(default_gui)\n                    self.save_personalities(data[\"personalities\"])  # Save with defaults\n                \n                return data[\"personalities\"]\n        except FileNotFoundError:\n            self.save_personalities(default)\n            return default\n        except json.JSONDecodeError:\n            print(\"[yellow]Invalid config. Resetting to default.[/]\")\n            self.save_personalities(default)\n            return default\n\n    def save_personalities(self, personalities: List[Dict[str, str]]) -> None:\n        \"\"\"Save with GUI config.\"\"\"\n        data = {\"personalities\": personalities}\n        data.update({\"gui_enabled\": True, \"wake_word\": \"Jarvis\", \"overlay_opacity\": 0.8, \"font_size\": 16})  # Defaults\n        with open(self.config_file, 'w') as f:\n            json.dump(data, f, indent=4)\n\n    def add_personality(self, name: str, description: str, system_prompt: str) -> None:\n        \"\"\"Add a new personality.\"\"\"\n        self.personalities.append({\"name\": name, \"description\": description, \"system_prompt\": system_prompt})\n        self.save_personalities(self.personalities)\n\n    def list_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"List all personalities.\"\"\"\n        return self.personalities\n\n    def set_current_personality(self, name: str) -> bool:\n        \"\"\"Set the current personality.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == name:\n                self.current_personality = name\n                return True\n        return False\n\n    def get_current_personality(self) -> Dict[str, str]:\n        \"\"\"Get the current personality dict.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == self.current_personality:\n                return p\n        return {}  # Fallback",
    "file": "/mnt/ProjectData/omni/personality_manager.py"
  },
  {
    "id": 87,
    "hash": "da963f141c557fe12f1a26374f3e5ff4",
    "content": "# python_ast_adapter.py\n\n\"\"\"\nPythonASTAdapter - Concrete AST adapter for Python using built-in `ast` and `astor`.\n\nThis module implements the ASTAdapter interface specifically for Python,\nleveraging the standard library's `ast` module for parsing and\nmanipulation, and `astor` for code generation.\n\"\"\"\n\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for asttokens (for enhanced partial edits)\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n    # print(\"Warning: asttokens not installed. Partial edits will be limited.\")\n\n\nclass PythonASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for Python source code.\n\n    This adapter uses Python's built-in `ast` module to parse and manipulate\n    the code, and `astor` for code generation and source-to-source transformations.\n    It holds the parsed AST tree and provides methods to interact with it\n    according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the PythonASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The Python source code as a string.\n        \"\"\"\n        # Store source code for diffing and potential asttokens use\n        self.source_code: str = source_code\n        # Will hold the parsed AST tree\n        self.tree: Optional[ast.AST] = None\n        # Will hold a mapping of element names to their AST nodes\n        self.nodes: Dict[str, ast.AST] = {}\n        # asttokens instance for enhanced source mapping (if available)\n        self.atok: Optional[asttokens.ASTTokens] = None\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the Python source code and maps elements.\n\n        Args:\n            source_code: The Python source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid Python syntax.\n        \"\"\"\n        try:\n            self.tree = ast.parse(source_code)\n        except SyntaxError as e:\n            raise ValueError(f\"Invalid Python syntax: {e}\") from e\n\n        self.nodes = self._map_nodes()\n        if ASTTOKENS_AVAILABLE:\n            try:\n                self.atok = asttokens.ASTTokens(source_code, parse=True)\n            except Exception:\n                # If asttokens fails for any reason, continue without it\n                self.atok = None\n        else:\n            self.atok = None\n\n    def _map_nodes(self) -> Dict[str, ast.AST]:\n        \"\"\"\n        Walks the AST and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their AST nodes.\n        \"\"\"\n        nodes: Dict[str, ast.AST] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        for node in ast.walk(self.tree):\n            # Map functions and classes by name\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                # Use 'not in' to prioritize top-level definitions in case of conflicts\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            # Map assignments by target variable name(s)\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            # Map imports by their alias or original name\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int, line_end: Optional[int] = None) -> Optional[Tuple[int, ast.AST]]:\n        \"\"\"\n        Finds a statement within a body based on line numbers.\n\n        Args:\n            body: The list of AST nodes representing the body.\n            line_start: The starting line number to search for.\n            line_end: The optional ending line number.\n\n        Returns:\n            A tuple of (index, statement node) if found, otherwise None.\n        \"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = getattr(stmt, 'end_lineno', stmt.lineno)\n                    # Check for overlap or containment\n                    if (stmt.lineno <= line_start <= stmt_end) or (stmt.lineno <= line_end <= stmt_end) or \\\n                       (line_start <= stmt.lineno and line_end >= stmt_end):\n                        return (i, stmt)\n                else:\n                    if stmt.lineno == line_start:\n                        return (i, stmt)\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.ImportFrom]]) -> None:\n        \"\"\"\n        Adds new import nodes to the file's AST, typically at the top.\n\n        Args:\n            new_import_nodes: A list of ast.Import or ast.ImportFrom nodes.\n        \"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return # Cannot add imports without a valid module tree\n\n        # Get string representations of existing imports to avoid duplicates\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                try:\n                    existing_imports_str.add(astor.to_source(node).strip())\n                except Exception:\n                    # If astor fails, skip adding to set (might lead to potential duplicate, but safer)\n                    pass\n                last_import_index = i\n\n        # Insert new imports after the last existing import\n        # Reverse them so they are inserted in the correct order\n        for new_import in reversed(new_import_nodes):\n            try:\n                new_import_str = astor.to_source(new_import).strip()\n                if new_import_str not in existing_imports_str:\n                    self.tree.body.insert(last_import_index + 1, new_import)\n                    last_import_index += 1 # Update index for next insertion\n            except Exception:\n                # If we can't generate source, we can't check for duplicates, skip\n                self.tree.body.insert(last_import_index + 1, new_import)\n                last_import_index += 1\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return astor.to_source(node)\n            except Exception:\n                # Handle potential astor issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.__class__.__name__,\n            'line_start': getattr(node, 'lineno', None),\n            'line_end': getattr(node, 'end_lineno', None),\n            'body_items': []\n        }\n\n        if hasattr(node, 'body'):\n            for i, item in enumerate(node.body):\n                item_info = {\n                    'index': i,\n                    'type': item.__class__.__name__,\n                    'line_start': getattr(item, 'lineno', None),\n                    'line_end': getattr(item, 'end_lineno', None)\n                }\n\n                if isinstance(item, ast.Assign) and item.targets:\n                    target = item.targets[0]\n                    if isinstance(target, ast.Name):\n                        item_info['assigns'] = target.id\n                elif isinstance(item, (ast.If, ast.While, ast.For)):\n                    item_info['has_body'] = bool(getattr(item, 'body', None))\n                elif isinstance(item, ast.Return):\n                    item_info['returns'] = True\n\n                structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        if not self.atok:\n            return None # asttokens is required for precise original source retrieval\n\n        node = self.nodes.get(element_name)\n        if not node or not hasattr(node, 'body'):\n            return None\n\n        statements = []\n        for stmt in node.body:\n            if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                 # Check for overlap or containment of the statement within the requested range\n                stmt_start = stmt.lineno\n                stmt_end = stmt.end_lineno\n                if (stmt_start >= line_start and stmt_end <= line_end) or \\\n                   (stmt_start <= line_end and stmt_end >= line_start): # Overlap\n                    statements.append(stmt)\n\n        if not statements:\n            return None\n\n        # Use asttokens to get the original source text for accuracy\n        try:\n            # Combine text ranges of the found statements\n            combined_text = \"\"\n            last_end_pos = None\n            for stmt in sorted(statements, key=lambda s: s.lineno):\n                # Get the text range for the statement\n                stmt_text = self.atok.get_text_range(stmt)\n                if last_end_pos is not None and stmt_text[0] > last_end_pos:\n                     # Add the original whitespace/newlines between statements\n                    combined_text += self.source_code[last_end_pos:stmt_text[0]]\n                combined_text += self.atok.get_text(stmt)\n                last_end_pos = stmt_text[1]\n            return combined_text.strip()\n        except Exception:\n            # Fallback if asttokens text retrieval fails\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in statements)\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except SyntaxError:\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body: # Ensure there's actual code body to replace with\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # Walk the tree to find the parent node containing the element to replace\n        for parent_node in ast.walk(self.tree):\n            if hasattr(parent_node, 'body') and isinstance(parent_node.body, list):\n                try:\n                    old_node = self.nodes[element_name]\n                    idx = parent_node.body.index(old_node)\n                    # Remove the old node\n                    parent_node.body.pop(idx)\n                    # Insert the new nodes\n                    for i, new_node in enumerate(new_code_body):\n                        parent_node.body.insert(idx + i, new_node)\n\n                    # Update the nodes map: remove old, add new top-level definitions\n                    del self.nodes[element_name]\n                    for n in new_code_body:\n                        if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                            self.nodes[n.name] = n\n                    return True\n                except (ValueError, KeyError):\n                    # ValueError from index(), KeyError from accessing self.nodes\n                    continue\n        return False # Element not found in any body\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n             return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except (SyntaxError, IndexError):\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body:\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # --- Determine insertion index ---\n\n        # Find the `if __name__ == \"__main__\":` block index\n        main_block_idx = -1\n        for i, node in enumerate(self.tree.body):\n            if (isinstance(node, ast.If) and\n                isinstance(getattr(node, 'test', None), ast.Compare) and\n                isinstance(getattr(node.test, 'left', None), ast.Name) and\n                node.test.left.id == '__name__' and\n                len(getattr(node.test, 'ops', [])) == 1 and isinstance(node.test.ops[0], ast.Eq) and\n                len(getattr(node.test, 'comparators', [])) == 1):\n\n                comp = node.test.comparators[0]\n                # Check for both ast.Constant ('__main__') and older ast.Str ('__main__')\n                if ((isinstance(comp, ast.Constant) and comp.value == '__main__') or\n                    (isinstance(comp, ast.Str) and comp.s == '__main__')): # type: ignore\n                    main_block_idx = i\n                    break\n\n        insertion_index = -1\n        if anchor_name:\n            # If anchor is specified, find its index\n            if anchor_name not in self.nodes:\n                return False\n            anchor_node = self.nodes[anchor_name]\n            try:\n                anchor_idx = self.tree.body.index(anchor_node)\n                proposed_index = anchor_idx if before else anchor_idx + 1\n                # Prefer to stay before the main block if possible\n                if main_block_idx != -1:\n                    insertion_index = min(proposed_index, main_block_idx)\n                else:\n                    insertion_index = proposed_index\n            except ValueError:\n                return False # Anchor node not found in tree body\n        elif main_block_idx != -1:\n            # If no anchor, but there's a main block, insert before it\n            insertion_index = main_block_idx\n        # If no anchor and no main block, insertion_index remains -1\n\n        # --- Perform the insertion ---\n        if insertion_index == -1:\n            # Append to the end\n            self.tree.body.extend(new_code_body)\n        else:\n            # Insert at the calculated position\n            for i, new_node in enumerate(new_code_body):\n                self.tree.body.insert(insertion_index + i, new_node)\n\n        # Update the nodes map with any new top-level definitions\n        for node in new_code_body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                self.nodes[node.name] = node # This might overwrite if names clash\n\n        return True\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return False\n\n        deleted = False\n        if element_name in self.nodes:\n            node_to_delete = self.nodes[element_name]\n            # Walk the tree to find the parent node containing the element\n            for node in ast.walk(self.tree):\n                if hasattr(node, 'body') and isinstance(node.body, list):\n                    try:\n                        node.body.remove(node_to_delete)\n                        deleted = True\n                        break # Assume element appears only once at top level\n                    except ValueError:\n                        continue # This parent doesn't contain the node\n            if deleted:\n                del self.nodes[element_name]\n                # Although nodes map is passed by ref in base __init__, we should call _map_nodes\n                # to ensure consistency after a direct tree modification.\n                self.nodes = self._map_nodes()\n                return True\n\n        # If not found by node reference, try to find by name pattern matching (vars/imports)\n        new_body = []\n        for node in self.tree.body:\n            if isinstance(node, ast.Assign):\n                match = False\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id == element_name:\n                        match = True\n                        deleted = True\n                        break\n                if not match: # Keep the node if it doesn't match\n                    new_body.append(node)\n            elif isinstance(node, ast.Import):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                    # Keep the node if none of its aliases match (should theoretically be the same as above)\n                     new_body.append(node)\n                else:\n                    deleted = True # The import node is being completely removed\n            elif isinstance(node, ast.ImportFrom):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                     new_body.append(node)\n                else:\n                    deleted = True\n            else:\n                new_body.append(node)\n\n        if deleted:\n            self.tree.body = new_body\n            # Remap nodes after structural changes\n            self.nodes = self._map_nodes()\n\n        return deleted\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        if element_name not in self.nodes:\n            return False\n\n        node = self.nodes[element_name]\n        # Ensure the node has a body to modify\n        if not hasattr(node, 'body') or not isinstance(node.body, list):\n            return False\n\n        # Parse the new code to get AST nodes for the replacement\n        try:\n             # Heuristic: If new code looks like a def/class, extract its body.\n             # Otherwise, treat as standalone statements.\n            if new_code.strip().startswith(('def ', 'class ', 'async def ')):\n                # Parse as if it's a module with a single function/class\n                temp_module = ast.parse(new_code)\n                if temp_module.body and hasattr(temp_module.body[0], 'body'):\n                    new_statements = temp_module.body[0].body # Get the inner body\n                else:\n                    return False # Malformed attempt to define a func/class\n            else:\n                # Parse as a module and take its body\n                new_ast_module = ast.parse(new_code)\n                new_statements = new_ast_module.body\n        except SyntaxError:\n            return False # Invalid new code\n\n        if not new_statements: # Nothing to insert\n            return False\n\n        # --- Determine what to replace based on parameters ---\n        if statement_index is not None:\n            # Replace by statement index\n            if 0 <= statement_index < len(node.body):\n                # Replace the single statement at index with the list of new statements\n                node.body[statement_index:statement_index+1] = new_statements\n                return True\n        elif line_start is not None:\n            # Replace by line number(s)\n            result = self._find_statement_in_body(node.body, line_start, line_end)\n            if result:\n                idx, _ = result\n                if line_end:\n                    # Find the last statement within the specified range to replace multiple\n                    end_idx = idx\n                    # Iterate from the found index forward\n                    for i in range(idx, len(node.body)):\n                        stmt = node.body[i]\n                        stmt_s_ln = getattr(stmt, 'lineno', None)\n                        stmt_e_ln = getattr(stmt, 'end_lineno', stmt_s_ln)\n                        if stmt_s_ln is not None and stmt_e_ln is not None:\n                            # Check if the statement ends within the range or starts within the range\n                            # This handles overlapping ranges correctly\n                             if stmt_e_ln <= line_end or stmt_s_ln <= line_end:\n                                 end_idx = i\n                             else:\n                                 break # Statement is past the end range\n                        else:\n                            break # Can't determine statement range\n                    node.body[idx:end_idx+1] = new_statements\n                else:\n                    # line_end not specified, only replace the statement at line_start\n                    node.body[idx:idx+1] = new_statements\n                return True\n\n        # If none of the conditions were met to perform a replacement\n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        if self.tree:\n            try:\n                return astor.to_source(self.tree)\n            except Exception as e:\n                 # Fallback error handling, should ideally not happen if tree is valid\n                 return f\"# Error generating source: {e}\\n{self.source_code}\"\n        else:\n            # If somehow the tree is None, return the original source\n            return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        # Ensure line endings are consistent for diffing, keepends=True preserves them\n        # If source_code had different line endings, this might still cause issues,\n        # but this is a standard approach.\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/python_ast_adapter.py"
  },
  {
    "id": 88,
    "hash": "2914352eefed9d60de098e021dd79b67",
    "content": "import os\nimport sys\nimport argparse\nfrom typing import List\nfrom rag_manager import RAGManager\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\ndef create_sample_data() ->List[str]:\n    \"\"\"Create sample documents for the RAG example.\"\"\"\n    return [\n        'RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with language generation.'\n        ,\n        'The RAG model retrieves relevant documents from a knowledge base and uses them to generate more accurate responses.'\n        ,\n        'FAISS is a library for efficient similarity search and clustering of dense vectors, often used in RAG systems.'\n        ,\n        'Sentence transformers are used to create embeddings for documents and queries in RAG systems.'\n        ,\n        'Retrieval-Augmented Generation improves language models by allowing them to access external knowledge sources.'\n        ,\n        'In RAG systems, documents are indexed and searchable by their semantic embeddings rather than just keywords.'\n        ,\n        'Python is a great language for implementing RAG systems due to libraries like sentence-transformers and faiss.'\n        ,\n        'The retrieval component of RAG is crucial for finding relevant information before generation.'\n        ]\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_cli_example.py"
  },
  {
    "id": 89,
    "hash": "c27b11d2eaa8e13cdf8e698417efb75e",
    "content": "import os\nimport sys\nfrom typing import List, Dict, Tuple\n\"\"\"\nExample script demonstrating RAG (Retrieval-Augmented Generation) usage.\n\nThis script shows how to use a simple RAG implementation to answer questions\nbased on a given context or knowledge base.\n\"\"\"\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\nclass SimpleRAG:\n    \"\"\"A simple RAG implementation for demonstration purposes.\"\"\"\n\n    def __init__(self, knowledge_base: List[str]):\n        \"\"\"\n        Initialize the RAG with a knowledge base.\n        \n        Args:\n            knowledge_base: A list of strings representing the knowledge base.\n        \"\"\"\n        self.knowledge_base = knowledge_base\n\n    def retrieve(self, query: str, top_k: int=3) ->List[str]:\n        \"\"\"\n        Retrieve relevant documents from the knowledge base.\n        \n        This is a simplified implementation using keyword matching.\n        In a real implementation, you would use embeddings and vector search.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            A list of relevant documents.\n        \"\"\"\n        query_words = set(query.lower().split())\n        scores = []\n        for doc in self.knowledge_base:\n            doc_words = set(doc.lower().split())\n            score = len(query_words.intersection(doc_words))\n            scores.append((score, doc))\n        scores.sort(reverse=True)\n        return [doc for score, doc in scores[:top_k]]\n\n    def generate(self, query: str, retrieved_docs: List[str]) ->str:\n        \"\"\"\n        Generate an answer based on the query and retrieved documents.\n        \n        In a real implementation, this would use an LLM to generate the response.\n        For this example, we'll create a simple template-based response.\n        \n        Args:\n            query: The query string.\n            retrieved_docs: The retrieved documents.\n            \n        Returns:\n            A generated answer.\n        \"\"\"\n        context = '\\n'.join(retrieved_docs)\n        prompt = f\"\"\"\n        Context information:\n        {context}\n        \n        Question: {query}\n        \n        Based on the context provided above, please answer the question.\n        If the context doesn't contain relevant information, say so.\n        \"\"\"\n        return self._simple_response_generator(query, retrieved_docs)\n\n    def _simple_response_generator(self, query: str, retrieved_docs: List[str]\n        ) ->str:\n        \"\"\"\n        A simple response generator for demonstration.\n        \"\"\"\n        for doc in retrieved_docs:\n            if 'example' in doc.lower():\n                return (\n                    f'Based on the context provided, I found information about examples. {query} relates to the examples in the knowledge base.'\n                    )\n        return (\n            f\"I couldn't find specific information about '{query}' in the provided context. Please provide more details or check the knowledge base.\"\n            )\n\n    def query(self, query: str, top_k: int=3) ->str:\n        \"\"\"\n        Process a query through the full RAG pipeline.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            The generated answer.\n        \"\"\"\n        retrieved_docs = self.retrieve(query, top_k)\n        answer = self.generate(query, retrieved_docs)\n        return answer\n\n\ndef main():\n    \"\"\"Main function demonstrating the RAG implementation.\"\"\"\n    knowledge_base = ['This is an example document about machine learning.',\n        'Natural language processing is a subfield of artificial intelligence.'\n        , 'Python is a popular programming language for data science.',\n        'The quick brown fox jumps over the lazy dog.',\n        'RAG stands for Retrieval-Augmented Generation.',\n        'Vector databases are used for similarity search in RAG systems.',\n        'Transformers are a type of neural network architecture.',\n        'This example shows how to implement a simple RAG system.']\n    rag = SimpleRAG(knowledge_base)\n    queries = ['What is RAG?', 'How is Python used in data science?',\n        'Tell me about machine learning']\n    print('Simple RAG Example')\n    print('=' * 50)\n    for query in queries:\n        print(f'\\nQuery: {query}')\n        answer = rag.query(query)\n        print(f'Answer: {answer}')\n        print('-' * 30)\n    print(\"\\nInteractive Mode (type 'quit' to exit):\")\n    while True:\n        try:\n            user_query = input('\\nEnter your question: ').strip()\n            if user_query.lower() in ['quit', 'exit', 'q']:\n                break\n            if user_query:\n                answer = rag.query(user_query)\n                print(f'Answer: {answer}')\n        except KeyboardInterrupt:\n            print('\\nGoodbye!')\n            break\n        except EOFError:\n            break\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_example.py"
  },
  {
    "id": 90,
    "hash": "f151986bf2efa7602242590a357fab83",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n    Initialize the RAG manager.\n\n    Args:\n        model_name: Name of the sentence transformer model to use\n        index_path: Path to save/load the FAISS index\n    \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the RAG manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n",
    "file": "/mnt/ProjectData/omni/rag_manager.py"
  },
  {
    "id": 91,
    "hash": "f59a27842056dbb0dc95d0f29c1c5de8",
    "content": "Hello! I'm OmniForge, an AI coding assistant. I can help you scan, understand, and refactor your codebase using local (Ollama) or remote (OpenRouter) LLMs.\n\nI see you've opened the OmniForge project directory. Some key things I can help with:\n\n1. **Project Analysis**: I can look at your files to understand the structure\n2. **Code Editing**: I can make precise edits to functions/classes using AST-based transformations\n3. **Refactoring**: I can perform multi-file architectural changes with a plan\n4. **File Creation**: I can generate new files based on instructions\n\nFor example:\n- `look .` to scan the project\n- `edit code_editor.py \"add docstrings to main methods\"`\n- `refactor \"extract git operations into a separate module\"`\n- `create new_module.py \"implement a simple HTTP client\"`\n\nWhat would you like to do with this project?",
    "file": "/mnt/ProjectData/omni/requirements.txt"
  },
  {
    "id": 92,
    "hash": "4b879b8e64b677ec78d27f19b384623a",
    "content": "from typing import List\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.text import Text\nfrom rich.status import Status\nfrom rich import box\nfrom contextlib import contextmanager\nfrom rich.markup import escape\nimport gc\n\ntry:\n    from prompt_toolkit import prompt\n    from prompt_toolkit.completion import WordCompleter\n    from prompt_toolkit.history import InMemoryHistory\n    from prompt_toolkit.styles import Style\nexcept ImportError:\n    print('[yellow]prompt_toolkit not installed. Falling back to basic input.[/]')\n    prompt = input\n\n\nclass UIManager:\n    \"\"\"Manages interactive text-based UI with rich for display and prompt_toolkit for input.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initializes the UI manager with a rich console and prompt_toolkit components.\"\"\"\n        self.console = Console()\n        self.history = InMemoryHistory()\n        self.completer = WordCompleter([\n            'send', 'look', 'look_all', 'create', 'edit', 'refactor', 'commit',\n            'save', 'list', 'run', 'history', 'memory', 'backend', 'models',\n            'set', 'personality', 'help', 'exit'\n        ], ignore_case=True)\n        self.prompt_style = Style.from_dict({'prompt': 'bold cyan'})\n\n    def get_user_input(self, prompt_text: str) -> str:\n        try:\n            return prompt(prompt_text, history=self.history, completer=self.completer, style=self.prompt_style)\n        except Exception:\n            self.console.print('[yellow]Warning: Falling back to basic input.[/]')\n            return input(prompt_text)\n\n    def display_history(self, history_text: str) -> None:\n        if not history_text.strip():\n            self.console.print('[dim]No history yet.[/]')\n            return\n        \n        lines = history_text.split('\\n')\n        colored_text = Text()\n        for line in lines:\n            if line.startswith('User:'):\n                colored_text.append(line + '\\n', style='bold blue')\n            elif line.startswith('AI:'):\n                colored_text.append(line + '\\n', style='bold green')\n            elif line.startswith('File '):\n                colored_text.append(line + '\\n', style='yellow')\n            else:\n                colored_text.append(line + '\\n')\n        \n        self.console.print(Panel(\n            colored_text, \n            title='[bold magenta]Chat History[/]', \n            border_style='magenta', \n            expand=False, \n            box=box.ROUNDED\n        ))\n\n    @contextmanager\n    def show_spinner(self, message: str):\n        \"\"\"\n        Context manager that displays a spinner with the given message.\n        Handles Rich LiveError by cleaning up stuck live displays and \n        ensuring proper cleanup on exceptions.\n        \n        Usage:\n            with ui_manager.show_spinner(\"Loading...\"):\n                # do work here\n        \"\"\"\n        # Initialize spinner state if not exists\n        if not hasattr(self, '_spinner_active'):\n            self._spinner_active = False\n        \n        # If spinner is already active, just yield without additional output\n        if self._spinner_active:\n            try:\n                yield\n            except Exception as e:\n                raise e\n            return\n        \n        # Clean up any stuck Rich live displays before starting\n        self._cleanup_stuck_rich_displays()\n        \n        # Mark spinner as active\n        self._spinner_active = True\n        status_context = None\n        \n        try:\n            # Try to use rich status, but with fallback\n            try:\n                status_context = self.console.status(f'[bold yellow]{message}[/]')\n                status_context.__enter__()\n            except Exception:\n                # If rich.status fails, fallback to static print\n                status_context = None\n                self.console.print(f'[bold yellow]{message}[/]')\n            \n            yield\n            \n        except Exception as e:\n            # Re-raise actual work errors\n            raise e\n            \n        finally:\n            # Always cleanup spinner state and rich display\n            self._spinner_active = False\n            if status_context is not None:\n                try:\n                    status_context.__exit__(None, None, None)\n                except:\n                    pass  # Suppress cleanup errors\n            \n            # Force cleanup any remaining rich displays\n            self._cleanup_stuck_rich_displays()\n\n    def _cleanup_stuck_rich_displays(self):\n        \"\"\"\n        Clean up stuck Rich live displays that prevent new ones from starting.\n        Based on solution from: https://github.com/DLR-RM/stable-baselines3/issues/1645\n        \"\"\"\n        try:\n            # Method 1: Reset console live display if exists\n            if hasattr(self.console, '_live') and self.console._live is not None:\n                try:\n                    self.console._live.stop()\n                    self.console._live = None\n                except:\n                    pass\n            \n            # Method 2: Find and close stuck rich/tqdm objects using garbage collection\n            rich_objects = [obj for obj in gc.get_objects() \n                        if hasattr(obj, '__class__') and \n                        ('live' in type(obj).__name__.lower() or \n                            'progress' in type(obj).__name__.lower() or\n                            'status' in type(obj).__name__.lower()) and\n                        hasattr(obj, 'stop')]\n            \n            for rich_obj in rich_objects:\n                try:\n                    if hasattr(rich_obj, 'stop'):\n                        rich_obj.stop()\n                    elif hasattr(rich_obj, 'close'):\n                        rich_obj.close()\n                except:\n                    pass  # Suppress cleanup errors\n                    \n        except:\n            pass  # Suppress all cleanup errors to avoid breaking the main flow\n\n    def display_status_panel(self, personality: str, backend: str, model: str, msg_count: int, look_count: int) -> None:\n        status_text = (\n            f'[bold]Personality:[/] [green]{personality}[/] | '\n            f'[bold]Backend:[/] [green]{backend}[/] | '\n            f'[bold]Model:[/] [green]{model}[/] | '\n            f'[bold]Memory:[/] {msg_count} messages, {look_count} files'\n        )\n        self.console.print(Panel(\n            status_text, \n            title='[bold cyan]Status[/]', \n            border_style='cyan', \n            expand=False, \n            box=box.MINIMAL\n        ))\n\n    def show_success(self, message: str) -> None:\n        self.console.print(f'[green]\u2705 {message}[/]')\n\n    def show_error(self, message: str) -> None:\n        \"\"\"\n        Displays an error message, escaping any markup in the message.\n        \"\"\"\n        safe_message = escape(str(message))\n        self.console.print(f'[red]\u274c {safe_message}[/]')",
    "file": "/mnt/ProjectData/omni/ui_manager.py"
  },
  {
    "id": 93,
    "hash": "dbd143839288b400cafdedb655258434",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n",
    "file": "/mnt/ProjectData/omni/vectordb_manager.py"
  },
  {
    "id": 94,
    "hash": "47a91d3ac272236378053b23515fc9b0",
    "content": "import tkinter as tk\nfrom tkinter import ttk\nfrom time import strftime\n\n\ndef update_time():\n    current_time = strftime('%H:%M:%S %p\\n%Y-%m-%d')\n    time_label.config(text=current_time)\n    time_label.after(1000, update_time)\n\n\ndef center_window(root):\n    root.update_idletasks()\n    screen_width = root.winfo_screenwidth()\n    screen_height = root.winfo_screenheight()\n    window_width = root.winfo_width() + 4\n    window_height = root.winfo_height() + 4\n    x = (screen_width - window_width) // 2\n    y = (screen_height - window_height) // 2\n    root.geometry(f'{window_width}x{window_height}+{x}+{y}')\n\n\ndef create_3d_border(parent):\n    border_frame = tk.Frame(parent, bg='#c0c0c0')\n    border_frame.pack(padx=2, pady=2, expand=True, fill=tk.BOTH)\n    tk.Frame(border_frame, height=1, bg='#808080').pack(side=tk.TOP, fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#808080').pack(side=tk.LEFT, fill=tk.Y)\n    tk.Frame(border_frame, height=1, bg='#ffffff').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#ffffff').pack(side=tk.RIGHT, fill=tk.Y\n        )\n    inner_container = tk.Frame(border_frame, bg='#c0c0c0')\n    inner_container.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1\n        )\n    tk.Frame(inner_container, height=1, bg='#ffffff').pack(side=tk.TOP,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#ffffff').pack(side=tk.LEFT,\n        fill=tk.Y)\n    tk.Frame(inner_container, height=1, bg='#808080').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#808080').pack(side=tk.RIGHT,\n        fill=tk.Y)\n    content_area = tk.Frame(inner_container, bg='#c0c0c0')\n    content_area.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1)\n    return content_area\n\n\nroot = tk.Tk()\nroot.title('Current Time')\nroot.configure(bg='#008080')\nmain_frame = create_3d_border(root)\nmain_frame.config(padx=4, pady=4)\ninner_frame = tk.Frame(main_frame, bg='#c0c0c0', padx=8, pady=8)\ninner_frame.pack()\ntime_label = tk.Label(inner_frame, bg='#c0c0c0', fg='#000000', font=(\n    'MS Sans Serif', 18, 'bold'), padx=12, pady=8)\ntime_label.pack()\nroot.after(100, lambda : center_window(root))\nupdate_time()\nroot.mainloop()\n",
    "file": "/mnt/ProjectData/omni/omni_saves/watch.py"
  },
  {
    "id": 95,
    "hash": "6774a805052356775d8c4f0367253dc1",
    "content": "# OmniForge\n\n**Project\u2011Aware AI CLI for AST\u2011Precise Edits (\u201cScalpel\u201d) & Multi\u2011File Refactors (\u201cBlueprint\u201d).**\n\n> *OmniForge (a.k.a. the \"DualForge\" engine) helps you **scan**, **understand**, and **reforge** your codebase with local (Ollama) or remote (OpenRouter) LLMs. It is an independent open\u2011source project not affiliated with other products using the name \u201cOmni.\u201d*\n\n---\n\n## Core Features\n\n* **Project\u2011Aware Refactoring (`refactor`)**: Provide a high\u2011level goal (e.g. *\u201cmove all DB logic into `db/` and centralize config\u201d*). OmniForge generates & shows a multi\u2011step plan before touching files.\n* **Surgical AST Editing (`edit`)**: Target a single function/class. OmniForge parses the file, locates the node, applies a structural change, and shows you a diff.\n* **Context Ingestion (`look`)**: Scan a directory or single file to build a project manifest (paths + hashes + size + language hints) that guides subsequent edits/refactors.\n* **Dual Backends**: Seamlessly switch between **`openrouter`** (remote models) and **`ollama`** (local models) via `backend <name>`.\n* **Interactive Model Picker (`models`)**: Filter by source/provider and select from an up\u2011to\u2011date model list inside the terminal.\n* **Session Memory & History**: `history` shows conversation / action log; `memory clear` resets the working context.\n* **Safe AST\u2011Based Transformations**: Reduces syntax breakage vs naive text substitution. New imports / dependencies are auto\u2011inserted when possible.\n* **Dry\u2011Run Transparency**: Every multi\u2011file refactor presents (1) a generated plan, (2) per\u2011file proposed changes, (3) a consolidated diff for confirmation.\n\n---\n\n## Conceptual Modes\n\n| Mode          | Command(s) | Purpose                                              | Analogy              |\n| ------------- | ---------- | ---------------------------------------------------- | -------------------- |\n| **Survey**    | `look`     | Index project / ingest context                       | Mapping the terrain  |\n| **Scalpel**   | `edit`     | Precise single\u2011file structural change                | Surgery              |\n| **Blueprint** | `refactor` | Multi\u2011file architectural transformation              | Architecture         |\n| **Cast**      | `run`      | Execute last generated runnable block (if supported) | Forging the artifact |\n\nYou can reference these terms in docs, help screens, or UI banners for clarity.\n\n---\n\n## Installation\n\n> Requires Python 3.10+ and a Unix\u2011like shell.\n\n```bash\n# 1. Clone\ngit clone https://github.com/Snawyyy/omniforge.git\ncd omniforge\n\n# 2. (Optional) Inspect requirements\ncat requirements.txt\n\n# 3. Run installer (creates venv + installs deps)\nchmod +x install.sh\n./install.sh\n\n# 4. Activate environment\nsource venv/bin/activate\n\n# 5. Run CLI (interactive shell)\n./omni        # or: python omni.py\n```\n\nIf you later package it, expose a script entry point named `omni` while keeping an internal package name like `omniforge` to avoid namespace collisions.\n\n---\n\n## Configuration\n\nCreate a `.env` file to supply secrets (e.g. OpenRouter API key).\n\n```bash\ncp .env.example .env   # if example exists; otherwise create manually\n```\n\nIn `.env`:\n\n```dotenv\nOPENROUTER_API_KEY=\"sk-or-...\"\n```\n\n(Do **not** commit real keys. Ensure `.env` is listed in `.gitignore`.)\n\nOptional future keys can include local model paths, default model name, or feature flags.\n\n---\n\n## Quick Start Workflow\n\n```text\n> look .\n(Index project: builds manifest)\n\n> refactor \"extract hardcoded API URL to config/settings.py and update all imports\"\n(Shows plan \u2192 ask for confirmation)\n\n> edit src/utils.py \"add a doctring for calculate_average explaining parameters and return value\"\n(Shows targeted diff \u2192 confirm or abort)\n\n> models openai\n(Choose a different model)\n\n> backend ollama\n(Switch to local inference)\n```\n\n---\n\n## Command Reference\n\n| Command               | Example                                         | Description                                                                 |\n| --------------------- | ----------------------------------------------- | --------------------------------------------------------------------------- |\n| `look <path>`         | `look .`                                        | Scan directory or file; update project context manifest.                    |\n| `edit <file> \"instr\"` | `edit utils.py \"add error handling\"`            | AST\u2011guided targeted modification of a single file element or whole file.    |\n| `refactor \"goal\"`     | `refactor \"split monolith api.py into package\"` | High\u2011level multi\u2011file transformation with plan + diff review.               |\n| `send <prompt>`       | `send summarize module layout`                  | Generic prompt to current model with current context summary.               |\n| `models [filter]`     | `models google`                                 | Interactive model selector (filter by provider/source).                     |\n| `backend <name>`      | `backend ollama`                                | Switch between `openrouter` / `ollama`.                                     |\n| `history`             | `history`                                       | Display session interaction log.                                            |\n| `memory clear`        | `memory clear`                                  | Clear internal AI context memory (project manifest may persist separately). |\n| `run`                 | `run`                                           | Execute the last generated runnable code snippet (if feature implemented).  |\n| `help`                | `help`                                          | Show help / usage summary.                                                  |\n\n---\n\n## How It Works (High Level)\n\n1. **Ingestion (`look`)**: Walks the directory (configurable ignore patterns), captures file metadata (path, size, language), optionally caches abbreviated content or hashes.\n2. **Prompt Construction**: Merges user instruction + contextual manifest + focused snippets (for `edit`) or diff summaries (for `refactor`).\n3. **AST Layer** (Python initially): Parses target file(s); identifies node(s) (function/class) based on name + heuristic similarity; applies transformations guided by model output (structured hints or patch templates) rather than raw blind overwrite.\n4. **Plan (Refactor)**: Model proposes steps (CREATE / MODIFY / RENAME / DELETE). User approves. Each step executed & validated; errors surface early.\n5. **Diff Presentation**: A unified colorized diff shown; user confirms to write changes.\n6. **Safety**: If AST parse fails or patch violates syntax, changes abort (or fallback to text patch with warning).\n\n---\n\n## Roadmap (Indicative)\n\n| Milestone | Features                                                                    |\n| --------- | --------------------------------------------------------------------------- |\n| 0.1.0     | Core commands (`look`, `edit`, `refactor`, `models`, `backend`, `history`). |\n| 0.2.0     | Config file (`omniforge.toml`), ignore patterns, improved diff viewer.      |\n| 0.3.0     | Multi-language AST adapters (JS/TS via `tree-sitter`).                      |\n| 0.4.0     | Test impact analysis & auto test file generation.                           |\n| 0.5.0     | Refactor preview metrics (LOC touched, complexity delta).                   |\n| 0.6.0     | Inline security / lint feedback integration.                                |\n| 0.7.0     | Partial GUI / TUI dashboard mode.                                           |\n\n(Adjust roadmap as project evolves.)\n\n---\n\n## Developer Notes\n\n* Keep `.env`, virtual environment dirs (`venv/`), caches, large artifacts in `.gitignore`.\n* Consider adding a thin `omniforge/` package directory now for future PyPI packaging.\n* Implement a pluggable *Model Adapter* layer to abstract provider differences (OpenRouter vs Ollama).\n* Logging: Provide `--verbose` or `OMNIFORGE_DEBUG=1` env flag.\n* Add a JSONL log of commands & decisions to enable replay or supervised improvements.\n\n---\n\n## Contributing\n\n1. Fork & create a feature branch: `git checkout -b feat/<short-name>`\n2. Run and add tests (if/when test harness exists in `tests/`).\n3. Ensure style/format (e.g. `ruff`, `black`) passes.\n4. Submit pull request with concise description + before/after examples.\n\nIssues / discussions welcome for architecture proposals, AST adapters, or performance improvements.\n\n---\n\n## License\n\nReleased under the **MIT License**. See `LICENSE` file for full text.\n\n---\n\n## Name & Trademark Disclaimer\n\n\u201cOmniForge\u201d is an independent open-source tool and not affiliated with The Omni Group or any other third-party products using similar names. If a future naming conflict arises, a soft alias strategy (keeping the `omni` CLI) will preserve user workflows.\n\n---\n\n## Example Session (Illustrative)\n\n```text\n$ ./omni\nOMNIFORGE 0.1.0  (backend=openrouter | model=anthropic/claude-3)\nType 'help' or 'look .' to begin.\n\n> look .\nIndexed 42 files (Python=30, Markdown=5, JSON=7)\n\n> refactor \"centralize logging into logging_util.py and update imports\"\nPlan:\n  [1] CREATE logging_util.py\n  [2] MODIFY app.py (replace inline log setup)\n  [3] MODIFY worker.py (import logging_util)\nProceed? (y/n) y\n... (diff preview) ...\nApply changes? (y/n) y\nRefactor complete in 3.2s.\n\n> edit worker.py \"add retry with exponential backoff to fetch_data\"\nParsed worker.py \u2713\nApplied modification (function: fetch_data)\nDiff shown. Accept? (y/n) y\nSaved.\n```\n\n---\n\n## Philosophy\n\n*The next wave of developer AI goes beyond paste\u2011in prompts.* OmniForge treats your repository as *structured material*, enabling incremental, auditable, and safer evolution rather than opaque code dumps. By combining **context scanning**, **AST precision**, and **human approval loops**, it aims to become a trustworthy co\u2011developer rather than an occasionally helpful code generator.\n\n---\n\n## Feedback / Support\n\nOpen a GitHub Issue for bugs & feature requests. For conceptual discussions (roadmap, design choices), use Discussions.\n\n---\n\nHappy forging!\n",
    "file": "/mnt/ProjectData/omni/README.md"
  },
  {
    "id": 96,
    "hash": "48f330cca4dc037b3ad4942e430e6393",
    "content": "# ast_adapter.py\n\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional, Dict, Any, Union\n\n# Define common types that adapters might use or return\n# This keeps the interface flexible without importing specific parser libraries\nASTNode = Any  # Generic type for a node in the AST/CST\nDiffContent = str # Type alias for the string output of a diff\n\nclass ASTAdapter(ABC):\n    \"\"\"\n    Abstract base class defining the interface for language-specific AST adapters.\n\n    This interface allows the CodeEditor to interact with the AST/CST of different\n    programming languages in a uniform way. Concrete implementations will handle\n    the specifics of parsing, traversing, and modifying the AST/CST for their\n    respective languages (e.g., Python's `ast`/`astor`, JavaScript's `tree-sitter`).\n\n    The adapter is responsible for holding the parsed tree structure and any\n    necessary metadata for operations.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the adapter by parsing the provided source code.\n\n        Args:\n            source_code: The string content of the source file to be parsed.\n\n        Raises:\n            ValueError: If the source code cannot be parsed due to syntax errors.\n        \"\"\"\n        self.source_code: str = source_code\n        self.tree: Optional[ASTNode] = None\n        self.nodes: Dict[str, ASTNode] = {} # A map for quick access to named elements\n        self._parse_and_map(source_code)\n\n    @abstractmethod\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Abstract method to parse the source code and populate `self.tree` and `self.nodes`.\n\n        This is the core method where language-specific parsing logic resides.\n        Implementations should:\n        1. Parse the `source_code` into an AST/CST representation.\n        2. Store the root of this representation in `self.tree`.\n        3. Identify key top-level elements (functions, classes, variables, imports)\n           and map their names to their nodes in `self.nodes`.\n\n        Args:\n            source_code: The string content to parse.\n\n        Raises:\n            ValueError: If the source code cannot be parsed.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_elements(self) -> List[str]:\n        \"\"\"\n        Abstract method to list the names of the main elements found in the code.\n\n        These are typically top-level functions, classes, variable assignments,\n        and imports that the adapter can identify and manipulate.\n\n        Returns:\n            A list of element names (strings).\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"\n        Abstract method to get the source code string for a specific element.\n\n        Args:\n            element_name: The name of the element (function, class, etc.).\n\n        Returns:\n            The source code string for the element, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"\n        Abstract method to get detailed structural information about an element.\n\n        This information can include type, line numbers, body items, etc., useful\n        for aiding the AI in understanding the code's layout.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            A dictionary containing structural details, or None if not found.\n            Example structure:\n            {\n                'name': 'func_name',\n                'type': 'FunctionDef', # or 'ClassDef', etc.\n                'line_start': 10,\n                'line_end': 25,\n                'body_items': [list of internal statement details...]\n            }\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"\n        Abstract method to extract a snippet of code from within an element's body.\n\n        Used for 'partial' edits where only a specific range of lines within\n        a function or class needs to be changed.\n\n        Args:\n            element_name: The name of the element containing the snippet.\n            line_start: The starting line number (1-based, absolute) of the snippet.\n            line_end: The ending line number (inclusive) of the snippet.\n\n        Returns:\n            The source code string for the specified lines within the element, or None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"\n        Abstract method to replace an entire named element.\n\n        This involves finding the old element in the tree and swapping it with\n        the representation of the `new_code`.\n\n        Args:\n            element_name: The name of the element to replace.\n            new_code: The new source code for the element (and potential helpers).\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"\n        Abstract method to add a new block of code (element) to the file.\n\n        This involves parsing the `new_code` and inserting its representation\n        into the tree at an appropriate location (e.g., end of file, near anchor).\n\n        Args:\n            new_code: The source code for the new element(s).\n            anchor_name: Optional name of an existing element to position relative to.\n            before: If True and `anchor_name` is provided, insert before the anchor.\n\n        Returns:\n            True if the element was added successfully, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"\n        Abstract method to delete a named element from the file.\n\n        This involves finding the element in the tree and removing its representation.\n\n        Args:\n            element_name: The name of the element to delete.\n\n        Returns:\n            True if the element was successfully deleted, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"\n        Abstract method for a 'surgical' edit within an element's body.\n\n        Replaces a specific statement or line range within the body of an element.\n\n        Args:\n            element_name: Name of the function/class to modify.\n            new_code: New code to insert (can be multiple statements).\n            line_start: Starting line number (absolute) within the element.\n            line_end: Ending line number (inclusive) within the element.\n            statement_index: Alternative to line numbers - replace the Nth statement.\n\n        Returns:\n            True if successful, False otherwise.\n        \"\"\"\n        pass\n\n    # --- Methods related to final output and change tracking ---\n\n    @abstractmethod\n    def get_modified_source(self) -> str:\n        \"\"\"\n        Abstract method to serialize the potentially modified AST/CST back to source code.\n\n        Returns:\n            The full source code string reflecting the current state of the tree.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_diff(self) -> str:\n        \"\"\"\n        Abstract method to generate a diff between the original source and the modified source.\n\n        Returns:\n            A string containing the unified diff.\n        \"\"\"\n        pass\n\n    # Internal helper methods (can be abstract or have common logic in base if needed)\n    # These are less critical for the interface but might be useful\n    # _add_imports(new_import_nodes) -> could be handled differently per language\n    # _find_statement_in_body(body, line_start, line_end) -> Tree-sitter needs different logic",
    "file": "/mnt/ProjectData/omni/ast_adapter.py"
  },
  {
    "id": 97,
    "hash": "f7b169444c2d435f115ad2d8801ee5db",
    "content": "\"\"\"\nCodeEditor - Enhanced AST-based code manipulation tool\n\nThis module provides a class to programmatically parse, analyze,\nand edit source code. It has been refactored to use a pluggable\nASTAdapter system, allowing it to support multiple languages.\nCurrently, it defaults to Python's built-in `ast` module via\nPythonASTAdapter for backward compatibility during the transition.\n\"\"\"\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Union, Tuple, Type, Any\nfrom ast_adapter import ASTAdapter\nfrom python_ast_adapter import PythonASTAdapter\nimport os\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n\n\nclass CodeEditor:\n    \"\"\"\n    An enhanced class to safely edit files using AST/CST with partial edit support.\n    The core logic for interacting with the code structure is now delegated to\n    a language-specific ASTAdapter.\n    \"\"\"\n\n    def __init__(self, file_path: str, adapter_class: Optional[Type[\n        ASTAdapter]]=None):\n        \"\"\"\n        Initializes the CodeEditor.\n\n        Args:\n            file_path: The path to the source file.\n            adapter_class: The ASTAdapter subclass to use. If None, defaults to\n                           PythonASTAdapter for .py files.\n        \"\"\"\n        self.file_path = file_path\n        self.source_code = self._read_file()\n        if adapter_class is None:\n            file_extension = os.path.splitext(self.file_path)[1].lower()\n            if file_extension == '.py':\n                try:\n                    from python_ast_adapter import PythonASTAdapter\n                    self.adapter: Optional[ASTAdapter] = PythonASTAdapter(self\n                        .source_code)\n                except ImportError:\n                    raise ValueError(\n                        'Python AST adapter is required but not available')\n            elif file_extension == '.js':\n                try:\n                    from javascript_ast_adapter import JavaScriptASTAdapter\n                    self.adapter: Optional[ASTAdapter] = JavaScriptASTAdapter(\n                        self.source_code)\n                except ImportError:\n                    raise ValueError(\n                        'tree-sitter is required for JavaScript support but not available'\n                        )\n            else:\n                raise ValueError(\n                    f'Unsupported file type: {file_extension}. Supported types: .py, .js'\n                    )\n        else:\n            self.adapter = adapter_class(self.source_code)\n\n    def _read_file(self) ->str:\n        \"\"\"Reads the source file.\"\"\"\n        try:\n            with open(self.file_path, 'r', encoding='utf-8') as f:\n                return f.read()\n        except FileNotFoundError:\n            raise ValueError(f'File not found: {self.file_path}')\n\n    def _parse_source(self) ->ast.AST:\n        \"\"\"Fallback parsing logic.\"\"\"\n        try:\n            return ast.parse(self.source_code)\n        except SyntaxError as e:\n            raise ValueError(f'Invalid Python syntax in {self.file_path}: {e}')\n\n    def list_elements(self) ->List[str]:\n        \"\"\"Lists top-level elements in the code.\"\"\"\n        if self.adapter:\n            return self.adapter.list_elements()\n        else:\n            return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"Gets the source code for a specific element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_source_of(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            return astor.to_source(node) if node else None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"Gets detailed structure information about an element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_structure(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            if not node:\n                return None\n            structure = {'name': element_name, 'type': node.__class__.\n                __name__, 'line_start': node.lineno if hasattr(node,\n                'lineno') else None, 'line_end': node.end_lineno if hasattr\n                (node, 'end_lineno') else None, 'body_items': []}\n            if hasattr(node, 'body'):\n                for i, item in enumerate(node.body):\n                    item_info = {'index': i, 'type': item.__class__.\n                        __name__, 'line_start': item.lineno if hasattr(item,\n                        'lineno') else None, 'line_end': item.end_lineno if\n                        hasattr(item, 'end_lineno') else None}\n                    if isinstance(item, ast.Assign) and item.targets:\n                        target = item.targets[0]\n                        if isinstance(target, ast.Name):\n                            item_info['assigns'] = target.id\n                    elif isinstance(item, (ast.If, ast.While, ast.For)):\n                        item_info['has_body'] = bool(item.body)\n                    elif isinstance(item, ast.Return):\n                        item_info['returns'] = True\n                    structure['body_items'].append(item_info)\n            return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"Gets a snippet from within an element's body.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_body_snippet(element_name,\n                line_start, line_end)\n        else:\n            if not self.atok:\n                return None\n            node = self.nodes.get(element_name)\n            if not node or not hasattr(node, 'body'):\n                return None\n            statements = []\n            for stmt in node.body:\n                if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                    if (line_start <= stmt.lineno <= line_end or line_start <=\n                        stmt.end_lineno <= line_end):\n                        statements.append(stmt)\n            if not statements:\n                return None\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in\n                statements)\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"Replaces a partial section of an element.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_partial(element_name, new_code,\n                line_start, line_end, statement_index)\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                if new_code.strip().startswith('def ') or new_code.strip(\n                    ).startswith('class '):\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body[0].body\n                else:\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if statement_index is not None:\n                if 0 <= statement_index < len(node.body):\n                    node.body[statement_index:statement_index + 1\n                        ] = new_statements\n                    return True\n            elif line_start is not None:\n                result = self._find_statement_in_body(node.body, line_start,\n                    line_end)\n                if result:\n                    idx, _ = result\n                    if line_end:\n                        end_idx = idx\n                        for i in range(idx + 1, len(node.body)):\n                            stmt = node.body[i]\n                            if hasattr(stmt, 'end_lineno'\n                                ) and stmt.end_lineno <= line_end:\n                                end_idx = i\n                            else:\n                                break\n                        node.body[idx:end_idx + 1] = new_statements\n                    else:\n                        node.body[idx:idx + 1] = new_statements\n                    return True\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"Adds a new block of code to the file.\"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name, before)\n        else:\n            try:\n                new_ast_module = ast.parse(new_code)\n            except (SyntaxError, IndexError):\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            insertion_index = -1\n            main_block_idx = -1\n            for i, _node in enumerate(self.tree.body):\n                if isinstance(_node, ast.If) and isinstance(_node.test, ast\n                    .Compare) and isinstance(_node.test.left, ast.Name\n                    ) and _node.test.left.id == '__name__' and len(_node.\n                    test.ops) == 1 and isinstance(_node.test.ops[0], ast.Eq\n                    ) and len(_node.test.comparators) == 1:\n                    comp = _node.test.comparators[0]\n                    if isinstance(comp, ast.Constant\n                        ) and comp.value == '__main__' or isinstance(comp,\n                        ast.Str) and comp.s == '__main__':\n                        main_block_idx = i\n                        break\n            if anchor_name:\n                if anchor_name not in self.nodes:\n                    return False\n                anchor_node = self.nodes[anchor_name]\n                try:\n                    anchor_idx = self.tree.body.index(anchor_node)\n                    proposed_index = anchor_idx if before else anchor_idx + 1\n                    if main_block_idx != -1:\n                        insertion_index = min(proposed_index, main_block_idx)\n                    else:\n                        insertion_index = proposed_index\n                except ValueError:\n                    return False\n            elif main_block_idx != -1:\n                insertion_index = main_block_idx\n            if insertion_index == -1:\n                self.tree.body.extend(new_code_body)\n            else:\n                for i, new_node in enumerate(new_code_body):\n                    self.tree.body.insert(insertion_index + i, new_node)\n            for _node in new_code_body:\n                if isinstance(_node, (ast.FunctionDef, ast.AsyncFunctionDef,\n                    ast.ClassDef)):\n                    self.nodes[_node.name] = _node\n            return True\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"Deletes an element by name.\"\"\"\n        if self.adapter:\n            return self.adapter.delete_element(element_name)\n        else:\n            deleted = False\n            if element_name in self.nodes:\n                node_to_delete = self.nodes[element_name]\n                for _node in ast.walk(self.tree):\n                    if hasattr(_node, 'body') and isinstance(_node.body, list):\n                        try:\n                            _node.body.remove(node_to_delete)\n                            deleted = True\n                            break\n                        except ValueError:\n                            continue\n                if deleted:\n                    del self.nodes[element_name]\n                    self.nodes = self._map_nodes()\n                    return True\n            new_body = []\n            for _node in self.tree.body:\n                if isinstance(_node, ast.Assign):\n                    match = False\n                    for target in _node.targets:\n                        if isinstance(target, ast.Name\n                            ) and target.id == element_name:\n                            match = True\n                            break\n                    if match:\n                        deleted = True\n                        continue\n                elif isinstance(_node, ast.Import):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                elif isinstance(_node, ast.ImportFrom):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                new_body.append(_node)\n            self.tree.body = new_body\n            if deleted:\n                self.nodes = self._map_nodes()\n            return deleted\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"Replaces a target element with new code.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_element(element_name, new_code)\n        else:\n            if element_name not in self.nodes:\n                return False\n            try:\n                new_ast_module = ast.parse(new_code)\n            except SyntaxError:\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            for _node in ast.walk(self.tree):\n                if hasattr(_node, 'body') and isinstance(_node.body, list):\n                    try:\n                        old_node = self.nodes[element_name]\n                        idx = _node.body.index(old_node)\n                        _node.body.pop(idx)\n                        for i, new_node in enumerate(new_code_body):\n                            _node.body.insert(idx + i, new_node)\n                        del self.nodes[element_name]\n                        for n in new_code_body:\n                            if isinstance(n, (ast.FunctionDef, ast.\n                                AsyncFunctionDef, ast.ClassDef)):\n                                self.nodes[n.name] = n\n                        return True\n                    except (ValueError, KeyError):\n                        continue\n            return False\n\n    def insert_in_element(self, element_name: str, new_code: str, position:\n        str='end', after_line: Optional[int]=None, before_line: Optional[\n        int]=None) ->bool:\n        \"\"\"\n        Insert new code into an element without replacing existing code.\n        This is an internal/helper method, delegating to adapter OR using fallback.\n        \"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name=\n                element_name, before=position == 'start')\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                new_ast = ast.parse(new_code)\n                new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if position == 'start':\n                node.body[0:0] = new_statements\n            elif position == 'end':\n                node.body.extend(new_statements)\n            elif after_line:\n                result = self._find_statement_in_body(node.body, after_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx + 1:idx + 1] = new_statements\n                else:\n                    return False\n            elif before_line:\n                result = self._find_statement_in_body(node.body, before_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx:idx] = new_statements\n                else:\n                    return False\n            else:\n                return False\n            return True\n\n    def _map_nodes(self) ->Dict[str, ast.AST]:\n        \"\"\"Fallback node mapping logic for Python AST.\"\"\"\n        nodes = {}\n        for node in ast.walk(self.tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast\n                .ClassDef)):\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int,\n        line_end: Optional[int]=None) ->Optional[Tuple[int, ast.AST]]:\n        \"\"\"Fallback statement finding logic for Python AST.\"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = stmt.end_lineno if hasattr(stmt, 'end_lineno'\n                        ) else stmt.lineno\n                    if (stmt.lineno <= line_start <= stmt_end or stmt.\n                        lineno <= line_end <= stmt_end):\n                        return i, stmt\n                elif stmt.lineno == line_start:\n                    return i, stmt\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.\n        ImportFrom]]) ->None:\n        \"\"\"Fallback logic to add imports to the top of the Python AST.\"\"\"\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                existing_imports_str.add(astor.to_source(node).strip())\n                last_import_index = i\n        for new_import in reversed(new_import_nodes):\n            new_import_str = astor.to_source(new_import).strip()\n            if new_import_str not in existing_imports_str:\n                self.tree.body.insert(last_import_index + 1, new_import)\n\n    def apply_arbitrary_change(self, new_source_code: str) ->bool:\n        \"\"\"\n        Rewrites the entire file's AST from a new source string.\n        This method resets the adapter if one exists, or uses fallback.\n        \"\"\"\n        if self.adapter:\n            try:\n                adapter_class = type(self.adapter)\n                self.adapter = adapter_class(new_source_code)\n                return True\n            except Exception:\n                return False\n        else:\n            try:\n                new_tree = ast.parse(new_source_code)\n                self.tree = new_tree\n                self.nodes = self._map_nodes()\n                if ASTTOKENS_AVAILABLE:\n                    self.source_code = new_source_code\n                    self.atok = asttokens.ASTTokens(self.source_code, parse\n                        =True)\n                return True\n            except SyntaxError:\n                return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"Serializes the potentially modified code structure back to source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_modified_source()\n        else:\n            return astor.to_source(self.tree)\n\n    def get_diff(self) ->str:\n        \"\"\"Generates a diff between the original source and the modified source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_diff()\n        else:\n            modified_source = self.get_modified_source()\n            return ''.join(difflib.unified_diff(self.source_code.splitlines\n                (keepends=True), modified_source.splitlines(keepends=True),\n                fromfile=f'{self.file_path} (original)', tofile=\n                f'{self.file_path} (modified)'))\n\n    def save_changes(self) ->None:\n        \"\"\"Saves the modified source code back to the file.\"\"\"\n        modified_source = self.get_modified_source()\n        with open(self.file_path, 'w', encoding='utf-8') as f:\n            f.write(modified_source)\n",
    "file": "/mnt/ProjectData/omni/code_editor.py"
  },
  {
    "id": 98,
    "hash": "cc52aa524d0929867d5d2ea3697229e6",
    "content": "\"\"\"\nGenerated file.\n\"\"\"\nimport os\n\"\"\"\nFileCreator - A utility for creating files.\n\nThis module provides a simple, encapsulated way to create files,\nensuring that their parent directories exist before writing.\n\"\"\"\n\n\nclass FileCreator:\n    \"\"\"\n    A utility class to handle the creation of new files.\n    \"\"\"\n\n    @staticmethod\n    def create(file_path: str, content: str) ->None:\n        \"\"\"\n        Creates a file at the specified path with the given content.\n\n        This method will automatically create any necessary parent\n        directories for the file path.\n\n        Args:\n            file_path: The full path where the file should be created.\n            content: The string content to write to the file.\n\n        Raises:\n            IOError: If there is an error creating the directories or writing the file.\n        \"\"\"\n        try:\n            directory = os.path.dirname(file_path)\n            if directory:\n                os.makedirs(directory, exist_ok=True)\n            with open(file_path, 'w', encoding='utf-8') as f:\n                f.write(content)\n        except (IOError, OSError) as e:\n            raise IOError(f\"Failed to create file '{file_path}': {e}\") from e\n",
    "file": "/mnt/ProjectData/omni/file_creator.py"
  },
  {
    "id": 99,
    "hash": "04a24ceab008bd649d0530d309c72e42",
    "content": "import subprocess\nimport os\nfrom typing import List, Optional, Union\n\n\nclass GitManager:\n    \"\"\"\n    Encapsulates Git-related logic for a specific repository.\n\n    This class provides methods to perform common Git operations such as\n    checking status, getting diffs, staging, committing, and pushing changes.\n    It relies on the Git command-line tool being installed and accessible\n    in the system's PATH.\n    \"\"\"\n\n    def __init__(self, repo_path: str):\n        \"\"\"\n        Initializes the GitManager for a given repository path.\n\n        Args:\n            repo_path: The absolute or relative path to the Git repository.\n\n        Raises:\n            ValueError: If the provided path is not a valid Git repository.\n        \"\"\"\n        if not os.path.isdir(os.path.join(repo_path, '.git')):\n            raise ValueError(\n                f\"The path '{repo_path}' is not a valid Git repository.\")\n        self.repo_path = repo_path\n\n    def _run_command(self, command: List[str]) ->str:\n        \"\"\"\n        Executes a Git command in the repository's directory.\n\n        Args:\n            command: A list of command arguments, starting with 'git'.\n\n        Returns:\n            The standard output of the command as a string.\n\n        Raises:\n            subprocess.CalledProcessError: If the command returns a non-zero exit code.\n        \"\"\"\n        try:\n            result = subprocess.run(command, cwd=self.repo_path, check=True,\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True,\n                encoding='utf-8')\n            return result.stdout.strip()\n        except subprocess.CalledProcessError as e:\n            error_message = (\n                f\"Git command failed: {' '.join(command)}\\nError: {e.stderr.strip()}\"\n                )\n            raise subprocess.CalledProcessError(e.returncode, e.cmd, output\n                =e.stdout, stderr=error_message) from e\n\n    def get_status(self) ->str:\n        \"\"\"\n        Gets the repository status in a condensed format.\n\n        Uses `git status --porcelain` for a machine-readable output.\n\n        Returns:\n            A string representing the repository's status.\n        \"\"\"\n        return self._run_command(['git', 'status', '--porcelain'])\n        \n    def get_changed_files(self) -> List[str]:\n        \"\"\"\n        Gets a list of all changed (modified, added, deleted, untracked, renamed, or copied) files.\n\n        This parses the output of `git status --porcelain`, which provides a stable,\n        machine-readable format.\n\n        Returns:\n            A list of file paths relative to the repository root. For renamed or\n            copied files, it returns the new path.\n        \"\"\"\n        status_output = self.get_status()\n        if not status_output:\n            return []\n        \n        changed_files = []\n        for line in status_output.splitlines():\n            if len(line) < 3:  # Skip malformed lines\n                continue\n                \n            # Git status porcelain format: XY filename\n            # X = index status, Y = working tree status\n            index_status = line[0]\n            worktree_status = line[1]\n            \n            # The filename starts after the two status characters and a space\n            # But let's be more defensive about finding where the filename actually starts\n            filename_start = 2\n            while filename_start < len(line) and line[filename_start] == ' ':\n                filename_start += 1\n                \n            if filename_start >= len(line):\n                continue  # Skip if no filename found\n                \n            path_info = line[filename_start:]\n            \n            # Check if either index or working tree status indicates rename/copy\n            if index_status in ('R', 'C') or worktree_status in ('R', 'C'):\n                if ' -> ' in path_info:\n                    _, new_path = path_info.split(' -> ', 1)  # Use maxsplit=1 for safety\n                    changed_files.append(new_path.strip())\n                else:\n                    # Fallback if format is unexpected\n                    changed_files.append(path_info.strip())\n            else:\n                changed_files.append(path_info.strip())\n        \n        # Remove duplicates while preserving order\n        return list(dict.fromkeys(changed_files))\n\n    def get_diff(self, file_path: Optional[str]=None, staged: bool=False\n        ) ->str:\n        \"\"\"\n        Gets the diff of changes in the repository.\n\n        Args:\n            file_path: Optional. Path to a specific file to diff.\n            staged: If True, shows the diff for staged changes (`--cached`).\n                    Otherwise, shows the diff for unstaged changes.\n\n        Returns:\n            The git diff output as a string.\n        \"\"\"\n        cmd = ['git', 'diff']\n        if staged:\n            cmd.append('--cached')\n        if file_path:\n            cmd.append('--')\n            cmd.append(file_path)\n        return self._run_command(cmd)\n\n    def add(self, files: Union[str, List[str]]) ->None:\n        \"\"\"\n    Stages one or more files, handling each one individually for robustness.\n\n    This approach prevents a single invalid file path from causing the\n    entire 'git add' operation to fail. Warnings will be printed for any\n    files that could not be staged.\n\n    Args:\n        files: A single file path or a list of file paths to stage.\n               Can also be '.' to stage all changes.\n    \"\"\"\n        if isinstance(files, str):\n            files = [files]\n        for file_path in files:\n            try:\n                cmd = ['git', 'add', '--', file_path]\n                self._run_command(cmd)\n            except subprocess.CalledProcessError as e:\n                print(\n                    f\"Warning: Could not stage file '{file_path}'. Git reported: {e.stderr}\"\n                    )\n\n    def commit(self, message: str) ->str:\n        \"\"\"\n        Commits staged changes with a given message.\n\n        Args:\n            message: The commit message.\n\n        Returns:\n            The stdout from the git commit command.\n        \"\"\"\n        return self._run_command(['git', 'commit', '-m', message])\n\n    def push(self, remote: str='origin', branch: Optional[str]=None) ->str:\n        \"\"\"\n        Pushes commits to a remote repository.\n\n        Args:\n            remote: The name of the remote to push to (default: 'origin').\n            branch: The branch to push. If None, uses the current branch.\n\n        Returns:\n            The stdout from the git push command.\n        \"\"\"\n        if branch is None:\n            branch = self.get_current_branch()\n        return self._run_command(['git', 'push', remote, branch])\n\n    def get_current_branch(self) ->str:\n        \"\"\"\n        Determines the current active branch name.\n\n        Returns:\n            The name of the current branch.\n        \"\"\"\n        return self._run_command(['git', 'rev-parse', '--abbrev-ref', 'HEAD'])\n",
    "file": "/mnt/ProjectData/omni/git_manager.py"
  },
  {
    "id": 100,
    "hash": "f3f7ab448ad3e233539c4e4bddcd64f4",
    "content": "# javascript_ast_adapter.py\n\n\"\"\"\nJavaScriptASTAdapter - Concrete AST adapter for JavaScript using tree-sitter.\n\nThis module implements the ASTAdapter interface specifically for JavaScript,\nleveraging the tree-sitter library for parsing and manipulation.\n\"\"\"\n\nimport difflib\nimport re\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for tree-sitter\ntry:\n    import tree_sitter\n    import tree_sitter_languages\n    TREETSITTER_AVAILABLE = True\nexcept ImportError:\n    TREETSITTER_AVAILABLE = False\n    # This will cause an error during initialization if the adapter is used\n\n\nclass JavaScriptASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for JavaScript source code.\n\n    This adapter uses tree-sitter to parse and manipulate JavaScript code.\n    It holds the parsed tree-sitter Tree and provides methods to interact\n    with it according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the JavaScriptASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The JavaScript source code as a string.\n\n        Raises:\n            ValueError: If tree-sitter libraries are not available or if\n                        the source code has invalid JavaScript syntax.\n        \"\"\"\n        if not TREETSITTER_AVAILABLE:\n            raise ValueError(\"tree-sitter and tree-sitter-languages are required for JavaScript support.\")\n            \n        # Store source code for diffing and manipulation\n        self.source_code: str = source_code\n        # Will hold the parsed tree-sitter tree\n        self.tree: Optional[tree_sitter.Tree] = None\n        # Will hold a mapping of element names to their tree-sitter nodes\n        self.nodes: Dict[str, tree_sitter.Node] = {}\n        # Tree-sitter language parser\n        self.language = tree_sitter_languages.get_language(\"javascript\")\n        self.parser = tree_sitter.Parser(self.language)\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the JavaScript source code and maps elements.\n\n        Args:\n            source_code: The JavaScript source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid JavaScript syntax.\n        \"\"\"\n        try:\n            # Encode the source code in bytes as required by tree-sitter\n            self.tree = self.parser.parse(bytes(source_code, \"utf-8\"))\n        except Exception as e:\n            raise ValueError(f\"Failed to parse JavaScript source: {e}\") from e\n\n        self.nodes = self._map_nodes()\n\n    def _map_nodes(self) -> Dict[str, tree_sitter.Node]:\n        \"\"\"\n        Walks the tree and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their tree-sitter nodes.\n        \"\"\"\n        nodes: Dict[str, tree_sitter.Node] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        # Define the types of nodes we're interested in\n        target_types = {\n            \"function_declaration\", \"class_declaration\", \n            \"variable_declarator\", \"import_statement\"\n        }\n        \n        # Walk the tree using a stack-based approach\n        stack = [self.tree.root_node]\n        while stack:\n            node = stack.pop()\n            \n            # Check if this is a target node type\n            if node.type in target_types:\n                # Extract the name for different node types\n                name = self._get_node_name(node)\n                if name and name not in nodes:\n                    nodes[name] = node\n            \n            # Add children to the stack for further processing\n            for child in reversed(node.children):  # Reverse to maintain order when popping\n                stack.append(child)\n                \n        return nodes\n    \n    def _get_node_name(self, node: tree_sitter.Node) -> Optional[str]:\n        \"\"\"\n        Extracts the name of a node based on its type.\n        \n        Args:\n            node: The tree-sitter node to extract the name from.\n            \n        Returns:\n            The name of the node, or None if no name could be found.\n        \"\"\"\n        if node.type == \"function_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"class_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"variable_declarator\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"import_statement\":\n            # This is a more complex case - for now, we'll use a simplified approach\n            # Extract the module name from the import statement\n            # e.g., in \"import foo from 'bar'\", we want \"foo\"\n            # This is a simplified implementation and might need refinement\n            import_clause = None\n            for child in node.children:\n                if child.type == \"import_clause\":\n                    import_clause = child\n                    break\n            \n            if import_clause:\n                # Check for a simple identifier\n                for child in import_clause.children:\n                    if child.type == \"identifier\":\n                        return child.text.decode(\"utf-8\")\n                    elif child.type == \"named_imports\":\n                        # Handle named imports like { foo, bar }\n                        # For simplicity, we'll just return a placeholder\n                        # A more complete implementation would extract all names\n                        return f\"import_from_{hash(node.text.decode('utf-8')) % 10000}\"\n        \n        return None\n\n    def _find_node_by_position(self, start_point: Tuple[int, int], \n                              end_point: Optional[Tuple[int, int]] = None) -> Optional[tree_sitter.Node]:\n        \"\"\"\n        Finds a node in the tree that corresponds to a given range.\n        \n        Args:\n            start_point: A (row, column) tuple indicating the start position.\n            end_point: A (row, column) tuple indicating the end position.\n            \n        Returns:\n            The tree-sitter node that corresponds to the range, or None if not found.\n        \"\"\"\n        if not self.tree:\n            return None\n            \n        # A simple approach: find the smallest node that contains the range\n        # This is a simplified implementation and might need refinement\n        def contains_range(node):\n            node_start = (node.start_point[0], node.start_point[1])\n            node_end = (node.end_point[0], node.end_point[1])\n            if end_point:\n                return (node_start <= start_point and node_end >= end_point)\n            else:\n                return node_start <= start_point <= node_end\n        \n        # Walk the tree to find matching nodes\n        stack = [self.tree.root_node]\n        candidates = []\n        \n        while stack:\n            current_node = stack.pop()\n            if contains_range(current_node):\n                candidates.append(current_node)\n                # Add children to continue searching for smaller nodes\n                stack.extend(current_node.children)\n        \n        # Return the smallest (last) candidate\n        return candidates[-1] if candidates else None\n    \n    def _get_line_info_from_point(self, point: Tuple[int, int]) -> Dict[str, Any]:\n        \"\"\"\n        Converts a tree-sitter point to line information.\n        \n        Args:\n            point: A (row, column) tuple from tree-sitter.\n            \n        Returns:\n            A dictionary with line_start and line_end information.\n        \"\"\"\n        # Tree-sitter uses 0-based indexing for rows\n        return {\n            'line_start': point[0] + 1,  # Convert to 1-based\n            'line_end': point[0] + 1\n        }\n\n    def _reparse_tree(self, new_source: str) -> None:\n        \"\"\"\n        Re-parses the tree with new source code.\n        \n        This is necessary because tree-sitter trees are immutable.\n        \n        Args:\n            new_source: The new source code to parse.\n        \"\"\"\n        self.source_code = new_source\n        self.tree = self.parser.parse(bytes(new_source, \"utf-8\"))\n        self.nodes = self._map_nodes()\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return node.text.decode(\"utf-8\")\n            except Exception:\n                # Handle potential decoding issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.type,\n            'line_start': node.start_point[0] + 1,  # Convert to 1-based\n            'line_end': node.end_point[0] + 1,\n            'body_items': []\n        }\n\n        # Add body items for functions and classes\n        if node.type in (\"function_declaration\", \"class_declaration\"):\n            # Find the body block\n            body_node = None\n            for child in node.children:\n                if child.type == \"statement_block\":\n                    body_node = child\n                    break\n            \n            if body_node:\n                # Process statements in the body\n                for i, item in enumerate(body_node.children):\n                    # Skip '{' and '}' tokens\n                    if item.type in (\"{\", \"}\"):\n                        continue\n                    \n                    item_info = {\n                        'index': i,\n                        'type': item.type,\n                        'line_start': item.start_point[0] + 1,\n                        'line_end': item.end_point[0] + 1\n                    }\n                    \n                    # Add more specific information based on type\n                    if item.type == \"variable_declaration\":\n                        item_info['declares'] = \"variable\"\n                    elif item.type == \"return_statement\":\n                        item_info['returns'] = True\n                    elif item.type in (\"if_statement\", \"for_statement\", \"while_statement\"):\n                        item_info['has_body'] = True\n                    \n                    structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n            \n        # A simplified approach to extracting a snippet by line numbers\n        # This would need to be more sophisticated for production use\n        source_lines = self.source_code.split('\\n')\n        # Adjust for 0-based indexing\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(source_lines), line_end)\n        \n        if start_idx < end_idx:\n            return '\\n'.join(source_lines[start_idx:end_idx])\n        \n        return None\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Replace the node's text in the source code\n        new_source = self.source_code[:start_byte] + new_code + self.source_code[end_byte:]\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass  # If we can't even re-parse the original, we're in trouble\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree:\n            return False\n            \n        # For simplicity, we'll add the new code at the end of the file\n        # A more sophisticated implementation would handle the anchor and positioning\n        new_source = self.source_code.rstrip() + \"\\n\\n\" + new_code + \"\\n\"\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Find the full lines that contain the node\n        # This is a simplified approach to avoid leaving partial lines\n        source_lines = self.source_code.split('\\n')\n        start_line = node.start_point[0]\n        end_line = node.end_point[0]\n        \n        # Create new source without those lines\n        new_lines = source_lines[:start_line] + source_lines[end_line+1:]\n        new_source = '\\n'.join(new_lines)\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        # This is a complex operation that would require more sophisticated\n        # tree navigation and manipulation than what's shown here.\n        # For now, we'll provide a basic implementation.\n        \n        node = self.nodes.get(element_name)\n        if not node:\n            return False\n            \n        # Handle line-based replacement\n        if line_start is not None:\n            # Convert to 0-based indexing\n            start_idx = max(0, line_start - 1)\n            end_idx = line_end if line_end is not None else start_idx + 1\n            \n            source_lines = self.source_code.split('\\n')\n            if start_idx < len(source_lines):\n                # Replace the specified lines\n                end_idx = min(end_idx, len(source_lines))\n                new_lines = source_lines[:start_idx] + [new_code] + source_lines[end_idx:]\n                new_source = '\\n'.join(new_lines)\n                \n                # Re-parse the tree with the new source\n                try:\n                    self._reparse_tree(new_source)\n                    return True\n                except Exception:\n                    # If parsing fails, revert to the original source\n                    try:\n                        self._reparse_tree(self.source_code)\n                    except Exception:\n                        pass\n        \n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        # For tree-sitter, the source code is already maintained separately\n        return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        \n        # Ensure line endings are consistent for diffing\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/javascript_ast_adapter.py"
  },
  {
    "id": 101,
    "hash": "89fa0c06ca34019316daa58ce8fa9a20",
    "content": "import json\nimport os\nfrom typing import List, Dict, Optional\nfrom rag_manager import RAGManager\n\n\nclass MemoryManager:\n    \"\"\"Manages persistent chat memory, look data, and RAG integration via JSON.\"\"\"\n\n    def __init__(self, memory_file: str):\n        self.memory_file = memory_file\n        self.memory: Dict[str, List] = self.load_memory()\n        self.rag_manager = RAGManager()\n\n    def load_memory(self) ->Dict[str, List]:\n        try:\n            with open(self.memory_file, 'r') as f:\n                return json.load(f)\n        except FileNotFoundError:\n            default = {'chat': [], 'look': []}\n            self.save_memory(default)\n            return default\n        except json.JSONDecodeError:\n            print('[yellow]Invalid memory file. Resetting.[/]')\n            return {'chat': [], 'look': []}\n\n    def save_memory(self, memory: Optional[Dict[str, List]]=None) ->None:\n        if memory is None:\n            memory = self.memory\n        with open(self.memory_file, 'w') as f:\n            json.dump(memory, f, indent=4)\n\n    def add_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.memory['chat'].append({'role': role, 'content': content})\n        self.save_memory()\n\n    def add_chat_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        This is an alias for add_message to maintain compatibility.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.add_message(role, content)\n\n    def add_look_data(self, file_path: str, content: str) ->None:\n        \"\"\"\n    Adds a watched item (directory or file) to memory, distinguishing its type.\n\n    This method stores structured data that differentiates between a project\n    directory (containing a manifest) and a single file (containing its content).\n    It also prevents duplicate entries by updating existing ones.\n\n    Args:\n        file_path: The path to the directory or file.\n        content: The manifest for a directory or the content for a file.\n    \"\"\"\n        item_type = 'directory' if os.path.isdir(file_path) else 'file'\n        for item in self.memory['look']:\n            if item.get('file') == file_path:\n                item['content'] = content\n                item['type'] = item_type\n                self.save_memory()\n                return\n        self.memory['look'].append({'type': item_type, 'file': file_path,\n            'content': content})\n        self.save_memory()\n        if item_type == 'file':\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    file_content = f.read()\n                self.rag_manager.add_documents([file_content], [{'file':\n                    file_path}])\n            except Exception as e:\n                print(\n                    f'[yellow]Warning: Could not add {file_path} to RAG index: {e}[/]'\n                    )\n\n    def get_project_root(self) ->Optional[str]:\n        \"\"\"\n        Finds the root directory of the project currently in memory.\n\n        The project root is defined as the first item in the 'look' memory\n        that is of type 'directory'.\n\n        Returns:\n            The absolute path to the project root directory, or None if not found.\n        \"\"\"\n        for item in self.memory.get('look', []):\n            if item.get('type') == 'directory':\n                return item.get('file')\n        return None\n\n    def get_memory_context(self) ->str:\n        \"\"\"\n        Dynamically builds the context using RAG and chat history.\n\n        It retrieves relevant file content from the RAG index based on the latest\n        user query, includes project manifests for directories, and appends the\n        recent chat history.\n        \"\"\"\n        context = ''\n        for look in self.memory.get('look', []):\n            path = look.get('file')\n            if path and os.path.isdir(path):\n                content = look.get('content', '')\n                context += (\n                    f'--- Project Manifest for {path} ---\\n{content}\\n\\n')\n        last_user_message = next((msg['content'] for msg in reversed(self.\n            memory.get('chat', [])) if msg['role'] == 'user'), None)\n        if last_user_message:\n            rag_results = self.search_rag(last_user_message, k=3)\n            if rag_results:\n                context += '--- Relevant context from RAG ---\\n'\n                for doc, score, meta in rag_results:\n                    file_path = meta.get('file', 'Unknown source')\n                    context += f'Source: {file_path} (Score: {score:.4f})\\n'\n                    context += f'Content: {doc}\\n---\\n'\n                context += '\\n'\n        for msg in self.memory.get('chat', []):\n            context += f\"{msg['role'].capitalize()}: {msg['content']}\\n\"\n        return context.strip()\n\n    def clear_memory(self) ->None:\n        self.memory = {'chat': [], 'look': []}\n        self.save_memory()\n        self.rag_manager.clear_index()\n\n    def search_rag(self, query: str, k: int=3) ->List[tuple]:\n        \"\"\"\n        Search the RAG index for relevant documents.\n        \n        Args:\n            query: The search query\n            k: Number of results to return\n            \n        Returns:\n            List of (document_content, score, metadata) tuples\n        \"\"\"\n        return self.rag_manager.search(query, k)\n",
    "file": "/mnt/ProjectData/omni/memory_manager.py"
  },
  {
    "id": 102,
    "hash": "c71ec060a0d980ebd390a8ae427c7a7c",
    "content": "\"\"\"\nOmni - AI-powered code generation and project-aware editing CLI tool\n\nIntegrates modular UI, memory, personality, and AST-based code editing.\n\"\"\"\nimport os\nimport subprocess\nimport requests\nimport json\nimport sys\nimport re\nimport argparse\nimport ast\nfrom datetime import datetime\nimport threading\nimport queue as Queue\nimport time\nfrom typing import List, Dict, Optional\nfrom rich import print\nfrom rich.panel import Panel\nfrom rich.console import Console\nfrom rich.tree import Tree\nfrom ui_manager import UIManager\nfrom personality_manager import PersonalityManager\nfrom memory_manager import MemoryManager\nfrom code_editor import CodeEditor\nfrom file_creator import FileCreator\nfrom git_manager import GitManager\nimport traceback\nDEFAULT_BACKEND = 'openrouter'\nOLLAMA_MODEL = 'phi4-reasoning'\nOPENROUTER_MODEL = 'qwen/qwen3-coder'\nDEFAULT_SAVE_DIR = os.path.expanduser('/mnt/ProjectData/omni/omni_saves/')\nCONFIG_FILE = 'config.json'\nMEMORY_FILE = 'memory.json'\nOLLAMA_API_URL = 'http://localhost:11434/api/generate'\nOPENROUTER_API_URL = 'https://openrouter.ai/api/v1/chat/completions'\nOPENROUTER_MODELS_API_URL = 'https://openrouter.ai/api/v1/models'\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\ncurrent_backend = DEFAULT_BACKEND\ncurrent_model = (OLLAMA_MODEL if DEFAULT_BACKEND == 'ollama' else\n    OPENROUTER_MODEL)\nOLLAMA_MODELS = {'deepseek': 'deepseek-coder:6.7b', 'codellama':\n    'codellama:13b', 'mistral': 'mistral:latest', 'llama2': 'llama2:latest',\n    'phind': 'phind-codellama:34b'}\nos.makedirs(DEFAULT_SAVE_DIR, exist_ok=True)\nTEMPLATES = {'flask':\n    \"\"\"from flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/')\ndef home():\n    return '<h1>Hello, Flask!</h1>'\n\nif __name__ == '__main__':\n    app.run(debug=True)\"\"\"\n    , 'html5':\n    \"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>New Page</title>\n</head>\n<body>\n    <h1>Hello World</h1>\n</body>\n</html>\"\"\"\n    , 'scraper':\n    \"\"\"import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        print(soup.title.text)\n    except Exception as e:\n        print(f\"[bold red]Error scraping {url}:[/] {e}\")\n\nif __name__ == \"__main__\":\n    scrape(\"https://example.com\")\"\"\"\n    }\nconsole = Console()\npersonality_manager = PersonalityManager(CONFIG_FILE)\nmemory_manager = MemoryManager(MEMORY_FILE)\nui_manager = UIManager()\nlast_query: Optional[str] = None\nlast_response: Optional[str] = None\nlast_code: Optional[str] = None\n\n\ndef start_ollama_server() ->None:\n    if current_backend != 'ollama':\n        return\n    try:\n        requests.get('http://localhost:11434', timeout=1)\n    except requests.exceptions.ConnectionError:\n        print('[cyan]Starting Ollama server...[/]')\n        subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL)\n\n\ndef query_llm(prompt: str) ->str:\n    personality = personality_manager.get_current_personality()\n    system_prompt = personality.get('system_prompt', '') if personality else ''\n    memory_context = memory_manager.get_memory_context()\n    rag_context = ''\n    try:\n        from rag_manager import RAGManager\n        project_root = memory_manager.get_project_root()\n        if project_root:\n            rag_manager = RAGManager()\n            if rag_manager.get_document_count() > 0:\n                results = rag_manager.search(prompt, k=3)\n                if results:\n                    rag_context = '\\n\\nRelevant context from codebase:\\n'\n                    for i, (doc, score, meta) in enumerate(results, 1):\n                        file_path = meta.get('file', 'Unknown')\n                        rag_context += f'{i}. [{file_path}] {doc}\\n'\n    except Exception:\n        pass\n    full_prompt = (\n        f'{system_prompt}\\n\\n{memory_context}{rag_context}\\n\\nUser: {prompt}')\n    with ui_manager.show_spinner('AI is listening and thinking...'):\n        if current_backend == 'ollama':\n            response = query_ollama(full_prompt)\n        elif current_backend == 'openrouter':\n            response = query_openrouter(full_prompt)\n        else:\n            response = '[bold red]Error:[/] Unknown backend'\n    return response\n\n\ndef query_openrouter(prompt: str) ->str:\n    if not OPENROUTER_API_KEY:\n        return '[bold red]Error:[/] OPENROUTER_API_KEY not set.'\n    headers = {'Authorization': f'Bearer {OPENROUTER_API_KEY}',\n        'Content-Type': 'application/json'}\n    payload = {'model': current_model, 'messages': [{'role': 'user',\n        'content': prompt}]}\n    try:\n        response = requests.post(OPENROUTER_API_URL, headers=headers, json=\n            payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['choices'][0]['message']['content']\n    except Exception as e:\n        error_details = ''\n        try:\n            error_details = response.json()\n        except:\n            error_details = response.text if hasattr(response, 'text'\n                ) else str(e)\n        return (\n            f'[bold red]OpenRouter Error:[/] {e}\\n[dim]Details: {error_details}[/dim]'\n            )\n\n\ndef query_ollama(prompt: str) ->str:\n    payload = {'model': current_model, 'prompt': prompt, 'stream': False}\n    try:\n        response = requests.post(OLLAMA_API_URL, json=payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['response']\n    except Exception as e:\n        return f'[bold red]Ollama Error:[/] {e}'\n\n\ndef extract_code(text: str) ->List[tuple[str, str]]:\n    matches = re.findall('```(\\\\w*)\\\\n([\\\\s\\\\S]*?)```', text)\n    return [(lang or 'text', code.strip()) for lang, code in matches\n        ] if matches else []\n\n\ndef list_models(args: list=None) ->None:\n    if current_backend == 'ollama':\n        print('[bold cyan]Popular Ollama Models:[/]')\n        for name, model_id in OLLAMA_MODELS.items():\n            print(\n                f\"{'\u2b50' if model_id == current_model else '  '} [yellow]{name:12}[/] \u2192 {model_id}\"\n                )\n    elif current_backend == 'openrouter':\n        list_openrouter_models(args or [])\n\n\ndef list_openrouter_models(args: list):\n    try:\n        from simple_term_menu import TerminalMenu\n    except ImportError:\n        ui_manager.show_error(\n            \"'simple-term-menu' is required. `pip install simple-term-menu`\")\n        return\n    try:\n        with ui_manager.show_spinner('Fetching models...'):\n            response = requests.get(OPENROUTER_MODELS_API_URL)\n            response.raise_for_status()\n        api_models_data = response.json().get('data', [])\n    except requests.RequestException as e:\n        ui_manager.show_error(f'Error fetching models: {e}')\n        return\n    all_models, sources = [], set()\n    for model_data in api_models_data:\n        if (model_id := model_data.get('id')):\n            sources.add(model_id.split('/')[0])\n            pricing = model_data.get('pricing', {})\n            is_free = pricing.get('prompt') == '0' and pricing.get('completion'\n                ) == '0'\n            all_models.append({'id': model_id, 'name': model_data.get(\n                'name'), 'source': model_id.split('/')[0], 'is_free': is_free})\n    all_models.sort(key=lambda x: (x['source'], x['name']))\n    if args and args[0].lower() == 'sources':\n        print('[bold cyan]Available Model Sources:[/]')\n        [print(f'  [yellow]{s}[/]') for s in sorted(list(sources))]\n        return\n    models_to_display, title = all_models, 'Select an OpenRouter Model'\n    if args:\n        filter_keyword = args[0].lower()\n        title = f\"Select a Model from '{filter_keyword}'\"\n        models_to_display = [m for m in all_models if filter_keyword in m[\n            'source'].lower()]\n        if not models_to_display:\n            ui_manager.show_error(f\"No models for source: '{filter_keyword}'\")\n            return\n    menu_entries = [\n        f\"{'\u2b50' if m['id'] == current_model else '  '} {m['name']} [dim]({m['id']}){' [green](FREE)[/]' if m['is_free'] else ''}[/dim]\"\n         for m in models_to_display]\n    try:\n        cursor_idx = next((i for i, m in enumerate(models_to_display) if m[\n            'id'] == current_model), 0)\n        chosen_index = TerminalMenu(menu_entries, title=f'{title}',\n            cursor_index=cursor_idx, cycle_cursor=True, clear_screen=True\n            ).show()\n        if chosen_index is not None:\n            set_model(models_to_display[chosen_index]['id'])\n        else:\n            print('Model selection cancelled.')\n    except Exception as e:\n        ui_manager.show_error(f'Menu display error: {e}')\n\n\ndef set_model(model_id: str) ->None:\n    global current_model\n    current_model = model_id\n    ui_manager.show_success(f'Model set to: {current_model}')\n\n\ndef switch_backend(backend_name: str) ->None:\n    global current_backend, current_model\n    backend_name = backend_name.lower()\n    if backend_name not in ['ollama', 'openrouter']:\n        ui_manager.show_error(f'Unknown backend: {backend_name}')\n        return\n    current_backend = backend_name\n    current_model = (OLLAMA_MODEL if backend_name == 'ollama' else\n        OPENROUTER_MODEL)\n    ui_manager.show_success(\n        f'Switched to {backend_name} backend with model: {current_model}')\n    if backend_name == 'ollama':\n        start_ollama_server()\n\n\ndef generate_project_manifest(path: str) ->tuple[str, List[str]]:\n    manifest = ''\n    file_paths = []\n    tree = Tree(f'[bold cyan]Project: {os.path.basename(path)}[/]')\n    exclude_dirs = {'__pycache__', '.git', 'venv', 'node_modules', '.idea',\n        'ollama'}\n    for root, dirs, files in os.walk(path):\n        dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.\n            startswith('.')]\n        relative_path = os.path.relpath(root, path)\n        branch = tree\n        if relative_path != '.':\n            parts = relative_path.split(os.sep)\n            for part in parts:\n                child = next((c for c in branch.children if c.label ==\n                    f'[magenta]{part}[/]'), None)\n                if not child:\n                    child = branch.add(f'[magenta]{part}[/]')\n                branch = child\n        for fname in sorted(files):\n            ext = os.path.splitext(fname)[1]\n            if ext not in ('.py', '.js', '.html', '.css', '.md', '.txt'):\n                continue\n            rel_path = os.path.join(relative_path, fname\n                ) if relative_path != '.' else fname\n            file_paths.append(rel_path)\n            branch.add(f'[green]{fname}[/]' if ext == '.py' else\n                f'[dim]{fname}[/]')\n            manifest += f'File: {rel_path}\\n\\n'\n    console.print(tree)\n    return manifest.strip(), file_paths\n\n\ndef look_command(path: str) ->None:\n    \"\"\"\n    Scans a directory or file and loads it into memory. It can resolve paths\n    relative to the current working directory or the project root in memory.\n    If a new directory is scanned, the previous 'look' context is cleared\n    to ensure the context remains relevant.\n    \"\"\"\n    resolved_path = resolve_file_path(path)\n    if not resolved_path:\n        ui_manager.show_error(f'\u274c Path not found: {path}')\n        return\n    if resolved_path != os.path.abspath(path):\n        ui_manager.show_success(\n            f\"Found '{path}' in project. Using: {resolved_path}\")\n    if os.path.isdir(resolved_path):\n        ui_manager.show_success(\n            \"New project directory detected. Clearing previous 'look' context.\"\n            )\n        memory_manager.memory['look'] = []\n        with ui_manager.show_spinner('Generating project manifest...'):\n            manifest = generate_project_manifest(resolved_path)\n        memory_manager.add_look_data(resolved_path, manifest)\n        ui_manager.show_success('\u2705 Project manifest added to memory.')\n    else:\n        try:\n            with ui_manager.show_spinner('Loading file...'):\n                with open(resolved_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n            for item in memory_manager.memory['look']:\n                if item.get('file') == resolved_path:\n                    item['content'] = content\n                    memory_manager.save_memory()\n                    ui_manager.show_success(\n                        '\u2705 Refreshed file content in memory.')\n                    return\n            memory_manager.add_look_data(resolved_path, content)\n            ui_manager.show_success('\u2705 File content added to memory.')\n        except Exception as e:\n            ui_manager.show_error(f'\u274c Error reading file: {e}')\n\n\ndef resolve_file_path(path: str) ->Optional[str]:\n    \"\"\"Resolves a file path, checking CWD first, then against project root in memory.\"\"\"\n    if os.path.exists(path):\n        return os.path.abspath(path)\n    project_root = memory_manager.get_project_root()\n    if project_root:\n        full_path = os.path.join(project_root, path)\n        if os.path.exists(full_path):\n            return full_path\n    return None\n\n\ndef _create_prompt_for_file_creation(file_name: str, instruction: str) ->str:\n    \"\"\"\n    Generate a robust prompt for file creation that instructs the AI to act as an expert,\n    produce complete and clean code, and avoid any extra commentary.\n    \"\"\"\n    return f\"\"\"You are an expert programmer tasked with creating a new file. Your goal is to generate complete, production-ready content based on the user's instruction.\n\nIMPORTANT RULES:\n- Provide ONLY the raw file content - no explanations, notes, or commentary outside the file itself\n- Include all necessary imports, boilerplate, and complete implementations\n- If creating code, ensure it's syntactically correct and follows best practices\n- For configuration files, use appropriate formatting (JSON, YAML, etc.)\n- For documentation files, use proper markdown formatting\n\nFile to create: {file_name}\nUser instruction: {instruction}\n\nGenerate the complete file content now:\"\"\"\n\n\ndef handle_file_create_command(file_path: str, instruction: str):\n    \"\"\"\n    Uses the LLM to generate content for a new file based on an instruction.\n    \"\"\"\n    global last_code\n    if os.path.exists(file_path):\n        if ui_manager.get_user_input(\n            f\"File '{file_path}' already exists. Overwrite? (y/n): \").lower(\n            ) not in ['yes', 'y']:\n            ui_manager.show_error('File creation cancelled.')\n            return\n    prompt = _create_prompt_for_file_creation(os.path.basename(file_path),\n        instruction)\n    with ui_manager.show_spinner(\n        f\"AI is generating content for '{file_path}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    if code_blocks:\n        new_content = code_blocks[0][1]\n    else:\n        new_content = response.strip()\n    if not new_content:\n        ui_manager.show_error('AI did not return any content.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    print(Panel(new_content, title=\n        f'[bold yellow]Proposed content for {file_path}[/]', border_style=\n        'yellow'))\n    if ui_manager.get_user_input('Create this file? (y/n): ').lower() in ['yes'\n        , 'y']:\n        try:\n            FileCreator.create(file_path, new_content)\n            last_code = new_content\n            ui_manager.show_success(f'File created successfully: {file_path}')\n        except IOError as e:\n            ui_manager.show_error(f'Error creating file: {e}')\n    else:\n        ui_manager.show_error('File creation cancelled.')\n\n\ndef look_all_command() ->None:\n    \"\"\"\n    Finds the project manifest in memory, reads every file listed, and adds their content to memory.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first to generate a manifest.\"\n            )\n        return\n    manifest_data = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and item.get('type'\n            ) == 'directory':\n            manifest_data = item.get('content')\n            break\n    if not manifest_data or not isinstance(manifest_data, (list, tuple)\n        ) or len(manifest_data) != 2:\n        ui_manager.show_error(\n            \"Could not find a valid project manifest in memory. Please run 'look <directory>' again.\"\n            )\n        return\n    file_paths = manifest_data[1]\n    if not file_paths:\n        ui_manager.show_error('No files found in the project manifest.')\n        return\n    total_files = len(file_paths)\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Loading {total_files} files from project manifest...'):\n        for file_path_relative in file_paths:\n            full_path = os.path.join(project_root, file_path_relative)\n            if os.path.isfile(full_path):\n                try:\n                    with open(full_path, 'r', encoding='utf-8') as f:\n                        content = f.read().strip()\n                    if not any(look['file'] == full_path for look in\n                        memory_manager.memory['look']):\n                        memory_manager.add_look_data(full_path, content)\n                        loaded_count += 1\n                except Exception as e:\n                    print(\n                        f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\"\n                        )\n    ui_manager.show_success(\n        f'\u2705 Loaded content for {loaded_count} new files into memory.')\n\n\ndef _load_all_project_files_if_needed():\n    \"\"\"\n    Checks if a project is loaded and automatically loads any files from its\n    manifest that are not already in the 'look' memory. This ensures a\n    complete context for editing and refactoring commands.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        return\n    manifest_content = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and 'File:' in item.get('content',\n            ''):\n            manifest_content = item['content']\n            break\n    if not manifest_content:\n        return\n    existing_file_paths = {item['file'] for item in memory_manager.memory.\n        get('look', []) if item.get('type') == 'file'}\n    file_paths_relative = re.findall('File: (.*)', manifest_content)\n    files_to_load = []\n    for rel_path in file_paths_relative:\n        full_path = os.path.join(project_root, rel_path)\n        if full_path not in existing_file_paths and os.path.isfile(full_path):\n            files_to_load.append((full_path, rel_path))\n    if not files_to_load:\n        return\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Auto-loading {len(files_to_load)} project files for context...'):\n        for full_path, file_path_relative in files_to_load:\n            try:\n                with open(full_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n                memory_manager.add_look_data(full_path, content)\n                loaded_count += 1\n            except Exception as e:\n                print(f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\")\n    if loaded_count > 0:\n        ui_manager.show_success(\n            f'\u2705 Loaded {loaded_count} new file(s) into memory for full project context.'\n            )\n\n\ndef _create_prompt_for_element_selection(file_name: str, instruction: str,\n    elements: List[str], element_structures: Dict[str, Dict]) ->str:\n    \"\"\"\n    Create a helper for the first stage of the 'edit' command. This prompt asks the AI\n    to analyze the user's instruction and intelligently select the most relevant code element to modify.\n    \"\"\"\n    element_details = []\n    for elem in elements:\n        if elem in element_structures:\n            struct = element_structures[elem]\n            detail = (\n                f\"{elem} ({struct['type']}, lines {struct['line_start']}-{struct['line_end']})\"\n                )\n            element_details.append(detail)\n        else:\n            element_details.append(elem)\n    return f\"\"\"You are an expert code analyzer. Your task is to identify what should be modified based on the user's instruction.\n\nFile: {file_name}\nAvailable elements: {', '.join(element_details) if element_details else 'None'}\n\nUser instruction: {instruction}\n\nRESPONSE FORMAT:\nChoose one of these response types:\n1. \"ELEMENT: <element_name>\" - to edit an entire function/class\n2. \"PARTIAL: <element_name> LINES: <start>-<end>\" - to edit specific lines within an element\n3. \"FILE\" - to edit the entire file or multiple elements\n\nRULES:\n- If the instruction mentions specific line numbers or a specific part of a function, use PARTIAL\n- If the instruction targets an entire function/class, use ELEMENT\n- If the instruction requires changes to multiple elements or file structure, use FILE\n- For PARTIAL edits, provide absolute line numbers from the original file\n\nWhat should be edited?\"\"\"\n\n\ndef _create_prompt_for_element_rewrite(file_name: str, element_name: str,\n    instruction: str, original_code: str, is_full_file: bool=False) ->str:\n    \"\"\"\n    Create a helper for the second stage of the 'edit' command. This prompt instructs the AI\n    to rewrite a specific code element (or the whole file) based on the user's request,\n    demanding a complete and syntactically correct code block as output.\n    \"\"\"\n    if is_full_file:\n        return f\"\"\"You are an expert programmer. Rewrite the entire file to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the entire file\n- Ensure all syntax is correct and the code is ready to run\n- Preserve existing functionality unless explicitly asked to change it\n- Include all necessary imports and maintain the file's structure\n- Do NOT include any explanations or comments outside the code\n\nFile: {file_name}\nTask: {instruction}\n\nCurrent file content:\n```python\n{original_code}\n```\n\nGenerate the complete updated file now:\"\"\"\n    else:\n        return f\"\"\"You are an expert programmer. Rewrite the specified element to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the element\n- Include any necessary imports at the top of your code block\n- Ensure the code is syntactically correct and maintains the same interface\n- Do NOT include explanations or comments outside the code block\n- The code must be a drop-in replacement for the original element\n\nFile: {file_name}\nElement to modify: {element_name}\nTask: {instruction}\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the complete updated element now:\"\"\"\n\n\ndef _create_prompt_for_partial_edit(file_name: str, element_name: str,\n    instruction: str, original_snippet: str, line_start: int, line_end: int,\n    full_element_code: str) ->str:\n    \"\"\"\n    Create a prompt for partial edits within a function or class.\n    This allows surgical changes to specific parts of code.\n    \"\"\"\n    return f\"\"\"You are an expert programmer. Make a surgical edit to a specific part of a function/class.\n\nCONTEXT:\n- File: {file_name}\n- Element: {element_name}\n- Lines to modify: {line_start}-{line_end}\n- Task: {instruction}\n\nIMPORTANT RULES:\n- Provide ONLY the code that will replace lines {line_start}-{line_end}\n- Your code must fit seamlessly into the existing function\n- Maintain proper indentation (the code will be auto-indented)\n- Do NOT include the function definition or other parts\n- Do NOT include explanations outside the code\n\nFull element for context:\n```python\n{full_element_code}\n```\n\nCode section to replace (lines {line_start}-{line_end}):\n```python\n{original_snippet}\n```\n\nGenerate ONLY the replacement code for the specified lines:\"\"\"\n\n\ndef handle_file_edit_command(file_path: str, instruction: str):\n    \"\"\"\n    Handles the entire workflow for editing a single file, ensuring full\n    project context is loaded before the AI makes any decisions.\n    Now supports partial edits within functions.\n    \"\"\"\n    global last_code\n    _load_all_project_files_if_needed()\n    resolved_path = resolve_file_path(file_path)\n    if not resolved_path:\n        ui_manager.show_error(f'File not found: {file_path}')\n        return\n    if resolved_path != os.path.abspath(file_path):\n        ui_manager.show_success(\n            f\"Found '{file_path}' in project. Using: {resolved_path}\")\n    try:\n        editor = CodeEditor(resolved_path)\n    except (ValueError, FileNotFoundError) as e:\n        ui_manager.show_error(str(e))\n        return\n    elements = editor.list_elements()\n    element_structures = {}\n    for elem in elements:\n        struct = editor.get_element_structure(elem)\n        if struct:\n            element_structures[elem] = struct\n    prompt1 = _create_prompt_for_element_selection(os.path.basename(\n        resolved_path), instruction, elements, element_structures)\n    with ui_manager.show_spinner('AI is analyzing file...'):\n        ai_response = query_llm(prompt1).strip()\n    if ai_response.upper() == 'FILE':\n        ui_manager.show_success('AI has chosen to edit the entire file.')\n        original_snippet = editor.source_code\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), 'entire file', instruction, original_snippet,\n            is_full_file=True)\n        edit_type = 'FILE'\n        element_to_edit = None\n        line_range = None\n    elif ai_response.startswith('PARTIAL:'):\n        parts = ai_response.split()\n        element_to_edit = parts[1]\n        if 'LINES:' in ai_response:\n            line_part = ai_response.split('LINES:')[1].strip()\n            if '-' in line_part:\n                line_start, line_end = map(int, line_part.split('-'))\n                line_range = line_start, line_end\n            else:\n                ui_manager.show_error('Invalid line range format')\n                return\n        else:\n            ui_manager.show_error('Missing line range for partial edit')\n            return\n        if element_to_edit not in elements:\n            ui_manager.show_error(f\"Element '{element_to_edit}' not found\")\n            return\n        ui_manager.show_success(\n            f\"AI selected partial edit of '{element_to_edit}' (lines {line_start}-{line_end})\"\n            )\n        original_snippet = editor.get_element_body_snippet(element_to_edit,\n            line_start, line_end)\n        if not original_snippet:\n            original_snippet = editor.get_source_of(element_to_edit)\n        full_element_code = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_partial_edit(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet,\n            line_start, line_end, full_element_code)\n        edit_type = 'PARTIAL'\n    elif ai_response.startswith('ELEMENT:'):\n        element_to_edit = ai_response.split(':', 1)[1].strip()\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    else:\n        element_to_edit = ai_response.splitlines()[0]\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    with ui_manager.show_spinner(f'AI is editing...'):\n        response = query_llm(prompt2)\n    code_blocks = extract_code(response)\n    if not code_blocks:\n        ui_manager.show_error('AI did not return a valid code block.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    new_code = code_blocks[0][1]\n    success = False\n    if edit_type == 'FILE':\n        try:\n            editor.tree = ast.parse(new_code)\n            success = True\n        except SyntaxError as e:\n            ui_manager.show_error(f'AI returned invalid Python syntax: {e}')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    elif edit_type == 'PARTIAL':\n        success = editor.replace_partial(element_to_edit, new_code,\n            line_start=line_range[0], line_end=line_range[1])\n        if not success:\n            ui_manager.show_error('Failed to apply partial edit.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    else:\n        success = editor.replace_element(element_to_edit, new_code)\n        if not success:\n            ui_manager.show_error(\n                'AI returned invalid code; could not be parsed or applied.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    if not (diff := editor.get_diff()):\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(diff, title=\n        f'[bold yellow]Proposed Changes for {resolved_path}[/]'))\n    if ui_manager.get_user_input('Apply changes? (y/n): ').lower() in ['yes',\n        'y']:\n        editor.save_changes()\n        last_code = editor.get_modified_source()\n        ui_manager.show_success(f'Changes saved to {resolved_path}.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_plan(instruction: str, memory_context: str\n    ) ->str:\n    \"\"\"\n    Create a specialized prompt-generation function for the 'refactor' command.\n    This prompt will explicitly define the required JSON structure for the plan\n    and instruct the AI to act as an expert project manager.\n    \"\"\"\n    return f\"\"\"You are an expert project manager and software architect. Analyze the project context and create a detailed refactoring plan.\n\nYour plan must be a valid JSON object with this exact structure:\n{{\n    \"actions\": [\n        {{\n            \"type\": \"MODIFY\" | \"CREATE\" | \"DELETE\" | \"PARTIAL\",\n            \"file\": \"relative/path/to/file.py\",\n            \"element\": \"function_or_class_name\",  // For MODIFY/DELETE/PARTIAL\n            \"element_name\": \"new_element_name\",    // For CREATE\n            \"line_start\": 10,                      // For PARTIAL only\n            \"line_end\": 20,                        // For PARTIAL only\n            \"reason\": \"Clear explanation of why this change is needed\",\n            \"description\": \"What this action will accomplish\",\n            \"anchor_element\": \"optional_anchor\",   // Optional for CREATE\n            \"position\": \"before\" | \"after\"         // Optional for CREATE\n        }}\n    ]\n}}\n\nACTION TYPES:\n- MODIFY: Change an entire function, class, or method\n- PARTIAL: Change specific lines within a function/class (requires line_start and line_end)\n- CREATE: Add new functions, classes, or files\n- DELETE: Remove functions, classes, variables, or imports\n\nRULES FOR YOUR PLAN:\n- Use PARTIAL when you only need to change a small part of a function\n- Use MODIFY when restructuring an entire function or class\n- Each action must have all required fields based on its type\n- File paths must be relative to the project root\n- Be specific and surgical - avoid unnecessary changes\n- Consider dependencies between changes\n- Order actions logically (e.g., create dependencies before using them)\n\n### Project Context ###\n{memory_context}\n\n### Refactoring Request ###\n{instruction}\n\nGenerate ONLY the JSON plan - no explanations or markdown:\"\"\"\n\n\ndef _get_refactor_plan(instruction: str) ->Optional[List[Dict]]:\n    \"\"\"\n    Generates a refactoring plan from the LLM.\n\n    This function encapsulates the logic for checking project context,\n    constructing a prompt, querying the LLM, and parsing the resulting\n    JSON plan for a refactoring task.\n\n    Args:\n        instruction: The user's high-level refactoring instruction.\n\n    Returns:\n        A list of action dictionaries if a valid plan is generated,\n        otherwise None.\n    \"\"\"\n    if not memory_manager.get_project_root():\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return None\n    memory_context = memory_manager.get_memory_context()\n    plan_prompt = _create_prompt_for_refactor_plan(instruction, memory_context)\n    with ui_manager.show_spinner('AI is creating an execution plan...'):\n        plan_str = query_llm(plan_prompt)\n    try:\n        match = re.search('\\\\{.*\\\\}', plan_str, re.DOTALL)\n        if not match:\n            raise ValueError('No JSON object found in the response.')\n        plan = json.loads(match.group(0))\n        actions = plan.get('actions', [])\n        if not actions:\n            raise ValueError(\"No 'actions' key found in plan or plan is empty.\"\n                )\n        return actions\n    except (json.JSONDecodeError, ValueError) as e:\n        ui_manager.show_error(f'AI failed to generate a valid plan: {e}')\n        print(Panel(plan_str, title=\"[yellow]AI's Invalid Plan Response[/]\",\n            border_style='yellow'))\n        return None\n\n\ndef _display_and_confirm_plan(plan: Dict) ->bool:\n    \"\"\"\n    Displays the generated execution plan to the user and asks for confirmation.\n\n    This helper function separates the UI interaction of plan confirmation from\n    the main refactoring logic.\n\n    Args:\n        plan: A dictionary, expected to contain an 'actions' key with a list of action dicts.\n\n    Returns:\n        True if the user confirms the plan, False otherwise.\n    \"\"\"\n    actions = plan.get('actions', [])\n    if not actions:\n        ui_manager.show_error('The generated plan is empty. Aborting.')\n        return False\n    ui_manager.show_success('AI has created a plan:')\n    for i, action in enumerate(actions):\n        action_type = action.get('type', 'N/A')\n        element = action.get('element') or action.get('element_name', 'N/A')\n        reason = action.get('reason') or action.get('description', '')\n        file_path = action.get('file', '')\n        if action_type == 'PARTIAL':\n            line_start = action.get('line_start', '?')\n            line_end = action.get('line_end', '?')\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} (lines {line_start}-{line_end}) - {reason}'\n                )\n        else:\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} - {reason}'\n                )\n    if ui_manager.get_user_input('\\nProceed with this plan? (y/n): ').lower(\n        ) in ['yes', 'y']:\n        return True\n    else:\n        ui_manager.show_error('Execution aborted by user.')\n        return False\n\n\ndef _apply_refactor_changes(editors: Dict[str, CodeEditor]) ->None:\n    \"\"\"\n    Consolidates changes from multiple CodeEditor instances, shows a unified\n    diff, and prompts the user to apply them.\n    \n    This helper function abstracts the final step of a refactor, ensuring\n    all proposed modifications are presented to the user for a final review\n    before any files are written to disk.\n\n    Args:\n        editors: A dictionary mapping absolute file paths to their\n                 corresponding CodeEditor instances which hold the\n                 proposed changes in their AST.\n    \"\"\"\n    full_diff = ''\n    for editor in editors.values():\n        diff = editor.get_diff()\n        if diff:\n            full_diff += diff + '\\n'\n    if not full_diff.strip():\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(full_diff, title=\n        '[bold yellow]Proposed Project-Wide Changes[/]'))\n    if ui_manager.get_user_input('Apply all changes? (y/n): ').lower() in [\n        'yes', 'y']:\n        for editor in editors.values():\n            editor.save_changes()\n        ui_manager.show_success('\u2705 Project changes applied successfully.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_action(action_type: str, file_path: str,\n    action_details: Dict) ->str:\n    \"\"\"\n    Create a helper to generate prompts for individual 'CREATE' or 'MODIFY' steps\n    within a refactor plan. This ensures the AI produces code for the specific\n    sub-task in the correct context.\n    \"\"\"\n    if action_type == 'MODIFY':\n        element_name = action_details['element_name']\n        reason = action_details['reason']\n        original_code = action_details['original_code']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- Element: {element_name}\n- Reason for change: {reason}\n\nRULES:\n- Provide ONLY the complete updated code for the element\n- Include any necessary imports at the top\n- Ensure the code integrates properly with the rest of the file\n- Maintain the same function/class signature unless the change requires otherwise\n- No explanations outside the code block\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the updated element code:\"\"\"\n    elif action_type == 'CREATE':\n        element_name = action_details['element_name']\n        description = action_details['description']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- New element to create: {element_name}\n- Purpose: {description}\n\nRULES:\n- Provide ONLY the complete code for the new element\n- Include all necessary imports at the top\n- Follow the coding style and patterns used in the project\n- Ensure the code is production-ready and well-structured\n- For non-Python files, provide the complete file content\n- No explanations outside the code block\n\nGenerate the new element code:\"\"\"\n\n\ndef _process_refactor_action(action: Dict, project_base_path: str, editors:\n    Dict) ->bool:\n    \"\"\"\n    Processes a single refactoring action from the plan.\n\n    This function handles the execution of a single action from the refactoring plan,\n    including LLM code generation and applying changes to in-memory editors or files.\n\n    Args:\n        action: A dictionary containing action details (type, file, element, etc.)\n        project_base_path: The absolute path to the project root\n        editors: Dictionary mapping file paths to their CodeEditor instances\n\n    Returns:\n        True if the action was processed successfully, False otherwise\n    \"\"\"\n    file_path_relative = action.get('file')\n    if not file_path_relative:\n        ui_manager.show_error(\n            f\"Action is missing 'file' key. Skipping: {action}\")\n        return False\n    file_path_absolute = os.path.join(project_base_path, file_path_relative)\n    action_type = action.get('type', '').upper()\n    prompt, element_name = '', ''\n    if action_type == 'MODIFY':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_source_of(element_name)\n            if not original_snippet:\n                ui_manager.show_error(\n                    f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                    )\n                return False\n            action_details = {'element_name': element_name, 'reason':\n                reason, 'original_code': original_snippet}\n            prompt = _create_prompt_for_refactor_action('MODIFY',\n                file_path_relative, action_details)\n    elif action_type == 'PARTIAL':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        line_start = action.get('line_start')\n        line_end = action.get('line_end')\n        if not all([element_name, line_start, line_end]):\n            ui_manager.show_error(\n                f'PARTIAL action missing required fields. Skipping: {action}')\n            return False\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_element_body_snippet(element_name,\n                line_start, line_end)\n            if not original_snippet:\n                original_snippet = editor.get_source_of(element_name)\n                if not original_snippet:\n                    ui_manager.show_error(\n                        f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                        )\n                    return False\n            full_element_code = editor.get_source_of(element_name)\n            prompt = _create_prompt_for_partial_edit(file_path_relative,\n                element_name, reason, original_snippet, line_start,\n                line_end, full_element_code)\n    elif action_type == 'CREATE':\n        element_name = action.get('element_name')\n        description = action.get('description')\n        action_details = {'element_name': element_name, 'description':\n            description}\n        prompt = _create_prompt_for_refactor_action('CREATE',\n            file_path_relative, action_details)\n    else:\n        ui_manager.show_error(f\"Invalid action type '{action_type}'. Skipping.\"\n            )\n        return False\n    with ui_manager.show_spinner(\n        f\"AI: {action_type} on '{element_name or file_path_relative}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    new_content = code_blocks[0][1] if code_blocks else response.strip()\n    if not new_content:\n        ui_manager.show_error(\n            f'AI failed to generate content for action: {action}')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return False\n    if not file_path_relative.endswith('.py'):\n        try:\n            FileCreator.create(file_path_absolute, new_content)\n            ui_manager.show_success(\n                f\"File '{file_path_relative}' created/updated.\")\n            return True\n        except IOError as e:\n            ui_manager.show_error(\n                f\"Failed to create file '{file_path_relative}': {e}\")\n            return False\n    if file_path_absolute not in editors:\n        try:\n            if not os.path.exists(file_path_absolute):\n                os.makedirs(os.path.dirname(file_path_absolute), exist_ok=True)\n                with open(file_path_absolute, 'w') as f:\n                    f.write('')\n            editors[file_path_absolute] = CodeEditor(file_path_absolute)\n        except Exception as e:\n            ui_manager.show_error(\n                f'Error loading file {file_path_absolute}: {e}')\n            return False\n    editor = editors[file_path_absolute]\n    if action_type == 'MODIFY':\n        if not editor.replace_element(element_name, new_content):\n            ui_manager.show_error(\n                f\"Failed to apply MODIFY change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic MODIFY Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'PARTIAL':\n        if not editor.replace_partial(element_name, new_content, line_start,\n            line_end):\n            ui_manager.show_error(\n                f\"Failed to apply PARTIAL change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic PARTIAL Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'CREATE':\n        anchor = action.get('anchor_element')\n        position = action.get('position', 'after')\n        if not editor.add_element(new_content, anchor_name=anchor, before=\n            position == 'before'):\n            ui_manager.show_error(\n                f\"Failed to apply CREATE change for '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic CREATE Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    return True\n\n\ndef handle_project_refactor_command(instruction: str):\n    \"\"\"\n    Orchestrates a multi-file, multi-step code refactoring process.\n    \n    This function serves as a high-level orchestrator that delegates specific tasks\n    to helper functions, improving readability, modularity, and maintainability.\n    \"\"\"\n    _load_all_project_files_if_needed()\n    actions = _get_refactor_plan(instruction)\n    if not actions:\n        return\n    plan = {'actions': actions}\n    if not _display_and_confirm_plan(plan):\n        return\n    editors: Dict[str, CodeEditor] = {}\n    project_base_path = memory_manager.get_project_root()\n    successful_actions = 0\n    total_actions = len(actions)\n    for i, action in enumerate(actions, 1):\n        ui_manager.show_success(f'Processing action {i}/{total_actions}...')\n        action_type = action.get('type', '').upper()\n        file_path_relative = action.get('file')\n        if not file_path_relative:\n            ui_manager.show_error(\n                f\"Action is missing 'file' key. Skipping: {action}\")\n            continue\n        file_path_absolute = os.path.join(project_base_path, file_path_relative\n            )\n        if action_type == 'DELETE':\n            element_name = action.get('element')\n            if not element_name:\n                ui_manager.show_error(\n                    f\"DELETE action missing 'element' key. Skipping: {action}\")\n                continue\n            if not file_path_relative.endswith('.py'):\n                ui_manager.show_error(\n                    f'DELETE actions are only supported for Python files. Skipping.'\n                    )\n                continue\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    continue\n            editor = editors[file_path_absolute]\n            if editor.delete_element(element_name):\n                successful_actions += 1\n                ui_manager.show_success(\n                    f\"Successfully deleted '{element_name}' from '{file_path_relative}'.\"\n                    )\n            else:\n                ui_manager.show_error(\n                    f\"Failed to delete '{element_name}' from '{file_path_relative}'.\"\n                    )\n        elif _process_refactor_action(action, project_base_path, editors):\n            successful_actions += 1\n        else:\n            ui_manager.show_error(\n                f'Action {i} failed, continuing with remaining actions...')\n    if successful_actions == 0:\n        ui_manager.show_error('No actions were successfully executed.')\n        return\n    elif successful_actions < total_actions:\n        ui_manager.show_error(\n            f'Only {successful_actions}/{total_actions} actions completed successfully.'\n            )\n    else:\n        ui_manager.show_success(\n            f'All {total_actions} actions completed successfully.')\n    _apply_refactor_changes(editors)\n\n\ndef _create_prompt_for_commit_message(diff: str) ->str:\n    \"\"\"\n    Create a dedicated prompt function for the 'commit' command. This prompt will\n    instruct the AI to analyze a git diff and generate a concise commit message\n    following the Conventional Commits standard.\n    \"\"\"\n    return f\"\"\"You are an expert developer writing a Git commit message. Your task is to analyze the provided git diff and create a professional commit message.\n\nCOMMIT MESSAGE RULES:\n- Follow the Conventional Commits specification\n- Format: <type>(<optional scope>): <subject>\n- Types: feat, fix, docs, style, refactor, perf, test, build, ci, chore, revert\n- Subject line: max 50 characters, imperative mood, no period\n- Optional body: explain what and why (not how), wrap at 72 characters\n- Be specific and concise\n- Focus on the intent and impact of the changes\n\nEXAMPLES OF GOOD COMMIT MESSAGES:\n- feat(auth): add OAuth2 integration for Google login\n- fix(api): handle null response in user endpoint\n- refactor(database): optimize query performance for large datasets\n- docs(readme): update installation instructions for Windows\n\nRespond with ONLY the commit message - no markdown, quotes, or explanations.\n\n--- GIT DIFF TO ANALYZE ---\n{diff}\n\nGenerate the commit message:\"\"\"\n\n\ndef handle_commit_command():\n    \"\"\"\n    Orchestrates an AI-assisted Git commit workflow with improved error handling.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return\n    try:\n        git_manager = GitManager(project_root)\n    except ValueError as e:\n        ui_manager.show_error(str(e))\n        return\n    changed_files = git_manager.get_changed_files()\n    if not changed_files:\n        ui_manager.show_success(\n            'No changes to commit. Everything is up to date.')\n        return\n    staged_diff = git_manager.get_diff(staged=True)\n    unstaged_diff = git_manager.get_diff()\n    full_diff = f'{staged_diff}\\n{unstaged_diff}'.strip()\n    if not full_diff.strip():\n        ui_manager.show_success(\n            'No content changes detected (e.g., only file mode changes).')\n        return\n    prompt = _create_prompt_for_commit_message(full_diff)\n    commit_message = query_llm(prompt).strip()\n    if not commit_message:\n        ui_manager.show_error(\n            'AI failed to generate a commit message. Aborting.')\n        return\n    files_to_commit_str = '\\n'.join(f'- {f}' for f in changed_files)\n    plan_panel_content = f\"\"\"[bold]Files to be staged:[/]\n[yellow]{files_to_commit_str}[/]\n\n[bold]AI-Generated Commit Message:[/]\n[green]{commit_message}[/]\"\"\"\n    print(Panel(plan_panel_content, title='[bold cyan]Commit Plan[/]',\n        border_style='cyan'))\n    if ui_manager.get_user_input('\\nProceed with commit? (y/n): ').lower() in [\n        'yes', 'y']:\n        try:\n            git_manager.add(changed_files)\n            ui_manager.show_success('\u2705 Files staged.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Staging failed: {e.stderr}')\n            return\n        try:\n            git_manager.commit(commit_message)\n            ui_manager.show_success('\u2705 Commit successful.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Commit failed: {e.stderr}')\n            return\n        if ui_manager.get_user_input('Push changes to remote? (y/n): ').lower(\n            ) in ['yes', 'y']:\n            try:\n                git_manager.push()\n                ui_manager.show_success('\u2705 Push successful.')\n            except subprocess.CalledProcessError as e:\n                ui_manager.show_error(f'Push failed: {e.stderr}')\n        else:\n            ui_manager.show_error('Push cancelled.')\n    else:\n        ui_manager.show_error('Commit aborted by user.')\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef interactive_mode() ->None:\n    global last_query, last_response, last_code\n    try:\n        from Testing.overlay_engine import show_sequential_popup\n        gui_available = True\n    except ImportError:\n        gui_available = False\n    print(Panel(\n        \"\"\"[bold cyan]Omni Interactive Mode[/]\n[dim]Type 'help' for commands, 'exit' to quit.[/dim]\"\"\"\n        , border_style='cyan'))\n    personality_name = personality_manager.get_current_personality().get('name'\n        , 'Default')\n    gui_enabled = False\n    if gui_available:\n        try:\n            with open(CONFIG_FILE, 'r') as f:\n                config = json.load(f)\n                if config.get('gui_enabled', False):\n                    gui_enabled = True\n        except (FileNotFoundError, json.JSONDecodeError):\n            pass\n    refresh_status_panel(personality_name)\n    while True:\n        try:\n            user_input = ui_manager.get_user_input('\\n> ')\n            if not user_input:\n                continue\n            command, *args = user_input.split(maxsplit=1)\n            arg_str = args[0] if args else ''\n            if command == 'exit':\n                memory_manager.save_memory()\n                print('[bold cyan]Goodbye![/]')\n                break\n            elif command == 'help':\n                print(\n                    \"\"\"[bold]Commands:[/]\n\n  [bold cyan]Core & Project Commands[/]\n  [yellow]send <prompt>[/]        - Ask the LLM a question.\n  [yellow]look <path>[/]          - Read file or scan directory into memory.\n  [yellow]look_all[/]            - Recursively scan the project directory into memory.\n  [yellow]create <file> \"instr\"[/] - Create a new file using AI.\n  [yellow]edit <file> \"instr\"[/]   - Edit a specific file using AI.\n  [yellow]refactor \"instr\"[/]      - Refactor project in memory based on instruction.\n  [yellow]commit[/]               - Commit changes with an AI-generated message.\n  [yellow]rag <query>[/]         - Query the RAG system for context retrieval.\n\n  [bold cyan]File & Code Management[/]\n  [yellow]save <filename>[/]     - Save last AI response to a file.\n  [yellow]list[/]               - List saved files.\n  [yellow]run[/]                 - Run the last generated Python code.\n\n  [bold cyan]Session & Config[/]\n  [yellow]history[/]             - Show the full chat history.\n  [yellow]memory clear[/]        - Clear the chat and file memory.\n  [yellow]backend <name>[/]      - Switch AI backend (e.g., openrouter, ollama).\n  [yellow]models [src][/]        - Interactively list and select models.\n  [yellow]set model <id>[/]      - Set the model directly by its ID.\n  [yellow]personality <cmd>[/]   - Manage AI personalities ('list', 'set', 'add').\n\"\"\"\n                    )\n            elif command == 'send':\n                last_query = arg_str\n                response = query_llm(arg_str)\n                last_response = response\n                memory_manager.add_chat_message('user', last_query)\n                memory_manager.add_chat_message('assistant', last_response)\n                if gui_enabled:\n                    threading.Thread(target=show_sequential_popup, args=(\n                        100, 100, response, f'Omni - {personality_name}'),\n                        daemon=True).start()\n                print(Panel(response, title='[cyan]Response[/]'))\n                if (code_blocks := extract_code(response)):\n                    last_code = code_blocks[0][1]\n            elif command == 'look':\n                look_command(arg_str)\n            elif command == 'look_all':\n                look_all_command()\n            elif command == 'create':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_create_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: create <file_path> \"<instruction>\"')\n            elif command == 'edit':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_edit_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: edit <file_path> \"<instruction>\"')\n            elif command == 'refactor':\n                if not arg_str:\n                    ui_manager.show_error('Usage: refactor \"<instruction>\"')\n                else:\n                    handle_project_refactor_command(arg_str.strip('\"'))\n            elif command == 'commit':\n                handle_commit_command()\n            elif command == 'models':\n                list_models(arg_str.split())\n            elif command == 'set' and arg_str.startswith('model '):\n                set_model(arg_str[6:])\n            elif command == 'backend':\n                switch_backend(arg_str)\n            elif command == 'history':\n                ui_manager.display_history(memory_manager.get_memory_context())\n            elif command == 'memory' and arg_str == 'clear':\n                memory_manager.clear_memory()\n                ui_manager.show_success('\u2705 Memory cleared')\n            elif command == 'personality':\n                p_args = arg_str.split(maxsplit=1)\n                cmd = p_args[0] if p_args else ''\n                p_arg_str = p_args[1] if len(p_args) > 1 else ''\n                if cmd == 'list':\n                    for p in personality_manager.list_personalities():\n                        print(f\"- {p['name']}: {p['description']}\")\n                elif cmd == 'set' and p_arg_str:\n                    if personality_manager.set_current_personality(p_arg_str):\n                        personality_name = p_arg_str\n                        ui_manager.show_success(\n                            f'Set personality to {personality_name}')\n                    else:\n                        ui_manager.show_error('Personality not found.')\n                else:\n                    ui_manager.show_error(\n                        \"Invalid personality command. Use 'list' or 'set <name>'.\"\n                        )\n            elif command == 'run':\n                run_python_code()\n            elif command == 'save':\n                if last_response:\n                    save_code(last_response, arg_str or\n                        f\"omni_save_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n                        )\n                else:\n                    ui_manager.show_error('No response to save.')\n            elif command == 'list':\n                files = sorted(os.listdir(DEFAULT_SAVE_DIR))\n                print('\\n'.join(f'  - {f}' for f in files) if files else\n                    '[yellow]No saved files.[/]')\n            elif command == 'rag':\n                if not arg_str:\n                    ui_manager.show_error('Usage: rag \"<query>\"')\n                else:\n                    from rag_manager import RAGManager\n                    project_root = memory_manager.get_project_root()\n                    if not project_root:\n                        ui_manager.show_error(\n                            \"No project context in memory. Use 'look <directory>' first.\"\n                            )\n                        continue\n                    rag = RAGManager()\n                    if rag.get_document_count() == 0:\n                        ui_manager.show_error(\n                            'RAG index is empty. Please add documents first.')\n                        continue\n                    results = rag.search(arg_str, k=3)\n                    if not results:\n                        ui_manager.show_error('No relevant documents found.')\n                        continue\n                    print(Panel('[bold]RAG Results:[/]', title=\n                        '[cyan]Retrieval-Augmented Generation[/]'))\n                    for i, (content, score, metadata) in enumerate(results, 1):\n                        file_path = metadata.get('file', 'Unknown')\n                        print(\n                            f'[bold cyan]{i}. {file_path}[/] (Score: {score:.4f})'\n                            )\n                        print(Panel(content[:500] + '...' if len(content) >\n                            500 else content, border_style='dim'))\n                    follow_up = ui_manager.get_user_input(\n                        \"\"\"\nWould you like to ask a follow-up question with this context? (y/n): \"\"\"\n                        )\n                    if follow_up.lower() in ['y', 'yes']:\n                        follow_up_query = ui_manager.get_user_input(\n                            'Follow-up query: ')\n                        if follow_up_query:\n                            context_parts = [\n                                f'Document {i} (Score: {score:.4f}):\\n{content}'\n                                 for i, (content, score, _) in enumerate(\n                                results, 1)]\n                            context = '\\n\\n'.join(context_parts)\n                            rag_prompt = f\"\"\"Based on the following context, please answer the question.\n\nContext:\n{context}\n\nQuestion: {follow_up_query}\"\"\"\n                            response = query_llm(rag_prompt)\n                            print(Panel(response, title=\n                                '[cyan]RAG-Augmented Response[/]'))\n            else:\n                ui_manager.show_error(\"Unknown command. Type 'help'.\")\n            refresh_status_panel(personality_name)\n        except KeyboardInterrupt:\n            memory_manager.save_memory()\n            print('\\n[bold cyan]Goodbye![/]')\n            break\n        except Exception as e:\n            ui_manager.show_error(f'An unexpected error occurred: {e}')\n\n\ndef run_python_code() ->None:\n    global last_code\n    if not last_code:\n        ui_manager.show_error('No Python code in memory to run.')\n        return\n    temp_file = os.path.join(DEFAULT_SAVE_DIR, 'temp_run.py')\n    try:\n        with open(temp_file, 'w') as f:\n            f.write(last_code)\n        print('[bold cyan]\\n--- Running Code ---\\n[/]')\n        subprocess.run([sys.executable, temp_file], check=True)\n        print('[bold cyan]\\n--- Code Finished ---\\n[/]')\n    except Exception as e:\n        ui_manager.show_error(f'Error running code: {e}')\n    finally:\n        if os.path.exists(temp_file):\n            os.remove(temp_file)\n\n\ndef save_code(content: str, filename: str) ->None:\n    filepath = os.path.join(DEFAULT_SAVE_DIR, filename)\n    try:\n        with open(filepath, 'w') as f:\n            f.write(content)\n        ui_manager.show_success(f'Saved to: {filepath}')\n    except IOError as e:\n        ui_manager.show_error(f'Error saving file: {e}')\n\n\ndef main() ->None:\n    try:\n        import astor\n    except ImportError:\n        print(\"[bold red]Error:[/] 'astor' is required. `pip install astor`\")\n        sys.exit(1)\n    try:\n        import simple_term_menu\n    except ImportError:\n        print(\n            \"[bold red]Error:[/] 'simple-term-menu' is required. `pip install simple-term-menu`\"\n            )\n        sys.exit(1)\n    parser = argparse.ArgumentParser(description=\n        'Omni - AI-powered code tool', add_help=False)\n    parser.add_argument('command', nargs='?', help='Main command.')\n    parser.add_argument('args', nargs='*', help='Arguments for the command.')\n    parser.add_argument('-h', '--help', action='store_true')\n    args, _ = parser.parse_known_args()\n    if args.help or not args.command:\n        interactive_mode()\n    elif args.command == 'look' and args.args:\n        look_command(args.args[0])\n    elif args.command == 'edit' and len(args.args) >= 2:\n        handle_file_edit_command(args.args[0], ' '.join(args.args[1:]))\n    elif args.command == 'models':\n        list_models(args.args)\n    else:\n        interactive_mode()\n\n\ndef refresh_status_panel(personality_name: str) ->None:\n    ui_manager.display_status_panel(personality_name, current_backend,\n        current_model, len(memory_manager.memory.get('chat', [])), len(\n        memory_manager.memory.get('look', [])))\n\n\nif __name__ == '__main__':\n    main()             ",
    "file": "/mnt/ProjectData/omni/omni.py"
  },
  {
    "id": 103,
    "hash": "db1585da7840e9dc17f3ab8c0a19f6f2",
    "content": "import json\nfrom typing import Dict, List, Optional\n\nclass PersonalityManager:\n    \"\"\"Manages AI personalities via JSON config.\"\"\"\n\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.personalities: List[Dict[str, str]] = self.load_personalities()\n        self.current_personality: Optional[str] = \"default\"  # Default\n\n    def load_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"Load personalities from JSON; auto-create if missing.\"\"\"\n        default = [{\"name\": \"default\", \"description\": \"Helpful assistant\", \"system_prompt\": \"You are a helpful AI assistant.\"}]\n        default_gui = {\n            \"gui_enabled\": True,\n            \"wake_word\": \"Jarvis\",\n            \"overlay_opacity\": 0.8,\n            \"font_size\": 16\n        }\n        try:\n            with open(self.config_file, 'r') as f:\n                data = json.load(f)\n                if \"personalities\" not in data:\n                    data[\"personalities\"] = default\n                if \"gui_enabled\" not in data:\n                    data.update(default_gui)\n                    self.save_personalities(data[\"personalities\"])  # Save with defaults\n                \n                return data[\"personalities\"]\n        except FileNotFoundError:\n            self.save_personalities(default)\n            return default\n        except json.JSONDecodeError:\n            print(\"[yellow]Invalid config. Resetting to default.[/]\")\n            self.save_personalities(default)\n            return default\n\n    def save_personalities(self, personalities: List[Dict[str, str]]) -> None:\n        \"\"\"Save with GUI config.\"\"\"\n        data = {\"personalities\": personalities}\n        data.update({\"gui_enabled\": True, \"wake_word\": \"Jarvis\", \"overlay_opacity\": 0.8, \"font_size\": 16})  # Defaults\n        with open(self.config_file, 'w') as f:\n            json.dump(data, f, indent=4)\n\n    def add_personality(self, name: str, description: str, system_prompt: str) -> None:\n        \"\"\"Add a new personality.\"\"\"\n        self.personalities.append({\"name\": name, \"description\": description, \"system_prompt\": system_prompt})\n        self.save_personalities(self.personalities)\n\n    def list_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"List all personalities.\"\"\"\n        return self.personalities\n\n    def set_current_personality(self, name: str) -> bool:\n        \"\"\"Set the current personality.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == name:\n                self.current_personality = name\n                return True\n        return False\n\n    def get_current_personality(self) -> Dict[str, str]:\n        \"\"\"Get the current personality dict.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == self.current_personality:\n                return p\n        return {}  # Fallback",
    "file": "/mnt/ProjectData/omni/personality_manager.py"
  },
  {
    "id": 104,
    "hash": "da963f141c557fe12f1a26374f3e5ff4",
    "content": "# python_ast_adapter.py\n\n\"\"\"\nPythonASTAdapter - Concrete AST adapter for Python using built-in `ast` and `astor`.\n\nThis module implements the ASTAdapter interface specifically for Python,\nleveraging the standard library's `ast` module for parsing and\nmanipulation, and `astor` for code generation.\n\"\"\"\n\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for asttokens (for enhanced partial edits)\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n    # print(\"Warning: asttokens not installed. Partial edits will be limited.\")\n\n\nclass PythonASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for Python source code.\n\n    This adapter uses Python's built-in `ast` module to parse and manipulate\n    the code, and `astor` for code generation and source-to-source transformations.\n    It holds the parsed AST tree and provides methods to interact with it\n    according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the PythonASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The Python source code as a string.\n        \"\"\"\n        # Store source code for diffing and potential asttokens use\n        self.source_code: str = source_code\n        # Will hold the parsed AST tree\n        self.tree: Optional[ast.AST] = None\n        # Will hold a mapping of element names to their AST nodes\n        self.nodes: Dict[str, ast.AST] = {}\n        # asttokens instance for enhanced source mapping (if available)\n        self.atok: Optional[asttokens.ASTTokens] = None\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the Python source code and maps elements.\n\n        Args:\n            source_code: The Python source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid Python syntax.\n        \"\"\"\n        try:\n            self.tree = ast.parse(source_code)\n        except SyntaxError as e:\n            raise ValueError(f\"Invalid Python syntax: {e}\") from e\n\n        self.nodes = self._map_nodes()\n        if ASTTOKENS_AVAILABLE:\n            try:\n                self.atok = asttokens.ASTTokens(source_code, parse=True)\n            except Exception:\n                # If asttokens fails for any reason, continue without it\n                self.atok = None\n        else:\n            self.atok = None\n\n    def _map_nodes(self) -> Dict[str, ast.AST]:\n        \"\"\"\n        Walks the AST and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their AST nodes.\n        \"\"\"\n        nodes: Dict[str, ast.AST] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        for node in ast.walk(self.tree):\n            # Map functions and classes by name\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                # Use 'not in' to prioritize top-level definitions in case of conflicts\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            # Map assignments by target variable name(s)\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            # Map imports by their alias or original name\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int, line_end: Optional[int] = None) -> Optional[Tuple[int, ast.AST]]:\n        \"\"\"\n        Finds a statement within a body based on line numbers.\n\n        Args:\n            body: The list of AST nodes representing the body.\n            line_start: The starting line number to search for.\n            line_end: The optional ending line number.\n\n        Returns:\n            A tuple of (index, statement node) if found, otherwise None.\n        \"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = getattr(stmt, 'end_lineno', stmt.lineno)\n                    # Check for overlap or containment\n                    if (stmt.lineno <= line_start <= stmt_end) or (stmt.lineno <= line_end <= stmt_end) or \\\n                       (line_start <= stmt.lineno and line_end >= stmt_end):\n                        return (i, stmt)\n                else:\n                    if stmt.lineno == line_start:\n                        return (i, stmt)\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.ImportFrom]]) -> None:\n        \"\"\"\n        Adds new import nodes to the file's AST, typically at the top.\n\n        Args:\n            new_import_nodes: A list of ast.Import or ast.ImportFrom nodes.\n        \"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return # Cannot add imports without a valid module tree\n\n        # Get string representations of existing imports to avoid duplicates\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                try:\n                    existing_imports_str.add(astor.to_source(node).strip())\n                except Exception:\n                    # If astor fails, skip adding to set (might lead to potential duplicate, but safer)\n                    pass\n                last_import_index = i\n\n        # Insert new imports after the last existing import\n        # Reverse them so they are inserted in the correct order\n        for new_import in reversed(new_import_nodes):\n            try:\n                new_import_str = astor.to_source(new_import).strip()\n                if new_import_str not in existing_imports_str:\n                    self.tree.body.insert(last_import_index + 1, new_import)\n                    last_import_index += 1 # Update index for next insertion\n            except Exception:\n                # If we can't generate source, we can't check for duplicates, skip\n                self.tree.body.insert(last_import_index + 1, new_import)\n                last_import_index += 1\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return astor.to_source(node)\n            except Exception:\n                # Handle potential astor issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.__class__.__name__,\n            'line_start': getattr(node, 'lineno', None),\n            'line_end': getattr(node, 'end_lineno', None),\n            'body_items': []\n        }\n\n        if hasattr(node, 'body'):\n            for i, item in enumerate(node.body):\n                item_info = {\n                    'index': i,\n                    'type': item.__class__.__name__,\n                    'line_start': getattr(item, 'lineno', None),\n                    'line_end': getattr(item, 'end_lineno', None)\n                }\n\n                if isinstance(item, ast.Assign) and item.targets:\n                    target = item.targets[0]\n                    if isinstance(target, ast.Name):\n                        item_info['assigns'] = target.id\n                elif isinstance(item, (ast.If, ast.While, ast.For)):\n                    item_info['has_body'] = bool(getattr(item, 'body', None))\n                elif isinstance(item, ast.Return):\n                    item_info['returns'] = True\n\n                structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        if not self.atok:\n            return None # asttokens is required for precise original source retrieval\n\n        node = self.nodes.get(element_name)\n        if not node or not hasattr(node, 'body'):\n            return None\n\n        statements = []\n        for stmt in node.body:\n            if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                 # Check for overlap or containment of the statement within the requested range\n                stmt_start = stmt.lineno\n                stmt_end = stmt.end_lineno\n                if (stmt_start >= line_start and stmt_end <= line_end) or \\\n                   (stmt_start <= line_end and stmt_end >= line_start): # Overlap\n                    statements.append(stmt)\n\n        if not statements:\n            return None\n\n        # Use asttokens to get the original source text for accuracy\n        try:\n            # Combine text ranges of the found statements\n            combined_text = \"\"\n            last_end_pos = None\n            for stmt in sorted(statements, key=lambda s: s.lineno):\n                # Get the text range for the statement\n                stmt_text = self.atok.get_text_range(stmt)\n                if last_end_pos is not None and stmt_text[0] > last_end_pos:\n                     # Add the original whitespace/newlines between statements\n                    combined_text += self.source_code[last_end_pos:stmt_text[0]]\n                combined_text += self.atok.get_text(stmt)\n                last_end_pos = stmt_text[1]\n            return combined_text.strip()\n        except Exception:\n            # Fallback if asttokens text retrieval fails\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in statements)\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except SyntaxError:\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body: # Ensure there's actual code body to replace with\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # Walk the tree to find the parent node containing the element to replace\n        for parent_node in ast.walk(self.tree):\n            if hasattr(parent_node, 'body') and isinstance(parent_node.body, list):\n                try:\n                    old_node = self.nodes[element_name]\n                    idx = parent_node.body.index(old_node)\n                    # Remove the old node\n                    parent_node.body.pop(idx)\n                    # Insert the new nodes\n                    for i, new_node in enumerate(new_code_body):\n                        parent_node.body.insert(idx + i, new_node)\n\n                    # Update the nodes map: remove old, add new top-level definitions\n                    del self.nodes[element_name]\n                    for n in new_code_body:\n                        if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                            self.nodes[n.name] = n\n                    return True\n                except (ValueError, KeyError):\n                    # ValueError from index(), KeyError from accessing self.nodes\n                    continue\n        return False # Element not found in any body\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n             return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except (SyntaxError, IndexError):\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body:\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # --- Determine insertion index ---\n\n        # Find the `if __name__ == \"__main__\":` block index\n        main_block_idx = -1\n        for i, node in enumerate(self.tree.body):\n            if (isinstance(node, ast.If) and\n                isinstance(getattr(node, 'test', None), ast.Compare) and\n                isinstance(getattr(node.test, 'left', None), ast.Name) and\n                node.test.left.id == '__name__' and\n                len(getattr(node.test, 'ops', [])) == 1 and isinstance(node.test.ops[0], ast.Eq) and\n                len(getattr(node.test, 'comparators', [])) == 1):\n\n                comp = node.test.comparators[0]\n                # Check for both ast.Constant ('__main__') and older ast.Str ('__main__')\n                if ((isinstance(comp, ast.Constant) and comp.value == '__main__') or\n                    (isinstance(comp, ast.Str) and comp.s == '__main__')): # type: ignore\n                    main_block_idx = i\n                    break\n\n        insertion_index = -1\n        if anchor_name:\n            # If anchor is specified, find its index\n            if anchor_name not in self.nodes:\n                return False\n            anchor_node = self.nodes[anchor_name]\n            try:\n                anchor_idx = self.tree.body.index(anchor_node)\n                proposed_index = anchor_idx if before else anchor_idx + 1\n                # Prefer to stay before the main block if possible\n                if main_block_idx != -1:\n                    insertion_index = min(proposed_index, main_block_idx)\n                else:\n                    insertion_index = proposed_index\n            except ValueError:\n                return False # Anchor node not found in tree body\n        elif main_block_idx != -1:\n            # If no anchor, but there's a main block, insert before it\n            insertion_index = main_block_idx\n        # If no anchor and no main block, insertion_index remains -1\n\n        # --- Perform the insertion ---\n        if insertion_index == -1:\n            # Append to the end\n            self.tree.body.extend(new_code_body)\n        else:\n            # Insert at the calculated position\n            for i, new_node in enumerate(new_code_body):\n                self.tree.body.insert(insertion_index + i, new_node)\n\n        # Update the nodes map with any new top-level definitions\n        for node in new_code_body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                self.nodes[node.name] = node # This might overwrite if names clash\n\n        return True\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return False\n\n        deleted = False\n        if element_name in self.nodes:\n            node_to_delete = self.nodes[element_name]\n            # Walk the tree to find the parent node containing the element\n            for node in ast.walk(self.tree):\n                if hasattr(node, 'body') and isinstance(node.body, list):\n                    try:\n                        node.body.remove(node_to_delete)\n                        deleted = True\n                        break # Assume element appears only once at top level\n                    except ValueError:\n                        continue # This parent doesn't contain the node\n            if deleted:\n                del self.nodes[element_name]\n                # Although nodes map is passed by ref in base __init__, we should call _map_nodes\n                # to ensure consistency after a direct tree modification.\n                self.nodes = self._map_nodes()\n                return True\n\n        # If not found by node reference, try to find by name pattern matching (vars/imports)\n        new_body = []\n        for node in self.tree.body:\n            if isinstance(node, ast.Assign):\n                match = False\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id == element_name:\n                        match = True\n                        deleted = True\n                        break\n                if not match: # Keep the node if it doesn't match\n                    new_body.append(node)\n            elif isinstance(node, ast.Import):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                    # Keep the node if none of its aliases match (should theoretically be the same as above)\n                     new_body.append(node)\n                else:\n                    deleted = True # The import node is being completely removed\n            elif isinstance(node, ast.ImportFrom):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                     new_body.append(node)\n                else:\n                    deleted = True\n            else:\n                new_body.append(node)\n\n        if deleted:\n            self.tree.body = new_body\n            # Remap nodes after structural changes\n            self.nodes = self._map_nodes()\n\n        return deleted\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        if element_name not in self.nodes:\n            return False\n\n        node = self.nodes[element_name]\n        # Ensure the node has a body to modify\n        if not hasattr(node, 'body') or not isinstance(node.body, list):\n            return False\n\n        # Parse the new code to get AST nodes for the replacement\n        try:\n             # Heuristic: If new code looks like a def/class, extract its body.\n             # Otherwise, treat as standalone statements.\n            if new_code.strip().startswith(('def ', 'class ', 'async def ')):\n                # Parse as if it's a module with a single function/class\n                temp_module = ast.parse(new_code)\n                if temp_module.body and hasattr(temp_module.body[0], 'body'):\n                    new_statements = temp_module.body[0].body # Get the inner body\n                else:\n                    return False # Malformed attempt to define a func/class\n            else:\n                # Parse as a module and take its body\n                new_ast_module = ast.parse(new_code)\n                new_statements = new_ast_module.body\n        except SyntaxError:\n            return False # Invalid new code\n\n        if not new_statements: # Nothing to insert\n            return False\n\n        # --- Determine what to replace based on parameters ---\n        if statement_index is not None:\n            # Replace by statement index\n            if 0 <= statement_index < len(node.body):\n                # Replace the single statement at index with the list of new statements\n                node.body[statement_index:statement_index+1] = new_statements\n                return True\n        elif line_start is not None:\n            # Replace by line number(s)\n            result = self._find_statement_in_body(node.body, line_start, line_end)\n            if result:\n                idx, _ = result\n                if line_end:\n                    # Find the last statement within the specified range to replace multiple\n                    end_idx = idx\n                    # Iterate from the found index forward\n                    for i in range(idx, len(node.body)):\n                        stmt = node.body[i]\n                        stmt_s_ln = getattr(stmt, 'lineno', None)\n                        stmt_e_ln = getattr(stmt, 'end_lineno', stmt_s_ln)\n                        if stmt_s_ln is not None and stmt_e_ln is not None:\n                            # Check if the statement ends within the range or starts within the range\n                            # This handles overlapping ranges correctly\n                             if stmt_e_ln <= line_end or stmt_s_ln <= line_end:\n                                 end_idx = i\n                             else:\n                                 break # Statement is past the end range\n                        else:\n                            break # Can't determine statement range\n                    node.body[idx:end_idx+1] = new_statements\n                else:\n                    # line_end not specified, only replace the statement at line_start\n                    node.body[idx:idx+1] = new_statements\n                return True\n\n        # If none of the conditions were met to perform a replacement\n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        if self.tree:\n            try:\n                return astor.to_source(self.tree)\n            except Exception as e:\n                 # Fallback error handling, should ideally not happen if tree is valid\n                 return f\"# Error generating source: {e}\\n{self.source_code}\"\n        else:\n            # If somehow the tree is None, return the original source\n            return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        # Ensure line endings are consistent for diffing, keepends=True preserves them\n        # If source_code had different line endings, this might still cause issues,\n        # but this is a standard approach.\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/python_ast_adapter.py"
  },
  {
    "id": 105,
    "hash": "2914352eefed9d60de098e021dd79b67",
    "content": "import os\nimport sys\nimport argparse\nfrom typing import List\nfrom rag_manager import RAGManager\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\ndef create_sample_data() ->List[str]:\n    \"\"\"Create sample documents for the RAG example.\"\"\"\n    return [\n        'RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with language generation.'\n        ,\n        'The RAG model retrieves relevant documents from a knowledge base and uses them to generate more accurate responses.'\n        ,\n        'FAISS is a library for efficient similarity search and clustering of dense vectors, often used in RAG systems.'\n        ,\n        'Sentence transformers are used to create embeddings for documents and queries in RAG systems.'\n        ,\n        'Retrieval-Augmented Generation improves language models by allowing them to access external knowledge sources.'\n        ,\n        'In RAG systems, documents are indexed and searchable by their semantic embeddings rather than just keywords.'\n        ,\n        'Python is a great language for implementing RAG systems due to libraries like sentence-transformers and faiss.'\n        ,\n        'The retrieval component of RAG is crucial for finding relevant information before generation.'\n        ]\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_cli_example.py"
  },
  {
    "id": 106,
    "hash": "c27b11d2eaa8e13cdf8e698417efb75e",
    "content": "import os\nimport sys\nfrom typing import List, Dict, Tuple\n\"\"\"\nExample script demonstrating RAG (Retrieval-Augmented Generation) usage.\n\nThis script shows how to use a simple RAG implementation to answer questions\nbased on a given context or knowledge base.\n\"\"\"\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\nclass SimpleRAG:\n    \"\"\"A simple RAG implementation for demonstration purposes.\"\"\"\n\n    def __init__(self, knowledge_base: List[str]):\n        \"\"\"\n        Initialize the RAG with a knowledge base.\n        \n        Args:\n            knowledge_base: A list of strings representing the knowledge base.\n        \"\"\"\n        self.knowledge_base = knowledge_base\n\n    def retrieve(self, query: str, top_k: int=3) ->List[str]:\n        \"\"\"\n        Retrieve relevant documents from the knowledge base.\n        \n        This is a simplified implementation using keyword matching.\n        In a real implementation, you would use embeddings and vector search.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            A list of relevant documents.\n        \"\"\"\n        query_words = set(query.lower().split())\n        scores = []\n        for doc in self.knowledge_base:\n            doc_words = set(doc.lower().split())\n            score = len(query_words.intersection(doc_words))\n            scores.append((score, doc))\n        scores.sort(reverse=True)\n        return [doc for score, doc in scores[:top_k]]\n\n    def generate(self, query: str, retrieved_docs: List[str]) ->str:\n        \"\"\"\n        Generate an answer based on the query and retrieved documents.\n        \n        In a real implementation, this would use an LLM to generate the response.\n        For this example, we'll create a simple template-based response.\n        \n        Args:\n            query: The query string.\n            retrieved_docs: The retrieved documents.\n            \n        Returns:\n            A generated answer.\n        \"\"\"\n        context = '\\n'.join(retrieved_docs)\n        prompt = f\"\"\"\n        Context information:\n        {context}\n        \n        Question: {query}\n        \n        Based on the context provided above, please answer the question.\n        If the context doesn't contain relevant information, say so.\n        \"\"\"\n        return self._simple_response_generator(query, retrieved_docs)\n\n    def _simple_response_generator(self, query: str, retrieved_docs: List[str]\n        ) ->str:\n        \"\"\"\n        A simple response generator for demonstration.\n        \"\"\"\n        for doc in retrieved_docs:\n            if 'example' in doc.lower():\n                return (\n                    f'Based on the context provided, I found information about examples. {query} relates to the examples in the knowledge base.'\n                    )\n        return (\n            f\"I couldn't find specific information about '{query}' in the provided context. Please provide more details or check the knowledge base.\"\n            )\n\n    def query(self, query: str, top_k: int=3) ->str:\n        \"\"\"\n        Process a query through the full RAG pipeline.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            The generated answer.\n        \"\"\"\n        retrieved_docs = self.retrieve(query, top_k)\n        answer = self.generate(query, retrieved_docs)\n        return answer\n\n\ndef main():\n    \"\"\"Main function demonstrating the RAG implementation.\"\"\"\n    knowledge_base = ['This is an example document about machine learning.',\n        'Natural language processing is a subfield of artificial intelligence.'\n        , 'Python is a popular programming language for data science.',\n        'The quick brown fox jumps over the lazy dog.',\n        'RAG stands for Retrieval-Augmented Generation.',\n        'Vector databases are used for similarity search in RAG systems.',\n        'Transformers are a type of neural network architecture.',\n        'This example shows how to implement a simple RAG system.']\n    rag = SimpleRAG(knowledge_base)\n    queries = ['What is RAG?', 'How is Python used in data science?',\n        'Tell me about machine learning']\n    print('Simple RAG Example')\n    print('=' * 50)\n    for query in queries:\n        print(f'\\nQuery: {query}')\n        answer = rag.query(query)\n        print(f'Answer: {answer}')\n        print('-' * 30)\n    print(\"\\nInteractive Mode (type 'quit' to exit):\")\n    while True:\n        try:\n            user_query = input('\\nEnter your question: ').strip()\n            if user_query.lower() in ['quit', 'exit', 'q']:\n                break\n            if user_query:\n                answer = rag.query(user_query)\n                print(f'Answer: {answer}')\n        except KeyboardInterrupt:\n            print('\\nGoodbye!')\n            break\n        except EOFError:\n            break\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_example.py"
  },
  {
    "id": 107,
    "hash": "f151986bf2efa7602242590a357fab83",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n    Initialize the RAG manager.\n\n    Args:\n        model_name: Name of the sentence transformer model to use\n        index_path: Path to save/load the FAISS index\n    \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the RAG manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n",
    "file": "/mnt/ProjectData/omni/rag_manager.py"
  },
  {
    "id": 108,
    "hash": "f59a27842056dbb0dc95d0f29c1c5de8",
    "content": "Hello! I'm OmniForge, an AI coding assistant. I can help you scan, understand, and refactor your codebase using local (Ollama) or remote (OpenRouter) LLMs.\n\nI see you've opened the OmniForge project directory. Some key things I can help with:\n\n1. **Project Analysis**: I can look at your files to understand the structure\n2. **Code Editing**: I can make precise edits to functions/classes using AST-based transformations\n3. **Refactoring**: I can perform multi-file architectural changes with a plan\n4. **File Creation**: I can generate new files based on instructions\n\nFor example:\n- `look .` to scan the project\n- `edit code_editor.py \"add docstrings to main methods\"`\n- `refactor \"extract git operations into a separate module\"`\n- `create new_module.py \"implement a simple HTTP client\"`\n\nWhat would you like to do with this project?",
    "file": "/mnt/ProjectData/omni/requirements.txt"
  },
  {
    "id": 109,
    "hash": "4b879b8e64b677ec78d27f19b384623a",
    "content": "from typing import List\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.text import Text\nfrom rich.status import Status\nfrom rich import box\nfrom contextlib import contextmanager\nfrom rich.markup import escape\nimport gc\n\ntry:\n    from prompt_toolkit import prompt\n    from prompt_toolkit.completion import WordCompleter\n    from prompt_toolkit.history import InMemoryHistory\n    from prompt_toolkit.styles import Style\nexcept ImportError:\n    print('[yellow]prompt_toolkit not installed. Falling back to basic input.[/]')\n    prompt = input\n\n\nclass UIManager:\n    \"\"\"Manages interactive text-based UI with rich for display and prompt_toolkit for input.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initializes the UI manager with a rich console and prompt_toolkit components.\"\"\"\n        self.console = Console()\n        self.history = InMemoryHistory()\n        self.completer = WordCompleter([\n            'send', 'look', 'look_all', 'create', 'edit', 'refactor', 'commit',\n            'save', 'list', 'run', 'history', 'memory', 'backend', 'models',\n            'set', 'personality', 'help', 'exit'\n        ], ignore_case=True)\n        self.prompt_style = Style.from_dict({'prompt': 'bold cyan'})\n\n    def get_user_input(self, prompt_text: str) -> str:\n        try:\n            return prompt(prompt_text, history=self.history, completer=self.completer, style=self.prompt_style)\n        except Exception:\n            self.console.print('[yellow]Warning: Falling back to basic input.[/]')\n            return input(prompt_text)\n\n    def display_history(self, history_text: str) -> None:\n        if not history_text.strip():\n            self.console.print('[dim]No history yet.[/]')\n            return\n        \n        lines = history_text.split('\\n')\n        colored_text = Text()\n        for line in lines:\n            if line.startswith('User:'):\n                colored_text.append(line + '\\n', style='bold blue')\n            elif line.startswith('AI:'):\n                colored_text.append(line + '\\n', style='bold green')\n            elif line.startswith('File '):\n                colored_text.append(line + '\\n', style='yellow')\n            else:\n                colored_text.append(line + '\\n')\n        \n        self.console.print(Panel(\n            colored_text, \n            title='[bold magenta]Chat History[/]', \n            border_style='magenta', \n            expand=False, \n            box=box.ROUNDED\n        ))\n\n    @contextmanager\n    def show_spinner(self, message: str):\n        \"\"\"\n        Context manager that displays a spinner with the given message.\n        Handles Rich LiveError by cleaning up stuck live displays and \n        ensuring proper cleanup on exceptions.\n        \n        Usage:\n            with ui_manager.show_spinner(\"Loading...\"):\n                # do work here\n        \"\"\"\n        # Initialize spinner state if not exists\n        if not hasattr(self, '_spinner_active'):\n            self._spinner_active = False\n        \n        # If spinner is already active, just yield without additional output\n        if self._spinner_active:\n            try:\n                yield\n            except Exception as e:\n                raise e\n            return\n        \n        # Clean up any stuck Rich live displays before starting\n        self._cleanup_stuck_rich_displays()\n        \n        # Mark spinner as active\n        self._spinner_active = True\n        status_context = None\n        \n        try:\n            # Try to use rich status, but with fallback\n            try:\n                status_context = self.console.status(f'[bold yellow]{message}[/]')\n                status_context.__enter__()\n            except Exception:\n                # If rich.status fails, fallback to static print\n                status_context = None\n                self.console.print(f'[bold yellow]{message}[/]')\n            \n            yield\n            \n        except Exception as e:\n            # Re-raise actual work errors\n            raise e\n            \n        finally:\n            # Always cleanup spinner state and rich display\n            self._spinner_active = False\n            if status_context is not None:\n                try:\n                    status_context.__exit__(None, None, None)\n                except:\n                    pass  # Suppress cleanup errors\n            \n            # Force cleanup any remaining rich displays\n            self._cleanup_stuck_rich_displays()\n\n    def _cleanup_stuck_rich_displays(self):\n        \"\"\"\n        Clean up stuck Rich live displays that prevent new ones from starting.\n        Based on solution from: https://github.com/DLR-RM/stable-baselines3/issues/1645\n        \"\"\"\n        try:\n            # Method 1: Reset console live display if exists\n            if hasattr(self.console, '_live') and self.console._live is not None:\n                try:\n                    self.console._live.stop()\n                    self.console._live = None\n                except:\n                    pass\n            \n            # Method 2: Find and close stuck rich/tqdm objects using garbage collection\n            rich_objects = [obj for obj in gc.get_objects() \n                        if hasattr(obj, '__class__') and \n                        ('live' in type(obj).__name__.lower() or \n                            'progress' in type(obj).__name__.lower() or\n                            'status' in type(obj).__name__.lower()) and\n                        hasattr(obj, 'stop')]\n            \n            for rich_obj in rich_objects:\n                try:\n                    if hasattr(rich_obj, 'stop'):\n                        rich_obj.stop()\n                    elif hasattr(rich_obj, 'close'):\n                        rich_obj.close()\n                except:\n                    pass  # Suppress cleanup errors\n                    \n        except:\n            pass  # Suppress all cleanup errors to avoid breaking the main flow\n\n    def display_status_panel(self, personality: str, backend: str, model: str, msg_count: int, look_count: int) -> None:\n        status_text = (\n            f'[bold]Personality:[/] [green]{personality}[/] | '\n            f'[bold]Backend:[/] [green]{backend}[/] | '\n            f'[bold]Model:[/] [green]{model}[/] | '\n            f'[bold]Memory:[/] {msg_count} messages, {look_count} files'\n        )\n        self.console.print(Panel(\n            status_text, \n            title='[bold cyan]Status[/]', \n            border_style='cyan', \n            expand=False, \n            box=box.MINIMAL\n        ))\n\n    def show_success(self, message: str) -> None:\n        self.console.print(f'[green]\u2705 {message}[/]')\n\n    def show_error(self, message: str) -> None:\n        \"\"\"\n        Displays an error message, escaping any markup in the message.\n        \"\"\"\n        safe_message = escape(str(message))\n        self.console.print(f'[red]\u274c {safe_message}[/]')",
    "file": "/mnt/ProjectData/omni/ui_manager.py"
  },
  {
    "id": 110,
    "hash": "dbd143839288b400cafdedb655258434",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n",
    "file": "/mnt/ProjectData/omni/vectordb_manager.py"
  },
  {
    "id": 111,
    "hash": "47a91d3ac272236378053b23515fc9b0",
    "content": "import tkinter as tk\nfrom tkinter import ttk\nfrom time import strftime\n\n\ndef update_time():\n    current_time = strftime('%H:%M:%S %p\\n%Y-%m-%d')\n    time_label.config(text=current_time)\n    time_label.after(1000, update_time)\n\n\ndef center_window(root):\n    root.update_idletasks()\n    screen_width = root.winfo_screenwidth()\n    screen_height = root.winfo_screenheight()\n    window_width = root.winfo_width() + 4\n    window_height = root.winfo_height() + 4\n    x = (screen_width - window_width) // 2\n    y = (screen_height - window_height) // 2\n    root.geometry(f'{window_width}x{window_height}+{x}+{y}')\n\n\ndef create_3d_border(parent):\n    border_frame = tk.Frame(parent, bg='#c0c0c0')\n    border_frame.pack(padx=2, pady=2, expand=True, fill=tk.BOTH)\n    tk.Frame(border_frame, height=1, bg='#808080').pack(side=tk.TOP, fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#808080').pack(side=tk.LEFT, fill=tk.Y)\n    tk.Frame(border_frame, height=1, bg='#ffffff').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#ffffff').pack(side=tk.RIGHT, fill=tk.Y\n        )\n    inner_container = tk.Frame(border_frame, bg='#c0c0c0')\n    inner_container.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1\n        )\n    tk.Frame(inner_container, height=1, bg='#ffffff').pack(side=tk.TOP,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#ffffff').pack(side=tk.LEFT,\n        fill=tk.Y)\n    tk.Frame(inner_container, height=1, bg='#808080').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#808080').pack(side=tk.RIGHT,\n        fill=tk.Y)\n    content_area = tk.Frame(inner_container, bg='#c0c0c0')\n    content_area.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1)\n    return content_area\n\n\nroot = tk.Tk()\nroot.title('Current Time')\nroot.configure(bg='#008080')\nmain_frame = create_3d_border(root)\nmain_frame.config(padx=4, pady=4)\ninner_frame = tk.Frame(main_frame, bg='#c0c0c0', padx=8, pady=8)\ninner_frame.pack()\ntime_label = tk.Label(inner_frame, bg='#c0c0c0', fg='#000000', font=(\n    'MS Sans Serif', 18, 'bold'), padx=12, pady=8)\ntime_label.pack()\nroot.after(100, lambda : center_window(root))\nupdate_time()\nroot.mainloop()\n",
    "file": "/mnt/ProjectData/omni/omni_saves/watch.py"
  },
  {
    "id": 112,
    "hash": "6774a805052356775d8c4f0367253dc1",
    "content": "# OmniForge\n\n**Project\u2011Aware AI CLI for AST\u2011Precise Edits (\u201cScalpel\u201d) & Multi\u2011File Refactors (\u201cBlueprint\u201d).**\n\n> *OmniForge (a.k.a. the \"DualForge\" engine) helps you **scan**, **understand**, and **reforge** your codebase with local (Ollama) or remote (OpenRouter) LLMs. It is an independent open\u2011source project not affiliated with other products using the name \u201cOmni.\u201d*\n\n---\n\n## Core Features\n\n* **Project\u2011Aware Refactoring (`refactor`)**: Provide a high\u2011level goal (e.g. *\u201cmove all DB logic into `db/` and centralize config\u201d*). OmniForge generates & shows a multi\u2011step plan before touching files.\n* **Surgical AST Editing (`edit`)**: Target a single function/class. OmniForge parses the file, locates the node, applies a structural change, and shows you a diff.\n* **Context Ingestion (`look`)**: Scan a directory or single file to build a project manifest (paths + hashes + size + language hints) that guides subsequent edits/refactors.\n* **Dual Backends**: Seamlessly switch between **`openrouter`** (remote models) and **`ollama`** (local models) via `backend <name>`.\n* **Interactive Model Picker (`models`)**: Filter by source/provider and select from an up\u2011to\u2011date model list inside the terminal.\n* **Session Memory & History**: `history` shows conversation / action log; `memory clear` resets the working context.\n* **Safe AST\u2011Based Transformations**: Reduces syntax breakage vs naive text substitution. New imports / dependencies are auto\u2011inserted when possible.\n* **Dry\u2011Run Transparency**: Every multi\u2011file refactor presents (1) a generated plan, (2) per\u2011file proposed changes, (3) a consolidated diff for confirmation.\n\n---\n\n## Conceptual Modes\n\n| Mode          | Command(s) | Purpose                                              | Analogy              |\n| ------------- | ---------- | ---------------------------------------------------- | -------------------- |\n| **Survey**    | `look`     | Index project / ingest context                       | Mapping the terrain  |\n| **Scalpel**   | `edit`     | Precise single\u2011file structural change                | Surgery              |\n| **Blueprint** | `refactor` | Multi\u2011file architectural transformation              | Architecture         |\n| **Cast**      | `run`      | Execute last generated runnable block (if supported) | Forging the artifact |\n\nYou can reference these terms in docs, help screens, or UI banners for clarity.\n\n---\n\n## Installation\n\n> Requires Python 3.10+ and a Unix\u2011like shell.\n\n```bash\n# 1. Clone\ngit clone https://github.com/Snawyyy/omniforge.git\ncd omniforge\n\n# 2. (Optional) Inspect requirements\ncat requirements.txt\n\n# 3. Run installer (creates venv + installs deps)\nchmod +x install.sh\n./install.sh\n\n# 4. Activate environment\nsource venv/bin/activate\n\n# 5. Run CLI (interactive shell)\n./omni        # or: python omni.py\n```\n\nIf you later package it, expose a script entry point named `omni` while keeping an internal package name like `omniforge` to avoid namespace collisions.\n\n---\n\n## Configuration\n\nCreate a `.env` file to supply secrets (e.g. OpenRouter API key).\n\n```bash\ncp .env.example .env   # if example exists; otherwise create manually\n```\n\nIn `.env`:\n\n```dotenv\nOPENROUTER_API_KEY=\"sk-or-...\"\n```\n\n(Do **not** commit real keys. Ensure `.env` is listed in `.gitignore`.)\n\nOptional future keys can include local model paths, default model name, or feature flags.\n\n---\n\n## Quick Start Workflow\n\n```text\n> look .\n(Index project: builds manifest)\n\n> refactor \"extract hardcoded API URL to config/settings.py and update all imports\"\n(Shows plan \u2192 ask for confirmation)\n\n> edit src/utils.py \"add a doctring for calculate_average explaining parameters and return value\"\n(Shows targeted diff \u2192 confirm or abort)\n\n> models openai\n(Choose a different model)\n\n> backend ollama\n(Switch to local inference)\n```\n\n---\n\n## Command Reference\n\n| Command               | Example                                         | Description                                                                 |\n| --------------------- | ----------------------------------------------- | --------------------------------------------------------------------------- |\n| `look <path>`         | `look .`                                        | Scan directory or file; update project context manifest.                    |\n| `edit <file> \"instr\"` | `edit utils.py \"add error handling\"`            | AST\u2011guided targeted modification of a single file element or whole file.    |\n| `refactor \"goal\"`     | `refactor \"split monolith api.py into package\"` | High\u2011level multi\u2011file transformation with plan + diff review.               |\n| `send <prompt>`       | `send summarize module layout`                  | Generic prompt to current model with current context summary.               |\n| `models [filter]`     | `models google`                                 | Interactive model selector (filter by provider/source).                     |\n| `backend <name>`      | `backend ollama`                                | Switch between `openrouter` / `ollama`.                                     |\n| `history`             | `history`                                       | Display session interaction log.                                            |\n| `memory clear`        | `memory clear`                                  | Clear internal AI context memory (project manifest may persist separately). |\n| `run`                 | `run`                                           | Execute the last generated runnable code snippet (if feature implemented).  |\n| `help`                | `help`                                          | Show help / usage summary.                                                  |\n\n---\n\n## How It Works (High Level)\n\n1. **Ingestion (`look`)**: Walks the directory (configurable ignore patterns), captures file metadata (path, size, language), optionally caches abbreviated content or hashes.\n2. **Prompt Construction**: Merges user instruction + contextual manifest + focused snippets (for `edit`) or diff summaries (for `refactor`).\n3. **AST Layer** (Python initially): Parses target file(s); identifies node(s) (function/class) based on name + heuristic similarity; applies transformations guided by model output (structured hints or patch templates) rather than raw blind overwrite.\n4. **Plan (Refactor)**: Model proposes steps (CREATE / MODIFY / RENAME / DELETE). User approves. Each step executed & validated; errors surface early.\n5. **Diff Presentation**: A unified colorized diff shown; user confirms to write changes.\n6. **Safety**: If AST parse fails or patch violates syntax, changes abort (or fallback to text patch with warning).\n\n---\n\n## Roadmap (Indicative)\n\n| Milestone | Features                                                                    |\n| --------- | --------------------------------------------------------------------------- |\n| 0.1.0     | Core commands (`look`, `edit`, `refactor`, `models`, `backend`, `history`). |\n| 0.2.0     | Config file (`omniforge.toml`), ignore patterns, improved diff viewer.      |\n| 0.3.0     | Multi-language AST adapters (JS/TS via `tree-sitter`).                      |\n| 0.4.0     | Test impact analysis & auto test file generation.                           |\n| 0.5.0     | Refactor preview metrics (LOC touched, complexity delta).                   |\n| 0.6.0     | Inline security / lint feedback integration.                                |\n| 0.7.0     | Partial GUI / TUI dashboard mode.                                           |\n\n(Adjust roadmap as project evolves.)\n\n---\n\n## Developer Notes\n\n* Keep `.env`, virtual environment dirs (`venv/`), caches, large artifacts in `.gitignore`.\n* Consider adding a thin `omniforge/` package directory now for future PyPI packaging.\n* Implement a pluggable *Model Adapter* layer to abstract provider differences (OpenRouter vs Ollama).\n* Logging: Provide `--verbose` or `OMNIFORGE_DEBUG=1` env flag.\n* Add a JSONL log of commands & decisions to enable replay or supervised improvements.\n\n---\n\n## Contributing\n\n1. Fork & create a feature branch: `git checkout -b feat/<short-name>`\n2. Run and add tests (if/when test harness exists in `tests/`).\n3. Ensure style/format (e.g. `ruff`, `black`) passes.\n4. Submit pull request with concise description + before/after examples.\n\nIssues / discussions welcome for architecture proposals, AST adapters, or performance improvements.\n\n---\n\n## License\n\nReleased under the **MIT License**. See `LICENSE` file for full text.\n\n---\n\n## Name & Trademark Disclaimer\n\n\u201cOmniForge\u201d is an independent open-source tool and not affiliated with The Omni Group or any other third-party products using similar names. If a future naming conflict arises, a soft alias strategy (keeping the `omni` CLI) will preserve user workflows.\n\n---\n\n## Example Session (Illustrative)\n\n```text\n$ ./omni\nOMNIFORGE 0.1.0  (backend=openrouter | model=anthropic/claude-3)\nType 'help' or 'look .' to begin.\n\n> look .\nIndexed 42 files (Python=30, Markdown=5, JSON=7)\n\n> refactor \"centralize logging into logging_util.py and update imports\"\nPlan:\n  [1] CREATE logging_util.py\n  [2] MODIFY app.py (replace inline log setup)\n  [3] MODIFY worker.py (import logging_util)\nProceed? (y/n) y\n... (diff preview) ...\nApply changes? (y/n) y\nRefactor complete in 3.2s.\n\n> edit worker.py \"add retry with exponential backoff to fetch_data\"\nParsed worker.py \u2713\nApplied modification (function: fetch_data)\nDiff shown. Accept? (y/n) y\nSaved.\n```\n\n---\n\n## Philosophy\n\n*The next wave of developer AI goes beyond paste\u2011in prompts.* OmniForge treats your repository as *structured material*, enabling incremental, auditable, and safer evolution rather than opaque code dumps. By combining **context scanning**, **AST precision**, and **human approval loops**, it aims to become a trustworthy co\u2011developer rather than an occasionally helpful code generator.\n\n---\n\n## Feedback / Support\n\nOpen a GitHub Issue for bugs & feature requests. For conceptual discussions (roadmap, design choices), use Discussions.\n\n---\n\nHappy forging!\n",
    "file": "/mnt/ProjectData/omni/README.md"
  },
  {
    "id": 113,
    "hash": "48f330cca4dc037b3ad4942e430e6393",
    "content": "# ast_adapter.py\n\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional, Dict, Any, Union\n\n# Define common types that adapters might use or return\n# This keeps the interface flexible without importing specific parser libraries\nASTNode = Any  # Generic type for a node in the AST/CST\nDiffContent = str # Type alias for the string output of a diff\n\nclass ASTAdapter(ABC):\n    \"\"\"\n    Abstract base class defining the interface for language-specific AST adapters.\n\n    This interface allows the CodeEditor to interact with the AST/CST of different\n    programming languages in a uniform way. Concrete implementations will handle\n    the specifics of parsing, traversing, and modifying the AST/CST for their\n    respective languages (e.g., Python's `ast`/`astor`, JavaScript's `tree-sitter`).\n\n    The adapter is responsible for holding the parsed tree structure and any\n    necessary metadata for operations.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the adapter by parsing the provided source code.\n\n        Args:\n            source_code: The string content of the source file to be parsed.\n\n        Raises:\n            ValueError: If the source code cannot be parsed due to syntax errors.\n        \"\"\"\n        self.source_code: str = source_code\n        self.tree: Optional[ASTNode] = None\n        self.nodes: Dict[str, ASTNode] = {} # A map for quick access to named elements\n        self._parse_and_map(source_code)\n\n    @abstractmethod\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Abstract method to parse the source code and populate `self.tree` and `self.nodes`.\n\n        This is the core method where language-specific parsing logic resides.\n        Implementations should:\n        1. Parse the `source_code` into an AST/CST representation.\n        2. Store the root of this representation in `self.tree`.\n        3. Identify key top-level elements (functions, classes, variables, imports)\n           and map their names to their nodes in `self.nodes`.\n\n        Args:\n            source_code: The string content to parse.\n\n        Raises:\n            ValueError: If the source code cannot be parsed.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_elements(self) -> List[str]:\n        \"\"\"\n        Abstract method to list the names of the main elements found in the code.\n\n        These are typically top-level functions, classes, variable assignments,\n        and imports that the adapter can identify and manipulate.\n\n        Returns:\n            A list of element names (strings).\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"\n        Abstract method to get the source code string for a specific element.\n\n        Args:\n            element_name: The name of the element (function, class, etc.).\n\n        Returns:\n            The source code string for the element, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"\n        Abstract method to get detailed structural information about an element.\n\n        This information can include type, line numbers, body items, etc., useful\n        for aiding the AI in understanding the code's layout.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            A dictionary containing structural details, or None if not found.\n            Example structure:\n            {\n                'name': 'func_name',\n                'type': 'FunctionDef', # or 'ClassDef', etc.\n                'line_start': 10,\n                'line_end': 25,\n                'body_items': [list of internal statement details...]\n            }\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"\n        Abstract method to extract a snippet of code from within an element's body.\n\n        Used for 'partial' edits where only a specific range of lines within\n        a function or class needs to be changed.\n\n        Args:\n            element_name: The name of the element containing the snippet.\n            line_start: The starting line number (1-based, absolute) of the snippet.\n            line_end: The ending line number (inclusive) of the snippet.\n\n        Returns:\n            The source code string for the specified lines within the element, or None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"\n        Abstract method to replace an entire named element.\n\n        This involves finding the old element in the tree and swapping it with\n        the representation of the `new_code`.\n\n        Args:\n            element_name: The name of the element to replace.\n            new_code: The new source code for the element (and potential helpers).\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"\n        Abstract method to add a new block of code (element) to the file.\n\n        This involves parsing the `new_code` and inserting its representation\n        into the tree at an appropriate location (e.g., end of file, near anchor).\n\n        Args:\n            new_code: The source code for the new element(s).\n            anchor_name: Optional name of an existing element to position relative to.\n            before: If True and `anchor_name` is provided, insert before the anchor.\n\n        Returns:\n            True if the element was added successfully, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"\n        Abstract method to delete a named element from the file.\n\n        This involves finding the element in the tree and removing its representation.\n\n        Args:\n            element_name: The name of the element to delete.\n\n        Returns:\n            True if the element was successfully deleted, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"\n        Abstract method for a 'surgical' edit within an element's body.\n\n        Replaces a specific statement or line range within the body of an element.\n\n        Args:\n            element_name: Name of the function/class to modify.\n            new_code: New code to insert (can be multiple statements).\n            line_start: Starting line number (absolute) within the element.\n            line_end: Ending line number (inclusive) within the element.\n            statement_index: Alternative to line numbers - replace the Nth statement.\n\n        Returns:\n            True if successful, False otherwise.\n        \"\"\"\n        pass\n\n    # --- Methods related to final output and change tracking ---\n\n    @abstractmethod\n    def get_modified_source(self) -> str:\n        \"\"\"\n        Abstract method to serialize the potentially modified AST/CST back to source code.\n\n        Returns:\n            The full source code string reflecting the current state of the tree.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_diff(self) -> str:\n        \"\"\"\n        Abstract method to generate a diff between the original source and the modified source.\n\n        Returns:\n            A string containing the unified diff.\n        \"\"\"\n        pass\n\n    # Internal helper methods (can be abstract or have common logic in base if needed)\n    # These are less critical for the interface but might be useful\n    # _add_imports(new_import_nodes) -> could be handled differently per language\n    # _find_statement_in_body(body, line_start, line_end) -> Tree-sitter needs different logic",
    "file": "/mnt/ProjectData/omni/ast_adapter.py"
  },
  {
    "id": 114,
    "hash": "f7b169444c2d435f115ad2d8801ee5db",
    "content": "\"\"\"\nCodeEditor - Enhanced AST-based code manipulation tool\n\nThis module provides a class to programmatically parse, analyze,\nand edit source code. It has been refactored to use a pluggable\nASTAdapter system, allowing it to support multiple languages.\nCurrently, it defaults to Python's built-in `ast` module via\nPythonASTAdapter for backward compatibility during the transition.\n\"\"\"\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Union, Tuple, Type, Any\nfrom ast_adapter import ASTAdapter\nfrom python_ast_adapter import PythonASTAdapter\nimport os\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n\n\nclass CodeEditor:\n    \"\"\"\n    An enhanced class to safely edit files using AST/CST with partial edit support.\n    The core logic for interacting with the code structure is now delegated to\n    a language-specific ASTAdapter.\n    \"\"\"\n\n    def __init__(self, file_path: str, adapter_class: Optional[Type[\n        ASTAdapter]]=None):\n        \"\"\"\n        Initializes the CodeEditor.\n\n        Args:\n            file_path: The path to the source file.\n            adapter_class: The ASTAdapter subclass to use. If None, defaults to\n                           PythonASTAdapter for .py files.\n        \"\"\"\n        self.file_path = file_path\n        self.source_code = self._read_file()\n        if adapter_class is None:\n            file_extension = os.path.splitext(self.file_path)[1].lower()\n            if file_extension == '.py':\n                try:\n                    from python_ast_adapter import PythonASTAdapter\n                    self.adapter: Optional[ASTAdapter] = PythonASTAdapter(self\n                        .source_code)\n                except ImportError:\n                    raise ValueError(\n                        'Python AST adapter is required but not available')\n            elif file_extension == '.js':\n                try:\n                    from javascript_ast_adapter import JavaScriptASTAdapter\n                    self.adapter: Optional[ASTAdapter] = JavaScriptASTAdapter(\n                        self.source_code)\n                except ImportError:\n                    raise ValueError(\n                        'tree-sitter is required for JavaScript support but not available'\n                        )\n            else:\n                raise ValueError(\n                    f'Unsupported file type: {file_extension}. Supported types: .py, .js'\n                    )\n        else:\n            self.adapter = adapter_class(self.source_code)\n\n    def _read_file(self) ->str:\n        \"\"\"Reads the source file.\"\"\"\n        try:\n            with open(self.file_path, 'r', encoding='utf-8') as f:\n                return f.read()\n        except FileNotFoundError:\n            raise ValueError(f'File not found: {self.file_path}')\n\n    def _parse_source(self) ->ast.AST:\n        \"\"\"Fallback parsing logic.\"\"\"\n        try:\n            return ast.parse(self.source_code)\n        except SyntaxError as e:\n            raise ValueError(f'Invalid Python syntax in {self.file_path}: {e}')\n\n    def list_elements(self) ->List[str]:\n        \"\"\"Lists top-level elements in the code.\"\"\"\n        if self.adapter:\n            return self.adapter.list_elements()\n        else:\n            return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"Gets the source code for a specific element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_source_of(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            return astor.to_source(node) if node else None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"Gets detailed structure information about an element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_structure(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            if not node:\n                return None\n            structure = {'name': element_name, 'type': node.__class__.\n                __name__, 'line_start': node.lineno if hasattr(node,\n                'lineno') else None, 'line_end': node.end_lineno if hasattr\n                (node, 'end_lineno') else None, 'body_items': []}\n            if hasattr(node, 'body'):\n                for i, item in enumerate(node.body):\n                    item_info = {'index': i, 'type': item.__class__.\n                        __name__, 'line_start': item.lineno if hasattr(item,\n                        'lineno') else None, 'line_end': item.end_lineno if\n                        hasattr(item, 'end_lineno') else None}\n                    if isinstance(item, ast.Assign) and item.targets:\n                        target = item.targets[0]\n                        if isinstance(target, ast.Name):\n                            item_info['assigns'] = target.id\n                    elif isinstance(item, (ast.If, ast.While, ast.For)):\n                        item_info['has_body'] = bool(item.body)\n                    elif isinstance(item, ast.Return):\n                        item_info['returns'] = True\n                    structure['body_items'].append(item_info)\n            return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"Gets a snippet from within an element's body.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_body_snippet(element_name,\n                line_start, line_end)\n        else:\n            if not self.atok:\n                return None\n            node = self.nodes.get(element_name)\n            if not node or not hasattr(node, 'body'):\n                return None\n            statements = []\n            for stmt in node.body:\n                if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                    if (line_start <= stmt.lineno <= line_end or line_start <=\n                        stmt.end_lineno <= line_end):\n                        statements.append(stmt)\n            if not statements:\n                return None\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in\n                statements)\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"Replaces a partial section of an element.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_partial(element_name, new_code,\n                line_start, line_end, statement_index)\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                if new_code.strip().startswith('def ') or new_code.strip(\n                    ).startswith('class '):\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body[0].body\n                else:\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if statement_index is not None:\n                if 0 <= statement_index < len(node.body):\n                    node.body[statement_index:statement_index + 1\n                        ] = new_statements\n                    return True\n            elif line_start is not None:\n                result = self._find_statement_in_body(node.body, line_start,\n                    line_end)\n                if result:\n                    idx, _ = result\n                    if line_end:\n                        end_idx = idx\n                        for i in range(idx + 1, len(node.body)):\n                            stmt = node.body[i]\n                            if hasattr(stmt, 'end_lineno'\n                                ) and stmt.end_lineno <= line_end:\n                                end_idx = i\n                            else:\n                                break\n                        node.body[idx:end_idx + 1] = new_statements\n                    else:\n                        node.body[idx:idx + 1] = new_statements\n                    return True\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"Adds a new block of code to the file.\"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name, before)\n        else:\n            try:\n                new_ast_module = ast.parse(new_code)\n            except (SyntaxError, IndexError):\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            insertion_index = -1\n            main_block_idx = -1\n            for i, _node in enumerate(self.tree.body):\n                if isinstance(_node, ast.If) and isinstance(_node.test, ast\n                    .Compare) and isinstance(_node.test.left, ast.Name\n                    ) and _node.test.left.id == '__name__' and len(_node.\n                    test.ops) == 1 and isinstance(_node.test.ops[0], ast.Eq\n                    ) and len(_node.test.comparators) == 1:\n                    comp = _node.test.comparators[0]\n                    if isinstance(comp, ast.Constant\n                        ) and comp.value == '__main__' or isinstance(comp,\n                        ast.Str) and comp.s == '__main__':\n                        main_block_idx = i\n                        break\n            if anchor_name:\n                if anchor_name not in self.nodes:\n                    return False\n                anchor_node = self.nodes[anchor_name]\n                try:\n                    anchor_idx = self.tree.body.index(anchor_node)\n                    proposed_index = anchor_idx if before else anchor_idx + 1\n                    if main_block_idx != -1:\n                        insertion_index = min(proposed_index, main_block_idx)\n                    else:\n                        insertion_index = proposed_index\n                except ValueError:\n                    return False\n            elif main_block_idx != -1:\n                insertion_index = main_block_idx\n            if insertion_index == -1:\n                self.tree.body.extend(new_code_body)\n            else:\n                for i, new_node in enumerate(new_code_body):\n                    self.tree.body.insert(insertion_index + i, new_node)\n            for _node in new_code_body:\n                if isinstance(_node, (ast.FunctionDef, ast.AsyncFunctionDef,\n                    ast.ClassDef)):\n                    self.nodes[_node.name] = _node\n            return True\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"Deletes an element by name.\"\"\"\n        if self.adapter:\n            return self.adapter.delete_element(element_name)\n        else:\n            deleted = False\n            if element_name in self.nodes:\n                node_to_delete = self.nodes[element_name]\n                for _node in ast.walk(self.tree):\n                    if hasattr(_node, 'body') and isinstance(_node.body, list):\n                        try:\n                            _node.body.remove(node_to_delete)\n                            deleted = True\n                            break\n                        except ValueError:\n                            continue\n                if deleted:\n                    del self.nodes[element_name]\n                    self.nodes = self._map_nodes()\n                    return True\n            new_body = []\n            for _node in self.tree.body:\n                if isinstance(_node, ast.Assign):\n                    match = False\n                    for target in _node.targets:\n                        if isinstance(target, ast.Name\n                            ) and target.id == element_name:\n                            match = True\n                            break\n                    if match:\n                        deleted = True\n                        continue\n                elif isinstance(_node, ast.Import):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                elif isinstance(_node, ast.ImportFrom):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                new_body.append(_node)\n            self.tree.body = new_body\n            if deleted:\n                self.nodes = self._map_nodes()\n            return deleted\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"Replaces a target element with new code.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_element(element_name, new_code)\n        else:\n            if element_name not in self.nodes:\n                return False\n            try:\n                new_ast_module = ast.parse(new_code)\n            except SyntaxError:\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            for _node in ast.walk(self.tree):\n                if hasattr(_node, 'body') and isinstance(_node.body, list):\n                    try:\n                        old_node = self.nodes[element_name]\n                        idx = _node.body.index(old_node)\n                        _node.body.pop(idx)\n                        for i, new_node in enumerate(new_code_body):\n                            _node.body.insert(idx + i, new_node)\n                        del self.nodes[element_name]\n                        for n in new_code_body:\n                            if isinstance(n, (ast.FunctionDef, ast.\n                                AsyncFunctionDef, ast.ClassDef)):\n                                self.nodes[n.name] = n\n                        return True\n                    except (ValueError, KeyError):\n                        continue\n            return False\n\n    def insert_in_element(self, element_name: str, new_code: str, position:\n        str='end', after_line: Optional[int]=None, before_line: Optional[\n        int]=None) ->bool:\n        \"\"\"\n        Insert new code into an element without replacing existing code.\n        This is an internal/helper method, delegating to adapter OR using fallback.\n        \"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name=\n                element_name, before=position == 'start')\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                new_ast = ast.parse(new_code)\n                new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if position == 'start':\n                node.body[0:0] = new_statements\n            elif position == 'end':\n                node.body.extend(new_statements)\n            elif after_line:\n                result = self._find_statement_in_body(node.body, after_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx + 1:idx + 1] = new_statements\n                else:\n                    return False\n            elif before_line:\n                result = self._find_statement_in_body(node.body, before_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx:idx] = new_statements\n                else:\n                    return False\n            else:\n                return False\n            return True\n\n    def _map_nodes(self) ->Dict[str, ast.AST]:\n        \"\"\"Fallback node mapping logic for Python AST.\"\"\"\n        nodes = {}\n        for node in ast.walk(self.tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast\n                .ClassDef)):\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int,\n        line_end: Optional[int]=None) ->Optional[Tuple[int, ast.AST]]:\n        \"\"\"Fallback statement finding logic for Python AST.\"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = stmt.end_lineno if hasattr(stmt, 'end_lineno'\n                        ) else stmt.lineno\n                    if (stmt.lineno <= line_start <= stmt_end or stmt.\n                        lineno <= line_end <= stmt_end):\n                        return i, stmt\n                elif stmt.lineno == line_start:\n                    return i, stmt\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.\n        ImportFrom]]) ->None:\n        \"\"\"Fallback logic to add imports to the top of the Python AST.\"\"\"\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                existing_imports_str.add(astor.to_source(node).strip())\n                last_import_index = i\n        for new_import in reversed(new_import_nodes):\n            new_import_str = astor.to_source(new_import).strip()\n            if new_import_str not in existing_imports_str:\n                self.tree.body.insert(last_import_index + 1, new_import)\n\n    def apply_arbitrary_change(self, new_source_code: str) ->bool:\n        \"\"\"\n        Rewrites the entire file's AST from a new source string.\n        This method resets the adapter if one exists, or uses fallback.\n        \"\"\"\n        if self.adapter:\n            try:\n                adapter_class = type(self.adapter)\n                self.adapter = adapter_class(new_source_code)\n                return True\n            except Exception:\n                return False\n        else:\n            try:\n                new_tree = ast.parse(new_source_code)\n                self.tree = new_tree\n                self.nodes = self._map_nodes()\n                if ASTTOKENS_AVAILABLE:\n                    self.source_code = new_source_code\n                    self.atok = asttokens.ASTTokens(self.source_code, parse\n                        =True)\n                return True\n            except SyntaxError:\n                return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"Serializes the potentially modified code structure back to source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_modified_source()\n        else:\n            return astor.to_source(self.tree)\n\n    def get_diff(self) ->str:\n        \"\"\"Generates a diff between the original source and the modified source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_diff()\n        else:\n            modified_source = self.get_modified_source()\n            return ''.join(difflib.unified_diff(self.source_code.splitlines\n                (keepends=True), modified_source.splitlines(keepends=True),\n                fromfile=f'{self.file_path} (original)', tofile=\n                f'{self.file_path} (modified)'))\n\n    def save_changes(self) ->None:\n        \"\"\"Saves the modified source code back to the file.\"\"\"\n        modified_source = self.get_modified_source()\n        with open(self.file_path, 'w', encoding='utf-8') as f:\n            f.write(modified_source)\n",
    "file": "/mnt/ProjectData/omni/code_editor.py"
  },
  {
    "id": 115,
    "hash": "cc52aa524d0929867d5d2ea3697229e6",
    "content": "\"\"\"\nGenerated file.\n\"\"\"\nimport os\n\"\"\"\nFileCreator - A utility for creating files.\n\nThis module provides a simple, encapsulated way to create files,\nensuring that their parent directories exist before writing.\n\"\"\"\n\n\nclass FileCreator:\n    \"\"\"\n    A utility class to handle the creation of new files.\n    \"\"\"\n\n    @staticmethod\n    def create(file_path: str, content: str) ->None:\n        \"\"\"\n        Creates a file at the specified path with the given content.\n\n        This method will automatically create any necessary parent\n        directories for the file path.\n\n        Args:\n            file_path: The full path where the file should be created.\n            content: The string content to write to the file.\n\n        Raises:\n            IOError: If there is an error creating the directories or writing the file.\n        \"\"\"\n        try:\n            directory = os.path.dirname(file_path)\n            if directory:\n                os.makedirs(directory, exist_ok=True)\n            with open(file_path, 'w', encoding='utf-8') as f:\n                f.write(content)\n        except (IOError, OSError) as e:\n            raise IOError(f\"Failed to create file '{file_path}': {e}\") from e\n",
    "file": "/mnt/ProjectData/omni/file_creator.py"
  },
  {
    "id": 116,
    "hash": "04a24ceab008bd649d0530d309c72e42",
    "content": "import subprocess\nimport os\nfrom typing import List, Optional, Union\n\n\nclass GitManager:\n    \"\"\"\n    Encapsulates Git-related logic for a specific repository.\n\n    This class provides methods to perform common Git operations such as\n    checking status, getting diffs, staging, committing, and pushing changes.\n    It relies on the Git command-line tool being installed and accessible\n    in the system's PATH.\n    \"\"\"\n\n    def __init__(self, repo_path: str):\n        \"\"\"\n        Initializes the GitManager for a given repository path.\n\n        Args:\n            repo_path: The absolute or relative path to the Git repository.\n\n        Raises:\n            ValueError: If the provided path is not a valid Git repository.\n        \"\"\"\n        if not os.path.isdir(os.path.join(repo_path, '.git')):\n            raise ValueError(\n                f\"The path '{repo_path}' is not a valid Git repository.\")\n        self.repo_path = repo_path\n\n    def _run_command(self, command: List[str]) ->str:\n        \"\"\"\n        Executes a Git command in the repository's directory.\n\n        Args:\n            command: A list of command arguments, starting with 'git'.\n\n        Returns:\n            The standard output of the command as a string.\n\n        Raises:\n            subprocess.CalledProcessError: If the command returns a non-zero exit code.\n        \"\"\"\n        try:\n            result = subprocess.run(command, cwd=self.repo_path, check=True,\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True,\n                encoding='utf-8')\n            return result.stdout.strip()\n        except subprocess.CalledProcessError as e:\n            error_message = (\n                f\"Git command failed: {' '.join(command)}\\nError: {e.stderr.strip()}\"\n                )\n            raise subprocess.CalledProcessError(e.returncode, e.cmd, output\n                =e.stdout, stderr=error_message) from e\n\n    def get_status(self) ->str:\n        \"\"\"\n        Gets the repository status in a condensed format.\n\n        Uses `git status --porcelain` for a machine-readable output.\n\n        Returns:\n            A string representing the repository's status.\n        \"\"\"\n        return self._run_command(['git', 'status', '--porcelain'])\n        \n    def get_changed_files(self) -> List[str]:\n        \"\"\"\n        Gets a list of all changed (modified, added, deleted, untracked, renamed, or copied) files.\n\n        This parses the output of `git status --porcelain`, which provides a stable,\n        machine-readable format.\n\n        Returns:\n            A list of file paths relative to the repository root. For renamed or\n            copied files, it returns the new path.\n        \"\"\"\n        status_output = self.get_status()\n        if not status_output:\n            return []\n        \n        changed_files = []\n        for line in status_output.splitlines():\n            if len(line) < 3:  # Skip malformed lines\n                continue\n                \n            # Git status porcelain format: XY filename\n            # X = index status, Y = working tree status\n            index_status = line[0]\n            worktree_status = line[1]\n            \n            # The filename starts after the two status characters and a space\n            # But let's be more defensive about finding where the filename actually starts\n            filename_start = 2\n            while filename_start < len(line) and line[filename_start] == ' ':\n                filename_start += 1\n                \n            if filename_start >= len(line):\n                continue  # Skip if no filename found\n                \n            path_info = line[filename_start:]\n            \n            # Check if either index or working tree status indicates rename/copy\n            if index_status in ('R', 'C') or worktree_status in ('R', 'C'):\n                if ' -> ' in path_info:\n                    _, new_path = path_info.split(' -> ', 1)  # Use maxsplit=1 for safety\n                    changed_files.append(new_path.strip())\n                else:\n                    # Fallback if format is unexpected\n                    changed_files.append(path_info.strip())\n            else:\n                changed_files.append(path_info.strip())\n        \n        # Remove duplicates while preserving order\n        return list(dict.fromkeys(changed_files))\n\n    def get_diff(self, file_path: Optional[str]=None, staged: bool=False\n        ) ->str:\n        \"\"\"\n        Gets the diff of changes in the repository.\n\n        Args:\n            file_path: Optional. Path to a specific file to diff.\n            staged: If True, shows the diff for staged changes (`--cached`).\n                    Otherwise, shows the diff for unstaged changes.\n\n        Returns:\n            The git diff output as a string.\n        \"\"\"\n        cmd = ['git', 'diff']\n        if staged:\n            cmd.append('--cached')\n        if file_path:\n            cmd.append('--')\n            cmd.append(file_path)\n        return self._run_command(cmd)\n\n    def add(self, files: Union[str, List[str]]) ->None:\n        \"\"\"\n    Stages one or more files, handling each one individually for robustness.\n\n    This approach prevents a single invalid file path from causing the\n    entire 'git add' operation to fail. Warnings will be printed for any\n    files that could not be staged.\n\n    Args:\n        files: A single file path or a list of file paths to stage.\n               Can also be '.' to stage all changes.\n    \"\"\"\n        if isinstance(files, str):\n            files = [files]\n        for file_path in files:\n            try:\n                cmd = ['git', 'add', '--', file_path]\n                self._run_command(cmd)\n            except subprocess.CalledProcessError as e:\n                print(\n                    f\"Warning: Could not stage file '{file_path}'. Git reported: {e.stderr}\"\n                    )\n\n    def commit(self, message: str) ->str:\n        \"\"\"\n        Commits staged changes with a given message.\n\n        Args:\n            message: The commit message.\n\n        Returns:\n            The stdout from the git commit command.\n        \"\"\"\n        return self._run_command(['git', 'commit', '-m', message])\n\n    def push(self, remote: str='origin', branch: Optional[str]=None) ->str:\n        \"\"\"\n        Pushes commits to a remote repository.\n\n        Args:\n            remote: The name of the remote to push to (default: 'origin').\n            branch: The branch to push. If None, uses the current branch.\n\n        Returns:\n            The stdout from the git push command.\n        \"\"\"\n        if branch is None:\n            branch = self.get_current_branch()\n        return self._run_command(['git', 'push', remote, branch])\n\n    def get_current_branch(self) ->str:\n        \"\"\"\n        Determines the current active branch name.\n\n        Returns:\n            The name of the current branch.\n        \"\"\"\n        return self._run_command(['git', 'rev-parse', '--abbrev-ref', 'HEAD'])\n",
    "file": "/mnt/ProjectData/omni/git_manager.py"
  },
  {
    "id": 117,
    "hash": "f3f7ab448ad3e233539c4e4bddcd64f4",
    "content": "# javascript_ast_adapter.py\n\n\"\"\"\nJavaScriptASTAdapter - Concrete AST adapter for JavaScript using tree-sitter.\n\nThis module implements the ASTAdapter interface specifically for JavaScript,\nleveraging the tree-sitter library for parsing and manipulation.\n\"\"\"\n\nimport difflib\nimport re\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for tree-sitter\ntry:\n    import tree_sitter\n    import tree_sitter_languages\n    TREETSITTER_AVAILABLE = True\nexcept ImportError:\n    TREETSITTER_AVAILABLE = False\n    # This will cause an error during initialization if the adapter is used\n\n\nclass JavaScriptASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for JavaScript source code.\n\n    This adapter uses tree-sitter to parse and manipulate JavaScript code.\n    It holds the parsed tree-sitter Tree and provides methods to interact\n    with it according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the JavaScriptASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The JavaScript source code as a string.\n\n        Raises:\n            ValueError: If tree-sitter libraries are not available or if\n                        the source code has invalid JavaScript syntax.\n        \"\"\"\n        if not TREETSITTER_AVAILABLE:\n            raise ValueError(\"tree-sitter and tree-sitter-languages are required for JavaScript support.\")\n            \n        # Store source code for diffing and manipulation\n        self.source_code: str = source_code\n        # Will hold the parsed tree-sitter tree\n        self.tree: Optional[tree_sitter.Tree] = None\n        # Will hold a mapping of element names to their tree-sitter nodes\n        self.nodes: Dict[str, tree_sitter.Node] = {}\n        # Tree-sitter language parser\n        self.language = tree_sitter_languages.get_language(\"javascript\")\n        self.parser = tree_sitter.Parser(self.language)\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the JavaScript source code and maps elements.\n\n        Args:\n            source_code: The JavaScript source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid JavaScript syntax.\n        \"\"\"\n        try:\n            # Encode the source code in bytes as required by tree-sitter\n            self.tree = self.parser.parse(bytes(source_code, \"utf-8\"))\n        except Exception as e:\n            raise ValueError(f\"Failed to parse JavaScript source: {e}\") from e\n\n        self.nodes = self._map_nodes()\n\n    def _map_nodes(self) -> Dict[str, tree_sitter.Node]:\n        \"\"\"\n        Walks the tree and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their tree-sitter nodes.\n        \"\"\"\n        nodes: Dict[str, tree_sitter.Node] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        # Define the types of nodes we're interested in\n        target_types = {\n            \"function_declaration\", \"class_declaration\", \n            \"variable_declarator\", \"import_statement\"\n        }\n        \n        # Walk the tree using a stack-based approach\n        stack = [self.tree.root_node]\n        while stack:\n            node = stack.pop()\n            \n            # Check if this is a target node type\n            if node.type in target_types:\n                # Extract the name for different node types\n                name = self._get_node_name(node)\n                if name and name not in nodes:\n                    nodes[name] = node\n            \n            # Add children to the stack for further processing\n            for child in reversed(node.children):  # Reverse to maintain order when popping\n                stack.append(child)\n                \n        return nodes\n    \n    def _get_node_name(self, node: tree_sitter.Node) -> Optional[str]:\n        \"\"\"\n        Extracts the name of a node based on its type.\n        \n        Args:\n            node: The tree-sitter node to extract the name from.\n            \n        Returns:\n            The name of the node, or None if no name could be found.\n        \"\"\"\n        if node.type == \"function_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"class_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"variable_declarator\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"import_statement\":\n            # This is a more complex case - for now, we'll use a simplified approach\n            # Extract the module name from the import statement\n            # e.g., in \"import foo from 'bar'\", we want \"foo\"\n            # This is a simplified implementation and might need refinement\n            import_clause = None\n            for child in node.children:\n                if child.type == \"import_clause\":\n                    import_clause = child\n                    break\n            \n            if import_clause:\n                # Check for a simple identifier\n                for child in import_clause.children:\n                    if child.type == \"identifier\":\n                        return child.text.decode(\"utf-8\")\n                    elif child.type == \"named_imports\":\n                        # Handle named imports like { foo, bar }\n                        # For simplicity, we'll just return a placeholder\n                        # A more complete implementation would extract all names\n                        return f\"import_from_{hash(node.text.decode('utf-8')) % 10000}\"\n        \n        return None\n\n    def _find_node_by_position(self, start_point: Tuple[int, int], \n                              end_point: Optional[Tuple[int, int]] = None) -> Optional[tree_sitter.Node]:\n        \"\"\"\n        Finds a node in the tree that corresponds to a given range.\n        \n        Args:\n            start_point: A (row, column) tuple indicating the start position.\n            end_point: A (row, column) tuple indicating the end position.\n            \n        Returns:\n            The tree-sitter node that corresponds to the range, or None if not found.\n        \"\"\"\n        if not self.tree:\n            return None\n            \n        # A simple approach: find the smallest node that contains the range\n        # This is a simplified implementation and might need refinement\n        def contains_range(node):\n            node_start = (node.start_point[0], node.start_point[1])\n            node_end = (node.end_point[0], node.end_point[1])\n            if end_point:\n                return (node_start <= start_point and node_end >= end_point)\n            else:\n                return node_start <= start_point <= node_end\n        \n        # Walk the tree to find matching nodes\n        stack = [self.tree.root_node]\n        candidates = []\n        \n        while stack:\n            current_node = stack.pop()\n            if contains_range(current_node):\n                candidates.append(current_node)\n                # Add children to continue searching for smaller nodes\n                stack.extend(current_node.children)\n        \n        # Return the smallest (last) candidate\n        return candidates[-1] if candidates else None\n    \n    def _get_line_info_from_point(self, point: Tuple[int, int]) -> Dict[str, Any]:\n        \"\"\"\n        Converts a tree-sitter point to line information.\n        \n        Args:\n            point: A (row, column) tuple from tree-sitter.\n            \n        Returns:\n            A dictionary with line_start and line_end information.\n        \"\"\"\n        # Tree-sitter uses 0-based indexing for rows\n        return {\n            'line_start': point[0] + 1,  # Convert to 1-based\n            'line_end': point[0] + 1\n        }\n\n    def _reparse_tree(self, new_source: str) -> None:\n        \"\"\"\n        Re-parses the tree with new source code.\n        \n        This is necessary because tree-sitter trees are immutable.\n        \n        Args:\n            new_source: The new source code to parse.\n        \"\"\"\n        self.source_code = new_source\n        self.tree = self.parser.parse(bytes(new_source, \"utf-8\"))\n        self.nodes = self._map_nodes()\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return node.text.decode(\"utf-8\")\n            except Exception:\n                # Handle potential decoding issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.type,\n            'line_start': node.start_point[0] + 1,  # Convert to 1-based\n            'line_end': node.end_point[0] + 1,\n            'body_items': []\n        }\n\n        # Add body items for functions and classes\n        if node.type in (\"function_declaration\", \"class_declaration\"):\n            # Find the body block\n            body_node = None\n            for child in node.children:\n                if child.type == \"statement_block\":\n                    body_node = child\n                    break\n            \n            if body_node:\n                # Process statements in the body\n                for i, item in enumerate(body_node.children):\n                    # Skip '{' and '}' tokens\n                    if item.type in (\"{\", \"}\"):\n                        continue\n                    \n                    item_info = {\n                        'index': i,\n                        'type': item.type,\n                        'line_start': item.start_point[0] + 1,\n                        'line_end': item.end_point[0] + 1\n                    }\n                    \n                    # Add more specific information based on type\n                    if item.type == \"variable_declaration\":\n                        item_info['declares'] = \"variable\"\n                    elif item.type == \"return_statement\":\n                        item_info['returns'] = True\n                    elif item.type in (\"if_statement\", \"for_statement\", \"while_statement\"):\n                        item_info['has_body'] = True\n                    \n                    structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n            \n        # A simplified approach to extracting a snippet by line numbers\n        # This would need to be more sophisticated for production use\n        source_lines = self.source_code.split('\\n')\n        # Adjust for 0-based indexing\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(source_lines), line_end)\n        \n        if start_idx < end_idx:\n            return '\\n'.join(source_lines[start_idx:end_idx])\n        \n        return None\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Replace the node's text in the source code\n        new_source = self.source_code[:start_byte] + new_code + self.source_code[end_byte:]\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass  # If we can't even re-parse the original, we're in trouble\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree:\n            return False\n            \n        # For simplicity, we'll add the new code at the end of the file\n        # A more sophisticated implementation would handle the anchor and positioning\n        new_source = self.source_code.rstrip() + \"\\n\\n\" + new_code + \"\\n\"\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Find the full lines that contain the node\n        # This is a simplified approach to avoid leaving partial lines\n        source_lines = self.source_code.split('\\n')\n        start_line = node.start_point[0]\n        end_line = node.end_point[0]\n        \n        # Create new source without those lines\n        new_lines = source_lines[:start_line] + source_lines[end_line+1:]\n        new_source = '\\n'.join(new_lines)\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        # This is a complex operation that would require more sophisticated\n        # tree navigation and manipulation than what's shown here.\n        # For now, we'll provide a basic implementation.\n        \n        node = self.nodes.get(element_name)\n        if not node:\n            return False\n            \n        # Handle line-based replacement\n        if line_start is not None:\n            # Convert to 0-based indexing\n            start_idx = max(0, line_start - 1)\n            end_idx = line_end if line_end is not None else start_idx + 1\n            \n            source_lines = self.source_code.split('\\n')\n            if start_idx < len(source_lines):\n                # Replace the specified lines\n                end_idx = min(end_idx, len(source_lines))\n                new_lines = source_lines[:start_idx] + [new_code] + source_lines[end_idx:]\n                new_source = '\\n'.join(new_lines)\n                \n                # Re-parse the tree with the new source\n                try:\n                    self._reparse_tree(new_source)\n                    return True\n                except Exception:\n                    # If parsing fails, revert to the original source\n                    try:\n                        self._reparse_tree(self.source_code)\n                    except Exception:\n                        pass\n        \n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        # For tree-sitter, the source code is already maintained separately\n        return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        \n        # Ensure line endings are consistent for diffing\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/javascript_ast_adapter.py"
  },
  {
    "id": 118,
    "hash": "89fa0c06ca34019316daa58ce8fa9a20",
    "content": "import json\nimport os\nfrom typing import List, Dict, Optional\nfrom rag_manager import RAGManager\n\n\nclass MemoryManager:\n    \"\"\"Manages persistent chat memory, look data, and RAG integration via JSON.\"\"\"\n\n    def __init__(self, memory_file: str):\n        self.memory_file = memory_file\n        self.memory: Dict[str, List] = self.load_memory()\n        self.rag_manager = RAGManager()\n\n    def load_memory(self) ->Dict[str, List]:\n        try:\n            with open(self.memory_file, 'r') as f:\n                return json.load(f)\n        except FileNotFoundError:\n            default = {'chat': [], 'look': []}\n            self.save_memory(default)\n            return default\n        except json.JSONDecodeError:\n            print('[yellow]Invalid memory file. Resetting.[/]')\n            return {'chat': [], 'look': []}\n\n    def save_memory(self, memory: Optional[Dict[str, List]]=None) ->None:\n        if memory is None:\n            memory = self.memory\n        with open(self.memory_file, 'w') as f:\n            json.dump(memory, f, indent=4)\n\n    def add_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.memory['chat'].append({'role': role, 'content': content})\n        self.save_memory()\n\n    def add_chat_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        This is an alias for add_message to maintain compatibility.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.add_message(role, content)\n\n    def add_look_data(self, file_path: str, content: str) ->None:\n        \"\"\"\n    Adds a watched item (directory or file) to memory, distinguishing its type.\n\n    This method stores structured data that differentiates between a project\n    directory (containing a manifest) and a single file (containing its content).\n    It also prevents duplicate entries by updating existing ones.\n\n    Args:\n        file_path: The path to the directory or file.\n        content: The manifest for a directory or the content for a file.\n    \"\"\"\n        item_type = 'directory' if os.path.isdir(file_path) else 'file'\n        for item in self.memory['look']:\n            if item.get('file') == file_path:\n                item['content'] = content\n                item['type'] = item_type\n                self.save_memory()\n                return\n        self.memory['look'].append({'type': item_type, 'file': file_path,\n            'content': content})\n        self.save_memory()\n        if item_type == 'file':\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    file_content = f.read()\n                self.rag_manager.add_documents([file_content], [{'file':\n                    file_path}])\n            except Exception as e:\n                print(\n                    f'[yellow]Warning: Could not add {file_path} to RAG index: {e}[/]'\n                    )\n\n    def get_project_root(self) ->Optional[str]:\n        \"\"\"\n        Finds the root directory of the project currently in memory.\n\n        The project root is defined as the first item in the 'look' memory\n        that is of type 'directory'.\n\n        Returns:\n            The absolute path to the project root directory, or None if not found.\n        \"\"\"\n        for item in self.memory.get('look', []):\n            if item.get('type') == 'directory':\n                return item.get('file')\n        return None\n\n    def get_memory_context(self) ->str:\n        \"\"\"\n        Dynamically builds the context using RAG and chat history.\n\n        It retrieves relevant file content from the RAG index based on the latest\n        user query, includes project manifests for directories, and appends the\n        recent chat history.\n        \"\"\"\n        context = ''\n        for look in self.memory.get('look', []):\n            path = look.get('file')\n            if path and os.path.isdir(path):\n                content = look.get('content', '')\n                context += (\n                    f'--- Project Manifest for {path} ---\\n{content}\\n\\n')\n        last_user_message = next((msg['content'] for msg in reversed(self.\n            memory.get('chat', [])) if msg['role'] == 'user'), None)\n        if last_user_message:\n            rag_results = self.search_rag(last_user_message, k=3)\n            if rag_results:\n                context += '--- Relevant context from RAG ---\\n'\n                for doc, score, meta in rag_results:\n                    file_path = meta.get('file', 'Unknown source')\n                    context += f'Source: {file_path} (Score: {score:.4f})\\n'\n                    context += f'Content: {doc}\\n---\\n'\n                context += '\\n'\n        for msg in self.memory.get('chat', []):\n            context += f\"{msg['role'].capitalize()}: {msg['content']}\\n\"\n        return context.strip()\n\n    def clear_memory(self) ->None:\n        self.memory = {'chat': [], 'look': []}\n        self.save_memory()\n        self.rag_manager.clear_index()\n\n    def search_rag(self, query: str, k: int=3) ->List[tuple]:\n        \"\"\"\n        Search the RAG index for relevant documents.\n        \n        Args:\n            query: The search query\n            k: Number of results to return\n            \n        Returns:\n            List of (document_content, score, metadata) tuples\n        \"\"\"\n        return self.rag_manager.search(query, k)\n",
    "file": "/mnt/ProjectData/omni/memory_manager.py"
  },
  {
    "id": 119,
    "hash": "c71ec060a0d980ebd390a8ae427c7a7c",
    "content": "\"\"\"\nOmni - AI-powered code generation and project-aware editing CLI tool\n\nIntegrates modular UI, memory, personality, and AST-based code editing.\n\"\"\"\nimport os\nimport subprocess\nimport requests\nimport json\nimport sys\nimport re\nimport argparse\nimport ast\nfrom datetime import datetime\nimport threading\nimport queue as Queue\nimport time\nfrom typing import List, Dict, Optional\nfrom rich import print\nfrom rich.panel import Panel\nfrom rich.console import Console\nfrom rich.tree import Tree\nfrom ui_manager import UIManager\nfrom personality_manager import PersonalityManager\nfrom memory_manager import MemoryManager\nfrom code_editor import CodeEditor\nfrom file_creator import FileCreator\nfrom git_manager import GitManager\nimport traceback\nDEFAULT_BACKEND = 'openrouter'\nOLLAMA_MODEL = 'phi4-reasoning'\nOPENROUTER_MODEL = 'qwen/qwen3-coder'\nDEFAULT_SAVE_DIR = os.path.expanduser('/mnt/ProjectData/omni/omni_saves/')\nCONFIG_FILE = 'config.json'\nMEMORY_FILE = 'memory.json'\nOLLAMA_API_URL = 'http://localhost:11434/api/generate'\nOPENROUTER_API_URL = 'https://openrouter.ai/api/v1/chat/completions'\nOPENROUTER_MODELS_API_URL = 'https://openrouter.ai/api/v1/models'\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\ncurrent_backend = DEFAULT_BACKEND\ncurrent_model = (OLLAMA_MODEL if DEFAULT_BACKEND == 'ollama' else\n    OPENROUTER_MODEL)\nOLLAMA_MODELS = {'deepseek': 'deepseek-coder:6.7b', 'codellama':\n    'codellama:13b', 'mistral': 'mistral:latest', 'llama2': 'llama2:latest',\n    'phind': 'phind-codellama:34b'}\nos.makedirs(DEFAULT_SAVE_DIR, exist_ok=True)\nTEMPLATES = {'flask':\n    \"\"\"from flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/')\ndef home():\n    return '<h1>Hello, Flask!</h1>'\n\nif __name__ == '__main__':\n    app.run(debug=True)\"\"\"\n    , 'html5':\n    \"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>New Page</title>\n</head>\n<body>\n    <h1>Hello World</h1>\n</body>\n</html>\"\"\"\n    , 'scraper':\n    \"\"\"import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        print(soup.title.text)\n    except Exception as e:\n        print(f\"[bold red]Error scraping {url}:[/] {e}\")\n\nif __name__ == \"__main__\":\n    scrape(\"https://example.com\")\"\"\"\n    }\nconsole = Console()\npersonality_manager = PersonalityManager(CONFIG_FILE)\nmemory_manager = MemoryManager(MEMORY_FILE)\nui_manager = UIManager()\nlast_query: Optional[str] = None\nlast_response: Optional[str] = None\nlast_code: Optional[str] = None\n\n\ndef start_ollama_server() ->None:\n    if current_backend != 'ollama':\n        return\n    try:\n        requests.get('http://localhost:11434', timeout=1)\n    except requests.exceptions.ConnectionError:\n        print('[cyan]Starting Ollama server...[/]')\n        subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL)\n\n\ndef query_llm(prompt: str) ->str:\n    personality = personality_manager.get_current_personality()\n    system_prompt = personality.get('system_prompt', '') if personality else ''\n    memory_context = memory_manager.get_memory_context()\n    rag_context = ''\n    try:\n        from rag_manager import RAGManager\n        project_root = memory_manager.get_project_root()\n        if project_root:\n            rag_manager = RAGManager()\n            if rag_manager.get_document_count() > 0:\n                results = rag_manager.search(prompt, k=3)\n                if results:\n                    rag_context = '\\n\\nRelevant context from codebase:\\n'\n                    for i, (doc, score, meta) in enumerate(results, 1):\n                        file_path = meta.get('file', 'Unknown')\n                        rag_context += f'{i}. [{file_path}] {doc}\\n'\n    except Exception:\n        pass\n    full_prompt = (\n        f'{system_prompt}\\n\\n{memory_context}{rag_context}\\n\\nUser: {prompt}')\n    with ui_manager.show_spinner('AI is listening and thinking...'):\n        if current_backend == 'ollama':\n            response = query_ollama(full_prompt)\n        elif current_backend == 'openrouter':\n            response = query_openrouter(full_prompt)\n        else:\n            response = '[bold red]Error:[/] Unknown backend'\n    return response\n\n\ndef query_openrouter(prompt: str) ->str:\n    if not OPENROUTER_API_KEY:\n        return '[bold red]Error:[/] OPENROUTER_API_KEY not set.'\n    headers = {'Authorization': f'Bearer {OPENROUTER_API_KEY}',\n        'Content-Type': 'application/json'}\n    payload = {'model': current_model, 'messages': [{'role': 'user',\n        'content': prompt}]}\n    try:\n        response = requests.post(OPENROUTER_API_URL, headers=headers, json=\n            payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['choices'][0]['message']['content']\n    except Exception as e:\n        error_details = ''\n        try:\n            error_details = response.json()\n        except:\n            error_details = response.text if hasattr(response, 'text'\n                ) else str(e)\n        return (\n            f'[bold red]OpenRouter Error:[/] {e}\\n[dim]Details: {error_details}[/dim]'\n            )\n\n\ndef query_ollama(prompt: str) ->str:\n    payload = {'model': current_model, 'prompt': prompt, 'stream': False}\n    try:\n        response = requests.post(OLLAMA_API_URL, json=payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['response']\n    except Exception as e:\n        return f'[bold red]Ollama Error:[/] {e}'\n\n\ndef extract_code(text: str) ->List[tuple[str, str]]:\n    matches = re.findall('```(\\\\w*)\\\\n([\\\\s\\\\S]*?)```', text)\n    return [(lang or 'text', code.strip()) for lang, code in matches\n        ] if matches else []\n\n\ndef list_models(args: list=None) ->None:\n    if current_backend == 'ollama':\n        print('[bold cyan]Popular Ollama Models:[/]')\n        for name, model_id in OLLAMA_MODELS.items():\n            print(\n                f\"{'\u2b50' if model_id == current_model else '  '} [yellow]{name:12}[/] \u2192 {model_id}\"\n                )\n    elif current_backend == 'openrouter':\n        list_openrouter_models(args or [])\n\n\ndef list_openrouter_models(args: list):\n    try:\n        from simple_term_menu import TerminalMenu\n    except ImportError:\n        ui_manager.show_error(\n            \"'simple-term-menu' is required. `pip install simple-term-menu`\")\n        return\n    try:\n        with ui_manager.show_spinner('Fetching models...'):\n            response = requests.get(OPENROUTER_MODELS_API_URL)\n            response.raise_for_status()\n        api_models_data = response.json().get('data', [])\n    except requests.RequestException as e:\n        ui_manager.show_error(f'Error fetching models: {e}')\n        return\n    all_models, sources = [], set()\n    for model_data in api_models_data:\n        if (model_id := model_data.get('id')):\n            sources.add(model_id.split('/')[0])\n            pricing = model_data.get('pricing', {})\n            is_free = pricing.get('prompt') == '0' and pricing.get('completion'\n                ) == '0'\n            all_models.append({'id': model_id, 'name': model_data.get(\n                'name'), 'source': model_id.split('/')[0], 'is_free': is_free})\n    all_models.sort(key=lambda x: (x['source'], x['name']))\n    if args and args[0].lower() == 'sources':\n        print('[bold cyan]Available Model Sources:[/]')\n        [print(f'  [yellow]{s}[/]') for s in sorted(list(sources))]\n        return\n    models_to_display, title = all_models, 'Select an OpenRouter Model'\n    if args:\n        filter_keyword = args[0].lower()\n        title = f\"Select a Model from '{filter_keyword}'\"\n        models_to_display = [m for m in all_models if filter_keyword in m[\n            'source'].lower()]\n        if not models_to_display:\n            ui_manager.show_error(f\"No models for source: '{filter_keyword}'\")\n            return\n    menu_entries = [\n        f\"{'\u2b50' if m['id'] == current_model else '  '} {m['name']} [dim]({m['id']}){' [green](FREE)[/]' if m['is_free'] else ''}[/dim]\"\n         for m in models_to_display]\n    try:\n        cursor_idx = next((i for i, m in enumerate(models_to_display) if m[\n            'id'] == current_model), 0)\n        chosen_index = TerminalMenu(menu_entries, title=f'{title}',\n            cursor_index=cursor_idx, cycle_cursor=True, clear_screen=True\n            ).show()\n        if chosen_index is not None:\n            set_model(models_to_display[chosen_index]['id'])\n        else:\n            print('Model selection cancelled.')\n    except Exception as e:\n        ui_manager.show_error(f'Menu display error: {e}')\n\n\ndef set_model(model_id: str) ->None:\n    global current_model\n    current_model = model_id\n    ui_manager.show_success(f'Model set to: {current_model}')\n\n\ndef switch_backend(backend_name: str) ->None:\n    global current_backend, current_model\n    backend_name = backend_name.lower()\n    if backend_name not in ['ollama', 'openrouter']:\n        ui_manager.show_error(f'Unknown backend: {backend_name}')\n        return\n    current_backend = backend_name\n    current_model = (OLLAMA_MODEL if backend_name == 'ollama' else\n        OPENROUTER_MODEL)\n    ui_manager.show_success(\n        f'Switched to {backend_name} backend with model: {current_model}')\n    if backend_name == 'ollama':\n        start_ollama_server()\n\n\ndef generate_project_manifest(path: str) ->tuple[str, List[str]]:\n    manifest = ''\n    file_paths = []\n    tree = Tree(f'[bold cyan]Project: {os.path.basename(path)}[/]')\n    exclude_dirs = {'__pycache__', '.git', 'venv', 'node_modules', '.idea',\n        'ollama'}\n    for root, dirs, files in os.walk(path):\n        dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.\n            startswith('.')]\n        relative_path = os.path.relpath(root, path)\n        branch = tree\n        if relative_path != '.':\n            parts = relative_path.split(os.sep)\n            for part in parts:\n                child = next((c for c in branch.children if c.label ==\n                    f'[magenta]{part}[/]'), None)\n                if not child:\n                    child = branch.add(f'[magenta]{part}[/]')\n                branch = child\n        for fname in sorted(files):\n            ext = os.path.splitext(fname)[1]\n            if ext not in ('.py', '.js', '.html', '.css', '.md', '.txt'):\n                continue\n            rel_path = os.path.join(relative_path, fname\n                ) if relative_path != '.' else fname\n            file_paths.append(rel_path)\n            branch.add(f'[green]{fname}[/]' if ext == '.py' else\n                f'[dim]{fname}[/]')\n            manifest += f'File: {rel_path}\\n\\n'\n    console.print(tree)\n    return manifest.strip(), file_paths\n\n\ndef look_command(path: str) ->None:\n    \"\"\"\n    Scans a directory or file and loads it into memory. It can resolve paths\n    relative to the current working directory or the project root in memory.\n    If a new directory is scanned, the previous 'look' context is cleared\n    to ensure the context remains relevant.\n    \"\"\"\n    resolved_path = resolve_file_path(path)\n    if not resolved_path:\n        ui_manager.show_error(f'\u274c Path not found: {path}')\n        return\n    if resolved_path != os.path.abspath(path):\n        ui_manager.show_success(\n            f\"Found '{path}' in project. Using: {resolved_path}\")\n    if os.path.isdir(resolved_path):\n        ui_manager.show_success(\n            \"New project directory detected. Clearing previous 'look' context.\"\n            )\n        memory_manager.memory['look'] = []\n        with ui_manager.show_spinner('Generating project manifest...'):\n            manifest = generate_project_manifest(resolved_path)\n        memory_manager.add_look_data(resolved_path, manifest)\n        ui_manager.show_success('\u2705 Project manifest added to memory.')\n    else:\n        try:\n            with ui_manager.show_spinner('Loading file...'):\n                with open(resolved_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n            for item in memory_manager.memory['look']:\n                if item.get('file') == resolved_path:\n                    item['content'] = content\n                    memory_manager.save_memory()\n                    ui_manager.show_success(\n                        '\u2705 Refreshed file content in memory.')\n                    return\n            memory_manager.add_look_data(resolved_path, content)\n            ui_manager.show_success('\u2705 File content added to memory.')\n        except Exception as e:\n            ui_manager.show_error(f'\u274c Error reading file: {e}')\n\n\ndef resolve_file_path(path: str) ->Optional[str]:\n    \"\"\"Resolves a file path, checking CWD first, then against project root in memory.\"\"\"\n    if os.path.exists(path):\n        return os.path.abspath(path)\n    project_root = memory_manager.get_project_root()\n    if project_root:\n        full_path = os.path.join(project_root, path)\n        if os.path.exists(full_path):\n            return full_path\n    return None\n\n\ndef _create_prompt_for_file_creation(file_name: str, instruction: str) ->str:\n    \"\"\"\n    Generate a robust prompt for file creation that instructs the AI to act as an expert,\n    produce complete and clean code, and avoid any extra commentary.\n    \"\"\"\n    return f\"\"\"You are an expert programmer tasked with creating a new file. Your goal is to generate complete, production-ready content based on the user's instruction.\n\nIMPORTANT RULES:\n- Provide ONLY the raw file content - no explanations, notes, or commentary outside the file itself\n- Include all necessary imports, boilerplate, and complete implementations\n- If creating code, ensure it's syntactically correct and follows best practices\n- For configuration files, use appropriate formatting (JSON, YAML, etc.)\n- For documentation files, use proper markdown formatting\n\nFile to create: {file_name}\nUser instruction: {instruction}\n\nGenerate the complete file content now:\"\"\"\n\n\ndef handle_file_create_command(file_path: str, instruction: str):\n    \"\"\"\n    Uses the LLM to generate content for a new file based on an instruction.\n    \"\"\"\n    global last_code\n    if os.path.exists(file_path):\n        if ui_manager.get_user_input(\n            f\"File '{file_path}' already exists. Overwrite? (y/n): \").lower(\n            ) not in ['yes', 'y']:\n            ui_manager.show_error('File creation cancelled.')\n            return\n    prompt = _create_prompt_for_file_creation(os.path.basename(file_path),\n        instruction)\n    with ui_manager.show_spinner(\n        f\"AI is generating content for '{file_path}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    if code_blocks:\n        new_content = code_blocks[0][1]\n    else:\n        new_content = response.strip()\n    if not new_content:\n        ui_manager.show_error('AI did not return any content.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    print(Panel(new_content, title=\n        f'[bold yellow]Proposed content for {file_path}[/]', border_style=\n        'yellow'))\n    if ui_manager.get_user_input('Create this file? (y/n): ').lower() in ['yes'\n        , 'y']:\n        try:\n            FileCreator.create(file_path, new_content)\n            last_code = new_content\n            ui_manager.show_success(f'File created successfully: {file_path}')\n        except IOError as e:\n            ui_manager.show_error(f'Error creating file: {e}')\n    else:\n        ui_manager.show_error('File creation cancelled.')\n\n\ndef look_all_command() ->None:\n    \"\"\"\n    Finds the project manifest in memory, reads every file listed, and adds their content to memory.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first to generate a manifest.\"\n            )\n        return\n    manifest_data = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and item.get('type'\n            ) == 'directory':\n            manifest_data = item.get('content')\n            break\n    if not manifest_data or not isinstance(manifest_data, (list, tuple)\n        ) or len(manifest_data) != 2:\n        ui_manager.show_error(\n            \"Could not find a valid project manifest in memory. Please run 'look <directory>' again.\"\n            )\n        return\n    file_paths = manifest_data[1]\n    if not file_paths:\n        ui_manager.show_error('No files found in the project manifest.')\n        return\n    total_files = len(file_paths)\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Loading {total_files} files from project manifest...'):\n        for file_path_relative in file_paths:\n            full_path = os.path.join(project_root, file_path_relative)\n            if os.path.isfile(full_path):\n                try:\n                    with open(full_path, 'r', encoding='utf-8') as f:\n                        content = f.read().strip()\n                    if not any(look['file'] == full_path for look in\n                        memory_manager.memory['look']):\n                        memory_manager.add_look_data(full_path, content)\n                        loaded_count += 1\n                except Exception as e:\n                    print(\n                        f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\"\n                        )\n    ui_manager.show_success(\n        f'\u2705 Loaded content for {loaded_count} new files into memory.')\n\n\ndef _load_all_project_files_if_needed():\n    \"\"\"\n    Checks if a project is loaded and automatically loads any files from its\n    manifest that are not already in the 'look' memory. This ensures a\n    complete context for editing and refactoring commands.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        return\n    manifest_content = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and 'File:' in item.get('content',\n            ''):\n            manifest_content = item['content']\n            break\n    if not manifest_content:\n        return\n    existing_file_paths = {item['file'] for item in memory_manager.memory.\n        get('look', []) if item.get('type') == 'file'}\n    file_paths_relative = re.findall('File: (.*)', manifest_content)\n    files_to_load = []\n    for rel_path in file_paths_relative:\n        full_path = os.path.join(project_root, rel_path)\n        if full_path not in existing_file_paths and os.path.isfile(full_path):\n            files_to_load.append((full_path, rel_path))\n    if not files_to_load:\n        return\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Auto-loading {len(files_to_load)} project files for context...'):\n        for full_path, file_path_relative in files_to_load:\n            try:\n                with open(full_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n                memory_manager.add_look_data(full_path, content)\n                loaded_count += 1\n            except Exception as e:\n                print(f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\")\n    if loaded_count > 0:\n        ui_manager.show_success(\n            f'\u2705 Loaded {loaded_count} new file(s) into memory for full project context.'\n            )\n\n\ndef _create_prompt_for_element_selection(file_name: str, instruction: str,\n    elements: List[str], element_structures: Dict[str, Dict]) ->str:\n    \"\"\"\n    Create a helper for the first stage of the 'edit' command. This prompt asks the AI\n    to analyze the user's instruction and intelligently select the most relevant code element to modify.\n    \"\"\"\n    element_details = []\n    for elem in elements:\n        if elem in element_structures:\n            struct = element_structures[elem]\n            detail = (\n                f\"{elem} ({struct['type']}, lines {struct['line_start']}-{struct['line_end']})\"\n                )\n            element_details.append(detail)\n        else:\n            element_details.append(elem)\n    return f\"\"\"You are an expert code analyzer. Your task is to identify what should be modified based on the user's instruction.\n\nFile: {file_name}\nAvailable elements: {', '.join(element_details) if element_details else 'None'}\n\nUser instruction: {instruction}\n\nRESPONSE FORMAT:\nChoose one of these response types:\n1. \"ELEMENT: <element_name>\" - to edit an entire function/class\n2. \"PARTIAL: <element_name> LINES: <start>-<end>\" - to edit specific lines within an element\n3. \"FILE\" - to edit the entire file or multiple elements\n\nRULES:\n- If the instruction mentions specific line numbers or a specific part of a function, use PARTIAL\n- If the instruction targets an entire function/class, use ELEMENT\n- If the instruction requires changes to multiple elements or file structure, use FILE\n- For PARTIAL edits, provide absolute line numbers from the original file\n\nWhat should be edited?\"\"\"\n\n\ndef _create_prompt_for_element_rewrite(file_name: str, element_name: str,\n    instruction: str, original_code: str, is_full_file: bool=False) ->str:\n    \"\"\"\n    Create a helper for the second stage of the 'edit' command. This prompt instructs the AI\n    to rewrite a specific code element (or the whole file) based on the user's request,\n    demanding a complete and syntactically correct code block as output.\n    \"\"\"\n    if is_full_file:\n        return f\"\"\"You are an expert programmer. Rewrite the entire file to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the entire file\n- Ensure all syntax is correct and the code is ready to run\n- Preserve existing functionality unless explicitly asked to change it\n- Include all necessary imports and maintain the file's structure\n- Do NOT include any explanations or comments outside the code\n\nFile: {file_name}\nTask: {instruction}\n\nCurrent file content:\n```python\n{original_code}\n```\n\nGenerate the complete updated file now:\"\"\"\n    else:\n        return f\"\"\"You are an expert programmer. Rewrite the specified element to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the element\n- Include any necessary imports at the top of your code block\n- Ensure the code is syntactically correct and maintains the same interface\n- Do NOT include explanations or comments outside the code block\n- The code must be a drop-in replacement for the original element\n\nFile: {file_name}\nElement to modify: {element_name}\nTask: {instruction}\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the complete updated element now:\"\"\"\n\n\ndef _create_prompt_for_partial_edit(file_name: str, element_name: str,\n    instruction: str, original_snippet: str, line_start: int, line_end: int,\n    full_element_code: str) ->str:\n    \"\"\"\n    Create a prompt for partial edits within a function or class.\n    This allows surgical changes to specific parts of code.\n    \"\"\"\n    return f\"\"\"You are an expert programmer. Make a surgical edit to a specific part of a function/class.\n\nCONTEXT:\n- File: {file_name}\n- Element: {element_name}\n- Lines to modify: {line_start}-{line_end}\n- Task: {instruction}\n\nIMPORTANT RULES:\n- Provide ONLY the code that will replace lines {line_start}-{line_end}\n- Your code must fit seamlessly into the existing function\n- Maintain proper indentation (the code will be auto-indented)\n- Do NOT include the function definition or other parts\n- Do NOT include explanations outside the code\n\nFull element for context:\n```python\n{full_element_code}\n```\n\nCode section to replace (lines {line_start}-{line_end}):\n```python\n{original_snippet}\n```\n\nGenerate ONLY the replacement code for the specified lines:\"\"\"\n\n\ndef handle_file_edit_command(file_path: str, instruction: str):\n    \"\"\"\n    Handles the entire workflow for editing a single file, ensuring full\n    project context is loaded before the AI makes any decisions.\n    Now supports partial edits within functions.\n    \"\"\"\n    global last_code\n    _load_all_project_files_if_needed()\n    resolved_path = resolve_file_path(file_path)\n    if not resolved_path:\n        ui_manager.show_error(f'File not found: {file_path}')\n        return\n    if resolved_path != os.path.abspath(file_path):\n        ui_manager.show_success(\n            f\"Found '{file_path}' in project. Using: {resolved_path}\")\n    try:\n        editor = CodeEditor(resolved_path)\n    except (ValueError, FileNotFoundError) as e:\n        ui_manager.show_error(str(e))\n        return\n    elements = editor.list_elements()\n    element_structures = {}\n    for elem in elements:\n        struct = editor.get_element_structure(elem)\n        if struct:\n            element_structures[elem] = struct\n    prompt1 = _create_prompt_for_element_selection(os.path.basename(\n        resolved_path), instruction, elements, element_structures)\n    with ui_manager.show_spinner('AI is analyzing file...'):\n        ai_response = query_llm(prompt1).strip()\n    if ai_response.upper() == 'FILE':\n        ui_manager.show_success('AI has chosen to edit the entire file.')\n        original_snippet = editor.source_code\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), 'entire file', instruction, original_snippet,\n            is_full_file=True)\n        edit_type = 'FILE'\n        element_to_edit = None\n        line_range = None\n    elif ai_response.startswith('PARTIAL:'):\n        parts = ai_response.split()\n        element_to_edit = parts[1]\n        if 'LINES:' in ai_response:\n            line_part = ai_response.split('LINES:')[1].strip()\n            if '-' in line_part:\n                line_start, line_end = map(int, line_part.split('-'))\n                line_range = line_start, line_end\n            else:\n                ui_manager.show_error('Invalid line range format')\n                return\n        else:\n            ui_manager.show_error('Missing line range for partial edit')\n            return\n        if element_to_edit not in elements:\n            ui_manager.show_error(f\"Element '{element_to_edit}' not found\")\n            return\n        ui_manager.show_success(\n            f\"AI selected partial edit of '{element_to_edit}' (lines {line_start}-{line_end})\"\n            )\n        original_snippet = editor.get_element_body_snippet(element_to_edit,\n            line_start, line_end)\n        if not original_snippet:\n            original_snippet = editor.get_source_of(element_to_edit)\n        full_element_code = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_partial_edit(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet,\n            line_start, line_end, full_element_code)\n        edit_type = 'PARTIAL'\n    elif ai_response.startswith('ELEMENT:'):\n        element_to_edit = ai_response.split(':', 1)[1].strip()\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    else:\n        element_to_edit = ai_response.splitlines()[0]\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    with ui_manager.show_spinner(f'AI is editing...'):\n        response = query_llm(prompt2)\n    code_blocks = extract_code(response)\n    if not code_blocks:\n        ui_manager.show_error('AI did not return a valid code block.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    new_code = code_blocks[0][1]\n    success = False\n    if edit_type == 'FILE':\n        try:\n            editor.tree = ast.parse(new_code)\n            success = True\n        except SyntaxError as e:\n            ui_manager.show_error(f'AI returned invalid Python syntax: {e}')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    elif edit_type == 'PARTIAL':\n        success = editor.replace_partial(element_to_edit, new_code,\n            line_start=line_range[0], line_end=line_range[1])\n        if not success:\n            ui_manager.show_error('Failed to apply partial edit.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    else:\n        success = editor.replace_element(element_to_edit, new_code)\n        if not success:\n            ui_manager.show_error(\n                'AI returned invalid code; could not be parsed or applied.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    if not (diff := editor.get_diff()):\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(diff, title=\n        f'[bold yellow]Proposed Changes for {resolved_path}[/]'))\n    if ui_manager.get_user_input('Apply changes? (y/n): ').lower() in ['yes',\n        'y']:\n        editor.save_changes()\n        last_code = editor.get_modified_source()\n        ui_manager.show_success(f'Changes saved to {resolved_path}.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_plan(instruction: str, memory_context: str\n    ) ->str:\n    \"\"\"\n    Create a specialized prompt-generation function for the 'refactor' command.\n    This prompt will explicitly define the required JSON structure for the plan\n    and instruct the AI to act as an expert project manager.\n    \"\"\"\n    return f\"\"\"You are an expert project manager and software architect. Analyze the project context and create a detailed refactoring plan.\n\nYour plan must be a valid JSON object with this exact structure:\n{{\n    \"actions\": [\n        {{\n            \"type\": \"MODIFY\" | \"CREATE\" | \"DELETE\" | \"PARTIAL\",\n            \"file\": \"relative/path/to/file.py\",\n            \"element\": \"function_or_class_name\",  // For MODIFY/DELETE/PARTIAL\n            \"element_name\": \"new_element_name\",    // For CREATE\n            \"line_start\": 10,                      // For PARTIAL only\n            \"line_end\": 20,                        // For PARTIAL only\n            \"reason\": \"Clear explanation of why this change is needed\",\n            \"description\": \"What this action will accomplish\",\n            \"anchor_element\": \"optional_anchor\",   // Optional for CREATE\n            \"position\": \"before\" | \"after\"         // Optional for CREATE\n        }}\n    ]\n}}\n\nACTION TYPES:\n- MODIFY: Change an entire function, class, or method\n- PARTIAL: Change specific lines within a function/class (requires line_start and line_end)\n- CREATE: Add new functions, classes, or files\n- DELETE: Remove functions, classes, variables, or imports\n\nRULES FOR YOUR PLAN:\n- Use PARTIAL when you only need to change a small part of a function\n- Use MODIFY when restructuring an entire function or class\n- Each action must have all required fields based on its type\n- File paths must be relative to the project root\n- Be specific and surgical - avoid unnecessary changes\n- Consider dependencies between changes\n- Order actions logically (e.g., create dependencies before using them)\n\n### Project Context ###\n{memory_context}\n\n### Refactoring Request ###\n{instruction}\n\nGenerate ONLY the JSON plan - no explanations or markdown:\"\"\"\n\n\ndef _get_refactor_plan(instruction: str) ->Optional[List[Dict]]:\n    \"\"\"\n    Generates a refactoring plan from the LLM.\n\n    This function encapsulates the logic for checking project context,\n    constructing a prompt, querying the LLM, and parsing the resulting\n    JSON plan for a refactoring task.\n\n    Args:\n        instruction: The user's high-level refactoring instruction.\n\n    Returns:\n        A list of action dictionaries if a valid plan is generated,\n        otherwise None.\n    \"\"\"\n    if not memory_manager.get_project_root():\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return None\n    memory_context = memory_manager.get_memory_context()\n    plan_prompt = _create_prompt_for_refactor_plan(instruction, memory_context)\n    with ui_manager.show_spinner('AI is creating an execution plan...'):\n        plan_str = query_llm(plan_prompt)\n    try:\n        match = re.search('\\\\{.*\\\\}', plan_str, re.DOTALL)\n        if not match:\n            raise ValueError('No JSON object found in the response.')\n        plan = json.loads(match.group(0))\n        actions = plan.get('actions', [])\n        if not actions:\n            raise ValueError(\"No 'actions' key found in plan or plan is empty.\"\n                )\n        return actions\n    except (json.JSONDecodeError, ValueError) as e:\n        ui_manager.show_error(f'AI failed to generate a valid plan: {e}')\n        print(Panel(plan_str, title=\"[yellow]AI's Invalid Plan Response[/]\",\n            border_style='yellow'))\n        return None\n\n\ndef _display_and_confirm_plan(plan: Dict) ->bool:\n    \"\"\"\n    Displays the generated execution plan to the user and asks for confirmation.\n\n    This helper function separates the UI interaction of plan confirmation from\n    the main refactoring logic.\n\n    Args:\n        plan: A dictionary, expected to contain an 'actions' key with a list of action dicts.\n\n    Returns:\n        True if the user confirms the plan, False otherwise.\n    \"\"\"\n    actions = plan.get('actions', [])\n    if not actions:\n        ui_manager.show_error('The generated plan is empty. Aborting.')\n        return False\n    ui_manager.show_success('AI has created a plan:')\n    for i, action in enumerate(actions):\n        action_type = action.get('type', 'N/A')\n        element = action.get('element') or action.get('element_name', 'N/A')\n        reason = action.get('reason') or action.get('description', '')\n        file_path = action.get('file', '')\n        if action_type == 'PARTIAL':\n            line_start = action.get('line_start', '?')\n            line_end = action.get('line_end', '?')\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} (lines {line_start}-{line_end}) - {reason}'\n                )\n        else:\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} - {reason}'\n                )\n    if ui_manager.get_user_input('\\nProceed with this plan? (y/n): ').lower(\n        ) in ['yes', 'y']:\n        return True\n    else:\n        ui_manager.show_error('Execution aborted by user.')\n        return False\n\n\ndef _apply_refactor_changes(editors: Dict[str, CodeEditor]) ->None:\n    \"\"\"\n    Consolidates changes from multiple CodeEditor instances, shows a unified\n    diff, and prompts the user to apply them.\n    \n    This helper function abstracts the final step of a refactor, ensuring\n    all proposed modifications are presented to the user for a final review\n    before any files are written to disk.\n\n    Args:\n        editors: A dictionary mapping absolute file paths to their\n                 corresponding CodeEditor instances which hold the\n                 proposed changes in their AST.\n    \"\"\"\n    full_diff = ''\n    for editor in editors.values():\n        diff = editor.get_diff()\n        if diff:\n            full_diff += diff + '\\n'\n    if not full_diff.strip():\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(full_diff, title=\n        '[bold yellow]Proposed Project-Wide Changes[/]'))\n    if ui_manager.get_user_input('Apply all changes? (y/n): ').lower() in [\n        'yes', 'y']:\n        for editor in editors.values():\n            editor.save_changes()\n        ui_manager.show_success('\u2705 Project changes applied successfully.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_action(action_type: str, file_path: str,\n    action_details: Dict) ->str:\n    \"\"\"\n    Create a helper to generate prompts for individual 'CREATE' or 'MODIFY' steps\n    within a refactor plan. This ensures the AI produces code for the specific\n    sub-task in the correct context.\n    \"\"\"\n    if action_type == 'MODIFY':\n        element_name = action_details['element_name']\n        reason = action_details['reason']\n        original_code = action_details['original_code']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- Element: {element_name}\n- Reason for change: {reason}\n\nRULES:\n- Provide ONLY the complete updated code for the element\n- Include any necessary imports at the top\n- Ensure the code integrates properly with the rest of the file\n- Maintain the same function/class signature unless the change requires otherwise\n- No explanations outside the code block\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the updated element code:\"\"\"\n    elif action_type == 'CREATE':\n        element_name = action_details['element_name']\n        description = action_details['description']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- New element to create: {element_name}\n- Purpose: {description}\n\nRULES:\n- Provide ONLY the complete code for the new element\n- Include all necessary imports at the top\n- Follow the coding style and patterns used in the project\n- Ensure the code is production-ready and well-structured\n- For non-Python files, provide the complete file content\n- No explanations outside the code block\n\nGenerate the new element code:\"\"\"\n\n\ndef _process_refactor_action(action: Dict, project_base_path: str, editors:\n    Dict) ->bool:\n    \"\"\"\n    Processes a single refactoring action from the plan.\n\n    This function handles the execution of a single action from the refactoring plan,\n    including LLM code generation and applying changes to in-memory editors or files.\n\n    Args:\n        action: A dictionary containing action details (type, file, element, etc.)\n        project_base_path: The absolute path to the project root\n        editors: Dictionary mapping file paths to their CodeEditor instances\n\n    Returns:\n        True if the action was processed successfully, False otherwise\n    \"\"\"\n    file_path_relative = action.get('file')\n    if not file_path_relative:\n        ui_manager.show_error(\n            f\"Action is missing 'file' key. Skipping: {action}\")\n        return False\n    file_path_absolute = os.path.join(project_base_path, file_path_relative)\n    action_type = action.get('type', '').upper()\n    prompt, element_name = '', ''\n    if action_type == 'MODIFY':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_source_of(element_name)\n            if not original_snippet:\n                ui_manager.show_error(\n                    f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                    )\n                return False\n            action_details = {'element_name': element_name, 'reason':\n                reason, 'original_code': original_snippet}\n            prompt = _create_prompt_for_refactor_action('MODIFY',\n                file_path_relative, action_details)\n    elif action_type == 'PARTIAL':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        line_start = action.get('line_start')\n        line_end = action.get('line_end')\n        if not all([element_name, line_start, line_end]):\n            ui_manager.show_error(\n                f'PARTIAL action missing required fields. Skipping: {action}')\n            return False\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_element_body_snippet(element_name,\n                line_start, line_end)\n            if not original_snippet:\n                original_snippet = editor.get_source_of(element_name)\n                if not original_snippet:\n                    ui_manager.show_error(\n                        f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                        )\n                    return False\n            full_element_code = editor.get_source_of(element_name)\n            prompt = _create_prompt_for_partial_edit(file_path_relative,\n                element_name, reason, original_snippet, line_start,\n                line_end, full_element_code)\n    elif action_type == 'CREATE':\n        element_name = action.get('element_name')\n        description = action.get('description')\n        action_details = {'element_name': element_name, 'description':\n            description}\n        prompt = _create_prompt_for_refactor_action('CREATE',\n            file_path_relative, action_details)\n    else:\n        ui_manager.show_error(f\"Invalid action type '{action_type}'. Skipping.\"\n            )\n        return False\n    with ui_manager.show_spinner(\n        f\"AI: {action_type} on '{element_name or file_path_relative}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    new_content = code_blocks[0][1] if code_blocks else response.strip()\n    if not new_content:\n        ui_manager.show_error(\n            f'AI failed to generate content for action: {action}')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return False\n    if not file_path_relative.endswith('.py'):\n        try:\n            FileCreator.create(file_path_absolute, new_content)\n            ui_manager.show_success(\n                f\"File '{file_path_relative}' created/updated.\")\n            return True\n        except IOError as e:\n            ui_manager.show_error(\n                f\"Failed to create file '{file_path_relative}': {e}\")\n            return False\n    if file_path_absolute not in editors:\n        try:\n            if not os.path.exists(file_path_absolute):\n                os.makedirs(os.path.dirname(file_path_absolute), exist_ok=True)\n                with open(file_path_absolute, 'w') as f:\n                    f.write('')\n            editors[file_path_absolute] = CodeEditor(file_path_absolute)\n        except Exception as e:\n            ui_manager.show_error(\n                f'Error loading file {file_path_absolute}: {e}')\n            return False\n    editor = editors[file_path_absolute]\n    if action_type == 'MODIFY':\n        if not editor.replace_element(element_name, new_content):\n            ui_manager.show_error(\n                f\"Failed to apply MODIFY change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic MODIFY Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'PARTIAL':\n        if not editor.replace_partial(element_name, new_content, line_start,\n            line_end):\n            ui_manager.show_error(\n                f\"Failed to apply PARTIAL change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic PARTIAL Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'CREATE':\n        anchor = action.get('anchor_element')\n        position = action.get('position', 'after')\n        if not editor.add_element(new_content, anchor_name=anchor, before=\n            position == 'before'):\n            ui_manager.show_error(\n                f\"Failed to apply CREATE change for '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic CREATE Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    return True\n\n\ndef handle_project_refactor_command(instruction: str):\n    \"\"\"\n    Orchestrates a multi-file, multi-step code refactoring process.\n    \n    This function serves as a high-level orchestrator that delegates specific tasks\n    to helper functions, improving readability, modularity, and maintainability.\n    \"\"\"\n    _load_all_project_files_if_needed()\n    actions = _get_refactor_plan(instruction)\n    if not actions:\n        return\n    plan = {'actions': actions}\n    if not _display_and_confirm_plan(plan):\n        return\n    editors: Dict[str, CodeEditor] = {}\n    project_base_path = memory_manager.get_project_root()\n    successful_actions = 0\n    total_actions = len(actions)\n    for i, action in enumerate(actions, 1):\n        ui_manager.show_success(f'Processing action {i}/{total_actions}...')\n        action_type = action.get('type', '').upper()\n        file_path_relative = action.get('file')\n        if not file_path_relative:\n            ui_manager.show_error(\n                f\"Action is missing 'file' key. Skipping: {action}\")\n            continue\n        file_path_absolute = os.path.join(project_base_path, file_path_relative\n            )\n        if action_type == 'DELETE':\n            element_name = action.get('element')\n            if not element_name:\n                ui_manager.show_error(\n                    f\"DELETE action missing 'element' key. Skipping: {action}\")\n                continue\n            if not file_path_relative.endswith('.py'):\n                ui_manager.show_error(\n                    f'DELETE actions are only supported for Python files. Skipping.'\n                    )\n                continue\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    continue\n            editor = editors[file_path_absolute]\n            if editor.delete_element(element_name):\n                successful_actions += 1\n                ui_manager.show_success(\n                    f\"Successfully deleted '{element_name}' from '{file_path_relative}'.\"\n                    )\n            else:\n                ui_manager.show_error(\n                    f\"Failed to delete '{element_name}' from '{file_path_relative}'.\"\n                    )\n        elif _process_refactor_action(action, project_base_path, editors):\n            successful_actions += 1\n        else:\n            ui_manager.show_error(\n                f'Action {i} failed, continuing with remaining actions...')\n    if successful_actions == 0:\n        ui_manager.show_error('No actions were successfully executed.')\n        return\n    elif successful_actions < total_actions:\n        ui_manager.show_error(\n            f'Only {successful_actions}/{total_actions} actions completed successfully.'\n            )\n    else:\n        ui_manager.show_success(\n            f'All {total_actions} actions completed successfully.')\n    _apply_refactor_changes(editors)\n\n\ndef _create_prompt_for_commit_message(diff: str) ->str:\n    \"\"\"\n    Create a dedicated prompt function for the 'commit' command. This prompt will\n    instruct the AI to analyze a git diff and generate a concise commit message\n    following the Conventional Commits standard.\n    \"\"\"\n    return f\"\"\"You are an expert developer writing a Git commit message. Your task is to analyze the provided git diff and create a professional commit message.\n\nCOMMIT MESSAGE RULES:\n- Follow the Conventional Commits specification\n- Format: <type>(<optional scope>): <subject>\n- Types: feat, fix, docs, style, refactor, perf, test, build, ci, chore, revert\n- Subject line: max 50 characters, imperative mood, no period\n- Optional body: explain what and why (not how), wrap at 72 characters\n- Be specific and concise\n- Focus on the intent and impact of the changes\n\nEXAMPLES OF GOOD COMMIT MESSAGES:\n- feat(auth): add OAuth2 integration for Google login\n- fix(api): handle null response in user endpoint\n- refactor(database): optimize query performance for large datasets\n- docs(readme): update installation instructions for Windows\n\nRespond with ONLY the commit message - no markdown, quotes, or explanations.\n\n--- GIT DIFF TO ANALYZE ---\n{diff}\n\nGenerate the commit message:\"\"\"\n\n\ndef handle_commit_command():\n    \"\"\"\n    Orchestrates an AI-assisted Git commit workflow with improved error handling.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return\n    try:\n        git_manager = GitManager(project_root)\n    except ValueError as e:\n        ui_manager.show_error(str(e))\n        return\n    changed_files = git_manager.get_changed_files()\n    if not changed_files:\n        ui_manager.show_success(\n            'No changes to commit. Everything is up to date.')\n        return\n    staged_diff = git_manager.get_diff(staged=True)\n    unstaged_diff = git_manager.get_diff()\n    full_diff = f'{staged_diff}\\n{unstaged_diff}'.strip()\n    if not full_diff.strip():\n        ui_manager.show_success(\n            'No content changes detected (e.g., only file mode changes).')\n        return\n    prompt = _create_prompt_for_commit_message(full_diff)\n    commit_message = query_llm(prompt).strip()\n    if not commit_message:\n        ui_manager.show_error(\n            'AI failed to generate a commit message. Aborting.')\n        return\n    files_to_commit_str = '\\n'.join(f'- {f}' for f in changed_files)\n    plan_panel_content = f\"\"\"[bold]Files to be staged:[/]\n[yellow]{files_to_commit_str}[/]\n\n[bold]AI-Generated Commit Message:[/]\n[green]{commit_message}[/]\"\"\"\n    print(Panel(plan_panel_content, title='[bold cyan]Commit Plan[/]',\n        border_style='cyan'))\n    if ui_manager.get_user_input('\\nProceed with commit? (y/n): ').lower() in [\n        'yes', 'y']:\n        try:\n            git_manager.add(changed_files)\n            ui_manager.show_success('\u2705 Files staged.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Staging failed: {e.stderr}')\n            return\n        try:\n            git_manager.commit(commit_message)\n            ui_manager.show_success('\u2705 Commit successful.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Commit failed: {e.stderr}')\n            return\n        if ui_manager.get_user_input('Push changes to remote? (y/n): ').lower(\n            ) in ['yes', 'y']:\n            try:\n                git_manager.push()\n                ui_manager.show_success('\u2705 Push successful.')\n            except subprocess.CalledProcessError as e:\n                ui_manager.show_error(f'Push failed: {e.stderr}')\n        else:\n            ui_manager.show_error('Push cancelled.')\n    else:\n        ui_manager.show_error('Commit aborted by user.')\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef interactive_mode() ->None:\n    global last_query, last_response, last_code\n    try:\n        from Testing.overlay_engine import show_sequential_popup\n        gui_available = True\n    except ImportError:\n        gui_available = False\n    print(Panel(\n        \"\"\"[bold cyan]Omni Interactive Mode[/]\n[dim]Type 'help' for commands, 'exit' to quit.[/dim]\"\"\"\n        , border_style='cyan'))\n    personality_name = personality_manager.get_current_personality().get('name'\n        , 'Default')\n    gui_enabled = False\n    if gui_available:\n        try:\n            with open(CONFIG_FILE, 'r') as f:\n                config = json.load(f)\n                if config.get('gui_enabled', False):\n                    gui_enabled = True\n        except (FileNotFoundError, json.JSONDecodeError):\n            pass\n    refresh_status_panel(personality_name)\n    while True:\n        try:\n            user_input = ui_manager.get_user_input('\\n> ')\n            if not user_input:\n                continue\n            command, *args = user_input.split(maxsplit=1)\n            arg_str = args[0] if args else ''\n            if command == 'exit':\n                memory_manager.save_memory()\n                print('[bold cyan]Goodbye![/]')\n                break\n            elif command == 'help':\n                print(\n                    \"\"\"[bold]Commands:[/]\n\n  [bold cyan]Core & Project Commands[/]\n  [yellow]send <prompt>[/]        - Ask the LLM a question.\n  [yellow]look <path>[/]          - Read file or scan directory into memory.\n  [yellow]look_all[/]            - Recursively scan the project directory into memory.\n  [yellow]create <file> \"instr\"[/] - Create a new file using AI.\n  [yellow]edit <file> \"instr\"[/]   - Edit a specific file using AI.\n  [yellow]refactor \"instr\"[/]      - Refactor project in memory based on instruction.\n  [yellow]commit[/]               - Commit changes with an AI-generated message.\n  [yellow]rag <query>[/]         - Query the RAG system for context retrieval.\n\n  [bold cyan]File & Code Management[/]\n  [yellow]save <filename>[/]     - Save last AI response to a file.\n  [yellow]list[/]               - List saved files.\n  [yellow]run[/]                 - Run the last generated Python code.\n\n  [bold cyan]Session & Config[/]\n  [yellow]history[/]             - Show the full chat history.\n  [yellow]memory clear[/]        - Clear the chat and file memory.\n  [yellow]backend <name>[/]      - Switch AI backend (e.g., openrouter, ollama).\n  [yellow]models [src][/]        - Interactively list and select models.\n  [yellow]set model <id>[/]      - Set the model directly by its ID.\n  [yellow]personality <cmd>[/]   - Manage AI personalities ('list', 'set', 'add').\n\"\"\"\n                    )\n            elif command == 'send':\n                last_query = arg_str\n                response = query_llm(arg_str)\n                last_response = response\n                memory_manager.add_chat_message('user', last_query)\n                memory_manager.add_chat_message('assistant', last_response)\n                if gui_enabled:\n                    threading.Thread(target=show_sequential_popup, args=(\n                        100, 100, response, f'Omni - {personality_name}'),\n                        daemon=True).start()\n                print(Panel(response, title='[cyan]Response[/]'))\n                if (code_blocks := extract_code(response)):\n                    last_code = code_blocks[0][1]\n            elif command == 'look':\n                look_command(arg_str)\n            elif command == 'look_all':\n                look_all_command()\n            elif command == 'create':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_create_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: create <file_path> \"<instruction>\"')\n            elif command == 'edit':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_edit_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: edit <file_path> \"<instruction>\"')\n            elif command == 'refactor':\n                if not arg_str:\n                    ui_manager.show_error('Usage: refactor \"<instruction>\"')\n                else:\n                    handle_project_refactor_command(arg_str.strip('\"'))\n            elif command == 'commit':\n                handle_commit_command()\n            elif command == 'models':\n                list_models(arg_str.split())\n            elif command == 'set' and arg_str.startswith('model '):\n                set_model(arg_str[6:])\n            elif command == 'backend':\n                switch_backend(arg_str)\n            elif command == 'history':\n                ui_manager.display_history(memory_manager.get_memory_context())\n            elif command == 'memory' and arg_str == 'clear':\n                memory_manager.clear_memory()\n                ui_manager.show_success('\u2705 Memory cleared')\n            elif command == 'personality':\n                p_args = arg_str.split(maxsplit=1)\n                cmd = p_args[0] if p_args else ''\n                p_arg_str = p_args[1] if len(p_args) > 1 else ''\n                if cmd == 'list':\n                    for p in personality_manager.list_personalities():\n                        print(f\"- {p['name']}: {p['description']}\")\n                elif cmd == 'set' and p_arg_str:\n                    if personality_manager.set_current_personality(p_arg_str):\n                        personality_name = p_arg_str\n                        ui_manager.show_success(\n                            f'Set personality to {personality_name}')\n                    else:\n                        ui_manager.show_error('Personality not found.')\n                else:\n                    ui_manager.show_error(\n                        \"Invalid personality command. Use 'list' or 'set <name>'.\"\n                        )\n            elif command == 'run':\n                run_python_code()\n            elif command == 'save':\n                if last_response:\n                    save_code(last_response, arg_str or\n                        f\"omni_save_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n                        )\n                else:\n                    ui_manager.show_error('No response to save.')\n            elif command == 'list':\n                files = sorted(os.listdir(DEFAULT_SAVE_DIR))\n                print('\\n'.join(f'  - {f}' for f in files) if files else\n                    '[yellow]No saved files.[/]')\n            elif command == 'rag':\n                if not arg_str:\n                    ui_manager.show_error('Usage: rag \"<query>\"')\n                else:\n                    from rag_manager import RAGManager\n                    project_root = memory_manager.get_project_root()\n                    if not project_root:\n                        ui_manager.show_error(\n                            \"No project context in memory. Use 'look <directory>' first.\"\n                            )\n                        continue\n                    rag = RAGManager()\n                    if rag.get_document_count() == 0:\n                        ui_manager.show_error(\n                            'RAG index is empty. Please add documents first.')\n                        continue\n                    results = rag.search(arg_str, k=3)\n                    if not results:\n                        ui_manager.show_error('No relevant documents found.')\n                        continue\n                    print(Panel('[bold]RAG Results:[/]', title=\n                        '[cyan]Retrieval-Augmented Generation[/]'))\n                    for i, (content, score, metadata) in enumerate(results, 1):\n                        file_path = metadata.get('file', 'Unknown')\n                        print(\n                            f'[bold cyan]{i}. {file_path}[/] (Score: {score:.4f})'\n                            )\n                        print(Panel(content[:500] + '...' if len(content) >\n                            500 else content, border_style='dim'))\n                    follow_up = ui_manager.get_user_input(\n                        \"\"\"\nWould you like to ask a follow-up question with this context? (y/n): \"\"\"\n                        )\n                    if follow_up.lower() in ['y', 'yes']:\n                        follow_up_query = ui_manager.get_user_input(\n                            'Follow-up query: ')\n                        if follow_up_query:\n                            context_parts = [\n                                f'Document {i} (Score: {score:.4f}):\\n{content}'\n                                 for i, (content, score, _) in enumerate(\n                                results, 1)]\n                            context = '\\n\\n'.join(context_parts)\n                            rag_prompt = f\"\"\"Based on the following context, please answer the question.\n\nContext:\n{context}\n\nQuestion: {follow_up_query}\"\"\"\n                            response = query_llm(rag_prompt)\n                            print(Panel(response, title=\n                                '[cyan]RAG-Augmented Response[/]'))\n            else:\n                ui_manager.show_error(\"Unknown command. Type 'help'.\")\n            refresh_status_panel(personality_name)\n        except KeyboardInterrupt:\n            memory_manager.save_memory()\n            print('\\n[bold cyan]Goodbye![/]')\n            break\n        except Exception as e:\n            ui_manager.show_error(f'An unexpected error occurred: {e}')\n\n\ndef run_python_code() ->None:\n    global last_code\n    if not last_code:\n        ui_manager.show_error('No Python code in memory to run.')\n        return\n    temp_file = os.path.join(DEFAULT_SAVE_DIR, 'temp_run.py')\n    try:\n        with open(temp_file, 'w') as f:\n            f.write(last_code)\n        print('[bold cyan]\\n--- Running Code ---\\n[/]')\n        subprocess.run([sys.executable, temp_file], check=True)\n        print('[bold cyan]\\n--- Code Finished ---\\n[/]')\n    except Exception as e:\n        ui_manager.show_error(f'Error running code: {e}')\n    finally:\n        if os.path.exists(temp_file):\n            os.remove(temp_file)\n\n\ndef save_code(content: str, filename: str) ->None:\n    filepath = os.path.join(DEFAULT_SAVE_DIR, filename)\n    try:\n        with open(filepath, 'w') as f:\n            f.write(content)\n        ui_manager.show_success(f'Saved to: {filepath}')\n    except IOError as e:\n        ui_manager.show_error(f'Error saving file: {e}')\n\n\ndef main() ->None:\n    try:\n        import astor\n    except ImportError:\n        print(\"[bold red]Error:[/] 'astor' is required. `pip install astor`\")\n        sys.exit(1)\n    try:\n        import simple_term_menu\n    except ImportError:\n        print(\n            \"[bold red]Error:[/] 'simple-term-menu' is required. `pip install simple-term-menu`\"\n            )\n        sys.exit(1)\n    parser = argparse.ArgumentParser(description=\n        'Omni - AI-powered code tool', add_help=False)\n    parser.add_argument('command', nargs='?', help='Main command.')\n    parser.add_argument('args', nargs='*', help='Arguments for the command.')\n    parser.add_argument('-h', '--help', action='store_true')\n    args, _ = parser.parse_known_args()\n    if args.help or not args.command:\n        interactive_mode()\n    elif args.command == 'look' and args.args:\n        look_command(args.args[0])\n    elif args.command == 'edit' and len(args.args) >= 2:\n        handle_file_edit_command(args.args[0], ' '.join(args.args[1:]))\n    elif args.command == 'models':\n        list_models(args.args)\n    else:\n        interactive_mode()\n\n\ndef refresh_status_panel(personality_name: str) ->None:\n    ui_manager.display_status_panel(personality_name, current_backend,\n        current_model, len(memory_manager.memory.get('chat', [])), len(\n        memory_manager.memory.get('look', [])))\n\n\nif __name__ == '__main__':\n    main()             ",
    "file": "/mnt/ProjectData/omni/omni.py"
  },
  {
    "id": 120,
    "hash": "db1585da7840e9dc17f3ab8c0a19f6f2",
    "content": "import json\nfrom typing import Dict, List, Optional\n\nclass PersonalityManager:\n    \"\"\"Manages AI personalities via JSON config.\"\"\"\n\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.personalities: List[Dict[str, str]] = self.load_personalities()\n        self.current_personality: Optional[str] = \"default\"  # Default\n\n    def load_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"Load personalities from JSON; auto-create if missing.\"\"\"\n        default = [{\"name\": \"default\", \"description\": \"Helpful assistant\", \"system_prompt\": \"You are a helpful AI assistant.\"}]\n        default_gui = {\n            \"gui_enabled\": True,\n            \"wake_word\": \"Jarvis\",\n            \"overlay_opacity\": 0.8,\n            \"font_size\": 16\n        }\n        try:\n            with open(self.config_file, 'r') as f:\n                data = json.load(f)\n                if \"personalities\" not in data:\n                    data[\"personalities\"] = default\n                if \"gui_enabled\" not in data:\n                    data.update(default_gui)\n                    self.save_personalities(data[\"personalities\"])  # Save with defaults\n                \n                return data[\"personalities\"]\n        except FileNotFoundError:\n            self.save_personalities(default)\n            return default\n        except json.JSONDecodeError:\n            print(\"[yellow]Invalid config. Resetting to default.[/]\")\n            self.save_personalities(default)\n            return default\n\n    def save_personalities(self, personalities: List[Dict[str, str]]) -> None:\n        \"\"\"Save with GUI config.\"\"\"\n        data = {\"personalities\": personalities}\n        data.update({\"gui_enabled\": True, \"wake_word\": \"Jarvis\", \"overlay_opacity\": 0.8, \"font_size\": 16})  # Defaults\n        with open(self.config_file, 'w') as f:\n            json.dump(data, f, indent=4)\n\n    def add_personality(self, name: str, description: str, system_prompt: str) -> None:\n        \"\"\"Add a new personality.\"\"\"\n        self.personalities.append({\"name\": name, \"description\": description, \"system_prompt\": system_prompt})\n        self.save_personalities(self.personalities)\n\n    def list_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"List all personalities.\"\"\"\n        return self.personalities\n\n    def set_current_personality(self, name: str) -> bool:\n        \"\"\"Set the current personality.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == name:\n                self.current_personality = name\n                return True\n        return False\n\n    def get_current_personality(self) -> Dict[str, str]:\n        \"\"\"Get the current personality dict.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == self.current_personality:\n                return p\n        return {}  # Fallback",
    "file": "/mnt/ProjectData/omni/personality_manager.py"
  },
  {
    "id": 121,
    "hash": "da963f141c557fe12f1a26374f3e5ff4",
    "content": "# python_ast_adapter.py\n\n\"\"\"\nPythonASTAdapter - Concrete AST adapter for Python using built-in `ast` and `astor`.\n\nThis module implements the ASTAdapter interface specifically for Python,\nleveraging the standard library's `ast` module for parsing and\nmanipulation, and `astor` for code generation.\n\"\"\"\n\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for asttokens (for enhanced partial edits)\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n    # print(\"Warning: asttokens not installed. Partial edits will be limited.\")\n\n\nclass PythonASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for Python source code.\n\n    This adapter uses Python's built-in `ast` module to parse and manipulate\n    the code, and `astor` for code generation and source-to-source transformations.\n    It holds the parsed AST tree and provides methods to interact with it\n    according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the PythonASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The Python source code as a string.\n        \"\"\"\n        # Store source code for diffing and potential asttokens use\n        self.source_code: str = source_code\n        # Will hold the parsed AST tree\n        self.tree: Optional[ast.AST] = None\n        # Will hold a mapping of element names to their AST nodes\n        self.nodes: Dict[str, ast.AST] = {}\n        # asttokens instance for enhanced source mapping (if available)\n        self.atok: Optional[asttokens.ASTTokens] = None\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the Python source code and maps elements.\n\n        Args:\n            source_code: The Python source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid Python syntax.\n        \"\"\"\n        try:\n            self.tree = ast.parse(source_code)\n        except SyntaxError as e:\n            raise ValueError(f\"Invalid Python syntax: {e}\") from e\n\n        self.nodes = self._map_nodes()\n        if ASTTOKENS_AVAILABLE:\n            try:\n                self.atok = asttokens.ASTTokens(source_code, parse=True)\n            except Exception:\n                # If asttokens fails for any reason, continue without it\n                self.atok = None\n        else:\n            self.atok = None\n\n    def _map_nodes(self) -> Dict[str, ast.AST]:\n        \"\"\"\n        Walks the AST and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their AST nodes.\n        \"\"\"\n        nodes: Dict[str, ast.AST] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        for node in ast.walk(self.tree):\n            # Map functions and classes by name\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                # Use 'not in' to prioritize top-level definitions in case of conflicts\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            # Map assignments by target variable name(s)\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            # Map imports by their alias or original name\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int, line_end: Optional[int] = None) -> Optional[Tuple[int, ast.AST]]:\n        \"\"\"\n        Finds a statement within a body based on line numbers.\n\n        Args:\n            body: The list of AST nodes representing the body.\n            line_start: The starting line number to search for.\n            line_end: The optional ending line number.\n\n        Returns:\n            A tuple of (index, statement node) if found, otherwise None.\n        \"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = getattr(stmt, 'end_lineno', stmt.lineno)\n                    # Check for overlap or containment\n                    if (stmt.lineno <= line_start <= stmt_end) or (stmt.lineno <= line_end <= stmt_end) or \\\n                       (line_start <= stmt.lineno and line_end >= stmt_end):\n                        return (i, stmt)\n                else:\n                    if stmt.lineno == line_start:\n                        return (i, stmt)\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.ImportFrom]]) -> None:\n        \"\"\"\n        Adds new import nodes to the file's AST, typically at the top.\n\n        Args:\n            new_import_nodes: A list of ast.Import or ast.ImportFrom nodes.\n        \"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return # Cannot add imports without a valid module tree\n\n        # Get string representations of existing imports to avoid duplicates\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                try:\n                    existing_imports_str.add(astor.to_source(node).strip())\n                except Exception:\n                    # If astor fails, skip adding to set (might lead to potential duplicate, but safer)\n                    pass\n                last_import_index = i\n\n        # Insert new imports after the last existing import\n        # Reverse them so they are inserted in the correct order\n        for new_import in reversed(new_import_nodes):\n            try:\n                new_import_str = astor.to_source(new_import).strip()\n                if new_import_str not in existing_imports_str:\n                    self.tree.body.insert(last_import_index + 1, new_import)\n                    last_import_index += 1 # Update index for next insertion\n            except Exception:\n                # If we can't generate source, we can't check for duplicates, skip\n                self.tree.body.insert(last_import_index + 1, new_import)\n                last_import_index += 1\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return astor.to_source(node)\n            except Exception:\n                # Handle potential astor issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.__class__.__name__,\n            'line_start': getattr(node, 'lineno', None),\n            'line_end': getattr(node, 'end_lineno', None),\n            'body_items': []\n        }\n\n        if hasattr(node, 'body'):\n            for i, item in enumerate(node.body):\n                item_info = {\n                    'index': i,\n                    'type': item.__class__.__name__,\n                    'line_start': getattr(item, 'lineno', None),\n                    'line_end': getattr(item, 'end_lineno', None)\n                }\n\n                if isinstance(item, ast.Assign) and item.targets:\n                    target = item.targets[0]\n                    if isinstance(target, ast.Name):\n                        item_info['assigns'] = target.id\n                elif isinstance(item, (ast.If, ast.While, ast.For)):\n                    item_info['has_body'] = bool(getattr(item, 'body', None))\n                elif isinstance(item, ast.Return):\n                    item_info['returns'] = True\n\n                structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        if not self.atok:\n            return None # asttokens is required for precise original source retrieval\n\n        node = self.nodes.get(element_name)\n        if not node or not hasattr(node, 'body'):\n            return None\n\n        statements = []\n        for stmt in node.body:\n            if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                 # Check for overlap or containment of the statement within the requested range\n                stmt_start = stmt.lineno\n                stmt_end = stmt.end_lineno\n                if (stmt_start >= line_start and stmt_end <= line_end) or \\\n                   (stmt_start <= line_end and stmt_end >= line_start): # Overlap\n                    statements.append(stmt)\n\n        if not statements:\n            return None\n\n        # Use asttokens to get the original source text for accuracy\n        try:\n            # Combine text ranges of the found statements\n            combined_text = \"\"\n            last_end_pos = None\n            for stmt in sorted(statements, key=lambda s: s.lineno):\n                # Get the text range for the statement\n                stmt_text = self.atok.get_text_range(stmt)\n                if last_end_pos is not None and stmt_text[0] > last_end_pos:\n                     # Add the original whitespace/newlines between statements\n                    combined_text += self.source_code[last_end_pos:stmt_text[0]]\n                combined_text += self.atok.get_text(stmt)\n                last_end_pos = stmt_text[1]\n            return combined_text.strip()\n        except Exception:\n            # Fallback if asttokens text retrieval fails\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in statements)\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except SyntaxError:\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body: # Ensure there's actual code body to replace with\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # Walk the tree to find the parent node containing the element to replace\n        for parent_node in ast.walk(self.tree):\n            if hasattr(parent_node, 'body') and isinstance(parent_node.body, list):\n                try:\n                    old_node = self.nodes[element_name]\n                    idx = parent_node.body.index(old_node)\n                    # Remove the old node\n                    parent_node.body.pop(idx)\n                    # Insert the new nodes\n                    for i, new_node in enumerate(new_code_body):\n                        parent_node.body.insert(idx + i, new_node)\n\n                    # Update the nodes map: remove old, add new top-level definitions\n                    del self.nodes[element_name]\n                    for n in new_code_body:\n                        if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                            self.nodes[n.name] = n\n                    return True\n                except (ValueError, KeyError):\n                    # ValueError from index(), KeyError from accessing self.nodes\n                    continue\n        return False # Element not found in any body\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n             return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except (SyntaxError, IndexError):\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body:\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # --- Determine insertion index ---\n\n        # Find the `if __name__ == \"__main__\":` block index\n        main_block_idx = -1\n        for i, node in enumerate(self.tree.body):\n            if (isinstance(node, ast.If) and\n                isinstance(getattr(node, 'test', None), ast.Compare) and\n                isinstance(getattr(node.test, 'left', None), ast.Name) and\n                node.test.left.id == '__name__' and\n                len(getattr(node.test, 'ops', [])) == 1 and isinstance(node.test.ops[0], ast.Eq) and\n                len(getattr(node.test, 'comparators', [])) == 1):\n\n                comp = node.test.comparators[0]\n                # Check for both ast.Constant ('__main__') and older ast.Str ('__main__')\n                if ((isinstance(comp, ast.Constant) and comp.value == '__main__') or\n                    (isinstance(comp, ast.Str) and comp.s == '__main__')): # type: ignore\n                    main_block_idx = i\n                    break\n\n        insertion_index = -1\n        if anchor_name:\n            # If anchor is specified, find its index\n            if anchor_name not in self.nodes:\n                return False\n            anchor_node = self.nodes[anchor_name]\n            try:\n                anchor_idx = self.tree.body.index(anchor_node)\n                proposed_index = anchor_idx if before else anchor_idx + 1\n                # Prefer to stay before the main block if possible\n                if main_block_idx != -1:\n                    insertion_index = min(proposed_index, main_block_idx)\n                else:\n                    insertion_index = proposed_index\n            except ValueError:\n                return False # Anchor node not found in tree body\n        elif main_block_idx != -1:\n            # If no anchor, but there's a main block, insert before it\n            insertion_index = main_block_idx\n        # If no anchor and no main block, insertion_index remains -1\n\n        # --- Perform the insertion ---\n        if insertion_index == -1:\n            # Append to the end\n            self.tree.body.extend(new_code_body)\n        else:\n            # Insert at the calculated position\n            for i, new_node in enumerate(new_code_body):\n                self.tree.body.insert(insertion_index + i, new_node)\n\n        # Update the nodes map with any new top-level definitions\n        for node in new_code_body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                self.nodes[node.name] = node # This might overwrite if names clash\n\n        return True\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return False\n\n        deleted = False\n        if element_name in self.nodes:\n            node_to_delete = self.nodes[element_name]\n            # Walk the tree to find the parent node containing the element\n            for node in ast.walk(self.tree):\n                if hasattr(node, 'body') and isinstance(node.body, list):\n                    try:\n                        node.body.remove(node_to_delete)\n                        deleted = True\n                        break # Assume element appears only once at top level\n                    except ValueError:\n                        continue # This parent doesn't contain the node\n            if deleted:\n                del self.nodes[element_name]\n                # Although nodes map is passed by ref in base __init__, we should call _map_nodes\n                # to ensure consistency after a direct tree modification.\n                self.nodes = self._map_nodes()\n                return True\n\n        # If not found by node reference, try to find by name pattern matching (vars/imports)\n        new_body = []\n        for node in self.tree.body:\n            if isinstance(node, ast.Assign):\n                match = False\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id == element_name:\n                        match = True\n                        deleted = True\n                        break\n                if not match: # Keep the node if it doesn't match\n                    new_body.append(node)\n            elif isinstance(node, ast.Import):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                    # Keep the node if none of its aliases match (should theoretically be the same as above)\n                     new_body.append(node)\n                else:\n                    deleted = True # The import node is being completely removed\n            elif isinstance(node, ast.ImportFrom):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                     new_body.append(node)\n                else:\n                    deleted = True\n            else:\n                new_body.append(node)\n\n        if deleted:\n            self.tree.body = new_body\n            # Remap nodes after structural changes\n            self.nodes = self._map_nodes()\n\n        return deleted\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        if element_name not in self.nodes:\n            return False\n\n        node = self.nodes[element_name]\n        # Ensure the node has a body to modify\n        if not hasattr(node, 'body') or not isinstance(node.body, list):\n            return False\n\n        # Parse the new code to get AST nodes for the replacement\n        try:\n             # Heuristic: If new code looks like a def/class, extract its body.\n             # Otherwise, treat as standalone statements.\n            if new_code.strip().startswith(('def ', 'class ', 'async def ')):\n                # Parse as if it's a module with a single function/class\n                temp_module = ast.parse(new_code)\n                if temp_module.body and hasattr(temp_module.body[0], 'body'):\n                    new_statements = temp_module.body[0].body # Get the inner body\n                else:\n                    return False # Malformed attempt to define a func/class\n            else:\n                # Parse as a module and take its body\n                new_ast_module = ast.parse(new_code)\n                new_statements = new_ast_module.body\n        except SyntaxError:\n            return False # Invalid new code\n\n        if not new_statements: # Nothing to insert\n            return False\n\n        # --- Determine what to replace based on parameters ---\n        if statement_index is not None:\n            # Replace by statement index\n            if 0 <= statement_index < len(node.body):\n                # Replace the single statement at index with the list of new statements\n                node.body[statement_index:statement_index+1] = new_statements\n                return True\n        elif line_start is not None:\n            # Replace by line number(s)\n            result = self._find_statement_in_body(node.body, line_start, line_end)\n            if result:\n                idx, _ = result\n                if line_end:\n                    # Find the last statement within the specified range to replace multiple\n                    end_idx = idx\n                    # Iterate from the found index forward\n                    for i in range(idx, len(node.body)):\n                        stmt = node.body[i]\n                        stmt_s_ln = getattr(stmt, 'lineno', None)\n                        stmt_e_ln = getattr(stmt, 'end_lineno', stmt_s_ln)\n                        if stmt_s_ln is not None and stmt_e_ln is not None:\n                            # Check if the statement ends within the range or starts within the range\n                            # This handles overlapping ranges correctly\n                             if stmt_e_ln <= line_end or stmt_s_ln <= line_end:\n                                 end_idx = i\n                             else:\n                                 break # Statement is past the end range\n                        else:\n                            break # Can't determine statement range\n                    node.body[idx:end_idx+1] = new_statements\n                else:\n                    # line_end not specified, only replace the statement at line_start\n                    node.body[idx:idx+1] = new_statements\n                return True\n\n        # If none of the conditions were met to perform a replacement\n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        if self.tree:\n            try:\n                return astor.to_source(self.tree)\n            except Exception as e:\n                 # Fallback error handling, should ideally not happen if tree is valid\n                 return f\"# Error generating source: {e}\\n{self.source_code}\"\n        else:\n            # If somehow the tree is None, return the original source\n            return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        # Ensure line endings are consistent for diffing, keepends=True preserves them\n        # If source_code had different line endings, this might still cause issues,\n        # but this is a standard approach.\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/python_ast_adapter.py"
  },
  {
    "id": 122,
    "hash": "2914352eefed9d60de098e021dd79b67",
    "content": "import os\nimport sys\nimport argparse\nfrom typing import List\nfrom rag_manager import RAGManager\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\ndef create_sample_data() ->List[str]:\n    \"\"\"Create sample documents for the RAG example.\"\"\"\n    return [\n        'RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with language generation.'\n        ,\n        'The RAG model retrieves relevant documents from a knowledge base and uses them to generate more accurate responses.'\n        ,\n        'FAISS is a library for efficient similarity search and clustering of dense vectors, often used in RAG systems.'\n        ,\n        'Sentence transformers are used to create embeddings for documents and queries in RAG systems.'\n        ,\n        'Retrieval-Augmented Generation improves language models by allowing them to access external knowledge sources.'\n        ,\n        'In RAG systems, documents are indexed and searchable by their semantic embeddings rather than just keywords.'\n        ,\n        'Python is a great language for implementing RAG systems due to libraries like sentence-transformers and faiss.'\n        ,\n        'The retrieval component of RAG is crucial for finding relevant information before generation.'\n        ]\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_cli_example.py"
  },
  {
    "id": 123,
    "hash": "c27b11d2eaa8e13cdf8e698417efb75e",
    "content": "import os\nimport sys\nfrom typing import List, Dict, Tuple\n\"\"\"\nExample script demonstrating RAG (Retrieval-Augmented Generation) usage.\n\nThis script shows how to use a simple RAG implementation to answer questions\nbased on a given context or knowledge base.\n\"\"\"\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\nclass SimpleRAG:\n    \"\"\"A simple RAG implementation for demonstration purposes.\"\"\"\n\n    def __init__(self, knowledge_base: List[str]):\n        \"\"\"\n        Initialize the RAG with a knowledge base.\n        \n        Args:\n            knowledge_base: A list of strings representing the knowledge base.\n        \"\"\"\n        self.knowledge_base = knowledge_base\n\n    def retrieve(self, query: str, top_k: int=3) ->List[str]:\n        \"\"\"\n        Retrieve relevant documents from the knowledge base.\n        \n        This is a simplified implementation using keyword matching.\n        In a real implementation, you would use embeddings and vector search.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            A list of relevant documents.\n        \"\"\"\n        query_words = set(query.lower().split())\n        scores = []\n        for doc in self.knowledge_base:\n            doc_words = set(doc.lower().split())\n            score = len(query_words.intersection(doc_words))\n            scores.append((score, doc))\n        scores.sort(reverse=True)\n        return [doc for score, doc in scores[:top_k]]\n\n    def generate(self, query: str, retrieved_docs: List[str]) ->str:\n        \"\"\"\n        Generate an answer based on the query and retrieved documents.\n        \n        In a real implementation, this would use an LLM to generate the response.\n        For this example, we'll create a simple template-based response.\n        \n        Args:\n            query: The query string.\n            retrieved_docs: The retrieved documents.\n            \n        Returns:\n            A generated answer.\n        \"\"\"\n        context = '\\n'.join(retrieved_docs)\n        prompt = f\"\"\"\n        Context information:\n        {context}\n        \n        Question: {query}\n        \n        Based on the context provided above, please answer the question.\n        If the context doesn't contain relevant information, say so.\n        \"\"\"\n        return self._simple_response_generator(query, retrieved_docs)\n\n    def _simple_response_generator(self, query: str, retrieved_docs: List[str]\n        ) ->str:\n        \"\"\"\n        A simple response generator for demonstration.\n        \"\"\"\n        for doc in retrieved_docs:\n            if 'example' in doc.lower():\n                return (\n                    f'Based on the context provided, I found information about examples. {query} relates to the examples in the knowledge base.'\n                    )\n        return (\n            f\"I couldn't find specific information about '{query}' in the provided context. Please provide more details or check the knowledge base.\"\n            )\n\n    def query(self, query: str, top_k: int=3) ->str:\n        \"\"\"\n        Process a query through the full RAG pipeline.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            The generated answer.\n        \"\"\"\n        retrieved_docs = self.retrieve(query, top_k)\n        answer = self.generate(query, retrieved_docs)\n        return answer\n\n\ndef main():\n    \"\"\"Main function demonstrating the RAG implementation.\"\"\"\n    knowledge_base = ['This is an example document about machine learning.',\n        'Natural language processing is a subfield of artificial intelligence.'\n        , 'Python is a popular programming language for data science.',\n        'The quick brown fox jumps over the lazy dog.',\n        'RAG stands for Retrieval-Augmented Generation.',\n        'Vector databases are used for similarity search in RAG systems.',\n        'Transformers are a type of neural network architecture.',\n        'This example shows how to implement a simple RAG system.']\n    rag = SimpleRAG(knowledge_base)\n    queries = ['What is RAG?', 'How is Python used in data science?',\n        'Tell me about machine learning']\n    print('Simple RAG Example')\n    print('=' * 50)\n    for query in queries:\n        print(f'\\nQuery: {query}')\n        answer = rag.query(query)\n        print(f'Answer: {answer}')\n        print('-' * 30)\n    print(\"\\nInteractive Mode (type 'quit' to exit):\")\n    while True:\n        try:\n            user_query = input('\\nEnter your question: ').strip()\n            if user_query.lower() in ['quit', 'exit', 'q']:\n                break\n            if user_query:\n                answer = rag.query(user_query)\n                print(f'Answer: {answer}')\n        except KeyboardInterrupt:\n            print('\\nGoodbye!')\n            break\n        except EOFError:\n            break\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_example.py"
  },
  {
    "id": 124,
    "hash": "f151986bf2efa7602242590a357fab83",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n    Initialize the RAG manager.\n\n    Args:\n        model_name: Name of the sentence transformer model to use\n        index_path: Path to save/load the FAISS index\n    \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the RAG manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n",
    "file": "/mnt/ProjectData/omni/rag_manager.py"
  },
  {
    "id": 125,
    "hash": "f59a27842056dbb0dc95d0f29c1c5de8",
    "content": "Hello! I'm OmniForge, an AI coding assistant. I can help you scan, understand, and refactor your codebase using local (Ollama) or remote (OpenRouter) LLMs.\n\nI see you've opened the OmniForge project directory. Some key things I can help with:\n\n1. **Project Analysis**: I can look at your files to understand the structure\n2. **Code Editing**: I can make precise edits to functions/classes using AST-based transformations\n3. **Refactoring**: I can perform multi-file architectural changes with a plan\n4. **File Creation**: I can generate new files based on instructions\n\nFor example:\n- `look .` to scan the project\n- `edit code_editor.py \"add docstrings to main methods\"`\n- `refactor \"extract git operations into a separate module\"`\n- `create new_module.py \"implement a simple HTTP client\"`\n\nWhat would you like to do with this project?",
    "file": "/mnt/ProjectData/omni/requirements.txt"
  },
  {
    "id": 126,
    "hash": "4b879b8e64b677ec78d27f19b384623a",
    "content": "from typing import List\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.text import Text\nfrom rich.status import Status\nfrom rich import box\nfrom contextlib import contextmanager\nfrom rich.markup import escape\nimport gc\n\ntry:\n    from prompt_toolkit import prompt\n    from prompt_toolkit.completion import WordCompleter\n    from prompt_toolkit.history import InMemoryHistory\n    from prompt_toolkit.styles import Style\nexcept ImportError:\n    print('[yellow]prompt_toolkit not installed. Falling back to basic input.[/]')\n    prompt = input\n\n\nclass UIManager:\n    \"\"\"Manages interactive text-based UI with rich for display and prompt_toolkit for input.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initializes the UI manager with a rich console and prompt_toolkit components.\"\"\"\n        self.console = Console()\n        self.history = InMemoryHistory()\n        self.completer = WordCompleter([\n            'send', 'look', 'look_all', 'create', 'edit', 'refactor', 'commit',\n            'save', 'list', 'run', 'history', 'memory', 'backend', 'models',\n            'set', 'personality', 'help', 'exit'\n        ], ignore_case=True)\n        self.prompt_style = Style.from_dict({'prompt': 'bold cyan'})\n\n    def get_user_input(self, prompt_text: str) -> str:\n        try:\n            return prompt(prompt_text, history=self.history, completer=self.completer, style=self.prompt_style)\n        except Exception:\n            self.console.print('[yellow]Warning: Falling back to basic input.[/]')\n            return input(prompt_text)\n\n    def display_history(self, history_text: str) -> None:\n        if not history_text.strip():\n            self.console.print('[dim]No history yet.[/]')\n            return\n        \n        lines = history_text.split('\\n')\n        colored_text = Text()\n        for line in lines:\n            if line.startswith('User:'):\n                colored_text.append(line + '\\n', style='bold blue')\n            elif line.startswith('AI:'):\n                colored_text.append(line + '\\n', style='bold green')\n            elif line.startswith('File '):\n                colored_text.append(line + '\\n', style='yellow')\n            else:\n                colored_text.append(line + '\\n')\n        \n        self.console.print(Panel(\n            colored_text, \n            title='[bold magenta]Chat History[/]', \n            border_style='magenta', \n            expand=False, \n            box=box.ROUNDED\n        ))\n\n    @contextmanager\n    def show_spinner(self, message: str):\n        \"\"\"\n        Context manager that displays a spinner with the given message.\n        Handles Rich LiveError by cleaning up stuck live displays and \n        ensuring proper cleanup on exceptions.\n        \n        Usage:\n            with ui_manager.show_spinner(\"Loading...\"):\n                # do work here\n        \"\"\"\n        # Initialize spinner state if not exists\n        if not hasattr(self, '_spinner_active'):\n            self._spinner_active = False\n        \n        # If spinner is already active, just yield without additional output\n        if self._spinner_active:\n            try:\n                yield\n            except Exception as e:\n                raise e\n            return\n        \n        # Clean up any stuck Rich live displays before starting\n        self._cleanup_stuck_rich_displays()\n        \n        # Mark spinner as active\n        self._spinner_active = True\n        status_context = None\n        \n        try:\n            # Try to use rich status, but with fallback\n            try:\n                status_context = self.console.status(f'[bold yellow]{message}[/]')\n                status_context.__enter__()\n            except Exception:\n                # If rich.status fails, fallback to static print\n                status_context = None\n                self.console.print(f'[bold yellow]{message}[/]')\n            \n            yield\n            \n        except Exception as e:\n            # Re-raise actual work errors\n            raise e\n            \n        finally:\n            # Always cleanup spinner state and rich display\n            self._spinner_active = False\n            if status_context is not None:\n                try:\n                    status_context.__exit__(None, None, None)\n                except:\n                    pass  # Suppress cleanup errors\n            \n            # Force cleanup any remaining rich displays\n            self._cleanup_stuck_rich_displays()\n\n    def _cleanup_stuck_rich_displays(self):\n        \"\"\"\n        Clean up stuck Rich live displays that prevent new ones from starting.\n        Based on solution from: https://github.com/DLR-RM/stable-baselines3/issues/1645\n        \"\"\"\n        try:\n            # Method 1: Reset console live display if exists\n            if hasattr(self.console, '_live') and self.console._live is not None:\n                try:\n                    self.console._live.stop()\n                    self.console._live = None\n                except:\n                    pass\n            \n            # Method 2: Find and close stuck rich/tqdm objects using garbage collection\n            rich_objects = [obj for obj in gc.get_objects() \n                        if hasattr(obj, '__class__') and \n                        ('live' in type(obj).__name__.lower() or \n                            'progress' in type(obj).__name__.lower() or\n                            'status' in type(obj).__name__.lower()) and\n                        hasattr(obj, 'stop')]\n            \n            for rich_obj in rich_objects:\n                try:\n                    if hasattr(rich_obj, 'stop'):\n                        rich_obj.stop()\n                    elif hasattr(rich_obj, 'close'):\n                        rich_obj.close()\n                except:\n                    pass  # Suppress cleanup errors\n                    \n        except:\n            pass  # Suppress all cleanup errors to avoid breaking the main flow\n\n    def display_status_panel(self, personality: str, backend: str, model: str, msg_count: int, look_count: int) -> None:\n        status_text = (\n            f'[bold]Personality:[/] [green]{personality}[/] | '\n            f'[bold]Backend:[/] [green]{backend}[/] | '\n            f'[bold]Model:[/] [green]{model}[/] | '\n            f'[bold]Memory:[/] {msg_count} messages, {look_count} files'\n        )\n        self.console.print(Panel(\n            status_text, \n            title='[bold cyan]Status[/]', \n            border_style='cyan', \n            expand=False, \n            box=box.MINIMAL\n        ))\n\n    def show_success(self, message: str) -> None:\n        self.console.print(f'[green]\u2705 {message}[/]')\n\n    def show_error(self, message: str) -> None:\n        \"\"\"\n        Displays an error message, escaping any markup in the message.\n        \"\"\"\n        safe_message = escape(str(message))\n        self.console.print(f'[red]\u274c {safe_message}[/]')",
    "file": "/mnt/ProjectData/omni/ui_manager.py"
  },
  {
    "id": 127,
    "hash": "dbd143839288b400cafdedb655258434",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n",
    "file": "/mnt/ProjectData/omni/vectordb_manager.py"
  },
  {
    "id": 128,
    "hash": "47a91d3ac272236378053b23515fc9b0",
    "content": "import tkinter as tk\nfrom tkinter import ttk\nfrom time import strftime\n\n\ndef update_time():\n    current_time = strftime('%H:%M:%S %p\\n%Y-%m-%d')\n    time_label.config(text=current_time)\n    time_label.after(1000, update_time)\n\n\ndef center_window(root):\n    root.update_idletasks()\n    screen_width = root.winfo_screenwidth()\n    screen_height = root.winfo_screenheight()\n    window_width = root.winfo_width() + 4\n    window_height = root.winfo_height() + 4\n    x = (screen_width - window_width) // 2\n    y = (screen_height - window_height) // 2\n    root.geometry(f'{window_width}x{window_height}+{x}+{y}')\n\n\ndef create_3d_border(parent):\n    border_frame = tk.Frame(parent, bg='#c0c0c0')\n    border_frame.pack(padx=2, pady=2, expand=True, fill=tk.BOTH)\n    tk.Frame(border_frame, height=1, bg='#808080').pack(side=tk.TOP, fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#808080').pack(side=tk.LEFT, fill=tk.Y)\n    tk.Frame(border_frame, height=1, bg='#ffffff').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#ffffff').pack(side=tk.RIGHT, fill=tk.Y\n        )\n    inner_container = tk.Frame(border_frame, bg='#c0c0c0')\n    inner_container.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1\n        )\n    tk.Frame(inner_container, height=1, bg='#ffffff').pack(side=tk.TOP,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#ffffff').pack(side=tk.LEFT,\n        fill=tk.Y)\n    tk.Frame(inner_container, height=1, bg='#808080').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#808080').pack(side=tk.RIGHT,\n        fill=tk.Y)\n    content_area = tk.Frame(inner_container, bg='#c0c0c0')\n    content_area.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1)\n    return content_area\n\n\nroot = tk.Tk()\nroot.title('Current Time')\nroot.configure(bg='#008080')\nmain_frame = create_3d_border(root)\nmain_frame.config(padx=4, pady=4)\ninner_frame = tk.Frame(main_frame, bg='#c0c0c0', padx=8, pady=8)\ninner_frame.pack()\ntime_label = tk.Label(inner_frame, bg='#c0c0c0', fg='#000000', font=(\n    'MS Sans Serif', 18, 'bold'), padx=12, pady=8)\ntime_label.pack()\nroot.after(100, lambda : center_window(root))\nupdate_time()\nroot.mainloop()\n",
    "file": "/mnt/ProjectData/omni/omni_saves/watch.py"
  },
  {
    "id": 129,
    "hash": "6774a805052356775d8c4f0367253dc1",
    "content": "# OmniForge\n\n**Project\u2011Aware AI CLI for AST\u2011Precise Edits (\u201cScalpel\u201d) & Multi\u2011File Refactors (\u201cBlueprint\u201d).**\n\n> *OmniForge (a.k.a. the \"DualForge\" engine) helps you **scan**, **understand**, and **reforge** your codebase with local (Ollama) or remote (OpenRouter) LLMs. It is an independent open\u2011source project not affiliated with other products using the name \u201cOmni.\u201d*\n\n---\n\n## Core Features\n\n* **Project\u2011Aware Refactoring (`refactor`)**: Provide a high\u2011level goal (e.g. *\u201cmove all DB logic into `db/` and centralize config\u201d*). OmniForge generates & shows a multi\u2011step plan before touching files.\n* **Surgical AST Editing (`edit`)**: Target a single function/class. OmniForge parses the file, locates the node, applies a structural change, and shows you a diff.\n* **Context Ingestion (`look`)**: Scan a directory or single file to build a project manifest (paths + hashes + size + language hints) that guides subsequent edits/refactors.\n* **Dual Backends**: Seamlessly switch between **`openrouter`** (remote models) and **`ollama`** (local models) via `backend <name>`.\n* **Interactive Model Picker (`models`)**: Filter by source/provider and select from an up\u2011to\u2011date model list inside the terminal.\n* **Session Memory & History**: `history` shows conversation / action log; `memory clear` resets the working context.\n* **Safe AST\u2011Based Transformations**: Reduces syntax breakage vs naive text substitution. New imports / dependencies are auto\u2011inserted when possible.\n* **Dry\u2011Run Transparency**: Every multi\u2011file refactor presents (1) a generated plan, (2) per\u2011file proposed changes, (3) a consolidated diff for confirmation.\n\n---\n\n## Conceptual Modes\n\n| Mode          | Command(s) | Purpose                                              | Analogy              |\n| ------------- | ---------- | ---------------------------------------------------- | -------------------- |\n| **Survey**    | `look`     | Index project / ingest context                       | Mapping the terrain  |\n| **Scalpel**   | `edit`     | Precise single\u2011file structural change                | Surgery              |\n| **Blueprint** | `refactor` | Multi\u2011file architectural transformation              | Architecture         |\n| **Cast**      | `run`      | Execute last generated runnable block (if supported) | Forging the artifact |\n\nYou can reference these terms in docs, help screens, or UI banners for clarity.\n\n---\n\n## Installation\n\n> Requires Python 3.10+ and a Unix\u2011like shell.\n\n```bash\n# 1. Clone\ngit clone https://github.com/Snawyyy/omniforge.git\ncd omniforge\n\n# 2. (Optional) Inspect requirements\ncat requirements.txt\n\n# 3. Run installer (creates venv + installs deps)\nchmod +x install.sh\n./install.sh\n\n# 4. Activate environment\nsource venv/bin/activate\n\n# 5. Run CLI (interactive shell)\n./omni        # or: python omni.py\n```\n\nIf you later package it, expose a script entry point named `omni` while keeping an internal package name like `omniforge` to avoid namespace collisions.\n\n---\n\n## Configuration\n\nCreate a `.env` file to supply secrets (e.g. OpenRouter API key).\n\n```bash\ncp .env.example .env   # if example exists; otherwise create manually\n```\n\nIn `.env`:\n\n```dotenv\nOPENROUTER_API_KEY=\"sk-or-...\"\n```\n\n(Do **not** commit real keys. Ensure `.env` is listed in `.gitignore`.)\n\nOptional future keys can include local model paths, default model name, or feature flags.\n\n---\n\n## Quick Start Workflow\n\n```text\n> look .\n(Index project: builds manifest)\n\n> refactor \"extract hardcoded API URL to config/settings.py and update all imports\"\n(Shows plan \u2192 ask for confirmation)\n\n> edit src/utils.py \"add a doctring for calculate_average explaining parameters and return value\"\n(Shows targeted diff \u2192 confirm or abort)\n\n> models openai\n(Choose a different model)\n\n> backend ollama\n(Switch to local inference)\n```\n\n---\n\n## Command Reference\n\n| Command               | Example                                         | Description                                                                 |\n| --------------------- | ----------------------------------------------- | --------------------------------------------------------------------------- |\n| `look <path>`         | `look .`                                        | Scan directory or file; update project context manifest.                    |\n| `edit <file> \"instr\"` | `edit utils.py \"add error handling\"`            | AST\u2011guided targeted modification of a single file element or whole file.    |\n| `refactor \"goal\"`     | `refactor \"split monolith api.py into package\"` | High\u2011level multi\u2011file transformation with plan + diff review.               |\n| `send <prompt>`       | `send summarize module layout`                  | Generic prompt to current model with current context summary.               |\n| `models [filter]`     | `models google`                                 | Interactive model selector (filter by provider/source).                     |\n| `backend <name>`      | `backend ollama`                                | Switch between `openrouter` / `ollama`.                                     |\n| `history`             | `history`                                       | Display session interaction log.                                            |\n| `memory clear`        | `memory clear`                                  | Clear internal AI context memory (project manifest may persist separately). |\n| `run`                 | `run`                                           | Execute the last generated runnable code snippet (if feature implemented).  |\n| `help`                | `help`                                          | Show help / usage summary.                                                  |\n\n---\n\n## How It Works (High Level)\n\n1. **Ingestion (`look`)**: Walks the directory (configurable ignore patterns), captures file metadata (path, size, language), optionally caches abbreviated content or hashes.\n2. **Prompt Construction**: Merges user instruction + contextual manifest + focused snippets (for `edit`) or diff summaries (for `refactor`).\n3. **AST Layer** (Python initially): Parses target file(s); identifies node(s) (function/class) based on name + heuristic similarity; applies transformations guided by model output (structured hints or patch templates) rather than raw blind overwrite.\n4. **Plan (Refactor)**: Model proposes steps (CREATE / MODIFY / RENAME / DELETE). User approves. Each step executed & validated; errors surface early.\n5. **Diff Presentation**: A unified colorized diff shown; user confirms to write changes.\n6. **Safety**: If AST parse fails or patch violates syntax, changes abort (or fallback to text patch with warning).\n\n---\n\n## Roadmap (Indicative)\n\n| Milestone | Features                                                                    |\n| --------- | --------------------------------------------------------------------------- |\n| 0.1.0     | Core commands (`look`, `edit`, `refactor`, `models`, `backend`, `history`). |\n| 0.2.0     | Config file (`omniforge.toml`), ignore patterns, improved diff viewer.      |\n| 0.3.0     | Multi-language AST adapters (JS/TS via `tree-sitter`).                      |\n| 0.4.0     | Test impact analysis & auto test file generation.                           |\n| 0.5.0     | Refactor preview metrics (LOC touched, complexity delta).                   |\n| 0.6.0     | Inline security / lint feedback integration.                                |\n| 0.7.0     | Partial GUI / TUI dashboard mode.                                           |\n\n(Adjust roadmap as project evolves.)\n\n---\n\n## Developer Notes\n\n* Keep `.env`, virtual environment dirs (`venv/`), caches, large artifacts in `.gitignore`.\n* Consider adding a thin `omniforge/` package directory now for future PyPI packaging.\n* Implement a pluggable *Model Adapter* layer to abstract provider differences (OpenRouter vs Ollama).\n* Logging: Provide `--verbose` or `OMNIFORGE_DEBUG=1` env flag.\n* Add a JSONL log of commands & decisions to enable replay or supervised improvements.\n\n---\n\n## Contributing\n\n1. Fork & create a feature branch: `git checkout -b feat/<short-name>`\n2. Run and add tests (if/when test harness exists in `tests/`).\n3. Ensure style/format (e.g. `ruff`, `black`) passes.\n4. Submit pull request with concise description + before/after examples.\n\nIssues / discussions welcome for architecture proposals, AST adapters, or performance improvements.\n\n---\n\n## License\n\nReleased under the **MIT License**. See `LICENSE` file for full text.\n\n---\n\n## Name & Trademark Disclaimer\n\n\u201cOmniForge\u201d is an independent open-source tool and not affiliated with The Omni Group or any other third-party products using similar names. If a future naming conflict arises, a soft alias strategy (keeping the `omni` CLI) will preserve user workflows.\n\n---\n\n## Example Session (Illustrative)\n\n```text\n$ ./omni\nOMNIFORGE 0.1.0  (backend=openrouter | model=anthropic/claude-3)\nType 'help' or 'look .' to begin.\n\n> look .\nIndexed 42 files (Python=30, Markdown=5, JSON=7)\n\n> refactor \"centralize logging into logging_util.py and update imports\"\nPlan:\n  [1] CREATE logging_util.py\n  [2] MODIFY app.py (replace inline log setup)\n  [3] MODIFY worker.py (import logging_util)\nProceed? (y/n) y\n... (diff preview) ...\nApply changes? (y/n) y\nRefactor complete in 3.2s.\n\n> edit worker.py \"add retry with exponential backoff to fetch_data\"\nParsed worker.py \u2713\nApplied modification (function: fetch_data)\nDiff shown. Accept? (y/n) y\nSaved.\n```\n\n---\n\n## Philosophy\n\n*The next wave of developer AI goes beyond paste\u2011in prompts.* OmniForge treats your repository as *structured material*, enabling incremental, auditable, and safer evolution rather than opaque code dumps. By combining **context scanning**, **AST precision**, and **human approval loops**, it aims to become a trustworthy co\u2011developer rather than an occasionally helpful code generator.\n\n---\n\n## Feedback / Support\n\nOpen a GitHub Issue for bugs & feature requests. For conceptual discussions (roadmap, design choices), use Discussions.\n\n---\n\nHappy forging!\n",
    "file": "/mnt/ProjectData/omni/README.md"
  },
  {
    "id": 130,
    "hash": "b6c2845489f64b6396aaf85e5fd5909e",
    "content": "from abc import ABC, abstractmethod\nfrom typing import List, Optional, Dict, Any, Union\nfrom typing import List, Optional, Dict\nASTNode = Any\nDiffContent = str\n\n\nclass ASTAdapter(ABC):\n    \"\"\"\n    Abstract base class defining the interface for language-specific AST adapters.\n\n    This interface allows the CodeEditor to interact with the AST/CST of different\n    programming languages in a uniform way. Concrete implementations will handle\n    the specifics of parsing, traversing, and modifying the AST/CST for their\n    respective languages (e.g., Python's `ast`/`astor`, JavaScript's `tree-sitter`).\n\n    The adapter is responsible for holding the parsed tree structure and any\n    necessary metadata for operations.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the adapter by parsing the provided source code.\n\n        Args:\n            source_code: The string content of the source file to be parsed.\n\n        Raises:\n            ValueError: If the source code cannot be parsed due to syntax errors.\n        \"\"\"\n        self.source_code: str = source_code\n        self.tree: Optional[ASTNode] = None\n        self.nodes: Dict[str, ASTNode] = {}\n        self._parse_and_map(source_code)\n\n    @abstractmethod\n    def _parse_and_map(self, source_code: str) ->None:\n        \"\"\"\n        Abstract method to parse the source code and populate `self.tree` and `self.nodes`.\n\n        This is the core method where language-specific parsing logic resides.\n        Implementations should:\n        1. Parse the `source_code` into an AST/CST representation.\n        2. Store the root of this representation in `self.tree`.\n        3. Identify key top-level elements (functions, classes, variables, imports)\n           and map their names to their nodes in `self.nodes`.\n\n        Args:\n            source_code: The string content to parse.\n\n        Raises:\n            ValueError: If the source code cannot be parsed.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_elements(self) ->List[str]:\n        \"\"\"\n        Abstract method to list the names of the main elements found in the code.\n\n        These are typically top-level functions, classes, variable assignments,\n        and imports that the adapter can identify and manipulate.\n\n        Returns:\n            A list of element names (strings).\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"\n        Abstract method to get the source code string for a specific element.\n\n        Args:\n            element_name: The name of the element (function, class, etc.).\n\n        Returns:\n            The source code string for the element, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"\n        Abstract method to get detailed structural information about an element.\n\n        This information can include type, line numbers, body items, etc., useful\n        for aiding the AI in understanding the code's layout.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            A dictionary containing structural details, or None if not found.\n            Example structure:\n            {\n                'name': 'func_name',\n                'type': 'FunctionDef', # or 'ClassDef', etc.\n                'line_start': 10,\n                'line_end': 25,\n                'body_items': [list of internal statement details...]\n            }\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"\n        Abstract method to extract a snippet of code from within an element's body.\n\n        Used for 'partial' edits where only a specific range of lines within\n        a function or class needs to be changed.\n\n        Args:\n            element_name: The name of the element containing the snippet.\n            line_start: The starting line number (1-based, absolute) of the snippet.\n            line_end: The ending line number (inclusive) of the snippet.\n\n        Returns:\n            The source code string for the specified lines within the element, or None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"\n        Abstract method to replace an entire named element.\n\n        This involves finding the old element in the tree and swapping it with\n        the representation of the `new_code`.\n\n        Args:\n            element_name: The name of the element to replace.\n            new_code: The new source code for the element (and potential helpers).\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"\n        Abstract method to add a new block of code (element) to the file.\n\n        This involves parsing the `new_code` and inserting its representation\n        into the tree at an appropriate location (e.g., end of file, near anchor).\n\n        Args:\n            new_code: The source code for the new element(s).\n            anchor_name: Optional name of an existing element to position relative to.\n            before: If True and `anchor_name` is provided, insert before the anchor.\n\n        Returns:\n            True if the element was added successfully, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"\n        Abstract method to delete a named element from the file.\n\n        This involves finding the element in the tree and removing its representation.\n\n        Args:\n            element_name: The name of the element to delete.\n\n        Returns:\n            True if the element was successfully deleted, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"\n        Abstract method for a 'surgical' edit within an element's body.\n\n        Replaces a specific statement or line range within the body of an element.\n\n        Args:\n            element_name: Name of the function/class to modify.\n            new_code: New code to insert (can be multiple statements).\n            line_start: Starting line number (absolute) within the element.\n            line_end: Ending line number (inclusive) within the element.\n            statement_index: Alternative to line numbers - replace the Nth statement.\n\n        Returns:\n            True if successful, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_modified_source(self) ->str:\n        \"\"\"\n        Abstract method to serialize the potentially modified AST/CST back to source code.\n\n        Returns:\n            The full source code string reflecting the current state of the tree.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_diff(self) ->str:\n        \"\"\"\n        Abstract method to generate a diff between the original source and the modified source.\n\n        Returns:\n            A string containing the unified diff.\n        \"\"\"\n        pass\n\n\n\"\"\"\nTextFileAdapter - Basic adapter for text files\n\nThis module provides a basic adapter for text files that implements\nthe ASTAdapter interface. It allows text files to be used with the\nCodeEditor class.\n\"\"\"\n\n\nclass TextFileAdapter(ASTAdapter):\n    \"\"\"\n    A basic adapter for text files that implements the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the TextFileAdapter.\n\n        Args:\n            source_code: The source code as a string.\n        \"\"\"\n        self.source_code = source_code\n        self.modified_source = source_code\n\n    def list_elements(self) ->List[str]:\n        \"\"\"\n        Lists top-level elements in the text file.\n        For text files, this returns a single \"content\" element.\n\n        Returns:\n            A list containing \"content\".\n        \"\"\"\n        return ['content']\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"\n        Gets the source code for a specific element.\n        For text files, this returns the entire file content.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            The source code of the entire file.\n        \"\"\"\n        if element_name == 'content':\n            return self.source_code\n        return None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"\n        Gets detailed structure information about an element.\n        For text files, this provides minimal structure information.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            A dictionary with basic structure information.\n        \"\"\"\n        if element_name == 'content':\n            lines = self.source_code.splitlines()\n            return {'name': element_name, 'type': 'text', 'line_count': len\n                (lines), 'character_count': len(self.source_code)}\n        return None\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"\n        Gets a snippet from within an element's body.\n        For text files, this returns lines between line_start and line_end.\n\n        Args:\n            element_name: The name of the element.\n            line_start: The starting line number (1-indexed).\n            line_end: The ending line number (1-indexed).\n\n        Returns:\n            A string containing the specified lines.\n        \"\"\"\n        if element_name != 'content':\n            return None\n        lines = self.source_code.splitlines()\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(lines), line_end)\n        if start_idx >= len(lines) or start_idx >= end_idx:\n            return None\n        return '\\n'.join(lines[start_idx:end_idx])\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"\n        Replaces a partial section of an element.\n        For text files, this replaces lines between line_start and line_end.\n\n        Args:\n            element_name: The name of the element.\n            new_code: The new code to insert.\n            line_start: The starting line number (1-indexed).\n            line_end: The ending line number (1-indexed).\n            statement_index: Not used for text files.\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        if element_name != 'content':\n            return False\n        if line_start is None or line_end is None:\n            return False\n        lines = self.modified_source.splitlines()\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(lines), line_end)\n        if start_idx > len(lines) or start_idx > end_idx:\n            return False\n        new_lines = self.modified_source.splitlines()\n        new_code_lines = new_code.splitlines()\n        new_lines[start_idx:end_idx] = new_code_lines\n        self.modified_source = '\\n'.join(new_lines)\n        return True\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"\n        Adds new content to the text file.\n        For text files, this appends or prepends content.\n\n        Args:\n            new_code: The new code to add.\n            anchor_name: Not used for text files.\n            before: If True, prepend; if False, append.\n\n        Returns:\n            True if the addition was successful, False otherwise.\n        \"\"\"\n        if before:\n            self.modified_source = new_code + '\\n' + self.modified_source\n        else:\n            self.modified_source = self.modified_source + '\\n' + new_code\n        return True\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"\n        Deletes an element by name.\n        For text files, this clears the entire content if element_name is \"content\".\n\n        Args:\n            element_name: The name of the element to delete.\n\n        Returns:\n            True if the deletion was successful, False otherwise.\n        \"\"\"\n        if element_name == 'content':\n            self.modified_source = ''\n            return True\n        return False\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"\n        Replaces a target element with new code.\n        For text files, this replaces the entire content if element_name is \"content\".\n\n        Args:\n            element_name: The name of the element to replace.\n            new_code: The new code.\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        if element_name == 'content':\n            self.modified_source = new_code\n            return True\n        return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"\n        Gets the modified source code.\n\n        Returns:\n            The modified source code.\n        \"\"\"\n        return self.modified_source\n\n    def get_diff(self) ->str:\n        \"\"\"\n        Generates a diff between the original source and the modified source.\n\n        Returns:\n            A string containing the diff.\n        \"\"\"\n        import difflib\n        return ''.join(difflib.unified_diff(self.source_code.splitlines(\n            keepends=True), self.modified_source.splitlines(keepends=True),\n            fromfile='original', tofile='modified'))\n",
    "file": "/mnt/ProjectData/omni/ast_adapter.py"
  },
  {
    "id": 131,
    "hash": "2971f3027328602dba997938c23e1004",
    "content": "\"\"\"\nCodeEditor - Enhanced AST-based code manipulation tool\n\nThis module provides a class to programmatically parse, analyze,\nand edit source code. It has been refactored to use a pluggable\nASTAdapter system, allowing it to support multiple languages.\nCurrently, it defaults to Python's built-in `ast` module via\nPythonASTAdapter for backward compatibility during the transition.\n\"\"\"\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Union, Tuple, Type, Any\nfrom ast_adapter import ASTAdapter\nfrom python_ast_adapter import PythonASTAdapter\nimport os\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n\n\nclass CodeEditor:\n    \"\"\"\n    An enhanced class to safely edit files using AST/CST with partial edit support.\n    The core logic for interacting with the code structure is now delegated to\n    a language-specific ASTAdapter.\n    \"\"\"\n\n    def __init__(self, file_path: str, adapter_class: Optional[Type[\n        ASTAdapter]]=None):\n        \"\"\"\n        Initializes the CodeEditor.\n\n        Args:\n            file_path: The path to the source file.\n            adapter_class: The ASTAdapter subclass to use. If None, defaults to\n                           PythonASTAdapter for .py files.\n        \"\"\"\n        self.file_path = file_path\n        self.source_code = self._read_file()\n        if adapter_class is None:\n            file_extension = os.path.splitext(self.file_path)[1].lower()\n            if file_extension == '.py':\n                try:\n                    from python_ast_adapter import PythonASTAdapter\n                    self.adapter: Optional[ASTAdapter] = PythonASTAdapter(self\n                        .source_code)\n                except ImportError:\n                    raise ValueError(\n                        'Python AST adapter is required but not available')\n            elif file_extension == '.js':\n                try:\n                    from javascript_ast_adapter import JavaScriptASTAdapter\n                    self.adapter: Optional[ASTAdapter] = JavaScriptASTAdapter(\n                        self.source_code)\n                except ImportError as e:\n                    raise ValueError(\n                        f'tree-sitter is required for JavaScript support but not available: {e}'\n                        )\n                except Exception as e:\n                    raise ValueError(\n                        f'Failed to initialize JavaScript adapter: {e}')\n            elif file_extension == '.txt':\n                self.adapter = None\n            else:\n                raise ValueError(\n                    f'Unsupported file type: {file_extension}. Supported types: .py, .js, .txt'\n                    )\n        else:\n            self.adapter = adapter_class(self.source_code)\n\n    def _read_file(self) ->str:\n        \"\"\"Reads the source file.\"\"\"\n        try:\n            with open(self.file_path, 'r', encoding='utf-8') as f:\n                return f.read()\n        except FileNotFoundError:\n            raise ValueError(f'File not found: {self.file_path}')\n\n    def _parse_source(self) ->ast.AST:\n        \"\"\"Fallback parsing logic.\"\"\"\n        try:\n            return ast.parse(self.source_code)\n        except SyntaxError as e:\n            raise ValueError(f'Invalid Python syntax in {self.file_path}: {e}')\n\n    def list_elements(self) ->List[str]:\n        \"\"\"Lists top-level elements in the code.\"\"\"\n        if self.adapter:\n            return self.adapter.list_elements()\n        else:\n            return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"Gets the source code for a specific element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_source_of(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            return astor.to_source(node) if node else None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"Gets detailed structure information about an element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_structure(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            if not node:\n                return None\n            structure = {'name': element_name, 'type': node.__class__.\n                __name__, 'line_start': node.lineno if hasattr(node,\n                'lineno') else None, 'line_end': node.end_lineno if hasattr\n                (node, 'end_lineno') else None, 'body_items': []}\n            if hasattr(node, 'body'):\n                for i, item in enumerate(node.body):\n                    item_info = {'index': i, 'type': item.__class__.\n                        __name__, 'line_start': item.lineno if hasattr(item,\n                        'lineno') else None, 'line_end': item.end_lineno if\n                        hasattr(item, 'end_lineno') else None}\n                    if isinstance(item, ast.Assign) and item.targets:\n                        target = item.targets[0]\n                        if isinstance(target, ast.Name):\n                            item_info['assigns'] = target.id\n                    elif isinstance(item, (ast.If, ast.While, ast.For)):\n                        item_info['has_body'] = bool(item.body)\n                    elif isinstance(item, ast.Return):\n                        item_info['returns'] = True\n                    structure['body_items'].append(item_info)\n            return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"Gets a snippet from within an element's body.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_body_snippet(element_name,\n                line_start, line_end)\n        else:\n            if not self.atok:\n                return None\n            node = self.nodes.get(element_name)\n            if not node or not hasattr(node, 'body'):\n                return None\n            statements = []\n            for stmt in node.body:\n                if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                    if (line_start <= stmt.lineno <= line_end or line_start <=\n                        stmt.end_lineno <= line_end):\n                        statements.append(stmt)\n            if not statements:\n                return None\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in\n                statements)\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"Replaces a partial section of an element.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_partial(element_name, new_code,\n                line_start, line_end, statement_index)\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                if new_code.strip().startswith('def ') or new_code.strip(\n                    ).startswith('class '):\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body[0].body\n                else:\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if statement_index is not None:\n                if 0 <= statement_index < len(node.body):\n                    node.body[statement_index:statement_index + 1\n                        ] = new_statements\n                    return True\n            elif line_start is not None:\n                result = self._find_statement_in_body(node.body, line_start,\n                    line_end)\n                if result:\n                    idx, _ = result\n                    if line_end:\n                        end_idx = idx\n                        for i in range(idx + 1, len(node.body)):\n                            stmt = node.body[i]\n                            if hasattr(stmt, 'end_lineno'\n                                ) and stmt.end_lineno <= line_end:\n                                end_idx = i\n                            else:\n                                break\n                        node.body[idx:end_idx + 1] = new_statements\n                    else:\n                        node.body[idx:idx + 1] = new_statements\n                    return True\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"Adds a new block of code to the file.\"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name, before)\n        else:\n            try:\n                new_ast_module = ast.parse(new_code)\n            except (SyntaxError, IndexError):\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            insertion_index = -1\n            main_block_idx = -1\n            for i, _node in enumerate(self.tree.body):\n                if isinstance(_node, ast.If) and isinstance(_node.test, ast\n                    .Compare) and isinstance(_node.test.left, ast.Name\n                    ) and _node.test.left.id == '__name__' and len(_node.\n                    test.ops) == 1 and isinstance(_node.test.ops[0], ast.Eq\n                    ) and len(_node.test.comparators) == 1:\n                    comp = _node.test.comparators[0]\n                    if isinstance(comp, ast.Constant\n                        ) and comp.value == '__main__' or isinstance(comp,\n                        ast.Str) and comp.s == '__main__':\n                        main_block_idx = i\n                        break\n            if anchor_name:\n                if anchor_name not in self.nodes:\n                    return False\n                anchor_node = self.nodes[anchor_name]\n                try:\n                    anchor_idx = self.tree.body.index(anchor_node)\n                    proposed_index = anchor_idx if before else anchor_idx + 1\n                    if main_block_idx != -1:\n                        insertion_index = min(proposed_index, main_block_idx)\n                    else:\n                        insertion_index = proposed_index\n                except ValueError:\n                    return False\n            elif main_block_idx != -1:\n                insertion_index = main_block_idx\n            if insertion_index == -1:\n                self.tree.body.extend(new_code_body)\n            else:\n                for i, new_node in enumerate(new_code_body):\n                    self.tree.body.insert(insertion_index + i, new_node)\n            for _node in new_code_body:\n                if isinstance(_node, (ast.FunctionDef, ast.AsyncFunctionDef,\n                    ast.ClassDef)):\n                    self.nodes[_node.name] = _node\n            return True\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"Deletes an element by name.\"\"\"\n        if self.adapter:\n            return self.adapter.delete_element(element_name)\n        else:\n            deleted = False\n            if element_name in self.nodes:\n                node_to_delete = self.nodes[element_name]\n                for _node in ast.walk(self.tree):\n                    if hasattr(_node, 'body') and isinstance(_node.body, list):\n                        try:\n                            _node.body.remove(node_to_delete)\n                            deleted = True\n                            break\n                        except ValueError:\n                            continue\n                if deleted:\n                    del self.nodes[element_name]\n                    self.nodes = self._map_nodes()\n                    return True\n            new_body = []\n            for _node in self.tree.body:\n                if isinstance(_node, ast.Assign):\n                    match = False\n                    for target in _node.targets:\n                        if isinstance(target, ast.Name\n                            ) and target.id == element_name:\n                            match = True\n                            break\n                    if match:\n                        deleted = True\n                        continue\n                elif isinstance(_node, ast.Import):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                elif isinstance(_node, ast.ImportFrom):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                new_body.append(_node)\n            self.tree.body = new_body\n            if deleted:\n                self.nodes = self._map_nodes()\n            return deleted\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"Replaces a target element with new code.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_element(element_name, new_code)\n        else:\n            if element_name not in self.nodes:\n                return False\n            try:\n                new_ast_module = ast.parse(new_code)\n            except SyntaxError:\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            for _node in ast.walk(self.tree):\n                if hasattr(_node, 'body') and isinstance(_node.body, list):\n                    try:\n                        old_node = self.nodes[element_name]\n                        idx = _node.body.index(old_node)\n                        _node.body.pop(idx)\n                        for i, new_node in enumerate(new_code_body):\n                            _node.body.insert(idx + i, new_node)\n                        del self.nodes[element_name]\n                        for n in new_code_body:\n                            if isinstance(n, (ast.FunctionDef, ast.\n                                AsyncFunctionDef, ast.ClassDef)):\n                                self.nodes[n.name] = n\n                        return True\n                    except (ValueError, KeyError):\n                        continue\n            return False\n\n    def insert_in_element(self, element_name: str, new_code: str, position:\n        str='end', after_line: Optional[int]=None, before_line: Optional[\n        int]=None) ->bool:\n        \"\"\"\n        Insert new code into an element without replacing existing code.\n        This is an internal/helper method, delegating to adapter OR using fallback.\n        \"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name=\n                element_name, before=position == 'start')\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                new_ast = ast.parse(new_code)\n                new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if position == 'start':\n                node.body[0:0] = new_statements\n            elif position == 'end':\n                node.body.extend(new_statements)\n            elif after_line:\n                result = self._find_statement_in_body(node.body, after_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx + 1:idx + 1] = new_statements\n                else:\n                    return False\n            elif before_line:\n                result = self._find_statement_in_body(node.body, before_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx:idx] = new_statements\n                else:\n                    return False\n            else:\n                return False\n            return True\n\n    def _map_nodes(self) ->Dict[str, ast.AST]:\n        \"\"\"Fallback node mapping logic for Python AST.\"\"\"\n        nodes = {}\n        for node in ast.walk(self.tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast\n                .ClassDef)):\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int,\n        line_end: Optional[int]=None) ->Optional[Tuple[int, ast.AST]]:\n        \"\"\"Fallback statement finding logic for Python AST.\"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = stmt.end_lineno if hasattr(stmt, 'end_lineno'\n                        ) else stmt.lineno\n                    if (stmt.lineno <= line_start <= stmt_end or stmt.\n                        lineno <= line_end <= stmt_end):\n                        return i, stmt\n                elif stmt.lineno == line_start:\n                    return i, stmt\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.\n        ImportFrom]]) ->None:\n        \"\"\"Fallback logic to add imports to the top of the Python AST.\"\"\"\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                existing_imports_str.add(astor.to_source(node).strip())\n                last_import_index = i\n        for new_import in reversed(new_import_nodes):\n            new_import_str = astor.to_source(new_import).strip()\n            if new_import_str not in existing_imports_str:\n                self.tree.body.insert(last_import_index + 1, new_import)\n\n    def apply_arbitrary_change(self, new_source_code: str) ->bool:\n        \"\"\"\n        Rewrites the entire file's AST from a new source string.\n        This method resets the adapter if one exists, or uses fallback.\n        \"\"\"\n        if self.adapter:\n            try:\n                adapter_class = type(self.adapter)\n                self.adapter = adapter_class(new_source_code)\n                return True\n            except Exception:\n                return False\n        else:\n            try:\n                new_tree = ast.parse(new_source_code)\n                self.tree = new_tree\n                self.nodes = self._map_nodes()\n                if ASTTOKENS_AVAILABLE:\n                    self.source_code = new_source_code\n                    self.atok = asttokens.ASTTokens(self.source_code, parse\n                        =True)\n                return True\n            except SyntaxError:\n                return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"Serializes the potentially modified code structure back to source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_modified_source()\n        else:\n            return astor.to_source(self.tree)\n\n    def get_diff(self) ->str:\n        \"\"\"Generates a diff between the original source and the modified source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_diff()\n        else:\n            modified_source = self.get_modified_source()\n            return ''.join(difflib.unified_diff(self.source_code.splitlines\n                (keepends=True), modified_source.splitlines(keepends=True),\n                fromfile=f'{self.file_path} (original)', tofile=\n                f'{self.file_path} (modified)'))\n\n    def save_changes(self) ->None:\n        \"\"\"Saves the modified source code back to the file.\"\"\"\n        modified_source = self.get_modified_source()\n        with open(self.file_path, 'w', encoding='utf-8') as f:\n            f.write(modified_source)\n",
    "file": "/mnt/ProjectData/omni/code_editor.py"
  },
  {
    "id": 132,
    "hash": "cc52aa524d0929867d5d2ea3697229e6",
    "content": "\"\"\"\nGenerated file.\n\"\"\"\nimport os\n\"\"\"\nFileCreator - A utility for creating files.\n\nThis module provides a simple, encapsulated way to create files,\nensuring that their parent directories exist before writing.\n\"\"\"\n\n\nclass FileCreator:\n    \"\"\"\n    A utility class to handle the creation of new files.\n    \"\"\"\n\n    @staticmethod\n    def create(file_path: str, content: str) ->None:\n        \"\"\"\n        Creates a file at the specified path with the given content.\n\n        This method will automatically create any necessary parent\n        directories for the file path.\n\n        Args:\n            file_path: The full path where the file should be created.\n            content: The string content to write to the file.\n\n        Raises:\n            IOError: If there is an error creating the directories or writing the file.\n        \"\"\"\n        try:\n            directory = os.path.dirname(file_path)\n            if directory:\n                os.makedirs(directory, exist_ok=True)\n            with open(file_path, 'w', encoding='utf-8') as f:\n                f.write(content)\n        except (IOError, OSError) as e:\n            raise IOError(f\"Failed to create file '{file_path}': {e}\") from e\n",
    "file": "/mnt/ProjectData/omni/file_creator.py"
  },
  {
    "id": 133,
    "hash": "04a24ceab008bd649d0530d309c72e42",
    "content": "import subprocess\nimport os\nfrom typing import List, Optional, Union\n\n\nclass GitManager:\n    \"\"\"\n    Encapsulates Git-related logic for a specific repository.\n\n    This class provides methods to perform common Git operations such as\n    checking status, getting diffs, staging, committing, and pushing changes.\n    It relies on the Git command-line tool being installed and accessible\n    in the system's PATH.\n    \"\"\"\n\n    def __init__(self, repo_path: str):\n        \"\"\"\n        Initializes the GitManager for a given repository path.\n\n        Args:\n            repo_path: The absolute or relative path to the Git repository.\n\n        Raises:\n            ValueError: If the provided path is not a valid Git repository.\n        \"\"\"\n        if not os.path.isdir(os.path.join(repo_path, '.git')):\n            raise ValueError(\n                f\"The path '{repo_path}' is not a valid Git repository.\")\n        self.repo_path = repo_path\n\n    def _run_command(self, command: List[str]) ->str:\n        \"\"\"\n        Executes a Git command in the repository's directory.\n\n        Args:\n            command: A list of command arguments, starting with 'git'.\n\n        Returns:\n            The standard output of the command as a string.\n\n        Raises:\n            subprocess.CalledProcessError: If the command returns a non-zero exit code.\n        \"\"\"\n        try:\n            result = subprocess.run(command, cwd=self.repo_path, check=True,\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True,\n                encoding='utf-8')\n            return result.stdout.strip()\n        except subprocess.CalledProcessError as e:\n            error_message = (\n                f\"Git command failed: {' '.join(command)}\\nError: {e.stderr.strip()}\"\n                )\n            raise subprocess.CalledProcessError(e.returncode, e.cmd, output\n                =e.stdout, stderr=error_message) from e\n\n    def get_status(self) ->str:\n        \"\"\"\n        Gets the repository status in a condensed format.\n\n        Uses `git status --porcelain` for a machine-readable output.\n\n        Returns:\n            A string representing the repository's status.\n        \"\"\"\n        return self._run_command(['git', 'status', '--porcelain'])\n        \n    def get_changed_files(self) -> List[str]:\n        \"\"\"\n        Gets a list of all changed (modified, added, deleted, untracked, renamed, or copied) files.\n\n        This parses the output of `git status --porcelain`, which provides a stable,\n        machine-readable format.\n\n        Returns:\n            A list of file paths relative to the repository root. For renamed or\n            copied files, it returns the new path.\n        \"\"\"\n        status_output = self.get_status()\n        if not status_output:\n            return []\n        \n        changed_files = []\n        for line in status_output.splitlines():\n            if len(line) < 3:  # Skip malformed lines\n                continue\n                \n            # Git status porcelain format: XY filename\n            # X = index status, Y = working tree status\n            index_status = line[0]\n            worktree_status = line[1]\n            \n            # The filename starts after the two status characters and a space\n            # But let's be more defensive about finding where the filename actually starts\n            filename_start = 2\n            while filename_start < len(line) and line[filename_start] == ' ':\n                filename_start += 1\n                \n            if filename_start >= len(line):\n                continue  # Skip if no filename found\n                \n            path_info = line[filename_start:]\n            \n            # Check if either index or working tree status indicates rename/copy\n            if index_status in ('R', 'C') or worktree_status in ('R', 'C'):\n                if ' -> ' in path_info:\n                    _, new_path = path_info.split(' -> ', 1)  # Use maxsplit=1 for safety\n                    changed_files.append(new_path.strip())\n                else:\n                    # Fallback if format is unexpected\n                    changed_files.append(path_info.strip())\n            else:\n                changed_files.append(path_info.strip())\n        \n        # Remove duplicates while preserving order\n        return list(dict.fromkeys(changed_files))\n\n    def get_diff(self, file_path: Optional[str]=None, staged: bool=False\n        ) ->str:\n        \"\"\"\n        Gets the diff of changes in the repository.\n\n        Args:\n            file_path: Optional. Path to a specific file to diff.\n            staged: If True, shows the diff for staged changes (`--cached`).\n                    Otherwise, shows the diff for unstaged changes.\n\n        Returns:\n            The git diff output as a string.\n        \"\"\"\n        cmd = ['git', 'diff']\n        if staged:\n            cmd.append('--cached')\n        if file_path:\n            cmd.append('--')\n            cmd.append(file_path)\n        return self._run_command(cmd)\n\n    def add(self, files: Union[str, List[str]]) ->None:\n        \"\"\"\n    Stages one or more files, handling each one individually for robustness.\n\n    This approach prevents a single invalid file path from causing the\n    entire 'git add' operation to fail. Warnings will be printed for any\n    files that could not be staged.\n\n    Args:\n        files: A single file path or a list of file paths to stage.\n               Can also be '.' to stage all changes.\n    \"\"\"\n        if isinstance(files, str):\n            files = [files]\n        for file_path in files:\n            try:\n                cmd = ['git', 'add', '--', file_path]\n                self._run_command(cmd)\n            except subprocess.CalledProcessError as e:\n                print(\n                    f\"Warning: Could not stage file '{file_path}'. Git reported: {e.stderr}\"\n                    )\n\n    def commit(self, message: str) ->str:\n        \"\"\"\n        Commits staged changes with a given message.\n\n        Args:\n            message: The commit message.\n\n        Returns:\n            The stdout from the git commit command.\n        \"\"\"\n        return self._run_command(['git', 'commit', '-m', message])\n\n    def push(self, remote: str='origin', branch: Optional[str]=None) ->str:\n        \"\"\"\n        Pushes commits to a remote repository.\n\n        Args:\n            remote: The name of the remote to push to (default: 'origin').\n            branch: The branch to push. If None, uses the current branch.\n\n        Returns:\n            The stdout from the git push command.\n        \"\"\"\n        if branch is None:\n            branch = self.get_current_branch()\n        return self._run_command(['git', 'push', remote, branch])\n\n    def get_current_branch(self) ->str:\n        \"\"\"\n        Determines the current active branch name.\n\n        Returns:\n            The name of the current branch.\n        \"\"\"\n        return self._run_command(['git', 'rev-parse', '--abbrev-ref', 'HEAD'])\n",
    "file": "/mnt/ProjectData/omni/git_manager.py"
  },
  {
    "id": 134,
    "hash": "f3f7ab448ad3e233539c4e4bddcd64f4",
    "content": "# javascript_ast_adapter.py\n\n\"\"\"\nJavaScriptASTAdapter - Concrete AST adapter for JavaScript using tree-sitter.\n\nThis module implements the ASTAdapter interface specifically for JavaScript,\nleveraging the tree-sitter library for parsing and manipulation.\n\"\"\"\n\nimport difflib\nimport re\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for tree-sitter\ntry:\n    import tree_sitter\n    import tree_sitter_languages\n    TREETSITTER_AVAILABLE = True\nexcept ImportError:\n    TREETSITTER_AVAILABLE = False\n    # This will cause an error during initialization if the adapter is used\n\n\nclass JavaScriptASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for JavaScript source code.\n\n    This adapter uses tree-sitter to parse and manipulate JavaScript code.\n    It holds the parsed tree-sitter Tree and provides methods to interact\n    with it according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the JavaScriptASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The JavaScript source code as a string.\n\n        Raises:\n            ValueError: If tree-sitter libraries are not available or if\n                        the source code has invalid JavaScript syntax.\n        \"\"\"\n        if not TREETSITTER_AVAILABLE:\n            raise ValueError(\"tree-sitter and tree-sitter-languages are required for JavaScript support.\")\n            \n        # Store source code for diffing and manipulation\n        self.source_code: str = source_code\n        # Will hold the parsed tree-sitter tree\n        self.tree: Optional[tree_sitter.Tree] = None\n        # Will hold a mapping of element names to their tree-sitter nodes\n        self.nodes: Dict[str, tree_sitter.Node] = {}\n        # Tree-sitter language parser\n        self.language = tree_sitter_languages.get_language(\"javascript\")\n        self.parser = tree_sitter.Parser(self.language)\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the JavaScript source code and maps elements.\n\n        Args:\n            source_code: The JavaScript source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid JavaScript syntax.\n        \"\"\"\n        try:\n            # Encode the source code in bytes as required by tree-sitter\n            self.tree = self.parser.parse(bytes(source_code, \"utf-8\"))\n        except Exception as e:\n            raise ValueError(f\"Failed to parse JavaScript source: {e}\") from e\n\n        self.nodes = self._map_nodes()\n\n    def _map_nodes(self) -> Dict[str, tree_sitter.Node]:\n        \"\"\"\n        Walks the tree and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their tree-sitter nodes.\n        \"\"\"\n        nodes: Dict[str, tree_sitter.Node] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        # Define the types of nodes we're interested in\n        target_types = {\n            \"function_declaration\", \"class_declaration\", \n            \"variable_declarator\", \"import_statement\"\n        }\n        \n        # Walk the tree using a stack-based approach\n        stack = [self.tree.root_node]\n        while stack:\n            node = stack.pop()\n            \n            # Check if this is a target node type\n            if node.type in target_types:\n                # Extract the name for different node types\n                name = self._get_node_name(node)\n                if name and name not in nodes:\n                    nodes[name] = node\n            \n            # Add children to the stack for further processing\n            for child in reversed(node.children):  # Reverse to maintain order when popping\n                stack.append(child)\n                \n        return nodes\n    \n    def _get_node_name(self, node: tree_sitter.Node) -> Optional[str]:\n        \"\"\"\n        Extracts the name of a node based on its type.\n        \n        Args:\n            node: The tree-sitter node to extract the name from.\n            \n        Returns:\n            The name of the node, or None if no name could be found.\n        \"\"\"\n        if node.type == \"function_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"class_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"variable_declarator\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"import_statement\":\n            # This is a more complex case - for now, we'll use a simplified approach\n            # Extract the module name from the import statement\n            # e.g., in \"import foo from 'bar'\", we want \"foo\"\n            # This is a simplified implementation and might need refinement\n            import_clause = None\n            for child in node.children:\n                if child.type == \"import_clause\":\n                    import_clause = child\n                    break\n            \n            if import_clause:\n                # Check for a simple identifier\n                for child in import_clause.children:\n                    if child.type == \"identifier\":\n                        return child.text.decode(\"utf-8\")\n                    elif child.type == \"named_imports\":\n                        # Handle named imports like { foo, bar }\n                        # For simplicity, we'll just return a placeholder\n                        # A more complete implementation would extract all names\n                        return f\"import_from_{hash(node.text.decode('utf-8')) % 10000}\"\n        \n        return None\n\n    def _find_node_by_position(self, start_point: Tuple[int, int], \n                              end_point: Optional[Tuple[int, int]] = None) -> Optional[tree_sitter.Node]:\n        \"\"\"\n        Finds a node in the tree that corresponds to a given range.\n        \n        Args:\n            start_point: A (row, column) tuple indicating the start position.\n            end_point: A (row, column) tuple indicating the end position.\n            \n        Returns:\n            The tree-sitter node that corresponds to the range, or None if not found.\n        \"\"\"\n        if not self.tree:\n            return None\n            \n        # A simple approach: find the smallest node that contains the range\n        # This is a simplified implementation and might need refinement\n        def contains_range(node):\n            node_start = (node.start_point[0], node.start_point[1])\n            node_end = (node.end_point[0], node.end_point[1])\n            if end_point:\n                return (node_start <= start_point and node_end >= end_point)\n            else:\n                return node_start <= start_point <= node_end\n        \n        # Walk the tree to find matching nodes\n        stack = [self.tree.root_node]\n        candidates = []\n        \n        while stack:\n            current_node = stack.pop()\n            if contains_range(current_node):\n                candidates.append(current_node)\n                # Add children to continue searching for smaller nodes\n                stack.extend(current_node.children)\n        \n        # Return the smallest (last) candidate\n        return candidates[-1] if candidates else None\n    \n    def _get_line_info_from_point(self, point: Tuple[int, int]) -> Dict[str, Any]:\n        \"\"\"\n        Converts a tree-sitter point to line information.\n        \n        Args:\n            point: A (row, column) tuple from tree-sitter.\n            \n        Returns:\n            A dictionary with line_start and line_end information.\n        \"\"\"\n        # Tree-sitter uses 0-based indexing for rows\n        return {\n            'line_start': point[0] + 1,  # Convert to 1-based\n            'line_end': point[0] + 1\n        }\n\n    def _reparse_tree(self, new_source: str) -> None:\n        \"\"\"\n        Re-parses the tree with new source code.\n        \n        This is necessary because tree-sitter trees are immutable.\n        \n        Args:\n            new_source: The new source code to parse.\n        \"\"\"\n        self.source_code = new_source\n        self.tree = self.parser.parse(bytes(new_source, \"utf-8\"))\n        self.nodes = self._map_nodes()\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return node.text.decode(\"utf-8\")\n            except Exception:\n                # Handle potential decoding issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.type,\n            'line_start': node.start_point[0] + 1,  # Convert to 1-based\n            'line_end': node.end_point[0] + 1,\n            'body_items': []\n        }\n\n        # Add body items for functions and classes\n        if node.type in (\"function_declaration\", \"class_declaration\"):\n            # Find the body block\n            body_node = None\n            for child in node.children:\n                if child.type == \"statement_block\":\n                    body_node = child\n                    break\n            \n            if body_node:\n                # Process statements in the body\n                for i, item in enumerate(body_node.children):\n                    # Skip '{' and '}' tokens\n                    if item.type in (\"{\", \"}\"):\n                        continue\n                    \n                    item_info = {\n                        'index': i,\n                        'type': item.type,\n                        'line_start': item.start_point[0] + 1,\n                        'line_end': item.end_point[0] + 1\n                    }\n                    \n                    # Add more specific information based on type\n                    if item.type == \"variable_declaration\":\n                        item_info['declares'] = \"variable\"\n                    elif item.type == \"return_statement\":\n                        item_info['returns'] = True\n                    elif item.type in (\"if_statement\", \"for_statement\", \"while_statement\"):\n                        item_info['has_body'] = True\n                    \n                    structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n            \n        # A simplified approach to extracting a snippet by line numbers\n        # This would need to be more sophisticated for production use\n        source_lines = self.source_code.split('\\n')\n        # Adjust for 0-based indexing\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(source_lines), line_end)\n        \n        if start_idx < end_idx:\n            return '\\n'.join(source_lines[start_idx:end_idx])\n        \n        return None\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Replace the node's text in the source code\n        new_source = self.source_code[:start_byte] + new_code + self.source_code[end_byte:]\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass  # If we can't even re-parse the original, we're in trouble\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree:\n            return False\n            \n        # For simplicity, we'll add the new code at the end of the file\n        # A more sophisticated implementation would handle the anchor and positioning\n        new_source = self.source_code.rstrip() + \"\\n\\n\" + new_code + \"\\n\"\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Find the full lines that contain the node\n        # This is a simplified approach to avoid leaving partial lines\n        source_lines = self.source_code.split('\\n')\n        start_line = node.start_point[0]\n        end_line = node.end_point[0]\n        \n        # Create new source without those lines\n        new_lines = source_lines[:start_line] + source_lines[end_line+1:]\n        new_source = '\\n'.join(new_lines)\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        # This is a complex operation that would require more sophisticated\n        # tree navigation and manipulation than what's shown here.\n        # For now, we'll provide a basic implementation.\n        \n        node = self.nodes.get(element_name)\n        if not node:\n            return False\n            \n        # Handle line-based replacement\n        if line_start is not None:\n            # Convert to 0-based indexing\n            start_idx = max(0, line_start - 1)\n            end_idx = line_end if line_end is not None else start_idx + 1\n            \n            source_lines = self.source_code.split('\\n')\n            if start_idx < len(source_lines):\n                # Replace the specified lines\n                end_idx = min(end_idx, len(source_lines))\n                new_lines = source_lines[:start_idx] + [new_code] + source_lines[end_idx:]\n                new_source = '\\n'.join(new_lines)\n                \n                # Re-parse the tree with the new source\n                try:\n                    self._reparse_tree(new_source)\n                    return True\n                except Exception:\n                    # If parsing fails, revert to the original source\n                    try:\n                        self._reparse_tree(self.source_code)\n                    except Exception:\n                        pass\n        \n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        # For tree-sitter, the source code is already maintained separately\n        return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        \n        # Ensure line endings are consistent for diffing\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/javascript_ast_adapter.py"
  },
  {
    "id": 135,
    "hash": "89fa0c06ca34019316daa58ce8fa9a20",
    "content": "import json\nimport os\nfrom typing import List, Dict, Optional\nfrom rag_manager import RAGManager\n\n\nclass MemoryManager:\n    \"\"\"Manages persistent chat memory, look data, and RAG integration via JSON.\"\"\"\n\n    def __init__(self, memory_file: str):\n        self.memory_file = memory_file\n        self.memory: Dict[str, List] = self.load_memory()\n        self.rag_manager = RAGManager()\n\n    def load_memory(self) ->Dict[str, List]:\n        try:\n            with open(self.memory_file, 'r') as f:\n                return json.load(f)\n        except FileNotFoundError:\n            default = {'chat': [], 'look': []}\n            self.save_memory(default)\n            return default\n        except json.JSONDecodeError:\n            print('[yellow]Invalid memory file. Resetting.[/]')\n            return {'chat': [], 'look': []}\n\n    def save_memory(self, memory: Optional[Dict[str, List]]=None) ->None:\n        if memory is None:\n            memory = self.memory\n        with open(self.memory_file, 'w') as f:\n            json.dump(memory, f, indent=4)\n\n    def add_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.memory['chat'].append({'role': role, 'content': content})\n        self.save_memory()\n\n    def add_chat_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        This is an alias for add_message to maintain compatibility.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.add_message(role, content)\n\n    def add_look_data(self, file_path: str, content: str) ->None:\n        \"\"\"\n    Adds a watched item (directory or file) to memory, distinguishing its type.\n\n    This method stores structured data that differentiates between a project\n    directory (containing a manifest) and a single file (containing its content).\n    It also prevents duplicate entries by updating existing ones.\n\n    Args:\n        file_path: The path to the directory or file.\n        content: The manifest for a directory or the content for a file.\n    \"\"\"\n        item_type = 'directory' if os.path.isdir(file_path) else 'file'\n        for item in self.memory['look']:\n            if item.get('file') == file_path:\n                item['content'] = content\n                item['type'] = item_type\n                self.save_memory()\n                return\n        self.memory['look'].append({'type': item_type, 'file': file_path,\n            'content': content})\n        self.save_memory()\n        if item_type == 'file':\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    file_content = f.read()\n                self.rag_manager.add_documents([file_content], [{'file':\n                    file_path}])\n            except Exception as e:\n                print(\n                    f'[yellow]Warning: Could not add {file_path} to RAG index: {e}[/]'\n                    )\n\n    def get_project_root(self) ->Optional[str]:\n        \"\"\"\n        Finds the root directory of the project currently in memory.\n\n        The project root is defined as the first item in the 'look' memory\n        that is of type 'directory'.\n\n        Returns:\n            The absolute path to the project root directory, or None if not found.\n        \"\"\"\n        for item in self.memory.get('look', []):\n            if item.get('type') == 'directory':\n                return item.get('file')\n        return None\n\n    def get_memory_context(self) ->str:\n        \"\"\"\n        Dynamically builds the context using RAG and chat history.\n\n        It retrieves relevant file content from the RAG index based on the latest\n        user query, includes project manifests for directories, and appends the\n        recent chat history.\n        \"\"\"\n        context = ''\n        for look in self.memory.get('look', []):\n            path = look.get('file')\n            if path and os.path.isdir(path):\n                content = look.get('content', '')\n                context += (\n                    f'--- Project Manifest for {path} ---\\n{content}\\n\\n')\n        last_user_message = next((msg['content'] for msg in reversed(self.\n            memory.get('chat', [])) if msg['role'] == 'user'), None)\n        if last_user_message:\n            rag_results = self.search_rag(last_user_message, k=3)\n            if rag_results:\n                context += '--- Relevant context from RAG ---\\n'\n                for doc, score, meta in rag_results:\n                    file_path = meta.get('file', 'Unknown source')\n                    context += f'Source: {file_path} (Score: {score:.4f})\\n'\n                    context += f'Content: {doc}\\n---\\n'\n                context += '\\n'\n        for msg in self.memory.get('chat', []):\n            context += f\"{msg['role'].capitalize()}: {msg['content']}\\n\"\n        return context.strip()\n\n    def clear_memory(self) ->None:\n        self.memory = {'chat': [], 'look': []}\n        self.save_memory()\n        self.rag_manager.clear_index()\n\n    def search_rag(self, query: str, k: int=3) ->List[tuple]:\n        \"\"\"\n        Search the RAG index for relevant documents.\n        \n        Args:\n            query: The search query\n            k: Number of results to return\n            \n        Returns:\n            List of (document_content, score, metadata) tuples\n        \"\"\"\n        return self.rag_manager.search(query, k)\n",
    "file": "/mnt/ProjectData/omni/memory_manager.py"
  },
  {
    "id": 136,
    "hash": "c71ec060a0d980ebd390a8ae427c7a7c",
    "content": "\"\"\"\nOmni - AI-powered code generation and project-aware editing CLI tool\n\nIntegrates modular UI, memory, personality, and AST-based code editing.\n\"\"\"\nimport os\nimport subprocess\nimport requests\nimport json\nimport sys\nimport re\nimport argparse\nimport ast\nfrom datetime import datetime\nimport threading\nimport queue as Queue\nimport time\nfrom typing import List, Dict, Optional\nfrom rich import print\nfrom rich.panel import Panel\nfrom rich.console import Console\nfrom rich.tree import Tree\nfrom ui_manager import UIManager\nfrom personality_manager import PersonalityManager\nfrom memory_manager import MemoryManager\nfrom code_editor import CodeEditor\nfrom file_creator import FileCreator\nfrom git_manager import GitManager\nimport traceback\nDEFAULT_BACKEND = 'openrouter'\nOLLAMA_MODEL = 'phi4-reasoning'\nOPENROUTER_MODEL = 'qwen/qwen3-coder'\nDEFAULT_SAVE_DIR = os.path.expanduser('/mnt/ProjectData/omni/omni_saves/')\nCONFIG_FILE = 'config.json'\nMEMORY_FILE = 'memory.json'\nOLLAMA_API_URL = 'http://localhost:11434/api/generate'\nOPENROUTER_API_URL = 'https://openrouter.ai/api/v1/chat/completions'\nOPENROUTER_MODELS_API_URL = 'https://openrouter.ai/api/v1/models'\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\ncurrent_backend = DEFAULT_BACKEND\ncurrent_model = (OLLAMA_MODEL if DEFAULT_BACKEND == 'ollama' else\n    OPENROUTER_MODEL)\nOLLAMA_MODELS = {'deepseek': 'deepseek-coder:6.7b', 'codellama':\n    'codellama:13b', 'mistral': 'mistral:latest', 'llama2': 'llama2:latest',\n    'phind': 'phind-codellama:34b'}\nos.makedirs(DEFAULT_SAVE_DIR, exist_ok=True)\nTEMPLATES = {'flask':\n    \"\"\"from flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/')\ndef home():\n    return '<h1>Hello, Flask!</h1>'\n\nif __name__ == '__main__':\n    app.run(debug=True)\"\"\"\n    , 'html5':\n    \"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>New Page</title>\n</head>\n<body>\n    <h1>Hello World</h1>\n</body>\n</html>\"\"\"\n    , 'scraper':\n    \"\"\"import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        print(soup.title.text)\n    except Exception as e:\n        print(f\"[bold red]Error scraping {url}:[/] {e}\")\n\nif __name__ == \"__main__\":\n    scrape(\"https://example.com\")\"\"\"\n    }\nconsole = Console()\npersonality_manager = PersonalityManager(CONFIG_FILE)\nmemory_manager = MemoryManager(MEMORY_FILE)\nui_manager = UIManager()\nlast_query: Optional[str] = None\nlast_response: Optional[str] = None\nlast_code: Optional[str] = None\n\n\ndef start_ollama_server() ->None:\n    if current_backend != 'ollama':\n        return\n    try:\n        requests.get('http://localhost:11434', timeout=1)\n    except requests.exceptions.ConnectionError:\n        print('[cyan]Starting Ollama server...[/]')\n        subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL)\n\n\ndef query_llm(prompt: str) ->str:\n    personality = personality_manager.get_current_personality()\n    system_prompt = personality.get('system_prompt', '') if personality else ''\n    memory_context = memory_manager.get_memory_context()\n    rag_context = ''\n    try:\n        from rag_manager import RAGManager\n        project_root = memory_manager.get_project_root()\n        if project_root:\n            rag_manager = RAGManager()\n            if rag_manager.get_document_count() > 0:\n                results = rag_manager.search(prompt, k=3)\n                if results:\n                    rag_context = '\\n\\nRelevant context from codebase:\\n'\n                    for i, (doc, score, meta) in enumerate(results, 1):\n                        file_path = meta.get('file', 'Unknown')\n                        rag_context += f'{i}. [{file_path}] {doc}\\n'\n    except Exception:\n        pass\n    full_prompt = (\n        f'{system_prompt}\\n\\n{memory_context}{rag_context}\\n\\nUser: {prompt}')\n    with ui_manager.show_spinner('AI is listening and thinking...'):\n        if current_backend == 'ollama':\n            response = query_ollama(full_prompt)\n        elif current_backend == 'openrouter':\n            response = query_openrouter(full_prompt)\n        else:\n            response = '[bold red]Error:[/] Unknown backend'\n    return response\n\n\ndef query_openrouter(prompt: str) ->str:\n    if not OPENROUTER_API_KEY:\n        return '[bold red]Error:[/] OPENROUTER_API_KEY not set.'\n    headers = {'Authorization': f'Bearer {OPENROUTER_API_KEY}',\n        'Content-Type': 'application/json'}\n    payload = {'model': current_model, 'messages': [{'role': 'user',\n        'content': prompt}]}\n    try:\n        response = requests.post(OPENROUTER_API_URL, headers=headers, json=\n            payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['choices'][0]['message']['content']\n    except Exception as e:\n        error_details = ''\n        try:\n            error_details = response.json()\n        except:\n            error_details = response.text if hasattr(response, 'text'\n                ) else str(e)\n        return (\n            f'[bold red]OpenRouter Error:[/] {e}\\n[dim]Details: {error_details}[/dim]'\n            )\n\n\ndef query_ollama(prompt: str) ->str:\n    payload = {'model': current_model, 'prompt': prompt, 'stream': False}\n    try:\n        response = requests.post(OLLAMA_API_URL, json=payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['response']\n    except Exception as e:\n        return f'[bold red]Ollama Error:[/] {e}'\n\n\ndef extract_code(text: str) ->List[tuple[str, str]]:\n    matches = re.findall('```(\\\\w*)\\\\n([\\\\s\\\\S]*?)```', text)\n    return [(lang or 'text', code.strip()) for lang, code in matches\n        ] if matches else []\n\n\ndef list_models(args: list=None) ->None:\n    if current_backend == 'ollama':\n        print('[bold cyan]Popular Ollama Models:[/]')\n        for name, model_id in OLLAMA_MODELS.items():\n            print(\n                f\"{'\u2b50' if model_id == current_model else '  '} [yellow]{name:12}[/] \u2192 {model_id}\"\n                )\n    elif current_backend == 'openrouter':\n        list_openrouter_models(args or [])\n\n\ndef list_openrouter_models(args: list):\n    try:\n        from simple_term_menu import TerminalMenu\n    except ImportError:\n        ui_manager.show_error(\n            \"'simple-term-menu' is required. `pip install simple-term-menu`\")\n        return\n    try:\n        with ui_manager.show_spinner('Fetching models...'):\n            response = requests.get(OPENROUTER_MODELS_API_URL)\n            response.raise_for_status()\n        api_models_data = response.json().get('data', [])\n    except requests.RequestException as e:\n        ui_manager.show_error(f'Error fetching models: {e}')\n        return\n    all_models, sources = [], set()\n    for model_data in api_models_data:\n        if (model_id := model_data.get('id')):\n            sources.add(model_id.split('/')[0])\n            pricing = model_data.get('pricing', {})\n            is_free = pricing.get('prompt') == '0' and pricing.get('completion'\n                ) == '0'\n            all_models.append({'id': model_id, 'name': model_data.get(\n                'name'), 'source': model_id.split('/')[0], 'is_free': is_free})\n    all_models.sort(key=lambda x: (x['source'], x['name']))\n    if args and args[0].lower() == 'sources':\n        print('[bold cyan]Available Model Sources:[/]')\n        [print(f'  [yellow]{s}[/]') for s in sorted(list(sources))]\n        return\n    models_to_display, title = all_models, 'Select an OpenRouter Model'\n    if args:\n        filter_keyword = args[0].lower()\n        title = f\"Select a Model from '{filter_keyword}'\"\n        models_to_display = [m for m in all_models if filter_keyword in m[\n            'source'].lower()]\n        if not models_to_display:\n            ui_manager.show_error(f\"No models for source: '{filter_keyword}'\")\n            return\n    menu_entries = [\n        f\"{'\u2b50' if m['id'] == current_model else '  '} {m['name']} [dim]({m['id']}){' [green](FREE)[/]' if m['is_free'] else ''}[/dim]\"\n         for m in models_to_display]\n    try:\n        cursor_idx = next((i for i, m in enumerate(models_to_display) if m[\n            'id'] == current_model), 0)\n        chosen_index = TerminalMenu(menu_entries, title=f'{title}',\n            cursor_index=cursor_idx, cycle_cursor=True, clear_screen=True\n            ).show()\n        if chosen_index is not None:\n            set_model(models_to_display[chosen_index]['id'])\n        else:\n            print('Model selection cancelled.')\n    except Exception as e:\n        ui_manager.show_error(f'Menu display error: {e}')\n\n\ndef set_model(model_id: str) ->None:\n    global current_model\n    current_model = model_id\n    ui_manager.show_success(f'Model set to: {current_model}')\n\n\ndef switch_backend(backend_name: str) ->None:\n    global current_backend, current_model\n    backend_name = backend_name.lower()\n    if backend_name not in ['ollama', 'openrouter']:\n        ui_manager.show_error(f'Unknown backend: {backend_name}')\n        return\n    current_backend = backend_name\n    current_model = (OLLAMA_MODEL if backend_name == 'ollama' else\n        OPENROUTER_MODEL)\n    ui_manager.show_success(\n        f'Switched to {backend_name} backend with model: {current_model}')\n    if backend_name == 'ollama':\n        start_ollama_server()\n\n\ndef generate_project_manifest(path: str) ->tuple[str, List[str]]:\n    manifest = ''\n    file_paths = []\n    tree = Tree(f'[bold cyan]Project: {os.path.basename(path)}[/]')\n    exclude_dirs = {'__pycache__', '.git', 'venv', 'node_modules', '.idea',\n        'ollama'}\n    for root, dirs, files in os.walk(path):\n        dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.\n            startswith('.')]\n        relative_path = os.path.relpath(root, path)\n        branch = tree\n        if relative_path != '.':\n            parts = relative_path.split(os.sep)\n            for part in parts:\n                child = next((c for c in branch.children if c.label ==\n                    f'[magenta]{part}[/]'), None)\n                if not child:\n                    child = branch.add(f'[magenta]{part}[/]')\n                branch = child\n        for fname in sorted(files):\n            ext = os.path.splitext(fname)[1]\n            if ext not in ('.py', '.js', '.html', '.css', '.md', '.txt'):\n                continue\n            rel_path = os.path.join(relative_path, fname\n                ) if relative_path != '.' else fname\n            file_paths.append(rel_path)\n            branch.add(f'[green]{fname}[/]' if ext == '.py' else\n                f'[dim]{fname}[/]')\n            manifest += f'File: {rel_path}\\n\\n'\n    console.print(tree)\n    return manifest.strip(), file_paths\n\n\ndef look_command(path: str) ->None:\n    \"\"\"\n    Scans a directory or file and loads it into memory. It can resolve paths\n    relative to the current working directory or the project root in memory.\n    If a new directory is scanned, the previous 'look' context is cleared\n    to ensure the context remains relevant.\n    \"\"\"\n    resolved_path = resolve_file_path(path)\n    if not resolved_path:\n        ui_manager.show_error(f'\u274c Path not found: {path}')\n        return\n    if resolved_path != os.path.abspath(path):\n        ui_manager.show_success(\n            f\"Found '{path}' in project. Using: {resolved_path}\")\n    if os.path.isdir(resolved_path):\n        ui_manager.show_success(\n            \"New project directory detected. Clearing previous 'look' context.\"\n            )\n        memory_manager.memory['look'] = []\n        with ui_manager.show_spinner('Generating project manifest...'):\n            manifest = generate_project_manifest(resolved_path)\n        memory_manager.add_look_data(resolved_path, manifest)\n        ui_manager.show_success('\u2705 Project manifest added to memory.')\n    else:\n        try:\n            with ui_manager.show_spinner('Loading file...'):\n                with open(resolved_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n            for item in memory_manager.memory['look']:\n                if item.get('file') == resolved_path:\n                    item['content'] = content\n                    memory_manager.save_memory()\n                    ui_manager.show_success(\n                        '\u2705 Refreshed file content in memory.')\n                    return\n            memory_manager.add_look_data(resolved_path, content)\n            ui_manager.show_success('\u2705 File content added to memory.')\n        except Exception as e:\n            ui_manager.show_error(f'\u274c Error reading file: {e}')\n\n\ndef resolve_file_path(path: str) ->Optional[str]:\n    \"\"\"Resolves a file path, checking CWD first, then against project root in memory.\"\"\"\n    if os.path.exists(path):\n        return os.path.abspath(path)\n    project_root = memory_manager.get_project_root()\n    if project_root:\n        full_path = os.path.join(project_root, path)\n        if os.path.exists(full_path):\n            return full_path\n    return None\n\n\ndef _create_prompt_for_file_creation(file_name: str, instruction: str) ->str:\n    \"\"\"\n    Generate a robust prompt for file creation that instructs the AI to act as an expert,\n    produce complete and clean code, and avoid any extra commentary.\n    \"\"\"\n    return f\"\"\"You are an expert programmer tasked with creating a new file. Your goal is to generate complete, production-ready content based on the user's instruction.\n\nIMPORTANT RULES:\n- Provide ONLY the raw file content - no explanations, notes, or commentary outside the file itself\n- Include all necessary imports, boilerplate, and complete implementations\n- If creating code, ensure it's syntactically correct and follows best practices\n- For configuration files, use appropriate formatting (JSON, YAML, etc.)\n- For documentation files, use proper markdown formatting\n\nFile to create: {file_name}\nUser instruction: {instruction}\n\nGenerate the complete file content now:\"\"\"\n\n\ndef handle_file_create_command(file_path: str, instruction: str):\n    \"\"\"\n    Uses the LLM to generate content for a new file based on an instruction.\n    \"\"\"\n    global last_code\n    if os.path.exists(file_path):\n        if ui_manager.get_user_input(\n            f\"File '{file_path}' already exists. Overwrite? (y/n): \").lower(\n            ) not in ['yes', 'y']:\n            ui_manager.show_error('File creation cancelled.')\n            return\n    prompt = _create_prompt_for_file_creation(os.path.basename(file_path),\n        instruction)\n    with ui_manager.show_spinner(\n        f\"AI is generating content for '{file_path}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    if code_blocks:\n        new_content = code_blocks[0][1]\n    else:\n        new_content = response.strip()\n    if not new_content:\n        ui_manager.show_error('AI did not return any content.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    print(Panel(new_content, title=\n        f'[bold yellow]Proposed content for {file_path}[/]', border_style=\n        'yellow'))\n    if ui_manager.get_user_input('Create this file? (y/n): ').lower() in ['yes'\n        , 'y']:\n        try:\n            FileCreator.create(file_path, new_content)\n            last_code = new_content\n            ui_manager.show_success(f'File created successfully: {file_path}')\n        except IOError as e:\n            ui_manager.show_error(f'Error creating file: {e}')\n    else:\n        ui_manager.show_error('File creation cancelled.')\n\n\ndef look_all_command() ->None:\n    \"\"\"\n    Finds the project manifest in memory, reads every file listed, and adds their content to memory.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first to generate a manifest.\"\n            )\n        return\n    manifest_data = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and item.get('type'\n            ) == 'directory':\n            manifest_data = item.get('content')\n            break\n    if not manifest_data or not isinstance(manifest_data, (list, tuple)\n        ) or len(manifest_data) != 2:\n        ui_manager.show_error(\n            \"Could not find a valid project manifest in memory. Please run 'look <directory>' again.\"\n            )\n        return\n    file_paths = manifest_data[1]\n    if not file_paths:\n        ui_manager.show_error('No files found in the project manifest.')\n        return\n    total_files = len(file_paths)\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Loading {total_files} files from project manifest...'):\n        for file_path_relative in file_paths:\n            full_path = os.path.join(project_root, file_path_relative)\n            if os.path.isfile(full_path):\n                try:\n                    with open(full_path, 'r', encoding='utf-8') as f:\n                        content = f.read().strip()\n                    if not any(look['file'] == full_path for look in\n                        memory_manager.memory['look']):\n                        memory_manager.add_look_data(full_path, content)\n                        loaded_count += 1\n                except Exception as e:\n                    print(\n                        f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\"\n                        )\n    ui_manager.show_success(\n        f'\u2705 Loaded content for {loaded_count} new files into memory.')\n\n\ndef _load_all_project_files_if_needed():\n    \"\"\"\n    Checks if a project is loaded and automatically loads any files from its\n    manifest that are not already in the 'look' memory. This ensures a\n    complete context for editing and refactoring commands.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        return\n    manifest_content = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and 'File:' in item.get('content',\n            ''):\n            manifest_content = item['content']\n            break\n    if not manifest_content:\n        return\n    existing_file_paths = {item['file'] for item in memory_manager.memory.\n        get('look', []) if item.get('type') == 'file'}\n    file_paths_relative = re.findall('File: (.*)', manifest_content)\n    files_to_load = []\n    for rel_path in file_paths_relative:\n        full_path = os.path.join(project_root, rel_path)\n        if full_path not in existing_file_paths and os.path.isfile(full_path):\n            files_to_load.append((full_path, rel_path))\n    if not files_to_load:\n        return\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Auto-loading {len(files_to_load)} project files for context...'):\n        for full_path, file_path_relative in files_to_load:\n            try:\n                with open(full_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n                memory_manager.add_look_data(full_path, content)\n                loaded_count += 1\n            except Exception as e:\n                print(f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\")\n    if loaded_count > 0:\n        ui_manager.show_success(\n            f'\u2705 Loaded {loaded_count} new file(s) into memory for full project context.'\n            )\n\n\ndef _create_prompt_for_element_selection(file_name: str, instruction: str,\n    elements: List[str], element_structures: Dict[str, Dict]) ->str:\n    \"\"\"\n    Create a helper for the first stage of the 'edit' command. This prompt asks the AI\n    to analyze the user's instruction and intelligently select the most relevant code element to modify.\n    \"\"\"\n    element_details = []\n    for elem in elements:\n        if elem in element_structures:\n            struct = element_structures[elem]\n            detail = (\n                f\"{elem} ({struct['type']}, lines {struct['line_start']}-{struct['line_end']})\"\n                )\n            element_details.append(detail)\n        else:\n            element_details.append(elem)\n    return f\"\"\"You are an expert code analyzer. Your task is to identify what should be modified based on the user's instruction.\n\nFile: {file_name}\nAvailable elements: {', '.join(element_details) if element_details else 'None'}\n\nUser instruction: {instruction}\n\nRESPONSE FORMAT:\nChoose one of these response types:\n1. \"ELEMENT: <element_name>\" - to edit an entire function/class\n2. \"PARTIAL: <element_name> LINES: <start>-<end>\" - to edit specific lines within an element\n3. \"FILE\" - to edit the entire file or multiple elements\n\nRULES:\n- If the instruction mentions specific line numbers or a specific part of a function, use PARTIAL\n- If the instruction targets an entire function/class, use ELEMENT\n- If the instruction requires changes to multiple elements or file structure, use FILE\n- For PARTIAL edits, provide absolute line numbers from the original file\n\nWhat should be edited?\"\"\"\n\n\ndef _create_prompt_for_element_rewrite(file_name: str, element_name: str,\n    instruction: str, original_code: str, is_full_file: bool=False) ->str:\n    \"\"\"\n    Create a helper for the second stage of the 'edit' command. This prompt instructs the AI\n    to rewrite a specific code element (or the whole file) based on the user's request,\n    demanding a complete and syntactically correct code block as output.\n    \"\"\"\n    if is_full_file:\n        return f\"\"\"You are an expert programmer. Rewrite the entire file to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the entire file\n- Ensure all syntax is correct and the code is ready to run\n- Preserve existing functionality unless explicitly asked to change it\n- Include all necessary imports and maintain the file's structure\n- Do NOT include any explanations or comments outside the code\n\nFile: {file_name}\nTask: {instruction}\n\nCurrent file content:\n```python\n{original_code}\n```\n\nGenerate the complete updated file now:\"\"\"\n    else:\n        return f\"\"\"You are an expert programmer. Rewrite the specified element to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the element\n- Include any necessary imports at the top of your code block\n- Ensure the code is syntactically correct and maintains the same interface\n- Do NOT include explanations or comments outside the code block\n- The code must be a drop-in replacement for the original element\n\nFile: {file_name}\nElement to modify: {element_name}\nTask: {instruction}\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the complete updated element now:\"\"\"\n\n\ndef _create_prompt_for_partial_edit(file_name: str, element_name: str,\n    instruction: str, original_snippet: str, line_start: int, line_end: int,\n    full_element_code: str) ->str:\n    \"\"\"\n    Create a prompt for partial edits within a function or class.\n    This allows surgical changes to specific parts of code.\n    \"\"\"\n    return f\"\"\"You are an expert programmer. Make a surgical edit to a specific part of a function/class.\n\nCONTEXT:\n- File: {file_name}\n- Element: {element_name}\n- Lines to modify: {line_start}-{line_end}\n- Task: {instruction}\n\nIMPORTANT RULES:\n- Provide ONLY the code that will replace lines {line_start}-{line_end}\n- Your code must fit seamlessly into the existing function\n- Maintain proper indentation (the code will be auto-indented)\n- Do NOT include the function definition or other parts\n- Do NOT include explanations outside the code\n\nFull element for context:\n```python\n{full_element_code}\n```\n\nCode section to replace (lines {line_start}-{line_end}):\n```python\n{original_snippet}\n```\n\nGenerate ONLY the replacement code for the specified lines:\"\"\"\n\n\ndef handle_file_edit_command(file_path: str, instruction: str):\n    \"\"\"\n    Handles the entire workflow for editing a single file, ensuring full\n    project context is loaded before the AI makes any decisions.\n    Now supports partial edits within functions.\n    \"\"\"\n    global last_code\n    _load_all_project_files_if_needed()\n    resolved_path = resolve_file_path(file_path)\n    if not resolved_path:\n        ui_manager.show_error(f'File not found: {file_path}')\n        return\n    if resolved_path != os.path.abspath(file_path):\n        ui_manager.show_success(\n            f\"Found '{file_path}' in project. Using: {resolved_path}\")\n    try:\n        editor = CodeEditor(resolved_path)\n    except (ValueError, FileNotFoundError) as e:\n        ui_manager.show_error(str(e))\n        return\n    elements = editor.list_elements()\n    element_structures = {}\n    for elem in elements:\n        struct = editor.get_element_structure(elem)\n        if struct:\n            element_structures[elem] = struct\n    prompt1 = _create_prompt_for_element_selection(os.path.basename(\n        resolved_path), instruction, elements, element_structures)\n    with ui_manager.show_spinner('AI is analyzing file...'):\n        ai_response = query_llm(prompt1).strip()\n    if ai_response.upper() == 'FILE':\n        ui_manager.show_success('AI has chosen to edit the entire file.')\n        original_snippet = editor.source_code\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), 'entire file', instruction, original_snippet,\n            is_full_file=True)\n        edit_type = 'FILE'\n        element_to_edit = None\n        line_range = None\n    elif ai_response.startswith('PARTIAL:'):\n        parts = ai_response.split()\n        element_to_edit = parts[1]\n        if 'LINES:' in ai_response:\n            line_part = ai_response.split('LINES:')[1].strip()\n            if '-' in line_part:\n                line_start, line_end = map(int, line_part.split('-'))\n                line_range = line_start, line_end\n            else:\n                ui_manager.show_error('Invalid line range format')\n                return\n        else:\n            ui_manager.show_error('Missing line range for partial edit')\n            return\n        if element_to_edit not in elements:\n            ui_manager.show_error(f\"Element '{element_to_edit}' not found\")\n            return\n        ui_manager.show_success(\n            f\"AI selected partial edit of '{element_to_edit}' (lines {line_start}-{line_end})\"\n            )\n        original_snippet = editor.get_element_body_snippet(element_to_edit,\n            line_start, line_end)\n        if not original_snippet:\n            original_snippet = editor.get_source_of(element_to_edit)\n        full_element_code = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_partial_edit(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet,\n            line_start, line_end, full_element_code)\n        edit_type = 'PARTIAL'\n    elif ai_response.startswith('ELEMENT:'):\n        element_to_edit = ai_response.split(':', 1)[1].strip()\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    else:\n        element_to_edit = ai_response.splitlines()[0]\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    with ui_manager.show_spinner(f'AI is editing...'):\n        response = query_llm(prompt2)\n    code_blocks = extract_code(response)\n    if not code_blocks:\n        ui_manager.show_error('AI did not return a valid code block.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    new_code = code_blocks[0][1]\n    success = False\n    if edit_type == 'FILE':\n        try:\n            editor.tree = ast.parse(new_code)\n            success = True\n        except SyntaxError as e:\n            ui_manager.show_error(f'AI returned invalid Python syntax: {e}')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    elif edit_type == 'PARTIAL':\n        success = editor.replace_partial(element_to_edit, new_code,\n            line_start=line_range[0], line_end=line_range[1])\n        if not success:\n            ui_manager.show_error('Failed to apply partial edit.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    else:\n        success = editor.replace_element(element_to_edit, new_code)\n        if not success:\n            ui_manager.show_error(\n                'AI returned invalid code; could not be parsed or applied.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    if not (diff := editor.get_diff()):\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(diff, title=\n        f'[bold yellow]Proposed Changes for {resolved_path}[/]'))\n    if ui_manager.get_user_input('Apply changes? (y/n): ').lower() in ['yes',\n        'y']:\n        editor.save_changes()\n        last_code = editor.get_modified_source()\n        ui_manager.show_success(f'Changes saved to {resolved_path}.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_plan(instruction: str, memory_context: str\n    ) ->str:\n    \"\"\"\n    Create a specialized prompt-generation function for the 'refactor' command.\n    This prompt will explicitly define the required JSON structure for the plan\n    and instruct the AI to act as an expert project manager.\n    \"\"\"\n    return f\"\"\"You are an expert project manager and software architect. Analyze the project context and create a detailed refactoring plan.\n\nYour plan must be a valid JSON object with this exact structure:\n{{\n    \"actions\": [\n        {{\n            \"type\": \"MODIFY\" | \"CREATE\" | \"DELETE\" | \"PARTIAL\",\n            \"file\": \"relative/path/to/file.py\",\n            \"element\": \"function_or_class_name\",  // For MODIFY/DELETE/PARTIAL\n            \"element_name\": \"new_element_name\",    // For CREATE\n            \"line_start\": 10,                      // For PARTIAL only\n            \"line_end\": 20,                        // For PARTIAL only\n            \"reason\": \"Clear explanation of why this change is needed\",\n            \"description\": \"What this action will accomplish\",\n            \"anchor_element\": \"optional_anchor\",   // Optional for CREATE\n            \"position\": \"before\" | \"after\"         // Optional for CREATE\n        }}\n    ]\n}}\n\nACTION TYPES:\n- MODIFY: Change an entire function, class, or method\n- PARTIAL: Change specific lines within a function/class (requires line_start and line_end)\n- CREATE: Add new functions, classes, or files\n- DELETE: Remove functions, classes, variables, or imports\n\nRULES FOR YOUR PLAN:\n- Use PARTIAL when you only need to change a small part of a function\n- Use MODIFY when restructuring an entire function or class\n- Each action must have all required fields based on its type\n- File paths must be relative to the project root\n- Be specific and surgical - avoid unnecessary changes\n- Consider dependencies between changes\n- Order actions logically (e.g., create dependencies before using them)\n\n### Project Context ###\n{memory_context}\n\n### Refactoring Request ###\n{instruction}\n\nGenerate ONLY the JSON plan - no explanations or markdown:\"\"\"\n\n\ndef _get_refactor_plan(instruction: str) ->Optional[List[Dict]]:\n    \"\"\"\n    Generates a refactoring plan from the LLM.\n\n    This function encapsulates the logic for checking project context,\n    constructing a prompt, querying the LLM, and parsing the resulting\n    JSON plan for a refactoring task.\n\n    Args:\n        instruction: The user's high-level refactoring instruction.\n\n    Returns:\n        A list of action dictionaries if a valid plan is generated,\n        otherwise None.\n    \"\"\"\n    if not memory_manager.get_project_root():\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return None\n    memory_context = memory_manager.get_memory_context()\n    plan_prompt = _create_prompt_for_refactor_plan(instruction, memory_context)\n    with ui_manager.show_spinner('AI is creating an execution plan...'):\n        plan_str = query_llm(plan_prompt)\n    try:\n        match = re.search('\\\\{.*\\\\}', plan_str, re.DOTALL)\n        if not match:\n            raise ValueError('No JSON object found in the response.')\n        plan = json.loads(match.group(0))\n        actions = plan.get('actions', [])\n        if not actions:\n            raise ValueError(\"No 'actions' key found in plan or plan is empty.\"\n                )\n        return actions\n    except (json.JSONDecodeError, ValueError) as e:\n        ui_manager.show_error(f'AI failed to generate a valid plan: {e}')\n        print(Panel(plan_str, title=\"[yellow]AI's Invalid Plan Response[/]\",\n            border_style='yellow'))\n        return None\n\n\ndef _display_and_confirm_plan(plan: Dict) ->bool:\n    \"\"\"\n    Displays the generated execution plan to the user and asks for confirmation.\n\n    This helper function separates the UI interaction of plan confirmation from\n    the main refactoring logic.\n\n    Args:\n        plan: A dictionary, expected to contain an 'actions' key with a list of action dicts.\n\n    Returns:\n        True if the user confirms the plan, False otherwise.\n    \"\"\"\n    actions = plan.get('actions', [])\n    if not actions:\n        ui_manager.show_error('The generated plan is empty. Aborting.')\n        return False\n    ui_manager.show_success('AI has created a plan:')\n    for i, action in enumerate(actions):\n        action_type = action.get('type', 'N/A')\n        element = action.get('element') or action.get('element_name', 'N/A')\n        reason = action.get('reason') or action.get('description', '')\n        file_path = action.get('file', '')\n        if action_type == 'PARTIAL':\n            line_start = action.get('line_start', '?')\n            line_end = action.get('line_end', '?')\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} (lines {line_start}-{line_end}) - {reason}'\n                )\n        else:\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} - {reason}'\n                )\n    if ui_manager.get_user_input('\\nProceed with this plan? (y/n): ').lower(\n        ) in ['yes', 'y']:\n        return True\n    else:\n        ui_manager.show_error('Execution aborted by user.')\n        return False\n\n\ndef _apply_refactor_changes(editors: Dict[str, CodeEditor]) ->None:\n    \"\"\"\n    Consolidates changes from multiple CodeEditor instances, shows a unified\n    diff, and prompts the user to apply them.\n    \n    This helper function abstracts the final step of a refactor, ensuring\n    all proposed modifications are presented to the user for a final review\n    before any files are written to disk.\n\n    Args:\n        editors: A dictionary mapping absolute file paths to their\n                 corresponding CodeEditor instances which hold the\n                 proposed changes in their AST.\n    \"\"\"\n    full_diff = ''\n    for editor in editors.values():\n        diff = editor.get_diff()\n        if diff:\n            full_diff += diff + '\\n'\n    if not full_diff.strip():\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(full_diff, title=\n        '[bold yellow]Proposed Project-Wide Changes[/]'))\n    if ui_manager.get_user_input('Apply all changes? (y/n): ').lower() in [\n        'yes', 'y']:\n        for editor in editors.values():\n            editor.save_changes()\n        ui_manager.show_success('\u2705 Project changes applied successfully.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_action(action_type: str, file_path: str,\n    action_details: Dict) ->str:\n    \"\"\"\n    Create a helper to generate prompts for individual 'CREATE' or 'MODIFY' steps\n    within a refactor plan. This ensures the AI produces code for the specific\n    sub-task in the correct context.\n    \"\"\"\n    if action_type == 'MODIFY':\n        element_name = action_details['element_name']\n        reason = action_details['reason']\n        original_code = action_details['original_code']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- Element: {element_name}\n- Reason for change: {reason}\n\nRULES:\n- Provide ONLY the complete updated code for the element\n- Include any necessary imports at the top\n- Ensure the code integrates properly with the rest of the file\n- Maintain the same function/class signature unless the change requires otherwise\n- No explanations outside the code block\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the updated element code:\"\"\"\n    elif action_type == 'CREATE':\n        element_name = action_details['element_name']\n        description = action_details['description']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- New element to create: {element_name}\n- Purpose: {description}\n\nRULES:\n- Provide ONLY the complete code for the new element\n- Include all necessary imports at the top\n- Follow the coding style and patterns used in the project\n- Ensure the code is production-ready and well-structured\n- For non-Python files, provide the complete file content\n- No explanations outside the code block\n\nGenerate the new element code:\"\"\"\n\n\ndef _process_refactor_action(action: Dict, project_base_path: str, editors:\n    Dict) ->bool:\n    \"\"\"\n    Processes a single refactoring action from the plan.\n\n    This function handles the execution of a single action from the refactoring plan,\n    including LLM code generation and applying changes to in-memory editors or files.\n\n    Args:\n        action: A dictionary containing action details (type, file, element, etc.)\n        project_base_path: The absolute path to the project root\n        editors: Dictionary mapping file paths to their CodeEditor instances\n\n    Returns:\n        True if the action was processed successfully, False otherwise\n    \"\"\"\n    file_path_relative = action.get('file')\n    if not file_path_relative:\n        ui_manager.show_error(\n            f\"Action is missing 'file' key. Skipping: {action}\")\n        return False\n    file_path_absolute = os.path.join(project_base_path, file_path_relative)\n    action_type = action.get('type', '').upper()\n    prompt, element_name = '', ''\n    if action_type == 'MODIFY':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_source_of(element_name)\n            if not original_snippet:\n                ui_manager.show_error(\n                    f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                    )\n                return False\n            action_details = {'element_name': element_name, 'reason':\n                reason, 'original_code': original_snippet}\n            prompt = _create_prompt_for_refactor_action('MODIFY',\n                file_path_relative, action_details)\n    elif action_type == 'PARTIAL':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        line_start = action.get('line_start')\n        line_end = action.get('line_end')\n        if not all([element_name, line_start, line_end]):\n            ui_manager.show_error(\n                f'PARTIAL action missing required fields. Skipping: {action}')\n            return False\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_element_body_snippet(element_name,\n                line_start, line_end)\n            if not original_snippet:\n                original_snippet = editor.get_source_of(element_name)\n                if not original_snippet:\n                    ui_manager.show_error(\n                        f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                        )\n                    return False\n            full_element_code = editor.get_source_of(element_name)\n            prompt = _create_prompt_for_partial_edit(file_path_relative,\n                element_name, reason, original_snippet, line_start,\n                line_end, full_element_code)\n    elif action_type == 'CREATE':\n        element_name = action.get('element_name')\n        description = action.get('description')\n        action_details = {'element_name': element_name, 'description':\n            description}\n        prompt = _create_prompt_for_refactor_action('CREATE',\n            file_path_relative, action_details)\n    else:\n        ui_manager.show_error(f\"Invalid action type '{action_type}'. Skipping.\"\n            )\n        return False\n    with ui_manager.show_spinner(\n        f\"AI: {action_type} on '{element_name or file_path_relative}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    new_content = code_blocks[0][1] if code_blocks else response.strip()\n    if not new_content:\n        ui_manager.show_error(\n            f'AI failed to generate content for action: {action}')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return False\n    if not file_path_relative.endswith('.py'):\n        try:\n            FileCreator.create(file_path_absolute, new_content)\n            ui_manager.show_success(\n                f\"File '{file_path_relative}' created/updated.\")\n            return True\n        except IOError as e:\n            ui_manager.show_error(\n                f\"Failed to create file '{file_path_relative}': {e}\")\n            return False\n    if file_path_absolute not in editors:\n        try:\n            if not os.path.exists(file_path_absolute):\n                os.makedirs(os.path.dirname(file_path_absolute), exist_ok=True)\n                with open(file_path_absolute, 'w') as f:\n                    f.write('')\n            editors[file_path_absolute] = CodeEditor(file_path_absolute)\n        except Exception as e:\n            ui_manager.show_error(\n                f'Error loading file {file_path_absolute}: {e}')\n            return False\n    editor = editors[file_path_absolute]\n    if action_type == 'MODIFY':\n        if not editor.replace_element(element_name, new_content):\n            ui_manager.show_error(\n                f\"Failed to apply MODIFY change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic MODIFY Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'PARTIAL':\n        if not editor.replace_partial(element_name, new_content, line_start,\n            line_end):\n            ui_manager.show_error(\n                f\"Failed to apply PARTIAL change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic PARTIAL Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'CREATE':\n        anchor = action.get('anchor_element')\n        position = action.get('position', 'after')\n        if not editor.add_element(new_content, anchor_name=anchor, before=\n            position == 'before'):\n            ui_manager.show_error(\n                f\"Failed to apply CREATE change for '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic CREATE Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    return True\n\n\ndef handle_project_refactor_command(instruction: str):\n    \"\"\"\n    Orchestrates a multi-file, multi-step code refactoring process.\n    \n    This function serves as a high-level orchestrator that delegates specific tasks\n    to helper functions, improving readability, modularity, and maintainability.\n    \"\"\"\n    _load_all_project_files_if_needed()\n    actions = _get_refactor_plan(instruction)\n    if not actions:\n        return\n    plan = {'actions': actions}\n    if not _display_and_confirm_plan(plan):\n        return\n    editors: Dict[str, CodeEditor] = {}\n    project_base_path = memory_manager.get_project_root()\n    successful_actions = 0\n    total_actions = len(actions)\n    for i, action in enumerate(actions, 1):\n        ui_manager.show_success(f'Processing action {i}/{total_actions}...')\n        action_type = action.get('type', '').upper()\n        file_path_relative = action.get('file')\n        if not file_path_relative:\n            ui_manager.show_error(\n                f\"Action is missing 'file' key. Skipping: {action}\")\n            continue\n        file_path_absolute = os.path.join(project_base_path, file_path_relative\n            )\n        if action_type == 'DELETE':\n            element_name = action.get('element')\n            if not element_name:\n                ui_manager.show_error(\n                    f\"DELETE action missing 'element' key. Skipping: {action}\")\n                continue\n            if not file_path_relative.endswith('.py'):\n                ui_manager.show_error(\n                    f'DELETE actions are only supported for Python files. Skipping.'\n                    )\n                continue\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    continue\n            editor = editors[file_path_absolute]\n            if editor.delete_element(element_name):\n                successful_actions += 1\n                ui_manager.show_success(\n                    f\"Successfully deleted '{element_name}' from '{file_path_relative}'.\"\n                    )\n            else:\n                ui_manager.show_error(\n                    f\"Failed to delete '{element_name}' from '{file_path_relative}'.\"\n                    )\n        elif _process_refactor_action(action, project_base_path, editors):\n            successful_actions += 1\n        else:\n            ui_manager.show_error(\n                f'Action {i} failed, continuing with remaining actions...')\n    if successful_actions == 0:\n        ui_manager.show_error('No actions were successfully executed.')\n        return\n    elif successful_actions < total_actions:\n        ui_manager.show_error(\n            f'Only {successful_actions}/{total_actions} actions completed successfully.'\n            )\n    else:\n        ui_manager.show_success(\n            f'All {total_actions} actions completed successfully.')\n    _apply_refactor_changes(editors)\n\n\ndef _create_prompt_for_commit_message(diff: str) ->str:\n    \"\"\"\n    Create a dedicated prompt function for the 'commit' command. This prompt will\n    instruct the AI to analyze a git diff and generate a concise commit message\n    following the Conventional Commits standard.\n    \"\"\"\n    return f\"\"\"You are an expert developer writing a Git commit message. Your task is to analyze the provided git diff and create a professional commit message.\n\nCOMMIT MESSAGE RULES:\n- Follow the Conventional Commits specification\n- Format: <type>(<optional scope>): <subject>\n- Types: feat, fix, docs, style, refactor, perf, test, build, ci, chore, revert\n- Subject line: max 50 characters, imperative mood, no period\n- Optional body: explain what and why (not how), wrap at 72 characters\n- Be specific and concise\n- Focus on the intent and impact of the changes\n\nEXAMPLES OF GOOD COMMIT MESSAGES:\n- feat(auth): add OAuth2 integration for Google login\n- fix(api): handle null response in user endpoint\n- refactor(database): optimize query performance for large datasets\n- docs(readme): update installation instructions for Windows\n\nRespond with ONLY the commit message - no markdown, quotes, or explanations.\n\n--- GIT DIFF TO ANALYZE ---\n{diff}\n\nGenerate the commit message:\"\"\"\n\n\ndef handle_commit_command():\n    \"\"\"\n    Orchestrates an AI-assisted Git commit workflow with improved error handling.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return\n    try:\n        git_manager = GitManager(project_root)\n    except ValueError as e:\n        ui_manager.show_error(str(e))\n        return\n    changed_files = git_manager.get_changed_files()\n    if not changed_files:\n        ui_manager.show_success(\n            'No changes to commit. Everything is up to date.')\n        return\n    staged_diff = git_manager.get_diff(staged=True)\n    unstaged_diff = git_manager.get_diff()\n    full_diff = f'{staged_diff}\\n{unstaged_diff}'.strip()\n    if not full_diff.strip():\n        ui_manager.show_success(\n            'No content changes detected (e.g., only file mode changes).')\n        return\n    prompt = _create_prompt_for_commit_message(full_diff)\n    commit_message = query_llm(prompt).strip()\n    if not commit_message:\n        ui_manager.show_error(\n            'AI failed to generate a commit message. Aborting.')\n        return\n    files_to_commit_str = '\\n'.join(f'- {f}' for f in changed_files)\n    plan_panel_content = f\"\"\"[bold]Files to be staged:[/]\n[yellow]{files_to_commit_str}[/]\n\n[bold]AI-Generated Commit Message:[/]\n[green]{commit_message}[/]\"\"\"\n    print(Panel(plan_panel_content, title='[bold cyan]Commit Plan[/]',\n        border_style='cyan'))\n    if ui_manager.get_user_input('\\nProceed with commit? (y/n): ').lower() in [\n        'yes', 'y']:\n        try:\n            git_manager.add(changed_files)\n            ui_manager.show_success('\u2705 Files staged.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Staging failed: {e.stderr}')\n            return\n        try:\n            git_manager.commit(commit_message)\n            ui_manager.show_success('\u2705 Commit successful.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Commit failed: {e.stderr}')\n            return\n        if ui_manager.get_user_input('Push changes to remote? (y/n): ').lower(\n            ) in ['yes', 'y']:\n            try:\n                git_manager.push()\n                ui_manager.show_success('\u2705 Push successful.')\n            except subprocess.CalledProcessError as e:\n                ui_manager.show_error(f'Push failed: {e.stderr}')\n        else:\n            ui_manager.show_error('Push cancelled.')\n    else:\n        ui_manager.show_error('Commit aborted by user.')\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef interactive_mode() ->None:\n    global last_query, last_response, last_code\n    try:\n        from Testing.overlay_engine import show_sequential_popup\n        gui_available = True\n    except ImportError:\n        gui_available = False\n    print(Panel(\n        \"\"\"[bold cyan]Omni Interactive Mode[/]\n[dim]Type 'help' for commands, 'exit' to quit.[/dim]\"\"\"\n        , border_style='cyan'))\n    personality_name = personality_manager.get_current_personality().get('name'\n        , 'Default')\n    gui_enabled = False\n    if gui_available:\n        try:\n            with open(CONFIG_FILE, 'r') as f:\n                config = json.load(f)\n                if config.get('gui_enabled', False):\n                    gui_enabled = True\n        except (FileNotFoundError, json.JSONDecodeError):\n            pass\n    refresh_status_panel(personality_name)\n    while True:\n        try:\n            user_input = ui_manager.get_user_input('\\n> ')\n            if not user_input:\n                continue\n            command, *args = user_input.split(maxsplit=1)\n            arg_str = args[0] if args else ''\n            if command == 'exit':\n                memory_manager.save_memory()\n                print('[bold cyan]Goodbye![/]')\n                break\n            elif command == 'help':\n                print(\n                    \"\"\"[bold]Commands:[/]\n\n  [bold cyan]Core & Project Commands[/]\n  [yellow]send <prompt>[/]        - Ask the LLM a question.\n  [yellow]look <path>[/]          - Read file or scan directory into memory.\n  [yellow]look_all[/]            - Recursively scan the project directory into memory.\n  [yellow]create <file> \"instr\"[/] - Create a new file using AI.\n  [yellow]edit <file> \"instr\"[/]   - Edit a specific file using AI.\n  [yellow]refactor \"instr\"[/]      - Refactor project in memory based on instruction.\n  [yellow]commit[/]               - Commit changes with an AI-generated message.\n  [yellow]rag <query>[/]         - Query the RAG system for context retrieval.\n\n  [bold cyan]File & Code Management[/]\n  [yellow]save <filename>[/]     - Save last AI response to a file.\n  [yellow]list[/]               - List saved files.\n  [yellow]run[/]                 - Run the last generated Python code.\n\n  [bold cyan]Session & Config[/]\n  [yellow]history[/]             - Show the full chat history.\n  [yellow]memory clear[/]        - Clear the chat and file memory.\n  [yellow]backend <name>[/]      - Switch AI backend (e.g., openrouter, ollama).\n  [yellow]models [src][/]        - Interactively list and select models.\n  [yellow]set model <id>[/]      - Set the model directly by its ID.\n  [yellow]personality <cmd>[/]   - Manage AI personalities ('list', 'set', 'add').\n\"\"\"\n                    )\n            elif command == 'send':\n                last_query = arg_str\n                response = query_llm(arg_str)\n                last_response = response\n                memory_manager.add_chat_message('user', last_query)\n                memory_manager.add_chat_message('assistant', last_response)\n                if gui_enabled:\n                    threading.Thread(target=show_sequential_popup, args=(\n                        100, 100, response, f'Omni - {personality_name}'),\n                        daemon=True).start()\n                print(Panel(response, title='[cyan]Response[/]'))\n                if (code_blocks := extract_code(response)):\n                    last_code = code_blocks[0][1]\n            elif command == 'look':\n                look_command(arg_str)\n            elif command == 'look_all':\n                look_all_command()\n            elif command == 'create':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_create_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: create <file_path> \"<instruction>\"')\n            elif command == 'edit':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_edit_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: edit <file_path> \"<instruction>\"')\n            elif command == 'refactor':\n                if not arg_str:\n                    ui_manager.show_error('Usage: refactor \"<instruction>\"')\n                else:\n                    handle_project_refactor_command(arg_str.strip('\"'))\n            elif command == 'commit':\n                handle_commit_command()\n            elif command == 'models':\n                list_models(arg_str.split())\n            elif command == 'set' and arg_str.startswith('model '):\n                set_model(arg_str[6:])\n            elif command == 'backend':\n                switch_backend(arg_str)\n            elif command == 'history':\n                ui_manager.display_history(memory_manager.get_memory_context())\n            elif command == 'memory' and arg_str == 'clear':\n                memory_manager.clear_memory()\n                ui_manager.show_success('\u2705 Memory cleared')\n            elif command == 'personality':\n                p_args = arg_str.split(maxsplit=1)\n                cmd = p_args[0] if p_args else ''\n                p_arg_str = p_args[1] if len(p_args) > 1 else ''\n                if cmd == 'list':\n                    for p in personality_manager.list_personalities():\n                        print(f\"- {p['name']}: {p['description']}\")\n                elif cmd == 'set' and p_arg_str:\n                    if personality_manager.set_current_personality(p_arg_str):\n                        personality_name = p_arg_str\n                        ui_manager.show_success(\n                            f'Set personality to {personality_name}')\n                    else:\n                        ui_manager.show_error('Personality not found.')\n                else:\n                    ui_manager.show_error(\n                        \"Invalid personality command. Use 'list' or 'set <name>'.\"\n                        )\n            elif command == 'run':\n                run_python_code()\n            elif command == 'save':\n                if last_response:\n                    save_code(last_response, arg_str or\n                        f\"omni_save_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n                        )\n                else:\n                    ui_manager.show_error('No response to save.')\n            elif command == 'list':\n                files = sorted(os.listdir(DEFAULT_SAVE_DIR))\n                print('\\n'.join(f'  - {f}' for f in files) if files else\n                    '[yellow]No saved files.[/]')\n            elif command == 'rag':\n                if not arg_str:\n                    ui_manager.show_error('Usage: rag \"<query>\"')\n                else:\n                    from rag_manager import RAGManager\n                    project_root = memory_manager.get_project_root()\n                    if not project_root:\n                        ui_manager.show_error(\n                            \"No project context in memory. Use 'look <directory>' first.\"\n                            )\n                        continue\n                    rag = RAGManager()\n                    if rag.get_document_count() == 0:\n                        ui_manager.show_error(\n                            'RAG index is empty. Please add documents first.')\n                        continue\n                    results = rag.search(arg_str, k=3)\n                    if not results:\n                        ui_manager.show_error('No relevant documents found.')\n                        continue\n                    print(Panel('[bold]RAG Results:[/]', title=\n                        '[cyan]Retrieval-Augmented Generation[/]'))\n                    for i, (content, score, metadata) in enumerate(results, 1):\n                        file_path = metadata.get('file', 'Unknown')\n                        print(\n                            f'[bold cyan]{i}. {file_path}[/] (Score: {score:.4f})'\n                            )\n                        print(Panel(content[:500] + '...' if len(content) >\n                            500 else content, border_style='dim'))\n                    follow_up = ui_manager.get_user_input(\n                        \"\"\"\nWould you like to ask a follow-up question with this context? (y/n): \"\"\"\n                        )\n                    if follow_up.lower() in ['y', 'yes']:\n                        follow_up_query = ui_manager.get_user_input(\n                            'Follow-up query: ')\n                        if follow_up_query:\n                            context_parts = [\n                                f'Document {i} (Score: {score:.4f}):\\n{content}'\n                                 for i, (content, score, _) in enumerate(\n                                results, 1)]\n                            context = '\\n\\n'.join(context_parts)\n                            rag_prompt = f\"\"\"Based on the following context, please answer the question.\n\nContext:\n{context}\n\nQuestion: {follow_up_query}\"\"\"\n                            response = query_llm(rag_prompt)\n                            print(Panel(response, title=\n                                '[cyan]RAG-Augmented Response[/]'))\n            else:\n                ui_manager.show_error(\"Unknown command. Type 'help'.\")\n            refresh_status_panel(personality_name)\n        except KeyboardInterrupt:\n            memory_manager.save_memory()\n            print('\\n[bold cyan]Goodbye![/]')\n            break\n        except Exception as e:\n            ui_manager.show_error(f'An unexpected error occurred: {e}')\n\n\ndef run_python_code() ->None:\n    global last_code\n    if not last_code:\n        ui_manager.show_error('No Python code in memory to run.')\n        return\n    temp_file = os.path.join(DEFAULT_SAVE_DIR, 'temp_run.py')\n    try:\n        with open(temp_file, 'w') as f:\n            f.write(last_code)\n        print('[bold cyan]\\n--- Running Code ---\\n[/]')\n        subprocess.run([sys.executable, temp_file], check=True)\n        print('[bold cyan]\\n--- Code Finished ---\\n[/]')\n    except Exception as e:\n        ui_manager.show_error(f'Error running code: {e}')\n    finally:\n        if os.path.exists(temp_file):\n            os.remove(temp_file)\n\n\ndef save_code(content: str, filename: str) ->None:\n    filepath = os.path.join(DEFAULT_SAVE_DIR, filename)\n    try:\n        with open(filepath, 'w') as f:\n            f.write(content)\n        ui_manager.show_success(f'Saved to: {filepath}')\n    except IOError as e:\n        ui_manager.show_error(f'Error saving file: {e}')\n\n\ndef main() ->None:\n    try:\n        import astor\n    except ImportError:\n        print(\"[bold red]Error:[/] 'astor' is required. `pip install astor`\")\n        sys.exit(1)\n    try:\n        import simple_term_menu\n    except ImportError:\n        print(\n            \"[bold red]Error:[/] 'simple-term-menu' is required. `pip install simple-term-menu`\"\n            )\n        sys.exit(1)\n    parser = argparse.ArgumentParser(description=\n        'Omni - AI-powered code tool', add_help=False)\n    parser.add_argument('command', nargs='?', help='Main command.')\n    parser.add_argument('args', nargs='*', help='Arguments for the command.')\n    parser.add_argument('-h', '--help', action='store_true')\n    args, _ = parser.parse_known_args()\n    if args.help or not args.command:\n        interactive_mode()\n    elif args.command == 'look' and args.args:\n        look_command(args.args[0])\n    elif args.command == 'edit' and len(args.args) >= 2:\n        handle_file_edit_command(args.args[0], ' '.join(args.args[1:]))\n    elif args.command == 'models':\n        list_models(args.args)\n    else:\n        interactive_mode()\n\n\ndef refresh_status_panel(personality_name: str) ->None:\n    ui_manager.display_status_panel(personality_name, current_backend,\n        current_model, len(memory_manager.memory.get('chat', [])), len(\n        memory_manager.memory.get('look', [])))\n\n\nif __name__ == '__main__':\n    main()             ",
    "file": "/mnt/ProjectData/omni/omni.py"
  },
  {
    "id": 137,
    "hash": "db1585da7840e9dc17f3ab8c0a19f6f2",
    "content": "import json\nfrom typing import Dict, List, Optional\n\nclass PersonalityManager:\n    \"\"\"Manages AI personalities via JSON config.\"\"\"\n\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.personalities: List[Dict[str, str]] = self.load_personalities()\n        self.current_personality: Optional[str] = \"default\"  # Default\n\n    def load_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"Load personalities from JSON; auto-create if missing.\"\"\"\n        default = [{\"name\": \"default\", \"description\": \"Helpful assistant\", \"system_prompt\": \"You are a helpful AI assistant.\"}]\n        default_gui = {\n            \"gui_enabled\": True,\n            \"wake_word\": \"Jarvis\",\n            \"overlay_opacity\": 0.8,\n            \"font_size\": 16\n        }\n        try:\n            with open(self.config_file, 'r') as f:\n                data = json.load(f)\n                if \"personalities\" not in data:\n                    data[\"personalities\"] = default\n                if \"gui_enabled\" not in data:\n                    data.update(default_gui)\n                    self.save_personalities(data[\"personalities\"])  # Save with defaults\n                \n                return data[\"personalities\"]\n        except FileNotFoundError:\n            self.save_personalities(default)\n            return default\n        except json.JSONDecodeError:\n            print(\"[yellow]Invalid config. Resetting to default.[/]\")\n            self.save_personalities(default)\n            return default\n\n    def save_personalities(self, personalities: List[Dict[str, str]]) -> None:\n        \"\"\"Save with GUI config.\"\"\"\n        data = {\"personalities\": personalities}\n        data.update({\"gui_enabled\": True, \"wake_word\": \"Jarvis\", \"overlay_opacity\": 0.8, \"font_size\": 16})  # Defaults\n        with open(self.config_file, 'w') as f:\n            json.dump(data, f, indent=4)\n\n    def add_personality(self, name: str, description: str, system_prompt: str) -> None:\n        \"\"\"Add a new personality.\"\"\"\n        self.personalities.append({\"name\": name, \"description\": description, \"system_prompt\": system_prompt})\n        self.save_personalities(self.personalities)\n\n    def list_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"List all personalities.\"\"\"\n        return self.personalities\n\n    def set_current_personality(self, name: str) -> bool:\n        \"\"\"Set the current personality.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == name:\n                self.current_personality = name\n                return True\n        return False\n\n    def get_current_personality(self) -> Dict[str, str]:\n        \"\"\"Get the current personality dict.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == self.current_personality:\n                return p\n        return {}  # Fallback",
    "file": "/mnt/ProjectData/omni/personality_manager.py"
  },
  {
    "id": 138,
    "hash": "da963f141c557fe12f1a26374f3e5ff4",
    "content": "# python_ast_adapter.py\n\n\"\"\"\nPythonASTAdapter - Concrete AST adapter for Python using built-in `ast` and `astor`.\n\nThis module implements the ASTAdapter interface specifically for Python,\nleveraging the standard library's `ast` module for parsing and\nmanipulation, and `astor` for code generation.\n\"\"\"\n\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for asttokens (for enhanced partial edits)\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n    # print(\"Warning: asttokens not installed. Partial edits will be limited.\")\n\n\nclass PythonASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for Python source code.\n\n    This adapter uses Python's built-in `ast` module to parse and manipulate\n    the code, and `astor` for code generation and source-to-source transformations.\n    It holds the parsed AST tree and provides methods to interact with it\n    according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the PythonASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The Python source code as a string.\n        \"\"\"\n        # Store source code for diffing and potential asttokens use\n        self.source_code: str = source_code\n        # Will hold the parsed AST tree\n        self.tree: Optional[ast.AST] = None\n        # Will hold a mapping of element names to their AST nodes\n        self.nodes: Dict[str, ast.AST] = {}\n        # asttokens instance for enhanced source mapping (if available)\n        self.atok: Optional[asttokens.ASTTokens] = None\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the Python source code and maps elements.\n\n        Args:\n            source_code: The Python source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid Python syntax.\n        \"\"\"\n        try:\n            self.tree = ast.parse(source_code)\n        except SyntaxError as e:\n            raise ValueError(f\"Invalid Python syntax: {e}\") from e\n\n        self.nodes = self._map_nodes()\n        if ASTTOKENS_AVAILABLE:\n            try:\n                self.atok = asttokens.ASTTokens(source_code, parse=True)\n            except Exception:\n                # If asttokens fails for any reason, continue without it\n                self.atok = None\n        else:\n            self.atok = None\n\n    def _map_nodes(self) -> Dict[str, ast.AST]:\n        \"\"\"\n        Walks the AST and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their AST nodes.\n        \"\"\"\n        nodes: Dict[str, ast.AST] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        for node in ast.walk(self.tree):\n            # Map functions and classes by name\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                # Use 'not in' to prioritize top-level definitions in case of conflicts\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            # Map assignments by target variable name(s)\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            # Map imports by their alias or original name\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int, line_end: Optional[int] = None) -> Optional[Tuple[int, ast.AST]]:\n        \"\"\"\n        Finds a statement within a body based on line numbers.\n\n        Args:\n            body: The list of AST nodes representing the body.\n            line_start: The starting line number to search for.\n            line_end: The optional ending line number.\n\n        Returns:\n            A tuple of (index, statement node) if found, otherwise None.\n        \"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = getattr(stmt, 'end_lineno', stmt.lineno)\n                    # Check for overlap or containment\n                    if (stmt.lineno <= line_start <= stmt_end) or (stmt.lineno <= line_end <= stmt_end) or \\\n                       (line_start <= stmt.lineno and line_end >= stmt_end):\n                        return (i, stmt)\n                else:\n                    if stmt.lineno == line_start:\n                        return (i, stmt)\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.ImportFrom]]) -> None:\n        \"\"\"\n        Adds new import nodes to the file's AST, typically at the top.\n\n        Args:\n            new_import_nodes: A list of ast.Import or ast.ImportFrom nodes.\n        \"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return # Cannot add imports without a valid module tree\n\n        # Get string representations of existing imports to avoid duplicates\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                try:\n                    existing_imports_str.add(astor.to_source(node).strip())\n                except Exception:\n                    # If astor fails, skip adding to set (might lead to potential duplicate, but safer)\n                    pass\n                last_import_index = i\n\n        # Insert new imports after the last existing import\n        # Reverse them so they are inserted in the correct order\n        for new_import in reversed(new_import_nodes):\n            try:\n                new_import_str = astor.to_source(new_import).strip()\n                if new_import_str not in existing_imports_str:\n                    self.tree.body.insert(last_import_index + 1, new_import)\n                    last_import_index += 1 # Update index for next insertion\n            except Exception:\n                # If we can't generate source, we can't check for duplicates, skip\n                self.tree.body.insert(last_import_index + 1, new_import)\n                last_import_index += 1\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return astor.to_source(node)\n            except Exception:\n                # Handle potential astor issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.__class__.__name__,\n            'line_start': getattr(node, 'lineno', None),\n            'line_end': getattr(node, 'end_lineno', None),\n            'body_items': []\n        }\n\n        if hasattr(node, 'body'):\n            for i, item in enumerate(node.body):\n                item_info = {\n                    'index': i,\n                    'type': item.__class__.__name__,\n                    'line_start': getattr(item, 'lineno', None),\n                    'line_end': getattr(item, 'end_lineno', None)\n                }\n\n                if isinstance(item, ast.Assign) and item.targets:\n                    target = item.targets[0]\n                    if isinstance(target, ast.Name):\n                        item_info['assigns'] = target.id\n                elif isinstance(item, (ast.If, ast.While, ast.For)):\n                    item_info['has_body'] = bool(getattr(item, 'body', None))\n                elif isinstance(item, ast.Return):\n                    item_info['returns'] = True\n\n                structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        if not self.atok:\n            return None # asttokens is required for precise original source retrieval\n\n        node = self.nodes.get(element_name)\n        if not node or not hasattr(node, 'body'):\n            return None\n\n        statements = []\n        for stmt in node.body:\n            if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                 # Check for overlap or containment of the statement within the requested range\n                stmt_start = stmt.lineno\n                stmt_end = stmt.end_lineno\n                if (stmt_start >= line_start and stmt_end <= line_end) or \\\n                   (stmt_start <= line_end and stmt_end >= line_start): # Overlap\n                    statements.append(stmt)\n\n        if not statements:\n            return None\n\n        # Use asttokens to get the original source text for accuracy\n        try:\n            # Combine text ranges of the found statements\n            combined_text = \"\"\n            last_end_pos = None\n            for stmt in sorted(statements, key=lambda s: s.lineno):\n                # Get the text range for the statement\n                stmt_text = self.atok.get_text_range(stmt)\n                if last_end_pos is not None and stmt_text[0] > last_end_pos:\n                     # Add the original whitespace/newlines between statements\n                    combined_text += self.source_code[last_end_pos:stmt_text[0]]\n                combined_text += self.atok.get_text(stmt)\n                last_end_pos = stmt_text[1]\n            return combined_text.strip()\n        except Exception:\n            # Fallback if asttokens text retrieval fails\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in statements)\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except SyntaxError:\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body: # Ensure there's actual code body to replace with\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # Walk the tree to find the parent node containing the element to replace\n        for parent_node in ast.walk(self.tree):\n            if hasattr(parent_node, 'body') and isinstance(parent_node.body, list):\n                try:\n                    old_node = self.nodes[element_name]\n                    idx = parent_node.body.index(old_node)\n                    # Remove the old node\n                    parent_node.body.pop(idx)\n                    # Insert the new nodes\n                    for i, new_node in enumerate(new_code_body):\n                        parent_node.body.insert(idx + i, new_node)\n\n                    # Update the nodes map: remove old, add new top-level definitions\n                    del self.nodes[element_name]\n                    for n in new_code_body:\n                        if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                            self.nodes[n.name] = n\n                    return True\n                except (ValueError, KeyError):\n                    # ValueError from index(), KeyError from accessing self.nodes\n                    continue\n        return False # Element not found in any body\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n             return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except (SyntaxError, IndexError):\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body:\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # --- Determine insertion index ---\n\n        # Find the `if __name__ == \"__main__\":` block index\n        main_block_idx = -1\n        for i, node in enumerate(self.tree.body):\n            if (isinstance(node, ast.If) and\n                isinstance(getattr(node, 'test', None), ast.Compare) and\n                isinstance(getattr(node.test, 'left', None), ast.Name) and\n                node.test.left.id == '__name__' and\n                len(getattr(node.test, 'ops', [])) == 1 and isinstance(node.test.ops[0], ast.Eq) and\n                len(getattr(node.test, 'comparators', [])) == 1):\n\n                comp = node.test.comparators[0]\n                # Check for both ast.Constant ('__main__') and older ast.Str ('__main__')\n                if ((isinstance(comp, ast.Constant) and comp.value == '__main__') or\n                    (isinstance(comp, ast.Str) and comp.s == '__main__')): # type: ignore\n                    main_block_idx = i\n                    break\n\n        insertion_index = -1\n        if anchor_name:\n            # If anchor is specified, find its index\n            if anchor_name not in self.nodes:\n                return False\n            anchor_node = self.nodes[anchor_name]\n            try:\n                anchor_idx = self.tree.body.index(anchor_node)\n                proposed_index = anchor_idx if before else anchor_idx + 1\n                # Prefer to stay before the main block if possible\n                if main_block_idx != -1:\n                    insertion_index = min(proposed_index, main_block_idx)\n                else:\n                    insertion_index = proposed_index\n            except ValueError:\n                return False # Anchor node not found in tree body\n        elif main_block_idx != -1:\n            # If no anchor, but there's a main block, insert before it\n            insertion_index = main_block_idx\n        # If no anchor and no main block, insertion_index remains -1\n\n        # --- Perform the insertion ---\n        if insertion_index == -1:\n            # Append to the end\n            self.tree.body.extend(new_code_body)\n        else:\n            # Insert at the calculated position\n            for i, new_node in enumerate(new_code_body):\n                self.tree.body.insert(insertion_index + i, new_node)\n\n        # Update the nodes map with any new top-level definitions\n        for node in new_code_body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                self.nodes[node.name] = node # This might overwrite if names clash\n\n        return True\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return False\n\n        deleted = False\n        if element_name in self.nodes:\n            node_to_delete = self.nodes[element_name]\n            # Walk the tree to find the parent node containing the element\n            for node in ast.walk(self.tree):\n                if hasattr(node, 'body') and isinstance(node.body, list):\n                    try:\n                        node.body.remove(node_to_delete)\n                        deleted = True\n                        break # Assume element appears only once at top level\n                    except ValueError:\n                        continue # This parent doesn't contain the node\n            if deleted:\n                del self.nodes[element_name]\n                # Although nodes map is passed by ref in base __init__, we should call _map_nodes\n                # to ensure consistency after a direct tree modification.\n                self.nodes = self._map_nodes()\n                return True\n\n        # If not found by node reference, try to find by name pattern matching (vars/imports)\n        new_body = []\n        for node in self.tree.body:\n            if isinstance(node, ast.Assign):\n                match = False\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id == element_name:\n                        match = True\n                        deleted = True\n                        break\n                if not match: # Keep the node if it doesn't match\n                    new_body.append(node)\n            elif isinstance(node, ast.Import):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                    # Keep the node if none of its aliases match (should theoretically be the same as above)\n                     new_body.append(node)\n                else:\n                    deleted = True # The import node is being completely removed\n            elif isinstance(node, ast.ImportFrom):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                     new_body.append(node)\n                else:\n                    deleted = True\n            else:\n                new_body.append(node)\n\n        if deleted:\n            self.tree.body = new_body\n            # Remap nodes after structural changes\n            self.nodes = self._map_nodes()\n\n        return deleted\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        if element_name not in self.nodes:\n            return False\n\n        node = self.nodes[element_name]\n        # Ensure the node has a body to modify\n        if not hasattr(node, 'body') or not isinstance(node.body, list):\n            return False\n\n        # Parse the new code to get AST nodes for the replacement\n        try:\n             # Heuristic: If new code looks like a def/class, extract its body.\n             # Otherwise, treat as standalone statements.\n            if new_code.strip().startswith(('def ', 'class ', 'async def ')):\n                # Parse as if it's a module with a single function/class\n                temp_module = ast.parse(new_code)\n                if temp_module.body and hasattr(temp_module.body[0], 'body'):\n                    new_statements = temp_module.body[0].body # Get the inner body\n                else:\n                    return False # Malformed attempt to define a func/class\n            else:\n                # Parse as a module and take its body\n                new_ast_module = ast.parse(new_code)\n                new_statements = new_ast_module.body\n        except SyntaxError:\n            return False # Invalid new code\n\n        if not new_statements: # Nothing to insert\n            return False\n\n        # --- Determine what to replace based on parameters ---\n        if statement_index is not None:\n            # Replace by statement index\n            if 0 <= statement_index < len(node.body):\n                # Replace the single statement at index with the list of new statements\n                node.body[statement_index:statement_index+1] = new_statements\n                return True\n        elif line_start is not None:\n            # Replace by line number(s)\n            result = self._find_statement_in_body(node.body, line_start, line_end)\n            if result:\n                idx, _ = result\n                if line_end:\n                    # Find the last statement within the specified range to replace multiple\n                    end_idx = idx\n                    # Iterate from the found index forward\n                    for i in range(idx, len(node.body)):\n                        stmt = node.body[i]\n                        stmt_s_ln = getattr(stmt, 'lineno', None)\n                        stmt_e_ln = getattr(stmt, 'end_lineno', stmt_s_ln)\n                        if stmt_s_ln is not None and stmt_e_ln is not None:\n                            # Check if the statement ends within the range or starts within the range\n                            # This handles overlapping ranges correctly\n                             if stmt_e_ln <= line_end or stmt_s_ln <= line_end:\n                                 end_idx = i\n                             else:\n                                 break # Statement is past the end range\n                        else:\n                            break # Can't determine statement range\n                    node.body[idx:end_idx+1] = new_statements\n                else:\n                    # line_end not specified, only replace the statement at line_start\n                    node.body[idx:idx+1] = new_statements\n                return True\n\n        # If none of the conditions were met to perform a replacement\n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        if self.tree:\n            try:\n                return astor.to_source(self.tree)\n            except Exception as e:\n                 # Fallback error handling, should ideally not happen if tree is valid\n                 return f\"# Error generating source: {e}\\n{self.source_code}\"\n        else:\n            # If somehow the tree is None, return the original source\n            return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        # Ensure line endings are consistent for diffing, keepends=True preserves them\n        # If source_code had different line endings, this might still cause issues,\n        # but this is a standard approach.\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/python_ast_adapter.py"
  },
  {
    "id": 139,
    "hash": "2914352eefed9d60de098e021dd79b67",
    "content": "import os\nimport sys\nimport argparse\nfrom typing import List\nfrom rag_manager import RAGManager\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\ndef create_sample_data() ->List[str]:\n    \"\"\"Create sample documents for the RAG example.\"\"\"\n    return [\n        'RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with language generation.'\n        ,\n        'The RAG model retrieves relevant documents from a knowledge base and uses them to generate more accurate responses.'\n        ,\n        'FAISS is a library for efficient similarity search and clustering of dense vectors, often used in RAG systems.'\n        ,\n        'Sentence transformers are used to create embeddings for documents and queries in RAG systems.'\n        ,\n        'Retrieval-Augmented Generation improves language models by allowing them to access external knowledge sources.'\n        ,\n        'In RAG systems, documents are indexed and searchable by their semantic embeddings rather than just keywords.'\n        ,\n        'Python is a great language for implementing RAG systems due to libraries like sentence-transformers and faiss.'\n        ,\n        'The retrieval component of RAG is crucial for finding relevant information before generation.'\n        ]\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_cli_example.py"
  },
  {
    "id": 140,
    "hash": "c27b11d2eaa8e13cdf8e698417efb75e",
    "content": "import os\nimport sys\nfrom typing import List, Dict, Tuple\n\"\"\"\nExample script demonstrating RAG (Retrieval-Augmented Generation) usage.\n\nThis script shows how to use a simple RAG implementation to answer questions\nbased on a given context or knowledge base.\n\"\"\"\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\nclass SimpleRAG:\n    \"\"\"A simple RAG implementation for demonstration purposes.\"\"\"\n\n    def __init__(self, knowledge_base: List[str]):\n        \"\"\"\n        Initialize the RAG with a knowledge base.\n        \n        Args:\n            knowledge_base: A list of strings representing the knowledge base.\n        \"\"\"\n        self.knowledge_base = knowledge_base\n\n    def retrieve(self, query: str, top_k: int=3) ->List[str]:\n        \"\"\"\n        Retrieve relevant documents from the knowledge base.\n        \n        This is a simplified implementation using keyword matching.\n        In a real implementation, you would use embeddings and vector search.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            A list of relevant documents.\n        \"\"\"\n        query_words = set(query.lower().split())\n        scores = []\n        for doc in self.knowledge_base:\n            doc_words = set(doc.lower().split())\n            score = len(query_words.intersection(doc_words))\n            scores.append((score, doc))\n        scores.sort(reverse=True)\n        return [doc for score, doc in scores[:top_k]]\n\n    def generate(self, query: str, retrieved_docs: List[str]) ->str:\n        \"\"\"\n        Generate an answer based on the query and retrieved documents.\n        \n        In a real implementation, this would use an LLM to generate the response.\n        For this example, we'll create a simple template-based response.\n        \n        Args:\n            query: The query string.\n            retrieved_docs: The retrieved documents.\n            \n        Returns:\n            A generated answer.\n        \"\"\"\n        context = '\\n'.join(retrieved_docs)\n        prompt = f\"\"\"\n        Context information:\n        {context}\n        \n        Question: {query}\n        \n        Based on the context provided above, please answer the question.\n        If the context doesn't contain relevant information, say so.\n        \"\"\"\n        return self._simple_response_generator(query, retrieved_docs)\n\n    def _simple_response_generator(self, query: str, retrieved_docs: List[str]\n        ) ->str:\n        \"\"\"\n        A simple response generator for demonstration.\n        \"\"\"\n        for doc in retrieved_docs:\n            if 'example' in doc.lower():\n                return (\n                    f'Based on the context provided, I found information about examples. {query} relates to the examples in the knowledge base.'\n                    )\n        return (\n            f\"I couldn't find specific information about '{query}' in the provided context. Please provide more details or check the knowledge base.\"\n            )\n\n    def query(self, query: str, top_k: int=3) ->str:\n        \"\"\"\n        Process a query through the full RAG pipeline.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            The generated answer.\n        \"\"\"\n        retrieved_docs = self.retrieve(query, top_k)\n        answer = self.generate(query, retrieved_docs)\n        return answer\n\n\ndef main():\n    \"\"\"Main function demonstrating the RAG implementation.\"\"\"\n    knowledge_base = ['This is an example document about machine learning.',\n        'Natural language processing is a subfield of artificial intelligence.'\n        , 'Python is a popular programming language for data science.',\n        'The quick brown fox jumps over the lazy dog.',\n        'RAG stands for Retrieval-Augmented Generation.',\n        'Vector databases are used for similarity search in RAG systems.',\n        'Transformers are a type of neural network architecture.',\n        'This example shows how to implement a simple RAG system.']\n    rag = SimpleRAG(knowledge_base)\n    queries = ['What is RAG?', 'How is Python used in data science?',\n        'Tell me about machine learning']\n    print('Simple RAG Example')\n    print('=' * 50)\n    for query in queries:\n        print(f'\\nQuery: {query}')\n        answer = rag.query(query)\n        print(f'Answer: {answer}')\n        print('-' * 30)\n    print(\"\\nInteractive Mode (type 'quit' to exit):\")\n    while True:\n        try:\n            user_query = input('\\nEnter your question: ').strip()\n            if user_query.lower() in ['quit', 'exit', 'q']:\n                break\n            if user_query:\n                answer = rag.query(user_query)\n                print(f'Answer: {answer}')\n        except KeyboardInterrupt:\n            print('\\nGoodbye!')\n            break\n        except EOFError:\n            break\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_example.py"
  },
  {
    "id": 141,
    "hash": "f151986bf2efa7602242590a357fab83",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n    Initialize the RAG manager.\n\n    Args:\n        model_name: Name of the sentence transformer model to use\n        index_path: Path to save/load the FAISS index\n    \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the RAG manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n",
    "file": "/mnt/ProjectData/omni/rag_manager.py"
  },
  {
    "id": 142,
    "hash": "f59a27842056dbb0dc95d0f29c1c5de8",
    "content": "Hello! I'm OmniForge, an AI coding assistant. I can help you scan, understand, and refactor your codebase using local (Ollama) or remote (OpenRouter) LLMs.\n\nI see you've opened the OmniForge project directory. Some key things I can help with:\n\n1. **Project Analysis**: I can look at your files to understand the structure\n2. **Code Editing**: I can make precise edits to functions/classes using AST-based transformations\n3. **Refactoring**: I can perform multi-file architectural changes with a plan\n4. **File Creation**: I can generate new files based on instructions\n\nFor example:\n- `look .` to scan the project\n- `edit code_editor.py \"add docstrings to main methods\"`\n- `refactor \"extract git operations into a separate module\"`\n- `create new_module.py \"implement a simple HTTP client\"`\n\nWhat would you like to do with this project?",
    "file": "/mnt/ProjectData/omni/requirements.txt"
  },
  {
    "id": 143,
    "hash": "4b879b8e64b677ec78d27f19b384623a",
    "content": "from typing import List\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.text import Text\nfrom rich.status import Status\nfrom rich import box\nfrom contextlib import contextmanager\nfrom rich.markup import escape\nimport gc\n\ntry:\n    from prompt_toolkit import prompt\n    from prompt_toolkit.completion import WordCompleter\n    from prompt_toolkit.history import InMemoryHistory\n    from prompt_toolkit.styles import Style\nexcept ImportError:\n    print('[yellow]prompt_toolkit not installed. Falling back to basic input.[/]')\n    prompt = input\n\n\nclass UIManager:\n    \"\"\"Manages interactive text-based UI with rich for display and prompt_toolkit for input.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initializes the UI manager with a rich console and prompt_toolkit components.\"\"\"\n        self.console = Console()\n        self.history = InMemoryHistory()\n        self.completer = WordCompleter([\n            'send', 'look', 'look_all', 'create', 'edit', 'refactor', 'commit',\n            'save', 'list', 'run', 'history', 'memory', 'backend', 'models',\n            'set', 'personality', 'help', 'exit'\n        ], ignore_case=True)\n        self.prompt_style = Style.from_dict({'prompt': 'bold cyan'})\n\n    def get_user_input(self, prompt_text: str) -> str:\n        try:\n            return prompt(prompt_text, history=self.history, completer=self.completer, style=self.prompt_style)\n        except Exception:\n            self.console.print('[yellow]Warning: Falling back to basic input.[/]')\n            return input(prompt_text)\n\n    def display_history(self, history_text: str) -> None:\n        if not history_text.strip():\n            self.console.print('[dim]No history yet.[/]')\n            return\n        \n        lines = history_text.split('\\n')\n        colored_text = Text()\n        for line in lines:\n            if line.startswith('User:'):\n                colored_text.append(line + '\\n', style='bold blue')\n            elif line.startswith('AI:'):\n                colored_text.append(line + '\\n', style='bold green')\n            elif line.startswith('File '):\n                colored_text.append(line + '\\n', style='yellow')\n            else:\n                colored_text.append(line + '\\n')\n        \n        self.console.print(Panel(\n            colored_text, \n            title='[bold magenta]Chat History[/]', \n            border_style='magenta', \n            expand=False, \n            box=box.ROUNDED\n        ))\n\n    @contextmanager\n    def show_spinner(self, message: str):\n        \"\"\"\n        Context manager that displays a spinner with the given message.\n        Handles Rich LiveError by cleaning up stuck live displays and \n        ensuring proper cleanup on exceptions.\n        \n        Usage:\n            with ui_manager.show_spinner(\"Loading...\"):\n                # do work here\n        \"\"\"\n        # Initialize spinner state if not exists\n        if not hasattr(self, '_spinner_active'):\n            self._spinner_active = False\n        \n        # If spinner is already active, just yield without additional output\n        if self._spinner_active:\n            try:\n                yield\n            except Exception as e:\n                raise e\n            return\n        \n        # Clean up any stuck Rich live displays before starting\n        self._cleanup_stuck_rich_displays()\n        \n        # Mark spinner as active\n        self._spinner_active = True\n        status_context = None\n        \n        try:\n            # Try to use rich status, but with fallback\n            try:\n                status_context = self.console.status(f'[bold yellow]{message}[/]')\n                status_context.__enter__()\n            except Exception:\n                # If rich.status fails, fallback to static print\n                status_context = None\n                self.console.print(f'[bold yellow]{message}[/]')\n            \n            yield\n            \n        except Exception as e:\n            # Re-raise actual work errors\n            raise e\n            \n        finally:\n            # Always cleanup spinner state and rich display\n            self._spinner_active = False\n            if status_context is not None:\n                try:\n                    status_context.__exit__(None, None, None)\n                except:\n                    pass  # Suppress cleanup errors\n            \n            # Force cleanup any remaining rich displays\n            self._cleanup_stuck_rich_displays()\n\n    def _cleanup_stuck_rich_displays(self):\n        \"\"\"\n        Clean up stuck Rich live displays that prevent new ones from starting.\n        Based on solution from: https://github.com/DLR-RM/stable-baselines3/issues/1645\n        \"\"\"\n        try:\n            # Method 1: Reset console live display if exists\n            if hasattr(self.console, '_live') and self.console._live is not None:\n                try:\n                    self.console._live.stop()\n                    self.console._live = None\n                except:\n                    pass\n            \n            # Method 2: Find and close stuck rich/tqdm objects using garbage collection\n            rich_objects = [obj for obj in gc.get_objects() \n                        if hasattr(obj, '__class__') and \n                        ('live' in type(obj).__name__.lower() or \n                            'progress' in type(obj).__name__.lower() or\n                            'status' in type(obj).__name__.lower()) and\n                        hasattr(obj, 'stop')]\n            \n            for rich_obj in rich_objects:\n                try:\n                    if hasattr(rich_obj, 'stop'):\n                        rich_obj.stop()\n                    elif hasattr(rich_obj, 'close'):\n                        rich_obj.close()\n                except:\n                    pass  # Suppress cleanup errors\n                    \n        except:\n            pass  # Suppress all cleanup errors to avoid breaking the main flow\n\n    def display_status_panel(self, personality: str, backend: str, model: str, msg_count: int, look_count: int) -> None:\n        status_text = (\n            f'[bold]Personality:[/] [green]{personality}[/] | '\n            f'[bold]Backend:[/] [green]{backend}[/] | '\n            f'[bold]Model:[/] [green]{model}[/] | '\n            f'[bold]Memory:[/] {msg_count} messages, {look_count} files'\n        )\n        self.console.print(Panel(\n            status_text, \n            title='[bold cyan]Status[/]', \n            border_style='cyan', \n            expand=False, \n            box=box.MINIMAL\n        ))\n\n    def show_success(self, message: str) -> None:\n        self.console.print(f'[green]\u2705 {message}[/]')\n\n    def show_error(self, message: str) -> None:\n        \"\"\"\n        Displays an error message, escaping any markup in the message.\n        \"\"\"\n        safe_message = escape(str(message))\n        self.console.print(f'[red]\u274c {safe_message}[/]')",
    "file": "/mnt/ProjectData/omni/ui_manager.py"
  },
  {
    "id": 144,
    "hash": "dbd143839288b400cafdedb655258434",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n",
    "file": "/mnt/ProjectData/omni/vectordb_manager.py"
  },
  {
    "id": 145,
    "hash": "47a91d3ac272236378053b23515fc9b0",
    "content": "import tkinter as tk\nfrom tkinter import ttk\nfrom time import strftime\n\n\ndef update_time():\n    current_time = strftime('%H:%M:%S %p\\n%Y-%m-%d')\n    time_label.config(text=current_time)\n    time_label.after(1000, update_time)\n\n\ndef center_window(root):\n    root.update_idletasks()\n    screen_width = root.winfo_screenwidth()\n    screen_height = root.winfo_screenheight()\n    window_width = root.winfo_width() + 4\n    window_height = root.winfo_height() + 4\n    x = (screen_width - window_width) // 2\n    y = (screen_height - window_height) // 2\n    root.geometry(f'{window_width}x{window_height}+{x}+{y}')\n\n\ndef create_3d_border(parent):\n    border_frame = tk.Frame(parent, bg='#c0c0c0')\n    border_frame.pack(padx=2, pady=2, expand=True, fill=tk.BOTH)\n    tk.Frame(border_frame, height=1, bg='#808080').pack(side=tk.TOP, fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#808080').pack(side=tk.LEFT, fill=tk.Y)\n    tk.Frame(border_frame, height=1, bg='#ffffff').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#ffffff').pack(side=tk.RIGHT, fill=tk.Y\n        )\n    inner_container = tk.Frame(border_frame, bg='#c0c0c0')\n    inner_container.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1\n        )\n    tk.Frame(inner_container, height=1, bg='#ffffff').pack(side=tk.TOP,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#ffffff').pack(side=tk.LEFT,\n        fill=tk.Y)\n    tk.Frame(inner_container, height=1, bg='#808080').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#808080').pack(side=tk.RIGHT,\n        fill=tk.Y)\n    content_area = tk.Frame(inner_container, bg='#c0c0c0')\n    content_area.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1)\n    return content_area\n\n\nroot = tk.Tk()\nroot.title('Current Time')\nroot.configure(bg='#008080')\nmain_frame = create_3d_border(root)\nmain_frame.config(padx=4, pady=4)\ninner_frame = tk.Frame(main_frame, bg='#c0c0c0', padx=8, pady=8)\ninner_frame.pack()\ntime_label = tk.Label(inner_frame, bg='#c0c0c0', fg='#000000', font=(\n    'MS Sans Serif', 18, 'bold'), padx=12, pady=8)\ntime_label.pack()\nroot.after(100, lambda : center_window(root))\nupdate_time()\nroot.mainloop()\n",
    "file": "/mnt/ProjectData/omni/omni_saves/watch.py"
  },
  {
    "id": 146,
    "hash": "6774a805052356775d8c4f0367253dc1",
    "content": "# OmniForge\n\n**Project\u2011Aware AI CLI for AST\u2011Precise Edits (\u201cScalpel\u201d) & Multi\u2011File Refactors (\u201cBlueprint\u201d).**\n\n> *OmniForge (a.k.a. the \"DualForge\" engine) helps you **scan**, **understand**, and **reforge** your codebase with local (Ollama) or remote (OpenRouter) LLMs. It is an independent open\u2011source project not affiliated with other products using the name \u201cOmni.\u201d*\n\n---\n\n## Core Features\n\n* **Project\u2011Aware Refactoring (`refactor`)**: Provide a high\u2011level goal (e.g. *\u201cmove all DB logic into `db/` and centralize config\u201d*). OmniForge generates & shows a multi\u2011step plan before touching files.\n* **Surgical AST Editing (`edit`)**: Target a single function/class. OmniForge parses the file, locates the node, applies a structural change, and shows you a diff.\n* **Context Ingestion (`look`)**: Scan a directory or single file to build a project manifest (paths + hashes + size + language hints) that guides subsequent edits/refactors.\n* **Dual Backends**: Seamlessly switch between **`openrouter`** (remote models) and **`ollama`** (local models) via `backend <name>`.\n* **Interactive Model Picker (`models`)**: Filter by source/provider and select from an up\u2011to\u2011date model list inside the terminal.\n* **Session Memory & History**: `history` shows conversation / action log; `memory clear` resets the working context.\n* **Safe AST\u2011Based Transformations**: Reduces syntax breakage vs naive text substitution. New imports / dependencies are auto\u2011inserted when possible.\n* **Dry\u2011Run Transparency**: Every multi\u2011file refactor presents (1) a generated plan, (2) per\u2011file proposed changes, (3) a consolidated diff for confirmation.\n\n---\n\n## Conceptual Modes\n\n| Mode          | Command(s) | Purpose                                              | Analogy              |\n| ------------- | ---------- | ---------------------------------------------------- | -------------------- |\n| **Survey**    | `look`     | Index project / ingest context                       | Mapping the terrain  |\n| **Scalpel**   | `edit`     | Precise single\u2011file structural change                | Surgery              |\n| **Blueprint** | `refactor` | Multi\u2011file architectural transformation              | Architecture         |\n| **Cast**      | `run`      | Execute last generated runnable block (if supported) | Forging the artifact |\n\nYou can reference these terms in docs, help screens, or UI banners for clarity.\n\n---\n\n## Installation\n\n> Requires Python 3.10+ and a Unix\u2011like shell.\n\n```bash\n# 1. Clone\ngit clone https://github.com/Snawyyy/omniforge.git\ncd omniforge\n\n# 2. (Optional) Inspect requirements\ncat requirements.txt\n\n# 3. Run installer (creates venv + installs deps)\nchmod +x install.sh\n./install.sh\n\n# 4. Activate environment\nsource venv/bin/activate\n\n# 5. Run CLI (interactive shell)\n./omni        # or: python omni.py\n```\n\nIf you later package it, expose a script entry point named `omni` while keeping an internal package name like `omniforge` to avoid namespace collisions.\n\n---\n\n## Configuration\n\nCreate a `.env` file to supply secrets (e.g. OpenRouter API key).\n\n```bash\ncp .env.example .env   # if example exists; otherwise create manually\n```\n\nIn `.env`:\n\n```dotenv\nOPENROUTER_API_KEY=\"sk-or-...\"\n```\n\n(Do **not** commit real keys. Ensure `.env` is listed in `.gitignore`.)\n\nOptional future keys can include local model paths, default model name, or feature flags.\n\n---\n\n## Quick Start Workflow\n\n```text\n> look .\n(Index project: builds manifest)\n\n> refactor \"extract hardcoded API URL to config/settings.py and update all imports\"\n(Shows plan \u2192 ask for confirmation)\n\n> edit src/utils.py \"add a doctring for calculate_average explaining parameters and return value\"\n(Shows targeted diff \u2192 confirm or abort)\n\n> models openai\n(Choose a different model)\n\n> backend ollama\n(Switch to local inference)\n```\n\n---\n\n## Command Reference\n\n| Command               | Example                                         | Description                                                                 |\n| --------------------- | ----------------------------------------------- | --------------------------------------------------------------------------- |\n| `look <path>`         | `look .`                                        | Scan directory or file; update project context manifest.                    |\n| `edit <file> \"instr\"` | `edit utils.py \"add error handling\"`            | AST\u2011guided targeted modification of a single file element or whole file.    |\n| `refactor \"goal\"`     | `refactor \"split monolith api.py into package\"` | High\u2011level multi\u2011file transformation with plan + diff review.               |\n| `send <prompt>`       | `send summarize module layout`                  | Generic prompt to current model with current context summary.               |\n| `models [filter]`     | `models google`                                 | Interactive model selector (filter by provider/source).                     |\n| `backend <name>`      | `backend ollama`                                | Switch between `openrouter` / `ollama`.                                     |\n| `history`             | `history`                                       | Display session interaction log.                                            |\n| `memory clear`        | `memory clear`                                  | Clear internal AI context memory (project manifest may persist separately). |\n| `run`                 | `run`                                           | Execute the last generated runnable code snippet (if feature implemented).  |\n| `help`                | `help`                                          | Show help / usage summary.                                                  |\n\n---\n\n## How It Works (High Level)\n\n1. **Ingestion (`look`)**: Walks the directory (configurable ignore patterns), captures file metadata (path, size, language), optionally caches abbreviated content or hashes.\n2. **Prompt Construction**: Merges user instruction + contextual manifest + focused snippets (for `edit`) or diff summaries (for `refactor`).\n3. **AST Layer** (Python initially): Parses target file(s); identifies node(s) (function/class) based on name + heuristic similarity; applies transformations guided by model output (structured hints or patch templates) rather than raw blind overwrite.\n4. **Plan (Refactor)**: Model proposes steps (CREATE / MODIFY / RENAME / DELETE). User approves. Each step executed & validated; errors surface early.\n5. **Diff Presentation**: A unified colorized diff shown; user confirms to write changes.\n6. **Safety**: If AST parse fails or patch violates syntax, changes abort (or fallback to text patch with warning).\n\n---\n\n## Roadmap (Indicative)\n\n| Milestone | Features                                                                    |\n| --------- | --------------------------------------------------------------------------- |\n| 0.1.0     | Core commands (`look`, `edit`, `refactor`, `models`, `backend`, `history`). |\n| 0.2.0     | Config file (`omniforge.toml`), ignore patterns, improved diff viewer.      |\n| 0.3.0     | Multi-language AST adapters (JS/TS via `tree-sitter`).                      |\n| 0.4.0     | Test impact analysis & auto test file generation.                           |\n| 0.5.0     | Refactor preview metrics (LOC touched, complexity delta).                   |\n| 0.6.0     | Inline security / lint feedback integration.                                |\n| 0.7.0     | Partial GUI / TUI dashboard mode.                                           |\n\n(Adjust roadmap as project evolves.)\n\n---\n\n## Developer Notes\n\n* Keep `.env`, virtual environment dirs (`venv/`), caches, large artifacts in `.gitignore`.\n* Consider adding a thin `omniforge/` package directory now for future PyPI packaging.\n* Implement a pluggable *Model Adapter* layer to abstract provider differences (OpenRouter vs Ollama).\n* Logging: Provide `--verbose` or `OMNIFORGE_DEBUG=1` env flag.\n* Add a JSONL log of commands & decisions to enable replay or supervised improvements.\n\n---\n\n## Contributing\n\n1. Fork & create a feature branch: `git checkout -b feat/<short-name>`\n2. Run and add tests (if/when test harness exists in `tests/`).\n3. Ensure style/format (e.g. `ruff`, `black`) passes.\n4. Submit pull request with concise description + before/after examples.\n\nIssues / discussions welcome for architecture proposals, AST adapters, or performance improvements.\n\n---\n\n## License\n\nReleased under the **MIT License**. See `LICENSE` file for full text.\n\n---\n\n## Name & Trademark Disclaimer\n\n\u201cOmniForge\u201d is an independent open-source tool and not affiliated with The Omni Group or any other third-party products using similar names. If a future naming conflict arises, a soft alias strategy (keeping the `omni` CLI) will preserve user workflows.\n\n---\n\n## Example Session (Illustrative)\n\n```text\n$ ./omni\nOMNIFORGE 0.1.0  (backend=openrouter | model=anthropic/claude-3)\nType 'help' or 'look .' to begin.\n\n> look .\nIndexed 42 files (Python=30, Markdown=5, JSON=7)\n\n> refactor \"centralize logging into logging_util.py and update imports\"\nPlan:\n  [1] CREATE logging_util.py\n  [2] MODIFY app.py (replace inline log setup)\n  [3] MODIFY worker.py (import logging_util)\nProceed? (y/n) y\n... (diff preview) ...\nApply changes? (y/n) y\nRefactor complete in 3.2s.\n\n> edit worker.py \"add retry with exponential backoff to fetch_data\"\nParsed worker.py \u2713\nApplied modification (function: fetch_data)\nDiff shown. Accept? (y/n) y\nSaved.\n```\n\n---\n\n## Philosophy\n\n*The next wave of developer AI goes beyond paste\u2011in prompts.* OmniForge treats your repository as *structured material*, enabling incremental, auditable, and safer evolution rather than opaque code dumps. By combining **context scanning**, **AST precision**, and **human approval loops**, it aims to become a trustworthy co\u2011developer rather than an occasionally helpful code generator.\n\n---\n\n## Feedback / Support\n\nOpen a GitHub Issue for bugs & feature requests. For conceptual discussions (roadmap, design choices), use Discussions.\n\n---\n\nHappy forging!\n",
    "file": "/mnt/ProjectData/omni/README.md"
  },
  {
    "id": 147,
    "hash": "b6c2845489f64b6396aaf85e5fd5909e",
    "content": "from abc import ABC, abstractmethod\nfrom typing import List, Optional, Dict, Any, Union\nfrom typing import List, Optional, Dict\nASTNode = Any\nDiffContent = str\n\n\nclass ASTAdapter(ABC):\n    \"\"\"\n    Abstract base class defining the interface for language-specific AST adapters.\n\n    This interface allows the CodeEditor to interact with the AST/CST of different\n    programming languages in a uniform way. Concrete implementations will handle\n    the specifics of parsing, traversing, and modifying the AST/CST for their\n    respective languages (e.g., Python's `ast`/`astor`, JavaScript's `tree-sitter`).\n\n    The adapter is responsible for holding the parsed tree structure and any\n    necessary metadata for operations.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the adapter by parsing the provided source code.\n\n        Args:\n            source_code: The string content of the source file to be parsed.\n\n        Raises:\n            ValueError: If the source code cannot be parsed due to syntax errors.\n        \"\"\"\n        self.source_code: str = source_code\n        self.tree: Optional[ASTNode] = None\n        self.nodes: Dict[str, ASTNode] = {}\n        self._parse_and_map(source_code)\n\n    @abstractmethod\n    def _parse_and_map(self, source_code: str) ->None:\n        \"\"\"\n        Abstract method to parse the source code and populate `self.tree` and `self.nodes`.\n\n        This is the core method where language-specific parsing logic resides.\n        Implementations should:\n        1. Parse the `source_code` into an AST/CST representation.\n        2. Store the root of this representation in `self.tree`.\n        3. Identify key top-level elements (functions, classes, variables, imports)\n           and map their names to their nodes in `self.nodes`.\n\n        Args:\n            source_code: The string content to parse.\n\n        Raises:\n            ValueError: If the source code cannot be parsed.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_elements(self) ->List[str]:\n        \"\"\"\n        Abstract method to list the names of the main elements found in the code.\n\n        These are typically top-level functions, classes, variable assignments,\n        and imports that the adapter can identify and manipulate.\n\n        Returns:\n            A list of element names (strings).\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"\n        Abstract method to get the source code string for a specific element.\n\n        Args:\n            element_name: The name of the element (function, class, etc.).\n\n        Returns:\n            The source code string for the element, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"\n        Abstract method to get detailed structural information about an element.\n\n        This information can include type, line numbers, body items, etc., useful\n        for aiding the AI in understanding the code's layout.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            A dictionary containing structural details, or None if not found.\n            Example structure:\n            {\n                'name': 'func_name',\n                'type': 'FunctionDef', # or 'ClassDef', etc.\n                'line_start': 10,\n                'line_end': 25,\n                'body_items': [list of internal statement details...]\n            }\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"\n        Abstract method to extract a snippet of code from within an element's body.\n\n        Used for 'partial' edits where only a specific range of lines within\n        a function or class needs to be changed.\n\n        Args:\n            element_name: The name of the element containing the snippet.\n            line_start: The starting line number (1-based, absolute) of the snippet.\n            line_end: The ending line number (inclusive) of the snippet.\n\n        Returns:\n            The source code string for the specified lines within the element, or None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"\n        Abstract method to replace an entire named element.\n\n        This involves finding the old element in the tree and swapping it with\n        the representation of the `new_code`.\n\n        Args:\n            element_name: The name of the element to replace.\n            new_code: The new source code for the element (and potential helpers).\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"\n        Abstract method to add a new block of code (element) to the file.\n\n        This involves parsing the `new_code` and inserting its representation\n        into the tree at an appropriate location (e.g., end of file, near anchor).\n\n        Args:\n            new_code: The source code for the new element(s).\n            anchor_name: Optional name of an existing element to position relative to.\n            before: If True and `anchor_name` is provided, insert before the anchor.\n\n        Returns:\n            True if the element was added successfully, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"\n        Abstract method to delete a named element from the file.\n\n        This involves finding the element in the tree and removing its representation.\n\n        Args:\n            element_name: The name of the element to delete.\n\n        Returns:\n            True if the element was successfully deleted, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"\n        Abstract method for a 'surgical' edit within an element's body.\n\n        Replaces a specific statement or line range within the body of an element.\n\n        Args:\n            element_name: Name of the function/class to modify.\n            new_code: New code to insert (can be multiple statements).\n            line_start: Starting line number (absolute) within the element.\n            line_end: Ending line number (inclusive) within the element.\n            statement_index: Alternative to line numbers - replace the Nth statement.\n\n        Returns:\n            True if successful, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_modified_source(self) ->str:\n        \"\"\"\n        Abstract method to serialize the potentially modified AST/CST back to source code.\n\n        Returns:\n            The full source code string reflecting the current state of the tree.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_diff(self) ->str:\n        \"\"\"\n        Abstract method to generate a diff between the original source and the modified source.\n\n        Returns:\n            A string containing the unified diff.\n        \"\"\"\n        pass\n\n\n\"\"\"\nTextFileAdapter - Basic adapter for text files\n\nThis module provides a basic adapter for text files that implements\nthe ASTAdapter interface. It allows text files to be used with the\nCodeEditor class.\n\"\"\"\n\n\nclass TextFileAdapter(ASTAdapter):\n    \"\"\"\n    A basic adapter for text files that implements the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the TextFileAdapter.\n\n        Args:\n            source_code: The source code as a string.\n        \"\"\"\n        self.source_code = source_code\n        self.modified_source = source_code\n\n    def list_elements(self) ->List[str]:\n        \"\"\"\n        Lists top-level elements in the text file.\n        For text files, this returns a single \"content\" element.\n\n        Returns:\n            A list containing \"content\".\n        \"\"\"\n        return ['content']\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"\n        Gets the source code for a specific element.\n        For text files, this returns the entire file content.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            The source code of the entire file.\n        \"\"\"\n        if element_name == 'content':\n            return self.source_code\n        return None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"\n        Gets detailed structure information about an element.\n        For text files, this provides minimal structure information.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            A dictionary with basic structure information.\n        \"\"\"\n        if element_name == 'content':\n            lines = self.source_code.splitlines()\n            return {'name': element_name, 'type': 'text', 'line_count': len\n                (lines), 'character_count': len(self.source_code)}\n        return None\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"\n        Gets a snippet from within an element's body.\n        For text files, this returns lines between line_start and line_end.\n\n        Args:\n            element_name: The name of the element.\n            line_start: The starting line number (1-indexed).\n            line_end: The ending line number (1-indexed).\n\n        Returns:\n            A string containing the specified lines.\n        \"\"\"\n        if element_name != 'content':\n            return None\n        lines = self.source_code.splitlines()\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(lines), line_end)\n        if start_idx >= len(lines) or start_idx >= end_idx:\n            return None\n        return '\\n'.join(lines[start_idx:end_idx])\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"\n        Replaces a partial section of an element.\n        For text files, this replaces lines between line_start and line_end.\n\n        Args:\n            element_name: The name of the element.\n            new_code: The new code to insert.\n            line_start: The starting line number (1-indexed).\n            line_end: The ending line number (1-indexed).\n            statement_index: Not used for text files.\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        if element_name != 'content':\n            return False\n        if line_start is None or line_end is None:\n            return False\n        lines = self.modified_source.splitlines()\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(lines), line_end)\n        if start_idx > len(lines) or start_idx > end_idx:\n            return False\n        new_lines = self.modified_source.splitlines()\n        new_code_lines = new_code.splitlines()\n        new_lines[start_idx:end_idx] = new_code_lines\n        self.modified_source = '\\n'.join(new_lines)\n        return True\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"\n        Adds new content to the text file.\n        For text files, this appends or prepends content.\n\n        Args:\n            new_code: The new code to add.\n            anchor_name: Not used for text files.\n            before: If True, prepend; if False, append.\n\n        Returns:\n            True if the addition was successful, False otherwise.\n        \"\"\"\n        if before:\n            self.modified_source = new_code + '\\n' + self.modified_source\n        else:\n            self.modified_source = self.modified_source + '\\n' + new_code\n        return True\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"\n        Deletes an element by name.\n        For text files, this clears the entire content if element_name is \"content\".\n\n        Args:\n            element_name: The name of the element to delete.\n\n        Returns:\n            True if the deletion was successful, False otherwise.\n        \"\"\"\n        if element_name == 'content':\n            self.modified_source = ''\n            return True\n        return False\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"\n        Replaces a target element with new code.\n        For text files, this replaces the entire content if element_name is \"content\".\n\n        Args:\n            element_name: The name of the element to replace.\n            new_code: The new code.\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        if element_name == 'content':\n            self.modified_source = new_code\n            return True\n        return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"\n        Gets the modified source code.\n\n        Returns:\n            The modified source code.\n        \"\"\"\n        return self.modified_source\n\n    def get_diff(self) ->str:\n        \"\"\"\n        Generates a diff between the original source and the modified source.\n\n        Returns:\n            A string containing the diff.\n        \"\"\"\n        import difflib\n        return ''.join(difflib.unified_diff(self.source_code.splitlines(\n            keepends=True), self.modified_source.splitlines(keepends=True),\n            fromfile='original', tofile='modified'))\n",
    "file": "/mnt/ProjectData/omni/ast_adapter.py"
  },
  {
    "id": 148,
    "hash": "3fa6303779874a8e61c7a1a4ffc75e58",
    "content": "\"\"\"\nCodeEditor - Enhanced AST-based code manipulation tool\n\nThis module provides a class to programmatically parse, analyze,\nand edit source code. It has been refactored to use a pluggable\nASTAdapter system, allowing it to support multiple languages.\nCurrently, it defaults to Python's built-in `ast` module via\nPythonASTAdapter for backward compatibility during the transition.\n\"\"\"\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Union, Tuple, Type, Any\nfrom ast_adapter import ASTAdapter\nfrom python_ast_adapter import PythonASTAdapter\nimport os\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n\n\nclass CodeEditor:\n    \"\"\"\n    An enhanced class to safely edit files using AST/CST with partial edit support.\n    The core logic for interacting with the code structure is now delegated to\n    a language-specific ASTAdapter.\n    \"\"\"\n\n    def __init__(self, file_path: str, adapter_class: Optional[Type[\n        ASTAdapter]]=None):\n        \"\"\"\n        Initializes the CodeEditor.\n\n        Args:\n            file_path: The path to the source file.\n            adapter_class: The ASTAdapter subclass to use. If None, defaults to\n                           PythonASTAdapter for .py files.\n        \"\"\"\n        self.file_path = file_path\n        self.source_code = self._read_file()\n        self.adapter: Optional[ASTAdapter] = None\n        self.tree: Optional[ast.AST] = None\n        self.nodes: Dict[str, ast.AST] = {}\n        self.atok: Optional[Any] = None\n        if adapter_class is None:\n            file_extension = os.path.splitext(self.file_path)[1].lower()\n            if file_extension == '.py':\n                try:\n                    from python_ast_adapter import PythonASTAdapter\n                    self.adapter = PythonASTAdapter(self.source_code)\n                except ImportError as e:\n                    try:\n                        self.tree = self._parse_source()\n                        self.nodes = self._map_nodes()\n                        if ASTTOKENS_AVAILABLE:\n                            self.atok = asttokens.ASTTokens(self.\n                                source_code, parse=True)\n                    except Exception as parse_error:\n                        raise ValueError(\n                            f'Failed to parse Python file: {parse_error}')\n            elif file_extension == '.js':\n                try:\n                    from javascript_ast_adapter import JavaScriptASTAdapter\n                    self.adapter = JavaScriptASTAdapter(self.source_code)\n                except ImportError as e:\n                    raise ValueError(\n                        f'tree-sitter is required for JavaScript support but not available: {e}'\n                        )\n                except Exception as e:\n                    raise ValueError(\n                        f'Failed to initialize JavaScript adapter: {e}')\n            elif file_extension == '.txt':\n                pass\n            else:\n                raise ValueError(\n                    f'Unsupported file type: {file_extension}. Supported types: .py, .js, .txt'\n                    )\n        else:\n            try:\n                self.adapter = adapter_class(self.source_code)\n            except Exception as e:\n                raise ValueError(\n                    f'Failed to initialize adapter {adapter_class.__name__}: {e}'\n                    )\n\n    def _read_file(self) ->str:\n        \"\"\"Reads the source file.\"\"\"\n        try:\n            with open(self.file_path, 'r', encoding='utf-8') as f:\n                return f.read()\n        except FileNotFoundError:\n            raise ValueError(f'File not found: {self.file_path}')\n\n    def _parse_source(self) ->ast.AST:\n        \"\"\"Fallback parsing logic.\"\"\"\n        try:\n            return ast.parse(self.source_code)\n        except SyntaxError as e:\n            raise ValueError(f'Invalid Python syntax in {self.file_path}: {e}')\n\n    def list_elements(self) ->List[str]:\n        \"\"\"Lists top-level elements in the code.\"\"\"\n        if self.adapter:\n            return self.adapter.list_elements()\n        else:\n            return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"Gets the source code for a specific element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_source_of(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            return astor.to_source(node) if node else None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"Gets detailed structure information about an element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_structure(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            if not node:\n                return None\n            structure = {'name': element_name, 'type': node.__class__.\n                __name__, 'line_start': node.lineno if hasattr(node,\n                'lineno') else None, 'line_end': node.end_lineno if hasattr\n                (node, 'end_lineno') else None, 'body_items': []}\n            if hasattr(node, 'body'):\n                for i, item in enumerate(node.body):\n                    item_info = {'index': i, 'type': item.__class__.\n                        __name__, 'line_start': item.lineno if hasattr(item,\n                        'lineno') else None, 'line_end': item.end_lineno if\n                        hasattr(item, 'end_lineno') else None}\n                    if isinstance(item, ast.Assign) and item.targets:\n                        target = item.targets[0]\n                        if isinstance(target, ast.Name):\n                            item_info['assigns'] = target.id\n                    elif isinstance(item, (ast.If, ast.While, ast.For)):\n                        item_info['has_body'] = bool(item.body)\n                    elif isinstance(item, ast.Return):\n                        item_info['returns'] = True\n                    structure['body_items'].append(item_info)\n            return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"Gets a snippet from within an element's body.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_body_snippet(element_name,\n                line_start, line_end)\n        else:\n            if not self.atok:\n                return None\n            node = self.nodes.get(element_name)\n            if not node or not hasattr(node, 'body'):\n                return None\n            statements = []\n            for stmt in node.body:\n                if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                    if (line_start <= stmt.lineno <= line_end or line_start <=\n                        stmt.end_lineno <= line_end):\n                        statements.append(stmt)\n            if not statements:\n                return None\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in\n                statements)\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"Replaces a partial section of an element.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_partial(element_name, new_code,\n                line_start, line_end, statement_index)\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                if new_code.strip().startswith('def ') or new_code.strip(\n                    ).startswith('class '):\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body[0].body\n                else:\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if statement_index is not None:\n                if 0 <= statement_index < len(node.body):\n                    node.body[statement_index:statement_index + 1\n                        ] = new_statements\n                    return True\n            elif line_start is not None:\n                result = self._find_statement_in_body(node.body, line_start,\n                    line_end)\n                if result:\n                    idx, _ = result\n                    if line_end:\n                        end_idx = idx\n                        for i in range(idx + 1, len(node.body)):\n                            stmt = node.body[i]\n                            if hasattr(stmt, 'end_lineno'\n                                ) and stmt.end_lineno <= line_end:\n                                end_idx = i\n                            else:\n                                break\n                        node.body[idx:end_idx + 1] = new_statements\n                    else:\n                        node.body[idx:idx + 1] = new_statements\n                    return True\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"Adds a new block of code to the file.\"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name, before)\n        else:\n            try:\n                new_ast_module = ast.parse(new_code)\n            except (SyntaxError, IndexError):\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            insertion_index = -1\n            main_block_idx = -1\n            for i, _node in enumerate(self.tree.body):\n                if isinstance(_node, ast.If) and isinstance(_node.test, ast\n                    .Compare) and isinstance(_node.test.left, ast.Name\n                    ) and _node.test.left.id == '__name__' and len(_node.\n                    test.ops) == 1 and isinstance(_node.test.ops[0], ast.Eq\n                    ) and len(_node.test.comparators) == 1:\n                    comp = _node.test.comparators[0]\n                    if isinstance(comp, ast.Constant\n                        ) and comp.value == '__main__' or isinstance(comp,\n                        ast.Str) and comp.s == '__main__':\n                        main_block_idx = i\n                        break\n            if anchor_name:\n                if anchor_name not in self.nodes:\n                    return False\n                anchor_node = self.nodes[anchor_name]\n                try:\n                    anchor_idx = self.tree.body.index(anchor_node)\n                    proposed_index = anchor_idx if before else anchor_idx + 1\n                    if main_block_idx != -1:\n                        insertion_index = min(proposed_index, main_block_idx)\n                    else:\n                        insertion_index = proposed_index\n                except ValueError:\n                    return False\n            elif main_block_idx != -1:\n                insertion_index = main_block_idx\n            if insertion_index == -1:\n                self.tree.body.extend(new_code_body)\n            else:\n                for i, new_node in enumerate(new_code_body):\n                    self.tree.body.insert(insertion_index + i, new_node)\n            for _node in new_code_body:\n                if isinstance(_node, (ast.FunctionDef, ast.AsyncFunctionDef,\n                    ast.ClassDef)):\n                    self.nodes[_node.name] = _node\n            return True\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"Deletes an element by name.\"\"\"\n        if self.adapter:\n            return self.adapter.delete_element(element_name)\n        else:\n            deleted = False\n            if element_name in self.nodes:\n                node_to_delete = self.nodes[element_name]\n                for _node in ast.walk(self.tree):\n                    if hasattr(_node, 'body') and isinstance(_node.body, list):\n                        try:\n                            _node.body.remove(node_to_delete)\n                            deleted = True\n                            break\n                        except ValueError:\n                            continue\n                if deleted:\n                    del self.nodes[element_name]\n                    self.nodes = self._map_nodes()\n                    return True\n            new_body = []\n            for _node in self.tree.body:\n                if isinstance(_node, ast.Assign):\n                    match = False\n                    for target in _node.targets:\n                        if isinstance(target, ast.Name\n                            ) and target.id == element_name:\n                            match = True\n                            break\n                    if match:\n                        deleted = True\n                        continue\n                elif isinstance(_node, ast.Import):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                elif isinstance(_node, ast.ImportFrom):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                new_body.append(_node)\n            self.tree.body = new_body\n            if deleted:\n                self.nodes = self._map_nodes()\n            return deleted\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"Replaces a target element with new code.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_element(element_name, new_code)\n        else:\n            if element_name not in self.nodes:\n                return False\n            try:\n                new_ast_module = ast.parse(new_code)\n            except SyntaxError:\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            for _node in ast.walk(self.tree):\n                if hasattr(_node, 'body') and isinstance(_node.body, list):\n                    try:\n                        old_node = self.nodes[element_name]\n                        idx = _node.body.index(old_node)\n                        _node.body.pop(idx)\n                        for i, new_node in enumerate(new_code_body):\n                            _node.body.insert(idx + i, new_node)\n                        del self.nodes[element_name]\n                        for n in new_code_body:\n                            if isinstance(n, (ast.FunctionDef, ast.\n                                AsyncFunctionDef, ast.ClassDef)):\n                                self.nodes[n.name] = n\n                        return True\n                    except (ValueError, KeyError):\n                        continue\n            return False\n\n    def insert_in_element(self, element_name: str, new_code: str, position:\n        str='end', after_line: Optional[int]=None, before_line: Optional[\n        int]=None) ->bool:\n        \"\"\"\n        Insert new code into an element without replacing existing code.\n        This is an internal/helper method, delegating to adapter OR using fallback.\n        \"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name=\n                element_name, before=position == 'start')\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                new_ast = ast.parse(new_code)\n                new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if position == 'start':\n                node.body[0:0] = new_statements\n            elif position == 'end':\n                node.body.extend(new_statements)\n            elif after_line:\n                result = self._find_statement_in_body(node.body, after_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx + 1:idx + 1] = new_statements\n                else:\n                    return False\n            elif before_line:\n                result = self._find_statement_in_body(node.body, before_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx:idx] = new_statements\n                else:\n                    return False\n            else:\n                return False\n            return True\n\n    def _map_nodes(self) ->Dict[str, ast.AST]:\n        \"\"\"Fallback node mapping logic for Python AST.\"\"\"\n        nodes = {}\n        for node in ast.walk(self.tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast\n                .ClassDef)):\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int,\n        line_end: Optional[int]=None) ->Optional[Tuple[int, ast.AST]]:\n        \"\"\"Fallback statement finding logic for Python AST.\"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = stmt.end_lineno if hasattr(stmt, 'end_lineno'\n                        ) else stmt.lineno\n                    if (stmt.lineno <= line_start <= stmt_end or stmt.\n                        lineno <= line_end <= stmt_end):\n                        return i, stmt\n                elif stmt.lineno == line_start:\n                    return i, stmt\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.\n        ImportFrom]]) ->None:\n        \"\"\"Fallback logic to add imports to the top of the Python AST.\"\"\"\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                existing_imports_str.add(astor.to_source(node).strip())\n                last_import_index = i\n        for new_import in reversed(new_import_nodes):\n            new_import_str = astor.to_source(new_import).strip()\n            if new_import_str not in existing_imports_str:\n                self.tree.body.insert(last_import_index + 1, new_import)\n\n    def apply_arbitrary_change(self, new_source_code: str) ->bool:\n        \"\"\"\n        Rewrites the entire file's AST from a new source string.\n        This method resets the adapter if one exists, or uses fallback.\n        \"\"\"\n        if self.adapter:\n            try:\n                adapter_class = type(self.adapter)\n                self.adapter = adapter_class(new_source_code)\n                return True\n            except Exception:\n                return False\n        else:\n            try:\n                new_tree = ast.parse(new_source_code)\n                self.tree = new_tree\n                self.nodes = self._map_nodes()\n                if ASTTOKENS_AVAILABLE:\n                    self.source_code = new_source_code\n                    self.atok = asttokens.ASTTokens(self.source_code, parse\n                        =True)\n                return True\n            except SyntaxError:\n                return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"Serializes the potentially modified code structure back to source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_modified_source()\n        else:\n            return astor.to_source(self.tree)\n\n    def get_diff(self) ->str:\n        \"\"\"Generates a diff between the original source and the modified source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_diff()\n        else:\n            modified_source = self.get_modified_source()\n            return ''.join(difflib.unified_diff(self.source_code.splitlines\n                (keepends=True), modified_source.splitlines(keepends=True),\n                fromfile=f'{self.file_path} (original)', tofile=\n                f'{self.file_path} (modified)'))\n\n    def save_changes(self) ->None:\n        \"\"\"Saves the modified source code back to the file.\"\"\"\n        modified_source = self.get_modified_source()\n        with open(self.file_path, 'w', encoding='utf-8') as f:\n            f.write(modified_source)\n",
    "file": "/mnt/ProjectData/omni/code_editor.py"
  },
  {
    "id": 149,
    "hash": "cc52aa524d0929867d5d2ea3697229e6",
    "content": "\"\"\"\nGenerated file.\n\"\"\"\nimport os\n\"\"\"\nFileCreator - A utility for creating files.\n\nThis module provides a simple, encapsulated way to create files,\nensuring that their parent directories exist before writing.\n\"\"\"\n\n\nclass FileCreator:\n    \"\"\"\n    A utility class to handle the creation of new files.\n    \"\"\"\n\n    @staticmethod\n    def create(file_path: str, content: str) ->None:\n        \"\"\"\n        Creates a file at the specified path with the given content.\n\n        This method will automatically create any necessary parent\n        directories for the file path.\n\n        Args:\n            file_path: The full path where the file should be created.\n            content: The string content to write to the file.\n\n        Raises:\n            IOError: If there is an error creating the directories or writing the file.\n        \"\"\"\n        try:\n            directory = os.path.dirname(file_path)\n            if directory:\n                os.makedirs(directory, exist_ok=True)\n            with open(file_path, 'w', encoding='utf-8') as f:\n                f.write(content)\n        except (IOError, OSError) as e:\n            raise IOError(f\"Failed to create file '{file_path}': {e}\") from e\n",
    "file": "/mnt/ProjectData/omni/file_creator.py"
  },
  {
    "id": 150,
    "hash": "04a24ceab008bd649d0530d309c72e42",
    "content": "import subprocess\nimport os\nfrom typing import List, Optional, Union\n\n\nclass GitManager:\n    \"\"\"\n    Encapsulates Git-related logic for a specific repository.\n\n    This class provides methods to perform common Git operations such as\n    checking status, getting diffs, staging, committing, and pushing changes.\n    It relies on the Git command-line tool being installed and accessible\n    in the system's PATH.\n    \"\"\"\n\n    def __init__(self, repo_path: str):\n        \"\"\"\n        Initializes the GitManager for a given repository path.\n\n        Args:\n            repo_path: The absolute or relative path to the Git repository.\n\n        Raises:\n            ValueError: If the provided path is not a valid Git repository.\n        \"\"\"\n        if not os.path.isdir(os.path.join(repo_path, '.git')):\n            raise ValueError(\n                f\"The path '{repo_path}' is not a valid Git repository.\")\n        self.repo_path = repo_path\n\n    def _run_command(self, command: List[str]) ->str:\n        \"\"\"\n        Executes a Git command in the repository's directory.\n\n        Args:\n            command: A list of command arguments, starting with 'git'.\n\n        Returns:\n            The standard output of the command as a string.\n\n        Raises:\n            subprocess.CalledProcessError: If the command returns a non-zero exit code.\n        \"\"\"\n        try:\n            result = subprocess.run(command, cwd=self.repo_path, check=True,\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True,\n                encoding='utf-8')\n            return result.stdout.strip()\n        except subprocess.CalledProcessError as e:\n            error_message = (\n                f\"Git command failed: {' '.join(command)}\\nError: {e.stderr.strip()}\"\n                )\n            raise subprocess.CalledProcessError(e.returncode, e.cmd, output\n                =e.stdout, stderr=error_message) from e\n\n    def get_status(self) ->str:\n        \"\"\"\n        Gets the repository status in a condensed format.\n\n        Uses `git status --porcelain` for a machine-readable output.\n\n        Returns:\n            A string representing the repository's status.\n        \"\"\"\n        return self._run_command(['git', 'status', '--porcelain'])\n        \n    def get_changed_files(self) -> List[str]:\n        \"\"\"\n        Gets a list of all changed (modified, added, deleted, untracked, renamed, or copied) files.\n\n        This parses the output of `git status --porcelain`, which provides a stable,\n        machine-readable format.\n\n        Returns:\n            A list of file paths relative to the repository root. For renamed or\n            copied files, it returns the new path.\n        \"\"\"\n        status_output = self.get_status()\n        if not status_output:\n            return []\n        \n        changed_files = []\n        for line in status_output.splitlines():\n            if len(line) < 3:  # Skip malformed lines\n                continue\n                \n            # Git status porcelain format: XY filename\n            # X = index status, Y = working tree status\n            index_status = line[0]\n            worktree_status = line[1]\n            \n            # The filename starts after the two status characters and a space\n            # But let's be more defensive about finding where the filename actually starts\n            filename_start = 2\n            while filename_start < len(line) and line[filename_start] == ' ':\n                filename_start += 1\n                \n            if filename_start >= len(line):\n                continue  # Skip if no filename found\n                \n            path_info = line[filename_start:]\n            \n            # Check if either index or working tree status indicates rename/copy\n            if index_status in ('R', 'C') or worktree_status in ('R', 'C'):\n                if ' -> ' in path_info:\n                    _, new_path = path_info.split(' -> ', 1)  # Use maxsplit=1 for safety\n                    changed_files.append(new_path.strip())\n                else:\n                    # Fallback if format is unexpected\n                    changed_files.append(path_info.strip())\n            else:\n                changed_files.append(path_info.strip())\n        \n        # Remove duplicates while preserving order\n        return list(dict.fromkeys(changed_files))\n\n    def get_diff(self, file_path: Optional[str]=None, staged: bool=False\n        ) ->str:\n        \"\"\"\n        Gets the diff of changes in the repository.\n\n        Args:\n            file_path: Optional. Path to a specific file to diff.\n            staged: If True, shows the diff for staged changes (`--cached`).\n                    Otherwise, shows the diff for unstaged changes.\n\n        Returns:\n            The git diff output as a string.\n        \"\"\"\n        cmd = ['git', 'diff']\n        if staged:\n            cmd.append('--cached')\n        if file_path:\n            cmd.append('--')\n            cmd.append(file_path)\n        return self._run_command(cmd)\n\n    def add(self, files: Union[str, List[str]]) ->None:\n        \"\"\"\n    Stages one or more files, handling each one individually for robustness.\n\n    This approach prevents a single invalid file path from causing the\n    entire 'git add' operation to fail. Warnings will be printed for any\n    files that could not be staged.\n\n    Args:\n        files: A single file path or a list of file paths to stage.\n               Can also be '.' to stage all changes.\n    \"\"\"\n        if isinstance(files, str):\n            files = [files]\n        for file_path in files:\n            try:\n                cmd = ['git', 'add', '--', file_path]\n                self._run_command(cmd)\n            except subprocess.CalledProcessError as e:\n                print(\n                    f\"Warning: Could not stage file '{file_path}'. Git reported: {e.stderr}\"\n                    )\n\n    def commit(self, message: str) ->str:\n        \"\"\"\n        Commits staged changes with a given message.\n\n        Args:\n            message: The commit message.\n\n        Returns:\n            The stdout from the git commit command.\n        \"\"\"\n        return self._run_command(['git', 'commit', '-m', message])\n\n    def push(self, remote: str='origin', branch: Optional[str]=None) ->str:\n        \"\"\"\n        Pushes commits to a remote repository.\n\n        Args:\n            remote: The name of the remote to push to (default: 'origin').\n            branch: The branch to push. If None, uses the current branch.\n\n        Returns:\n            The stdout from the git push command.\n        \"\"\"\n        if branch is None:\n            branch = self.get_current_branch()\n        return self._run_command(['git', 'push', remote, branch])\n\n    def get_current_branch(self) ->str:\n        \"\"\"\n        Determines the current active branch name.\n\n        Returns:\n            The name of the current branch.\n        \"\"\"\n        return self._run_command(['git', 'rev-parse', '--abbrev-ref', 'HEAD'])\n",
    "file": "/mnt/ProjectData/omni/git_manager.py"
  },
  {
    "id": 151,
    "hash": "f3f7ab448ad3e233539c4e4bddcd64f4",
    "content": "# javascript_ast_adapter.py\n\n\"\"\"\nJavaScriptASTAdapter - Concrete AST adapter for JavaScript using tree-sitter.\n\nThis module implements the ASTAdapter interface specifically for JavaScript,\nleveraging the tree-sitter library for parsing and manipulation.\n\"\"\"\n\nimport difflib\nimport re\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for tree-sitter\ntry:\n    import tree_sitter\n    import tree_sitter_languages\n    TREETSITTER_AVAILABLE = True\nexcept ImportError:\n    TREETSITTER_AVAILABLE = False\n    # This will cause an error during initialization if the adapter is used\n\n\nclass JavaScriptASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for JavaScript source code.\n\n    This adapter uses tree-sitter to parse and manipulate JavaScript code.\n    It holds the parsed tree-sitter Tree and provides methods to interact\n    with it according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the JavaScriptASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The JavaScript source code as a string.\n\n        Raises:\n            ValueError: If tree-sitter libraries are not available or if\n                        the source code has invalid JavaScript syntax.\n        \"\"\"\n        if not TREETSITTER_AVAILABLE:\n            raise ValueError(\"tree-sitter and tree-sitter-languages are required for JavaScript support.\")\n            \n        # Store source code for diffing and manipulation\n        self.source_code: str = source_code\n        # Will hold the parsed tree-sitter tree\n        self.tree: Optional[tree_sitter.Tree] = None\n        # Will hold a mapping of element names to their tree-sitter nodes\n        self.nodes: Dict[str, tree_sitter.Node] = {}\n        # Tree-sitter language parser\n        self.language = tree_sitter_languages.get_language(\"javascript\")\n        self.parser = tree_sitter.Parser(self.language)\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the JavaScript source code and maps elements.\n\n        Args:\n            source_code: The JavaScript source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid JavaScript syntax.\n        \"\"\"\n        try:\n            # Encode the source code in bytes as required by tree-sitter\n            self.tree = self.parser.parse(bytes(source_code, \"utf-8\"))\n        except Exception as e:\n            raise ValueError(f\"Failed to parse JavaScript source: {e}\") from e\n\n        self.nodes = self._map_nodes()\n\n    def _map_nodes(self) -> Dict[str, tree_sitter.Node]:\n        \"\"\"\n        Walks the tree and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their tree-sitter nodes.\n        \"\"\"\n        nodes: Dict[str, tree_sitter.Node] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        # Define the types of nodes we're interested in\n        target_types = {\n            \"function_declaration\", \"class_declaration\", \n            \"variable_declarator\", \"import_statement\"\n        }\n        \n        # Walk the tree using a stack-based approach\n        stack = [self.tree.root_node]\n        while stack:\n            node = stack.pop()\n            \n            # Check if this is a target node type\n            if node.type in target_types:\n                # Extract the name for different node types\n                name = self._get_node_name(node)\n                if name and name not in nodes:\n                    nodes[name] = node\n            \n            # Add children to the stack for further processing\n            for child in reversed(node.children):  # Reverse to maintain order when popping\n                stack.append(child)\n                \n        return nodes\n    \n    def _get_node_name(self, node: tree_sitter.Node) -> Optional[str]:\n        \"\"\"\n        Extracts the name of a node based on its type.\n        \n        Args:\n            node: The tree-sitter node to extract the name from.\n            \n        Returns:\n            The name of the node, or None if no name could be found.\n        \"\"\"\n        if node.type == \"function_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"class_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"variable_declarator\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"import_statement\":\n            # This is a more complex case - for now, we'll use a simplified approach\n            # Extract the module name from the import statement\n            # e.g., in \"import foo from 'bar'\", we want \"foo\"\n            # This is a simplified implementation and might need refinement\n            import_clause = None\n            for child in node.children:\n                if child.type == \"import_clause\":\n                    import_clause = child\n                    break\n            \n            if import_clause:\n                # Check for a simple identifier\n                for child in import_clause.children:\n                    if child.type == \"identifier\":\n                        return child.text.decode(\"utf-8\")\n                    elif child.type == \"named_imports\":\n                        # Handle named imports like { foo, bar }\n                        # For simplicity, we'll just return a placeholder\n                        # A more complete implementation would extract all names\n                        return f\"import_from_{hash(node.text.decode('utf-8')) % 10000}\"\n        \n        return None\n\n    def _find_node_by_position(self, start_point: Tuple[int, int], \n                              end_point: Optional[Tuple[int, int]] = None) -> Optional[tree_sitter.Node]:\n        \"\"\"\n        Finds a node in the tree that corresponds to a given range.\n        \n        Args:\n            start_point: A (row, column) tuple indicating the start position.\n            end_point: A (row, column) tuple indicating the end position.\n            \n        Returns:\n            The tree-sitter node that corresponds to the range, or None if not found.\n        \"\"\"\n        if not self.tree:\n            return None\n            \n        # A simple approach: find the smallest node that contains the range\n        # This is a simplified implementation and might need refinement\n        def contains_range(node):\n            node_start = (node.start_point[0], node.start_point[1])\n            node_end = (node.end_point[0], node.end_point[1])\n            if end_point:\n                return (node_start <= start_point and node_end >= end_point)\n            else:\n                return node_start <= start_point <= node_end\n        \n        # Walk the tree to find matching nodes\n        stack = [self.tree.root_node]\n        candidates = []\n        \n        while stack:\n            current_node = stack.pop()\n            if contains_range(current_node):\n                candidates.append(current_node)\n                # Add children to continue searching for smaller nodes\n                stack.extend(current_node.children)\n        \n        # Return the smallest (last) candidate\n        return candidates[-1] if candidates else None\n    \n    def _get_line_info_from_point(self, point: Tuple[int, int]) -> Dict[str, Any]:\n        \"\"\"\n        Converts a tree-sitter point to line information.\n        \n        Args:\n            point: A (row, column) tuple from tree-sitter.\n            \n        Returns:\n            A dictionary with line_start and line_end information.\n        \"\"\"\n        # Tree-sitter uses 0-based indexing for rows\n        return {\n            'line_start': point[0] + 1,  # Convert to 1-based\n            'line_end': point[0] + 1\n        }\n\n    def _reparse_tree(self, new_source: str) -> None:\n        \"\"\"\n        Re-parses the tree with new source code.\n        \n        This is necessary because tree-sitter trees are immutable.\n        \n        Args:\n            new_source: The new source code to parse.\n        \"\"\"\n        self.source_code = new_source\n        self.tree = self.parser.parse(bytes(new_source, \"utf-8\"))\n        self.nodes = self._map_nodes()\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return node.text.decode(\"utf-8\")\n            except Exception:\n                # Handle potential decoding issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.type,\n            'line_start': node.start_point[0] + 1,  # Convert to 1-based\n            'line_end': node.end_point[0] + 1,\n            'body_items': []\n        }\n\n        # Add body items for functions and classes\n        if node.type in (\"function_declaration\", \"class_declaration\"):\n            # Find the body block\n            body_node = None\n            for child in node.children:\n                if child.type == \"statement_block\":\n                    body_node = child\n                    break\n            \n            if body_node:\n                # Process statements in the body\n                for i, item in enumerate(body_node.children):\n                    # Skip '{' and '}' tokens\n                    if item.type in (\"{\", \"}\"):\n                        continue\n                    \n                    item_info = {\n                        'index': i,\n                        'type': item.type,\n                        'line_start': item.start_point[0] + 1,\n                        'line_end': item.end_point[0] + 1\n                    }\n                    \n                    # Add more specific information based on type\n                    if item.type == \"variable_declaration\":\n                        item_info['declares'] = \"variable\"\n                    elif item.type == \"return_statement\":\n                        item_info['returns'] = True\n                    elif item.type in (\"if_statement\", \"for_statement\", \"while_statement\"):\n                        item_info['has_body'] = True\n                    \n                    structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n            \n        # A simplified approach to extracting a snippet by line numbers\n        # This would need to be more sophisticated for production use\n        source_lines = self.source_code.split('\\n')\n        # Adjust for 0-based indexing\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(source_lines), line_end)\n        \n        if start_idx < end_idx:\n            return '\\n'.join(source_lines[start_idx:end_idx])\n        \n        return None\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Replace the node's text in the source code\n        new_source = self.source_code[:start_byte] + new_code + self.source_code[end_byte:]\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass  # If we can't even re-parse the original, we're in trouble\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree:\n            return False\n            \n        # For simplicity, we'll add the new code at the end of the file\n        # A more sophisticated implementation would handle the anchor and positioning\n        new_source = self.source_code.rstrip() + \"\\n\\n\" + new_code + \"\\n\"\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Find the full lines that contain the node\n        # This is a simplified approach to avoid leaving partial lines\n        source_lines = self.source_code.split('\\n')\n        start_line = node.start_point[0]\n        end_line = node.end_point[0]\n        \n        # Create new source without those lines\n        new_lines = source_lines[:start_line] + source_lines[end_line+1:]\n        new_source = '\\n'.join(new_lines)\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        # This is a complex operation that would require more sophisticated\n        # tree navigation and manipulation than what's shown here.\n        # For now, we'll provide a basic implementation.\n        \n        node = self.nodes.get(element_name)\n        if not node:\n            return False\n            \n        # Handle line-based replacement\n        if line_start is not None:\n            # Convert to 0-based indexing\n            start_idx = max(0, line_start - 1)\n            end_idx = line_end if line_end is not None else start_idx + 1\n            \n            source_lines = self.source_code.split('\\n')\n            if start_idx < len(source_lines):\n                # Replace the specified lines\n                end_idx = min(end_idx, len(source_lines))\n                new_lines = source_lines[:start_idx] + [new_code] + source_lines[end_idx:]\n                new_source = '\\n'.join(new_lines)\n                \n                # Re-parse the tree with the new source\n                try:\n                    self._reparse_tree(new_source)\n                    return True\n                except Exception:\n                    # If parsing fails, revert to the original source\n                    try:\n                        self._reparse_tree(self.source_code)\n                    except Exception:\n                        pass\n        \n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        # For tree-sitter, the source code is already maintained separately\n        return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        \n        # Ensure line endings are consistent for diffing\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/javascript_ast_adapter.py"
  },
  {
    "id": 152,
    "hash": "89fa0c06ca34019316daa58ce8fa9a20",
    "content": "import json\nimport os\nfrom typing import List, Dict, Optional\nfrom rag_manager import RAGManager\n\n\nclass MemoryManager:\n    \"\"\"Manages persistent chat memory, look data, and RAG integration via JSON.\"\"\"\n\n    def __init__(self, memory_file: str):\n        self.memory_file = memory_file\n        self.memory: Dict[str, List] = self.load_memory()\n        self.rag_manager = RAGManager()\n\n    def load_memory(self) ->Dict[str, List]:\n        try:\n            with open(self.memory_file, 'r') as f:\n                return json.load(f)\n        except FileNotFoundError:\n            default = {'chat': [], 'look': []}\n            self.save_memory(default)\n            return default\n        except json.JSONDecodeError:\n            print('[yellow]Invalid memory file. Resetting.[/]')\n            return {'chat': [], 'look': []}\n\n    def save_memory(self, memory: Optional[Dict[str, List]]=None) ->None:\n        if memory is None:\n            memory = self.memory\n        with open(self.memory_file, 'w') as f:\n            json.dump(memory, f, indent=4)\n\n    def add_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.memory['chat'].append({'role': role, 'content': content})\n        self.save_memory()\n\n    def add_chat_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        This is an alias for add_message to maintain compatibility.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.add_message(role, content)\n\n    def add_look_data(self, file_path: str, content: str) ->None:\n        \"\"\"\n    Adds a watched item (directory or file) to memory, distinguishing its type.\n\n    This method stores structured data that differentiates between a project\n    directory (containing a manifest) and a single file (containing its content).\n    It also prevents duplicate entries by updating existing ones.\n\n    Args:\n        file_path: The path to the directory or file.\n        content: The manifest for a directory or the content for a file.\n    \"\"\"\n        item_type = 'directory' if os.path.isdir(file_path) else 'file'\n        for item in self.memory['look']:\n            if item.get('file') == file_path:\n                item['content'] = content\n                item['type'] = item_type\n                self.save_memory()\n                return\n        self.memory['look'].append({'type': item_type, 'file': file_path,\n            'content': content})\n        self.save_memory()\n        if item_type == 'file':\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    file_content = f.read()\n                self.rag_manager.add_documents([file_content], [{'file':\n                    file_path}])\n            except Exception as e:\n                print(\n                    f'[yellow]Warning: Could not add {file_path} to RAG index: {e}[/]'\n                    )\n\n    def get_project_root(self) ->Optional[str]:\n        \"\"\"\n        Finds the root directory of the project currently in memory.\n\n        The project root is defined as the first item in the 'look' memory\n        that is of type 'directory'.\n\n        Returns:\n            The absolute path to the project root directory, or None if not found.\n        \"\"\"\n        for item in self.memory.get('look', []):\n            if item.get('type') == 'directory':\n                return item.get('file')\n        return None\n\n    def get_memory_context(self) ->str:\n        \"\"\"\n        Dynamically builds the context using RAG and chat history.\n\n        It retrieves relevant file content from the RAG index based on the latest\n        user query, includes project manifests for directories, and appends the\n        recent chat history.\n        \"\"\"\n        context = ''\n        for look in self.memory.get('look', []):\n            path = look.get('file')\n            if path and os.path.isdir(path):\n                content = look.get('content', '')\n                context += (\n                    f'--- Project Manifest for {path} ---\\n{content}\\n\\n')\n        last_user_message = next((msg['content'] for msg in reversed(self.\n            memory.get('chat', [])) if msg['role'] == 'user'), None)\n        if last_user_message:\n            rag_results = self.search_rag(last_user_message, k=3)\n            if rag_results:\n                context += '--- Relevant context from RAG ---\\n'\n                for doc, score, meta in rag_results:\n                    file_path = meta.get('file', 'Unknown source')\n                    context += f'Source: {file_path} (Score: {score:.4f})\\n'\n                    context += f'Content: {doc}\\n---\\n'\n                context += '\\n'\n        for msg in self.memory.get('chat', []):\n            context += f\"{msg['role'].capitalize()}: {msg['content']}\\n\"\n        return context.strip()\n\n    def clear_memory(self) ->None:\n        self.memory = {'chat': [], 'look': []}\n        self.save_memory()\n        self.rag_manager.clear_index()\n\n    def search_rag(self, query: str, k: int=3) ->List[tuple]:\n        \"\"\"\n        Search the RAG index for relevant documents.\n        \n        Args:\n            query: The search query\n            k: Number of results to return\n            \n        Returns:\n            List of (document_content, score, metadata) tuples\n        \"\"\"\n        return self.rag_manager.search(query, k)\n",
    "file": "/mnt/ProjectData/omni/memory_manager.py"
  },
  {
    "id": 153,
    "hash": "fefce358bada61faf78f7880c778938c",
    "content": "\"\"\"\nOmni - AI-powered code generation and project-aware editing CLI tool\n\nIntegrates modular UI, memory, personality, and AST-based code editing.\n\"\"\"\nimport os\nimport subprocess\nimport requests\nimport json\nimport sys\nimport re\nimport argparse\nimport ast\nfrom datetime import datetime\nimport threading\nimport queue as Queue\nimport time\nfrom typing import List, Dict, Optional\nfrom rich import print\nfrom rich.panel import Panel\nfrom rich.console import Console\nfrom rich.tree import Tree\nfrom ui_manager import UIManager\nfrom personality_manager import PersonalityManager\nfrom memory_manager import MemoryManager\nfrom code_editor import CodeEditor\nfrom file_creator import FileCreator\nfrom git_manager import GitManager\nimport traceback\nDEFAULT_BACKEND = 'openrouter'\nOLLAMA_MODEL = 'phi4-reasoning'\nOPENROUTER_MODEL = 'qwen/qwen3-coder'\nDEFAULT_SAVE_DIR = os.path.expanduser('/mnt/ProjectData/omni/omni_saves/')\nCONFIG_FILE = 'config.json'\nMEMORY_FILE = 'memory.json'\nOLLAMA_API_URL = 'http://localhost:11434/api/generate'\nOPENROUTER_API_URL = 'https://openrouter.ai/api/v1/chat/completions'\nOPENROUTER_MODELS_API_URL = 'https://openrouter.ai/api/v1/models'\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\ncurrent_backend = DEFAULT_BACKEND\ncurrent_model = (OLLAMA_MODEL if DEFAULT_BACKEND == 'ollama' else\n    OPENROUTER_MODEL)\nOLLAMA_MODELS = {'deepseek': 'deepseek-coder:6.7b', 'codellama':\n    'codellama:13b', 'mistral': 'mistral:latest', 'llama2': 'llama2:latest',\n    'phind': 'phind-codellama:34b'}\nos.makedirs(DEFAULT_SAVE_DIR, exist_ok=True)\nTEMPLATES = {'flask':\n    \"\"\"from flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/')\ndef home():\n    return '<h1>Hello, Flask!</h1>'\n\nif __name__ == '__main__':\n    app.run(debug=True)\"\"\"\n    , 'html5':\n    \"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>New Page</title>\n</head>\n<body>\n    <h1>Hello World</h1>\n</body>\n</html>\"\"\"\n    , 'scraper':\n    \"\"\"import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        print(soup.title.text)\n    except Exception as e:\n        print(f\"[bold red]Error scraping {url}:[/] {e}\")\n\nif __name__ == \"__main__\":\n    scrape(\"https://example.com\")\"\"\"\n    }\nconsole = Console()\npersonality_manager = PersonalityManager(CONFIG_FILE)\nmemory_manager = MemoryManager(MEMORY_FILE)\nui_manager = UIManager()\nlast_query: Optional[str] = None\nlast_response: Optional[str] = None\nlast_code: Optional[str] = None\n\n\ndef start_ollama_server() ->None:\n    if current_backend != 'ollama':\n        return\n    try:\n        requests.get('http://localhost:11434', timeout=1)\n    except requests.exceptions.ConnectionError:\n        print('[cyan]Starting Ollama server...[/]')\n        subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL)\n\n\ndef query_llm(prompt: str) ->str:\n    personality = personality_manager.get_current_personality()\n    system_prompt = personality.get('system_prompt', '') if personality else ''\n    memory_context = memory_manager.get_memory_context()\n    rag_context = ''\n    try:\n        from rag_manager import RAGManager\n        project_root = memory_manager.get_project_root()\n        if project_root:\n            rag_manager = RAGManager()\n            if rag_manager.get_document_count() > 0:\n                results = rag_manager.search(prompt, k=3)\n                if results:\n                    rag_context = '\\n\\nRelevant context from codebase:\\n'\n                    for i, (doc, score, meta) in enumerate(results, 1):\n                        file_path = meta.get('file', 'Unknown')\n                        rag_context += f'{i}. [{file_path}] {doc}\\n'\n    except Exception:\n        pass\n    full_prompt = (\n        f'{system_prompt}\\n\\n{memory_context}{rag_context}\\n\\nUser: {prompt}')\n    with ui_manager.show_spinner('AI is listening and thinking...'):\n        if current_backend == 'ollama':\n            response = query_ollama(full_prompt)\n        elif current_backend == 'openrouter':\n            response = query_openrouter(full_prompt)\n        else:\n            response = '[bold red]Error:[/] Unknown backend'\n    return response\n\n\ndef query_openrouter(prompt: str) ->str:\n    if not OPENROUTER_API_KEY:\n        return '[bold red]Error:[/] OPENROUTER_API_KEY not set.'\n    headers = {'Authorization': f'Bearer {OPENROUTER_API_KEY}',\n        'Content-Type': 'application/json'}\n    payload = {'model': current_model, 'messages': [{'role': 'user',\n        'content': prompt}]}\n    try:\n        response = requests.post(OPENROUTER_API_URL, headers=headers, json=\n            payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['choices'][0]['message']['content']\n    except Exception as e:\n        error_details = ''\n        try:\n            error_details = response.json()\n        except:\n            error_details = response.text if hasattr(response, 'text'\n                ) else str(e)\n        return (\n            f'[bold red]OpenRouter Error:[/] {e}\\n[dim]Details: {error_details}[/dim]'\n            )\n\n\ndef query_ollama(prompt: str) ->str:\n    payload = {'model': current_model, 'prompt': prompt, 'stream': False}\n    try:\n        response = requests.post(OLLAMA_API_URL, json=payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['response']\n    except Exception as e:\n        return f'[bold red]Ollama Error:[/] {e}'\n\n\ndef extract_code(text: str) ->List[tuple[str, str]]:\n    matches = re.findall('```(\\\\w*)\\\\n([\\\\s\\\\S]*?)```', text)\n    return [(lang or 'text', code.strip()) for lang, code in matches\n        ] if matches else []\n\n\ndef list_models(args: list=None) ->None:\n    if current_backend == 'ollama':\n        print('[bold cyan]Popular Ollama Models:[/]')\n        for name, model_id in OLLAMA_MODELS.items():\n            print(\n                f\"{'\u2b50' if model_id == current_model else '  '} [yellow]{name:12}[/] \u2192 {model_id}\"\n                )\n    elif current_backend == 'openrouter':\n        list_openrouter_models(args or [])\n\n\ndef list_openrouter_models(args: list):\n    try:\n        from simple_term_menu import TerminalMenu\n    except ImportError:\n        ui_manager.show_error(\n            \"'simple-term-menu' is required. `pip install simple-term-menu`\")\n        return\n    try:\n        with ui_manager.show_spinner('Fetching models...'):\n            response = requests.get(OPENROUTER_MODELS_API_URL)\n            response.raise_for_status()\n        api_models_data = response.json().get('data', [])\n    except requests.RequestException as e:\n        ui_manager.show_error(f'Error fetching models: {e}')\n        return\n    all_models, sources = [], set()\n    for model_data in api_models_data:\n        if (model_id := model_data.get('id')):\n            sources.add(model_id.split('/')[0])\n            pricing = model_data.get('pricing', {})\n            is_free = pricing.get('prompt') == '0' and pricing.get('completion'\n                ) == '0'\n            all_models.append({'id': model_id, 'name': model_data.get(\n                'name'), 'source': model_id.split('/')[0], 'is_free': is_free})\n    all_models.sort(key=lambda x: (x['source'], x['name']))\n    if args and args[0].lower() == 'sources':\n        print('[bold cyan]Available Model Sources:[/]')\n        [print(f'  [yellow]{s}[/]') for s in sorted(list(sources))]\n        return\n    models_to_display, title = all_models, 'Select an OpenRouter Model'\n    if args:\n        filter_keyword = args[0].lower()\n        title = f\"Select a Model from '{filter_keyword}'\"\n        models_to_display = [m for m in all_models if filter_keyword in m[\n            'source'].lower()]\n        if not models_to_display:\n            ui_manager.show_error(f\"No models for source: '{filter_keyword}'\")\n            return\n    menu_entries = [\n        f\"{'\u2b50' if m['id'] == current_model else '  '} {m['name']} [dim]({m['id']}){' [green](FREE)[/]' if m['is_free'] else ''}[/dim]\"\n         for m in models_to_display]\n    try:\n        cursor_idx = next((i for i, m in enumerate(models_to_display) if m[\n            'id'] == current_model), 0)\n        chosen_index = TerminalMenu(menu_entries, title=f'{title}',\n            cursor_index=cursor_idx, cycle_cursor=True, clear_screen=True\n            ).show()\n        if chosen_index is not None:\n            set_model(models_to_display[chosen_index]['id'])\n        else:\n            print('Model selection cancelled.')\n    except Exception as e:\n        ui_manager.show_error(f'Menu display error: {e}')\n\n\ndef set_model(model_id: str) ->None:\n    global current_model\n    current_model = model_id\n    ui_manager.show_success(f'Model set to: {current_model}')\n\n\ndef switch_backend(backend_name: str) ->None:\n    global current_backend, current_model\n    backend_name = backend_name.lower()\n    if backend_name not in ['ollama', 'openrouter']:\n        ui_manager.show_error(f'Unknown backend: {backend_name}')\n        return\n    current_backend = backend_name\n    current_model = (OLLAMA_MODEL if backend_name == 'ollama' else\n        OPENROUTER_MODEL)\n    ui_manager.show_success(\n        f'Switched to {backend_name} backend with model: {current_model}')\n    if backend_name == 'ollama':\n        start_ollama_server()\n\n\ndef generate_project_manifest(path: str) ->tuple[str, List[str]]:\n    manifest = ''\n    file_paths = []\n    tree = Tree(f'[bold cyan]Project: {os.path.basename(path)}[/]')\n    exclude_dirs = {'__pycache__', '.git', 'venv', 'node_modules', '.idea',\n        'ollama'}\n    for root, dirs, files in os.walk(path):\n        dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.\n            startswith('.')]\n        relative_path = os.path.relpath(root, path)\n        branch = tree\n        if relative_path != '.':\n            parts = relative_path.split(os.sep)\n            for part in parts:\n                child = next((c for c in branch.children if c.label ==\n                    f'[magenta]{part}[/]'), None)\n                if not child:\n                    child = branch.add(f'[magenta]{part}[/]')\n                branch = child\n        for fname in sorted(files):\n            ext = os.path.splitext(fname)[1]\n            if ext not in ('.py', '.js', '.html', '.css', '.md', '.txt'):\n                continue\n            rel_path = os.path.join(relative_path, fname\n                ) if relative_path != '.' else fname\n            file_paths.append(rel_path)\n            branch.add(f'[green]{fname}[/]' if ext == '.py' else\n                f'[dim]{fname}[/]')\n            manifest += f'File: {rel_path}\\n\\n'\n    console.print(tree)\n    return manifest.strip(), file_paths\n\n\ndef look_command(path: str) ->None:\n    \"\"\"\n    Scans a directory or file and loads it into memory. It can resolve paths\n    relative to the current working directory or the project root in memory.\n    If a new directory is scanned, the previous 'look' context is cleared\n    to ensure the context remains relevant.\n    \"\"\"\n    resolved_path = resolve_file_path(path)\n    if not resolved_path:\n        ui_manager.show_error(f'\u274c Path not found: {path}')\n        return\n    if resolved_path != os.path.abspath(path):\n        ui_manager.show_success(\n            f\"Found '{path}' in project. Using: {resolved_path}\")\n    if os.path.isdir(resolved_path):\n        ui_manager.show_success(\n            \"New project directory detected. Clearing previous 'look' context.\"\n            )\n        memory_manager.memory['look'] = []\n        with ui_manager.show_spinner('Generating project manifest...'):\n            manifest = generate_project_manifest(resolved_path)\n        memory_manager.add_look_data(resolved_path, manifest)\n        ui_manager.show_success('\u2705 Project manifest added to memory.')\n    else:\n        try:\n            with ui_manager.show_spinner('Loading file...'):\n                with open(resolved_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n            for item in memory_manager.memory['look']:\n                if item.get('file') == resolved_path:\n                    item['content'] = content\n                    memory_manager.save_memory()\n                    ui_manager.show_success(\n                        '\u2705 Refreshed file content in memory.')\n                    return\n            memory_manager.add_look_data(resolved_path, content)\n            ui_manager.show_success('\u2705 File content added to memory.')\n        except Exception as e:\n            ui_manager.show_error(f'\u274c Error reading file: {e}')\n\n\ndef resolve_file_path(path: str) ->Optional[str]:\n    \"\"\"Resolves a file path, checking CWD first, then against project root in memory.\"\"\"\n    if os.path.exists(path):\n        return os.path.abspath(path)\n    project_root = memory_manager.get_project_root()\n    if project_root:\n        full_path = os.path.join(project_root, path)\n        if os.path.exists(full_path):\n            return full_path\n    return None\n\n\ndef _create_prompt_for_file_creation(file_name: str, instruction: str) ->str:\n    \"\"\"\n    Generate a robust prompt for file creation that instructs the AI to act as an expert,\n    produce complete and clean code, and avoid any extra commentary.\n    \"\"\"\n    return f\"\"\"You are an expert programmer tasked with creating a new file. Your goal is to generate complete, production-ready content based on the user's instruction.\n\nIMPORTANT RULES:\n- Provide ONLY the raw file content - no explanations, notes, or commentary outside the file itself\n- Include all necessary imports, boilerplate, and complete implementations\n- If creating code, ensure it's syntactically correct and follows best practices\n- For configuration files, use appropriate formatting (JSON, YAML, etc.)\n- For documentation files, use proper markdown formatting\n\nFile to create: {file_name}\nUser instruction: {instruction}\n\nGenerate the complete file content now:\"\"\"\n\n\ndef handle_file_create_command(file_path: str, instruction: str):\n    \"\"\"\n    Uses the LLM to generate content for a new file based on an instruction.\n    \"\"\"\n    global last_code\n    if os.path.exists(file_path):\n        if ui_manager.get_user_input(\n            f\"File '{file_path}' already exists. Overwrite? (y/n): \").lower(\n            ) not in ['yes', 'y']:\n            ui_manager.show_error('File creation cancelled.')\n            return\n    prompt = _create_prompt_for_file_creation(os.path.basename(file_path),\n        instruction)\n    with ui_manager.show_spinner(\n        f\"AI is generating content for '{file_path}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    if code_blocks:\n        new_content = code_blocks[0][1]\n    else:\n        new_content = response.strip()\n    if not new_content:\n        ui_manager.show_error('AI did not return any content.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    print(Panel(new_content, title=\n        f'[bold yellow]Proposed content for {file_path}[/]', border_style=\n        'yellow'))\n    if ui_manager.get_user_input('Create this file? (y/n): ').lower() in ['yes'\n        , 'y']:\n        try:\n            FileCreator.create(file_path, new_content)\n            last_code = new_content\n            ui_manager.show_success(f'File created successfully: {file_path}')\n        except IOError as e:\n            ui_manager.show_error(f'Error creating file: {e}')\n    else:\n        ui_manager.show_error('File creation cancelled.')\n\n\ndef look_all_command() ->None:\n    \"\"\"\n    Finds the project manifest in memory, reads every file listed, and adds their content to memory.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first to generate a manifest.\"\n            )\n        return\n    manifest_data = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and item.get('type'\n            ) == 'directory':\n            manifest_data = item.get('content')\n            break\n    if not manifest_data or not isinstance(manifest_data, (list, tuple)\n        ) or len(manifest_data) != 2:\n        ui_manager.show_error(\n            \"Could not find a valid project manifest in memory. Please run 'look <directory>' again.\"\n            )\n        return\n    file_paths = manifest_data[1]\n    if not file_paths:\n        ui_manager.show_error('No files found in the project manifest.')\n        return\n    total_files = len(file_paths)\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Loading {total_files} files from project manifest...'):\n        for file_path_relative in file_paths:\n            full_path = os.path.join(project_root, file_path_relative)\n            if os.path.isfile(full_path):\n                try:\n                    with open(full_path, 'r', encoding='utf-8') as f:\n                        content = f.read().strip()\n                    if not any(look['file'] == full_path for look in\n                        memory_manager.memory['look']):\n                        memory_manager.add_look_data(full_path, content)\n                        loaded_count += 1\n                except Exception as e:\n                    print(\n                        f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\"\n                        )\n    ui_manager.show_success(\n        f'\u2705 Loaded content for {loaded_count} new files into memory.')\n\n\ndef _load_all_project_files_if_needed():\n    \"\"\"\n    Checks if a project is loaded and automatically loads any files from its\n    manifest that are not already in the 'look' memory. This ensures a\n    complete context for editing and refactoring commands.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        return\n    manifest_content = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and 'File:' in item.get('content',\n            ''):\n            manifest_content = item['content']\n            break\n    if not manifest_content:\n        return\n    existing_file_paths = {item['file'] for item in memory_manager.memory.\n        get('look', []) if item.get('type') == 'file'}\n    file_paths_relative = re.findall('File: (.*)', manifest_content)\n    files_to_load = []\n    for rel_path in file_paths_relative:\n        full_path = os.path.join(project_root, rel_path)\n        if full_path not in existing_file_paths and os.path.isfile(full_path):\n            files_to_load.append((full_path, rel_path))\n    if not files_to_load:\n        return\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Auto-loading {len(files_to_load)} project files for context...'):\n        for full_path, file_path_relative in files_to_load:\n            try:\n                with open(full_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n                memory_manager.add_look_data(full_path, content)\n                loaded_count += 1\n            except Exception as e:\n                print(f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\")\n    if loaded_count > 0:\n        ui_manager.show_success(\n            f'\u2705 Loaded {loaded_count} new file(s) into memory for full project context.'\n            )\n\n\ndef _create_prompt_for_element_selection(file_name: str, instruction: str,\n    elements: List[str], element_structures: Dict[str, Dict]) ->str:\n    \"\"\"\n    Create a helper for the first stage of the 'edit' command. This prompt asks the AI\n    to analyze the user's instruction and intelligently select the most relevant code element to modify.\n    \"\"\"\n    element_details = []\n    for elem in elements:\n        if elem in element_structures:\n            struct = element_structures[elem]\n            detail = (\n                f\"{elem} ({struct['type']}, lines {struct['line_start']}-{struct['line_end']})\"\n                )\n            element_details.append(detail)\n        else:\n            element_details.append(elem)\n    elements_str = ', '.join(element_details) if element_details else 'None'\n    return f\"\"\"You are an expert code analyzer. Your task is to identify what should be modified based on the user's instruction.\n\nFile: {file_name}\nAvailable elements: {elements_str}\n\nUser instruction: {instruction}\n\nRESPONSE FORMAT:\nChoose one of these response types:\n1. \"ELEMENT: <element_name>\" - to edit an entire function/class\n2. \"PARTIAL: <element_name> LINES: <start>-<end>\" - to edit specific lines within an element\n3. \"FILE\" - to edit the entire file or multiple elements\n\nVALID ELEMENT NAMES:\n{chr(10).join(f'- {elem}' for elem in elements) if elements else 'None'}\n\nRULES:\n- If the instruction mentions specific line numbers or a specific part of a function, use PARTIAL\n- If the instruction targets an entire function/class, use ELEMENT\n- If the instruction requires changes to multiple elements or file structure, use FILE\n- For PARTIAL edits, provide absolute line numbers from the original file\n- ONLY use element names from the \"Available elements\" list above\n- If no suitable element exists, use \"FILE\"\n- NEVER return an element name that is not in the available list\n\nWhat should be edited?\"\"\"\n\n\ndef _create_prompt_for_element_rewrite(file_name: str, element_name: str,\n    instruction: str, original_code: str, is_full_file: bool=False) ->str:\n    \"\"\"\n    Create a helper for the second stage of the 'edit' command. This prompt instructs the AI\n    to rewrite a specific code element (or the whole file) based on the user's request,\n    demanding a complete and syntactically correct code block as output.\n    \"\"\"\n    if is_full_file:\n        return f\"\"\"You are an expert programmer. Rewrite the entire file to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the entire file\n- Ensure all syntax is correct and the code is ready to run\n- Preserve existing functionality unless explicitly asked to change it\n- Include all necessary imports and maintain the file's structure\n- Do NOT include any explanations or comments outside the code\n\nFile: {file_name}\nTask: {instruction}\n\nCurrent file content:\n```python\n{original_code}\n```\n\nGenerate the complete updated file now:\"\"\"\n    else:\n        return f\"\"\"You are an expert programmer. Rewrite the specified element to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the element\n- Include any necessary imports at the top of your code block\n- Ensure the code is syntactically correct and maintains the same interface\n- Do NOT include explanations or comments outside the code block\n- The code must be a drop-in replacement for the original element\n\nFile: {file_name}\nElement to modify: {element_name}\nTask: {instruction}\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the complete updated element now:\"\"\"\n\n\ndef _create_prompt_for_partial_edit(file_name: str, element_name: str,\n    instruction: str, original_snippet: str, line_start: int, line_end: int,\n    full_element_code: str) ->str:\n    \"\"\"\n    Create a prompt for partial edits within a function or class.\n    This allows surgical changes to specific parts of code.\n    \"\"\"\n    return f\"\"\"You are an expert programmer. Make a surgical edit to a specific part of a function/class.\n\nCONTEXT:\n- File: {file_name}\n- Element: {element_name}\n- Lines to modify: {line_start}-{line_end}\n- Task: {instruction}\n\nIMPORTANT RULES:\n- Provide ONLY the code that will replace lines {line_start}-{line_end}\n- Your code must fit seamlessly into the existing function\n- Maintain proper indentation (the code will be auto-indented)\n- Do NOT include the function definition or other parts\n- Do NOT include explanations outside the code\n\nFull element for context:\n```python\n{full_element_code}\n```\n\nCode section to replace (lines {line_start}-{line_end}):\n```python\n{original_snippet}\n```\n\nGenerate ONLY the replacement code for the specified lines:\"\"\"\n\n\ndef handle_file_edit_command(file_path: str, instruction: str):\n    \"\"\"\n    Handles the entire workflow for editing a single file, ensuring full\n    project context is loaded before the AI makes any decisions.\n    Now supports partial edits within functions.\n    \"\"\"\n    global last_code\n    _load_all_project_files_if_needed()\n    resolved_path = resolve_file_path(file_path)\n    if not resolved_path:\n        ui_manager.show_error(f'File not found: {file_path}')\n        return\n    if resolved_path != os.path.abspath(file_path):\n        ui_manager.show_success(\n            f\"Found '{file_path}' in project. Using: {resolved_path}\")\n    try:\n        editor = CodeEditor(resolved_path)\n    except (ValueError, FileNotFoundError) as e:\n        ui_manager.show_error(str(e))\n        return\n    elements = editor.list_elements()\n    element_structures = {}\n    for elem in elements:\n        struct = editor.get_element_structure(elem)\n        if struct:\n            element_structures[elem] = struct\n    prompt1 = _create_prompt_for_element_selection(os.path.basename(\n        resolved_path), instruction, elements, element_structures)\n    with ui_manager.show_spinner('AI is analyzing file...'):\n        ai_response = query_llm(prompt1).strip()\n    if ai_response.upper() == 'FILE':\n        ui_manager.show_success('AI has chosen to edit the entire file.')\n        original_snippet = editor.source_code\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), 'entire file', instruction, original_snippet,\n            is_full_file=True)\n        edit_type = 'FILE'\n        element_to_edit = None\n        line_range = None\n    elif ai_response.startswith('PARTIAL:'):\n        parts = ai_response.split()\n        element_to_edit = parts[1]\n        if 'LINES:' in ai_response:\n            line_part = ai_response.split('LINES:')[1].strip()\n            if '-' in line_part:\n                line_start, line_end = map(int, line_part.split('-'))\n                line_range = line_start, line_end\n            else:\n                ui_manager.show_error('Invalid line range format')\n                return\n        else:\n            ui_manager.show_error('Missing line range for partial edit')\n            return\n        if element_to_edit not in elements:\n            ui_manager.show_error(f\"Element '{element_to_edit}' not found\")\n            return\n        ui_manager.show_success(\n            f\"AI selected partial edit of '{element_to_edit}' (lines {line_start}-{line_end})\"\n            )\n        original_snippet = editor.get_element_body_snippet(element_to_edit,\n            line_start, line_end)\n        if not original_snippet:\n            original_snippet = editor.get_source_of(element_to_edit)\n        full_element_code = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_partial_edit(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet,\n            line_start, line_end, full_element_code)\n        edit_type = 'PARTIAL'\n    elif ai_response.startswith('ELEMENT:'):\n        element_to_edit = ai_response.split(':', 1)[1].strip()\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    else:\n        element_to_edit = ai_response.splitlines()[0]\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    with ui_manager.show_spinner(f'AI is editing...'):\n        response = query_llm(prompt2)\n    code_blocks = extract_code(response)\n    if not code_blocks:\n        ui_manager.show_error('AI did not return a valid code block.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    new_code = code_blocks[0][1]\n    success = False\n    if edit_type == 'FILE':\n        try:\n            editor.tree = ast.parse(new_code)\n            success = True\n        except SyntaxError as e:\n            ui_manager.show_error(f'AI returned invalid Python syntax: {e}')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    elif edit_type == 'PARTIAL':\n        success = editor.replace_partial(element_to_edit, new_code,\n            line_start=line_range[0], line_end=line_range[1])\n        if not success:\n            ui_manager.show_error('Failed to apply partial edit.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    else:\n        success = editor.replace_element(element_to_edit, new_code)\n        if not success:\n            ui_manager.show_error(\n                'AI returned invalid code; could not be parsed or applied.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    if not (diff := editor.get_diff()):\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(diff, title=\n        f'[bold yellow]Proposed Changes for {resolved_path}[/]'))\n    if ui_manager.get_user_input('Apply changes? (y/n): ').lower() in ['yes',\n        'y']:\n        editor.save_changes()\n        last_code = editor.get_modified_source()\n        ui_manager.show_success(f'Changes saved to {resolved_path}.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_plan(instruction: str, memory_context: str\n    ) ->str:\n    \"\"\"\n    Create a specialized prompt-generation function for the 'refactor' command.\n    This prompt will explicitly define the required JSON structure for the plan\n    and instruct the AI to act as an expert project manager.\n    \"\"\"\n    return f\"\"\"You are an expert project manager and software architect. Analyze the project context and create a detailed refactoring plan.\n\nYour plan must be a valid JSON object with this exact structure:\n{{\n    \"actions\": [\n        {{\n            \"type\": \"MODIFY\" | \"CREATE\" | \"DELETE\" | \"PARTIAL\",\n            \"file\": \"relative/path/to/file.py\",\n            \"element\": \"function_or_class_name\",  // For MODIFY/DELETE/PARTIAL\n            \"element_name\": \"new_element_name\",    // For CREATE\n            \"line_start\": 10,                      // For PARTIAL only\n            \"line_end\": 20,                        // For PARTIAL only\n            \"reason\": \"Clear explanation of why this change is needed\",\n            \"description\": \"What this action will accomplish\",\n            \"anchor_element\": \"optional_anchor\",   // Optional for CREATE\n            \"position\": \"before\" | \"after\"         // Optional for CREATE\n        }}\n    ]\n}}\n\nACTION TYPES:\n- MODIFY: Change an entire function, class, or method\n- PARTIAL: Change specific lines within a function/class (requires line_start and line_end)\n- CREATE: Add new functions, classes, or files\n- DELETE: Remove functions, classes, variables, or imports\n\nRULES FOR YOUR PLAN:\n- Use PARTIAL when you only need to change a small part of a function\n- Use MODIFY when restructuring an entire function or class\n- Each action must have all required fields based on its type\n- File paths must be relative to the project root\n- Be specific and surgical - avoid unnecessary changes\n- Consider dependencies between changes\n- Order actions logically (e.g., create dependencies before using them)\n\n### Project Context ###\n{memory_context}\n\n### Refactoring Request ###\n{instruction}\n\nGenerate ONLY the JSON plan - no explanations or markdown:\"\"\"\n\n\ndef _get_refactor_plan(instruction: str) ->Optional[List[Dict]]:\n    \"\"\"\n    Generates a refactoring plan from the LLM.\n\n    This function encapsulates the logic for checking project context,\n    constructing a prompt, querying the LLM, and parsing the resulting\n    JSON plan for a refactoring task.\n\n    Args:\n        instruction: The user's high-level refactoring instruction.\n\n    Returns:\n        A list of action dictionaries if a valid plan is generated,\n        otherwise None.\n    \"\"\"\n    if not memory_manager.get_project_root():\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return None\n    memory_context = memory_manager.get_memory_context()\n    plan_prompt = _create_prompt_for_refactor_plan(instruction, memory_context)\n    with ui_manager.show_spinner('AI is creating an execution plan...'):\n        plan_str = query_llm(plan_prompt)\n    try:\n        match = re.search('\\\\{.*\\\\}', plan_str, re.DOTALL)\n        if not match:\n            raise ValueError('No JSON object found in the response.')\n        plan = json.loads(match.group(0))\n        actions = plan.get('actions', [])\n        if not actions:\n            raise ValueError(\"No 'actions' key found in plan or plan is empty.\"\n                )\n        return actions\n    except (json.JSONDecodeError, ValueError) as e:\n        ui_manager.show_error(f'AI failed to generate a valid plan: {e}')\n        print(Panel(plan_str, title=\"[yellow]AI's Invalid Plan Response[/]\",\n            border_style='yellow'))\n        return None\n\n\ndef _display_and_confirm_plan(plan: Dict) ->bool:\n    \"\"\"\n    Displays the generated execution plan to the user and asks for confirmation.\n\n    This helper function separates the UI interaction of plan confirmation from\n    the main refactoring logic.\n\n    Args:\n        plan: A dictionary, expected to contain an 'actions' key with a list of action dicts.\n\n    Returns:\n        True if the user confirms the plan, False otherwise.\n    \"\"\"\n    actions = plan.get('actions', [])\n    if not actions:\n        ui_manager.show_error('The generated plan is empty. Aborting.')\n        return False\n    ui_manager.show_success('AI has created a plan:')\n    for i, action in enumerate(actions):\n        action_type = action.get('type', 'N/A')\n        element = action.get('element') or action.get('element_name', 'N/A')\n        reason = action.get('reason') or action.get('description', '')\n        file_path = action.get('file', '')\n        if action_type == 'PARTIAL':\n            line_start = action.get('line_start', '?')\n            line_end = action.get('line_end', '?')\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} (lines {line_start}-{line_end}) - {reason}'\n                )\n        else:\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} - {reason}'\n                )\n    if ui_manager.get_user_input('\\nProceed with this plan? (y/n): ').lower(\n        ) in ['yes', 'y']:\n        return True\n    else:\n        ui_manager.show_error('Execution aborted by user.')\n        return False\n\n\ndef _apply_refactor_changes(editors: Dict[str, CodeEditor]) ->None:\n    \"\"\"\n    Consolidates changes from multiple CodeEditor instances, shows a unified\n    diff, and prompts the user to apply them.\n    \n    This helper function abstracts the final step of a refactor, ensuring\n    all proposed modifications are presented to the user for a final review\n    before any files are written to disk.\n\n    Args:\n        editors: A dictionary mapping absolute file paths to their\n                 corresponding CodeEditor instances which hold the\n                 proposed changes in their AST.\n    \"\"\"\n    full_diff = ''\n    for editor in editors.values():\n        diff = editor.get_diff()\n        if diff:\n            full_diff += diff + '\\n'\n    if not full_diff.strip():\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(full_diff, title=\n        '[bold yellow]Proposed Project-Wide Changes[/]'))\n    if ui_manager.get_user_input('Apply all changes? (y/n): ').lower() in [\n        'yes', 'y']:\n        for editor in editors.values():\n            editor.save_changes()\n        ui_manager.show_success('\u2705 Project changes applied successfully.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_action(action_type: str, file_path: str,\n    action_details: Dict) ->str:\n    \"\"\"\n    Create a helper to generate prompts for individual 'CREATE' or 'MODIFY' steps\n    within a refactor plan. This ensures the AI produces code for the specific\n    sub-task in the correct context.\n    \"\"\"\n    if action_type == 'MODIFY':\n        element_name = action_details['element_name']\n        reason = action_details['reason']\n        original_code = action_details['original_code']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- Element: {element_name}\n- Reason for change: {reason}\n\nRULES:\n- Provide ONLY the complete updated code for the element\n- Include any necessary imports at the top\n- Ensure the code integrates properly with the rest of the file\n- Maintain the same function/class signature unless the change requires otherwise\n- No explanations outside the code block\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the updated element code:\"\"\"\n    elif action_type == 'CREATE':\n        element_name = action_details['element_name']\n        description = action_details['description']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- New element to create: {element_name}\n- Purpose: {description}\n\nRULES:\n- Provide ONLY the complete code for the new element\n- Include all necessary imports at the top\n- Follow the coding style and patterns used in the project\n- Ensure the code is production-ready and well-structured\n- For non-Python files, provide the complete file content\n- No explanations outside the code block\n\nGenerate the new element code:\"\"\"\n\n\ndef _process_refactor_action(action: Dict, project_base_path: str, editors:\n    Dict) ->bool:\n    \"\"\"\n    Processes a single refactoring action from the plan.\n\n    This function handles the execution of a single action from the refactoring plan,\n    including LLM code generation and applying changes to in-memory editors or files.\n\n    Args:\n        action: A dictionary containing action details (type, file, element, etc.)\n        project_base_path: The absolute path to the project root\n        editors: Dictionary mapping file paths to their CodeEditor instances\n\n    Returns:\n        True if the action was processed successfully, False otherwise\n    \"\"\"\n    file_path_relative = action.get('file')\n    if not file_path_relative:\n        ui_manager.show_error(\n            f\"Action is missing 'file' key. Skipping: {action}\")\n        return False\n    file_path_absolute = os.path.join(project_base_path, file_path_relative)\n    action_type = action.get('type', '').upper()\n    prompt, element_name = '', ''\n    if action_type == 'MODIFY':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_source_of(element_name)\n            if not original_snippet:\n                ui_manager.show_error(\n                    f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                    )\n                return False\n            action_details = {'element_name': element_name, 'reason':\n                reason, 'original_code': original_snippet}\n            prompt = _create_prompt_for_refactor_action('MODIFY',\n                file_path_relative, action_details)\n    elif action_type == 'PARTIAL':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        line_start = action.get('line_start')\n        line_end = action.get('line_end')\n        if not all([element_name, line_start, line_end]):\n            ui_manager.show_error(\n                f'PARTIAL action missing required fields. Skipping: {action}')\n            return False\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_element_body_snippet(element_name,\n                line_start, line_end)\n            if not original_snippet:\n                original_snippet = editor.get_source_of(element_name)\n                if not original_snippet:\n                    ui_manager.show_error(\n                        f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                        )\n                    return False\n            full_element_code = editor.get_source_of(element_name)\n            prompt = _create_prompt_for_partial_edit(file_path_relative,\n                element_name, reason, original_snippet, line_start,\n                line_end, full_element_code)\n    elif action_type == 'CREATE':\n        element_name = action.get('element_name')\n        description = action.get('description')\n        action_details = {'element_name': element_name, 'description':\n            description}\n        prompt = _create_prompt_for_refactor_action('CREATE',\n            file_path_relative, action_details)\n    else:\n        ui_manager.show_error(f\"Invalid action type '{action_type}'. Skipping.\"\n            )\n        return False\n    with ui_manager.show_spinner(\n        f\"AI: {action_type} on '{element_name or file_path_relative}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    new_content = code_blocks[0][1] if code_blocks else response.strip()\n    if not new_content:\n        ui_manager.show_error(\n            f'AI failed to generate content for action: {action}')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return False\n    if not file_path_relative.endswith('.py'):\n        try:\n            FileCreator.create(file_path_absolute, new_content)\n            ui_manager.show_success(\n                f\"File '{file_path_relative}' created/updated.\")\n            return True\n        except IOError as e:\n            ui_manager.show_error(\n                f\"Failed to create file '{file_path_relative}': {e}\")\n            return False\n    if file_path_absolute not in editors:\n        try:\n            if not os.path.exists(file_path_absolute):\n                os.makedirs(os.path.dirname(file_path_absolute), exist_ok=True)\n                with open(file_path_absolute, 'w') as f:\n                    f.write('')\n            editors[file_path_absolute] = CodeEditor(file_path_absolute)\n        except Exception as e:\n            ui_manager.show_error(\n                f'Error loading file {file_path_absolute}: {e}')\n            return False\n    editor = editors[file_path_absolute]\n    if action_type == 'MODIFY':\n        if not editor.replace_element(element_name, new_content):\n            ui_manager.show_error(\n                f\"Failed to apply MODIFY change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic MODIFY Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'PARTIAL':\n        if not editor.replace_partial(element_name, new_content, line_start,\n            line_end):\n            ui_manager.show_error(\n                f\"Failed to apply PARTIAL change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic PARTIAL Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'CREATE':\n        anchor = action.get('anchor_element')\n        position = action.get('position', 'after')\n        if not editor.add_element(new_content, anchor_name=anchor, before=\n            position == 'before'):\n            ui_manager.show_error(\n                f\"Failed to apply CREATE change for '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic CREATE Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    return True\n\n\ndef handle_project_refactor_command(instruction: str):\n    \"\"\"\n    Orchestrates a multi-file, multi-step code refactoring process.\n    \n    This function serves as a high-level orchestrator that delegates specific tasks\n    to helper functions, improving readability, modularity, and maintainability.\n    \"\"\"\n    _load_all_project_files_if_needed()\n    actions = _get_refactor_plan(instruction)\n    if not actions:\n        return\n    plan = {'actions': actions}\n    if not _display_and_confirm_plan(plan):\n        return\n    editors: Dict[str, CodeEditor] = {}\n    project_base_path = memory_manager.get_project_root()\n    successful_actions = 0\n    total_actions = len(actions)\n    for i, action in enumerate(actions, 1):\n        ui_manager.show_success(f'Processing action {i}/{total_actions}...')\n        action_type = action.get('type', '').upper()\n        file_path_relative = action.get('file')\n        if not file_path_relative:\n            ui_manager.show_error(\n                f\"Action is missing 'file' key. Skipping: {action}\")\n            continue\n        file_path_absolute = os.path.join(project_base_path, file_path_relative\n            )\n        if action_type == 'DELETE':\n            element_name = action.get('element')\n            if not element_name:\n                ui_manager.show_error(\n                    f\"DELETE action missing 'element' key. Skipping: {action}\")\n                continue\n            if not file_path_relative.endswith('.py'):\n                ui_manager.show_error(\n                    f'DELETE actions are only supported for Python files. Skipping.'\n                    )\n                continue\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    continue\n            editor = editors[file_path_absolute]\n            if editor.delete_element(element_name):\n                successful_actions += 1\n                ui_manager.show_success(\n                    f\"Successfully deleted '{element_name}' from '{file_path_relative}'.\"\n                    )\n            else:\n                ui_manager.show_error(\n                    f\"Failed to delete '{element_name}' from '{file_path_relative}'.\"\n                    )\n        elif _process_refactor_action(action, project_base_path, editors):\n            successful_actions += 1\n        else:\n            ui_manager.show_error(\n                f'Action {i} failed, continuing with remaining actions...')\n    if successful_actions == 0:\n        ui_manager.show_error('No actions were successfully executed.')\n        return\n    elif successful_actions < total_actions:\n        ui_manager.show_error(\n            f'Only {successful_actions}/{total_actions} actions completed successfully.'\n            )\n    else:\n        ui_manager.show_success(\n            f'All {total_actions} actions completed successfully.')\n    _apply_refactor_changes(editors)\n\n\ndef _create_prompt_for_commit_message(diff: str) ->str:\n    \"\"\"\n    Create a dedicated prompt function for the 'commit' command. This prompt will\n    instruct the AI to analyze a git diff and generate a concise commit message\n    following the Conventional Commits standard.\n    \"\"\"\n    return f\"\"\"You are an expert developer writing a Git commit message. Your task is to analyze the provided git diff and create a professional commit message.\n\nCOMMIT MESSAGE RULES:\n- Follow the Conventional Commits specification\n- Format: <type>(<optional scope>): <subject>\n- Types: feat, fix, docs, style, refactor, perf, test, build, ci, chore, revert\n- Subject line: max 50 characters, imperative mood, no period\n- Optional body: explain what and why (not how), wrap at 72 characters\n- Be specific and concise\n- Focus on the intent and impact of the changes\n\nEXAMPLES OF GOOD COMMIT MESSAGES:\n- feat(auth): add OAuth2 integration for Google login\n- fix(api): handle null response in user endpoint\n- refactor(database): optimize query performance for large datasets\n- docs(readme): update installation instructions for Windows\n\nRespond with ONLY the commit message - no markdown, quotes, or explanations.\n\n--- GIT DIFF TO ANALYZE ---\n{diff}\n\nGenerate the commit message:\"\"\"\n\n\ndef handle_commit_command():\n    \"\"\"\n    Orchestrates an AI-assisted Git commit workflow with improved error handling.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return\n    try:\n        git_manager = GitManager(project_root)\n    except ValueError as e:\n        ui_manager.show_error(str(e))\n        return\n    changed_files = git_manager.get_changed_files()\n    if not changed_files:\n        ui_manager.show_success(\n            'No changes to commit. Everything is up to date.')\n        return\n    staged_diff = git_manager.get_diff(staged=True)\n    unstaged_diff = git_manager.get_diff()\n    full_diff = f'{staged_diff}\\n{unstaged_diff}'.strip()\n    if not full_diff.strip():\n        ui_manager.show_success(\n            'No content changes detected (e.g., only file mode changes).')\n        return\n    prompt = _create_prompt_for_commit_message(full_diff)\n    commit_message = query_llm(prompt).strip()\n    if not commit_message:\n        ui_manager.show_error(\n            'AI failed to generate a commit message. Aborting.')\n        return\n    files_to_commit_str = '\\n'.join(f'- {f}' for f in changed_files)\n    plan_panel_content = f\"\"\"[bold]Files to be staged:[/]\n[yellow]{files_to_commit_str}[/]\n\n[bold]AI-Generated Commit Message:[/]\n[green]{commit_message}[/]\"\"\"\n    print(Panel(plan_panel_content, title='[bold cyan]Commit Plan[/]',\n        border_style='cyan'))\n    if ui_manager.get_user_input('\\nProceed with commit? (y/n): ').lower() in [\n        'yes', 'y']:\n        try:\n            git_manager.add(changed_files)\n            ui_manager.show_success('\u2705 Files staged.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Staging failed: {e.stderr}')\n            return\n        try:\n            git_manager.commit(commit_message)\n            ui_manager.show_success('\u2705 Commit successful.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Commit failed: {e.stderr}')\n            return\n        if ui_manager.get_user_input('Push changes to remote? (y/n): ').lower(\n            ) in ['yes', 'y']:\n            try:\n                git_manager.push()\n                ui_manager.show_success('\u2705 Push successful.')\n            except subprocess.CalledProcessError as e:\n                ui_manager.show_error(f'Push failed: {e.stderr}')\n        else:\n            ui_manager.show_error('Push cancelled.')\n    else:\n        ui_manager.show_error('Commit aborted by user.')\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef interactive_mode() ->None:\n    global last_query, last_response, last_code\n    try:\n        from Testing.overlay_engine import show_sequential_popup\n        gui_available = True\n    except ImportError:\n        gui_available = False\n    print(Panel(\n        \"\"\"[bold cyan]Omni Interactive Mode[/]\n[dim]Type 'help' for commands, 'exit' to quit.[/dim]\"\"\"\n        , border_style='cyan'))\n    personality_name = personality_manager.get_current_personality().get('name'\n        , 'Default')\n    gui_enabled = False\n    if gui_available:\n        try:\n            with open(CONFIG_FILE, 'r') as f:\n                config = json.load(f)\n                if config.get('gui_enabled', False):\n                    gui_enabled = True\n        except (FileNotFoundError, json.JSONDecodeError):\n            pass\n    refresh_status_panel(personality_name)\n    while True:\n        try:\n            user_input = ui_manager.get_user_input('\\n> ')\n            if not user_input:\n                continue\n            command, *args = user_input.split(maxsplit=1)\n            arg_str = args[0] if args else ''\n            if command == 'exit':\n                memory_manager.save_memory()\n                print('[bold cyan]Goodbye![/]')\n                break\n            elif command == 'help':\n                print(\n                    \"\"\"[bold]Commands:[/]\n\n  [bold cyan]Core & Project Commands[/]\n  [yellow]send <prompt>[/]        - Ask the LLM a question.\n  [yellow]look <path>[/]          - Read file or scan directory into memory.\n  [yellow]look_all[/]            - Recursively scan the project directory into memory.\n  [yellow]create <file> \"instr\"[/] - Create a new file using AI.\n  [yellow]edit <file> \"instr\"[/]   - Edit a specific file using AI.\n  [yellow]refactor \"instr\"[/]      - Refactor project in memory based on instruction.\n  [yellow]commit[/]               - Commit changes with an AI-generated message.\n  [yellow]rag <query>[/]         - Query the RAG system for context retrieval.\n\n  [bold cyan]File & Code Management[/]\n  [yellow]save <filename>[/]     - Save last AI response to a file.\n  [yellow]list[/]               - List saved files.\n  [yellow]run[/]                 - Run the last generated Python code.\n\n  [bold cyan]Session & Config[/]\n  [yellow]history[/]             - Show the full chat history.\n  [yellow]memory clear[/]        - Clear the chat and file memory.\n  [yellow]backend <name>[/]      - Switch AI backend (e.g., openrouter, ollama).\n  [yellow]models [src][/]        - Interactively list and select models.\n  [yellow]set model <id>[/]      - Set the model directly by its ID.\n  [yellow]personality <cmd>[/]   - Manage AI personalities ('list', 'set', 'add').\n\"\"\"\n                    )\n            elif command == 'send':\n                last_query = arg_str\n                response = query_llm(arg_str)\n                last_response = response\n                memory_manager.add_chat_message('user', last_query)\n                memory_manager.add_chat_message('assistant', last_response)\n                if gui_enabled:\n                    threading.Thread(target=show_sequential_popup, args=(\n                        100, 100, response, f'Omni - {personality_name}'),\n                        daemon=True).start()\n                print(Panel(response, title='[cyan]Response[/]'))\n                if (code_blocks := extract_code(response)):\n                    last_code = code_blocks[0][1]\n            elif command == 'look':\n                look_command(arg_str)\n            elif command == 'look_all':\n                look_all_command()\n            elif command == 'create':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_create_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: create <file_path> \"<instruction>\"')\n            elif command == 'edit':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_edit_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: edit <file_path> \"<instruction>\"')\n            elif command == 'refactor':\n                if not arg_str:\n                    ui_manager.show_error('Usage: refactor \"<instruction>\"')\n                else:\n                    handle_project_refactor_command(arg_str.strip('\"'))\n            elif command == 'commit':\n                handle_commit_command()\n            elif command == 'models':\n                list_models(arg_str.split())\n            elif command == 'set' and arg_str.startswith('model '):\n                set_model(arg_str[6:])\n            elif command == 'backend':\n                switch_backend(arg_str)\n            elif command == 'history':\n                ui_manager.display_history(memory_manager.get_memory_context())\n            elif command == 'memory' and arg_str == 'clear':\n                memory_manager.clear_memory()\n                ui_manager.show_success('\u2705 Memory cleared')\n            elif command == 'personality':\n                p_args = arg_str.split(maxsplit=1)\n                cmd = p_args[0] if p_args else ''\n                p_arg_str = p_args[1] if len(p_args) > 1 else ''\n                if cmd == 'list':\n                    for p in personality_manager.list_personalities():\n                        print(f\"- {p['name']}: {p['description']}\")\n                elif cmd == 'set' and p_arg_str:\n                    if personality_manager.set_current_personality(p_arg_str):\n                        personality_name = p_arg_str\n                        ui_manager.show_success(\n                            f'Set personality to {personality_name}')\n                    else:\n                        ui_manager.show_error('Personality not found.')\n                else:\n                    ui_manager.show_error(\n                        \"Invalid personality command. Use 'list' or 'set <name>'.\"\n                        )\n            elif command == 'run':\n                run_python_code()\n            elif command == 'save':\n                if last_response:\n                    save_code(last_response, arg_str or\n                        f\"omni_save_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n                        )\n                else:\n                    ui_manager.show_error('No response to save.')\n            elif command == 'list':\n                files = sorted(os.listdir(DEFAULT_SAVE_DIR))\n                print('\\n'.join(f'  - {f}' for f in files) if files else\n                    '[yellow]No saved files.[/]')\n            elif command == 'rag':\n                if not arg_str:\n                    ui_manager.show_error('Usage: rag \"<query>\"')\n                else:\n                    from rag_manager import RAGManager\n                    project_root = memory_manager.get_project_root()\n                    if not project_root:\n                        ui_manager.show_error(\n                            \"No project context in memory. Use 'look <directory>' first.\"\n                            )\n                        continue\n                    rag = RAGManager()\n                    if rag.get_document_count() == 0:\n                        ui_manager.show_error(\n                            'RAG index is empty. Please add documents first.')\n                        continue\n                    results = rag.search(arg_str, k=3)\n                    if not results:\n                        ui_manager.show_error('No relevant documents found.')\n                        continue\n                    print(Panel('[bold]RAG Results:[/]', title=\n                        '[cyan]Retrieval-Augmented Generation[/]'))\n                    for i, (content, score, metadata) in enumerate(results, 1):\n                        file_path = metadata.get('file', 'Unknown')\n                        print(\n                            f'[bold cyan]{i}. {file_path}[/] (Score: {score:.4f})'\n                            )\n                        print(Panel(content[:500] + '...' if len(content) >\n                            500 else content, border_style='dim'))\n                    follow_up = ui_manager.get_user_input(\n                        \"\"\"\nWould you like to ask a follow-up question with this context? (y/n): \"\"\"\n                        )\n                    if follow_up.lower() in ['y', 'yes']:\n                        follow_up_query = ui_manager.get_user_input(\n                            'Follow-up query: ')\n                        if follow_up_query:\n                            context_parts = [\n                                f'Document {i} (Score: {score:.4f}):\\n{content}'\n                                 for i, (content, score, _) in enumerate(\n                                results, 1)]\n                            context = '\\n\\n'.join(context_parts)\n                            rag_prompt = f\"\"\"Based on the following context, please answer the question.\n\nContext:\n{context}\n\nQuestion: {follow_up_query}\"\"\"\n                            response = query_llm(rag_prompt)\n                            print(Panel(response, title=\n                                '[cyan]RAG-Augmented Response[/]'))\n            else:\n                ui_manager.show_error(\"Unknown command. Type 'help'.\")\n            refresh_status_panel(personality_name)\n        except KeyboardInterrupt:\n            memory_manager.save_memory()\n            print('\\n[bold cyan]Goodbye![/]')\n            break\n        except Exception as e:\n            ui_manager.show_error(f'An unexpected error occurred: {e}')\n\n\ndef run_python_code() ->None:\n    global last_code\n    if not last_code:\n        ui_manager.show_error('No Python code in memory to run.')\n        return\n    temp_file = os.path.join(DEFAULT_SAVE_DIR, 'temp_run.py')\n    try:\n        with open(temp_file, 'w') as f:\n            f.write(last_code)\n        print('[bold cyan]\\n--- Running Code ---\\n[/]')\n        subprocess.run([sys.executable, temp_file], check=True)\n        print('[bold cyan]\\n--- Code Finished ---\\n[/]')\n    except Exception as e:\n        ui_manager.show_error(f'Error running code: {e}')\n    finally:\n        if os.path.exists(temp_file):\n            os.remove(temp_file)\n\n\ndef save_code(content: str, filename: str) ->None:\n    filepath = os.path.join(DEFAULT_SAVE_DIR, filename)\n    try:\n        with open(filepath, 'w') as f:\n            f.write(content)\n        ui_manager.show_success(f'Saved to: {filepath}')\n    except IOError as e:\n        ui_manager.show_error(f'Error saving file: {e}')\n\n\ndef main() ->None:\n    try:\n        import astor\n    except ImportError:\n        print(\"[bold red]Error:[/] 'astor' is required. `pip install astor`\")\n        sys.exit(1)\n    try:\n        import simple_term_menu\n    except ImportError:\n        print(\n            \"[bold red]Error:[/] 'simple-term-menu' is required. `pip install simple-term-menu`\"\n            )\n        sys.exit(1)\n    parser = argparse.ArgumentParser(description=\n        'Omni - AI-powered code tool', add_help=False)\n    parser.add_argument('command', nargs='?', help='Main command.')\n    parser.add_argument('args', nargs='*', help='Arguments for the command.')\n    parser.add_argument('-h', '--help', action='store_true')\n    args, _ = parser.parse_known_args()\n    if args.help or not args.command:\n        interactive_mode()\n    elif args.command == 'look' and args.args:\n        look_command(args.args[0])\n    elif args.command == 'edit' and len(args.args) >= 2:\n        handle_file_edit_command(args.args[0], ' '.join(args.args[1:]))\n    elif args.command == 'models':\n        list_models(args.args)\n    else:\n        interactive_mode()\n\n\ndef refresh_status_panel(personality_name: str) ->None:\n    ui_manager.display_status_panel(personality_name, current_backend,\n        current_model, len(memory_manager.memory.get('chat', [])), len(\n        memory_manager.memory.get('look', [])))\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/omni.py"
  },
  {
    "id": 154,
    "hash": "db1585da7840e9dc17f3ab8c0a19f6f2",
    "content": "import json\nfrom typing import Dict, List, Optional\n\nclass PersonalityManager:\n    \"\"\"Manages AI personalities via JSON config.\"\"\"\n\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.personalities: List[Dict[str, str]] = self.load_personalities()\n        self.current_personality: Optional[str] = \"default\"  # Default\n\n    def load_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"Load personalities from JSON; auto-create if missing.\"\"\"\n        default = [{\"name\": \"default\", \"description\": \"Helpful assistant\", \"system_prompt\": \"You are a helpful AI assistant.\"}]\n        default_gui = {\n            \"gui_enabled\": True,\n            \"wake_word\": \"Jarvis\",\n            \"overlay_opacity\": 0.8,\n            \"font_size\": 16\n        }\n        try:\n            with open(self.config_file, 'r') as f:\n                data = json.load(f)\n                if \"personalities\" not in data:\n                    data[\"personalities\"] = default\n                if \"gui_enabled\" not in data:\n                    data.update(default_gui)\n                    self.save_personalities(data[\"personalities\"])  # Save with defaults\n                \n                return data[\"personalities\"]\n        except FileNotFoundError:\n            self.save_personalities(default)\n            return default\n        except json.JSONDecodeError:\n            print(\"[yellow]Invalid config. Resetting to default.[/]\")\n            self.save_personalities(default)\n            return default\n\n    def save_personalities(self, personalities: List[Dict[str, str]]) -> None:\n        \"\"\"Save with GUI config.\"\"\"\n        data = {\"personalities\": personalities}\n        data.update({\"gui_enabled\": True, \"wake_word\": \"Jarvis\", \"overlay_opacity\": 0.8, \"font_size\": 16})  # Defaults\n        with open(self.config_file, 'w') as f:\n            json.dump(data, f, indent=4)\n\n    def add_personality(self, name: str, description: str, system_prompt: str) -> None:\n        \"\"\"Add a new personality.\"\"\"\n        self.personalities.append({\"name\": name, \"description\": description, \"system_prompt\": system_prompt})\n        self.save_personalities(self.personalities)\n\n    def list_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"List all personalities.\"\"\"\n        return self.personalities\n\n    def set_current_personality(self, name: str) -> bool:\n        \"\"\"Set the current personality.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == name:\n                self.current_personality = name\n                return True\n        return False\n\n    def get_current_personality(self) -> Dict[str, str]:\n        \"\"\"Get the current personality dict.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == self.current_personality:\n                return p\n        return {}  # Fallback",
    "file": "/mnt/ProjectData/omni/personality_manager.py"
  },
  {
    "id": 155,
    "hash": "da963f141c557fe12f1a26374f3e5ff4",
    "content": "# python_ast_adapter.py\n\n\"\"\"\nPythonASTAdapter - Concrete AST adapter for Python using built-in `ast` and `astor`.\n\nThis module implements the ASTAdapter interface specifically for Python,\nleveraging the standard library's `ast` module for parsing and\nmanipulation, and `astor` for code generation.\n\"\"\"\n\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for asttokens (for enhanced partial edits)\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n    # print(\"Warning: asttokens not installed. Partial edits will be limited.\")\n\n\nclass PythonASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for Python source code.\n\n    This adapter uses Python's built-in `ast` module to parse and manipulate\n    the code, and `astor` for code generation and source-to-source transformations.\n    It holds the parsed AST tree and provides methods to interact with it\n    according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the PythonASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The Python source code as a string.\n        \"\"\"\n        # Store source code for diffing and potential asttokens use\n        self.source_code: str = source_code\n        # Will hold the parsed AST tree\n        self.tree: Optional[ast.AST] = None\n        # Will hold a mapping of element names to their AST nodes\n        self.nodes: Dict[str, ast.AST] = {}\n        # asttokens instance for enhanced source mapping (if available)\n        self.atok: Optional[asttokens.ASTTokens] = None\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the Python source code and maps elements.\n\n        Args:\n            source_code: The Python source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid Python syntax.\n        \"\"\"\n        try:\n            self.tree = ast.parse(source_code)\n        except SyntaxError as e:\n            raise ValueError(f\"Invalid Python syntax: {e}\") from e\n\n        self.nodes = self._map_nodes()\n        if ASTTOKENS_AVAILABLE:\n            try:\n                self.atok = asttokens.ASTTokens(source_code, parse=True)\n            except Exception:\n                # If asttokens fails for any reason, continue without it\n                self.atok = None\n        else:\n            self.atok = None\n\n    def _map_nodes(self) -> Dict[str, ast.AST]:\n        \"\"\"\n        Walks the AST and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their AST nodes.\n        \"\"\"\n        nodes: Dict[str, ast.AST] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        for node in ast.walk(self.tree):\n            # Map functions and classes by name\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                # Use 'not in' to prioritize top-level definitions in case of conflicts\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            # Map assignments by target variable name(s)\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            # Map imports by their alias or original name\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int, line_end: Optional[int] = None) -> Optional[Tuple[int, ast.AST]]:\n        \"\"\"\n        Finds a statement within a body based on line numbers.\n\n        Args:\n            body: The list of AST nodes representing the body.\n            line_start: The starting line number to search for.\n            line_end: The optional ending line number.\n\n        Returns:\n            A tuple of (index, statement node) if found, otherwise None.\n        \"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = getattr(stmt, 'end_lineno', stmt.lineno)\n                    # Check for overlap or containment\n                    if (stmt.lineno <= line_start <= stmt_end) or (stmt.lineno <= line_end <= stmt_end) or \\\n                       (line_start <= stmt.lineno and line_end >= stmt_end):\n                        return (i, stmt)\n                else:\n                    if stmt.lineno == line_start:\n                        return (i, stmt)\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.ImportFrom]]) -> None:\n        \"\"\"\n        Adds new import nodes to the file's AST, typically at the top.\n\n        Args:\n            new_import_nodes: A list of ast.Import or ast.ImportFrom nodes.\n        \"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return # Cannot add imports without a valid module tree\n\n        # Get string representations of existing imports to avoid duplicates\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                try:\n                    existing_imports_str.add(astor.to_source(node).strip())\n                except Exception:\n                    # If astor fails, skip adding to set (might lead to potential duplicate, but safer)\n                    pass\n                last_import_index = i\n\n        # Insert new imports after the last existing import\n        # Reverse them so they are inserted in the correct order\n        for new_import in reversed(new_import_nodes):\n            try:\n                new_import_str = astor.to_source(new_import).strip()\n                if new_import_str not in existing_imports_str:\n                    self.tree.body.insert(last_import_index + 1, new_import)\n                    last_import_index += 1 # Update index for next insertion\n            except Exception:\n                # If we can't generate source, we can't check for duplicates, skip\n                self.tree.body.insert(last_import_index + 1, new_import)\n                last_import_index += 1\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return astor.to_source(node)\n            except Exception:\n                # Handle potential astor issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.__class__.__name__,\n            'line_start': getattr(node, 'lineno', None),\n            'line_end': getattr(node, 'end_lineno', None),\n            'body_items': []\n        }\n\n        if hasattr(node, 'body'):\n            for i, item in enumerate(node.body):\n                item_info = {\n                    'index': i,\n                    'type': item.__class__.__name__,\n                    'line_start': getattr(item, 'lineno', None),\n                    'line_end': getattr(item, 'end_lineno', None)\n                }\n\n                if isinstance(item, ast.Assign) and item.targets:\n                    target = item.targets[0]\n                    if isinstance(target, ast.Name):\n                        item_info['assigns'] = target.id\n                elif isinstance(item, (ast.If, ast.While, ast.For)):\n                    item_info['has_body'] = bool(getattr(item, 'body', None))\n                elif isinstance(item, ast.Return):\n                    item_info['returns'] = True\n\n                structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        if not self.atok:\n            return None # asttokens is required for precise original source retrieval\n\n        node = self.nodes.get(element_name)\n        if not node or not hasattr(node, 'body'):\n            return None\n\n        statements = []\n        for stmt in node.body:\n            if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                 # Check for overlap or containment of the statement within the requested range\n                stmt_start = stmt.lineno\n                stmt_end = stmt.end_lineno\n                if (stmt_start >= line_start and stmt_end <= line_end) or \\\n                   (stmt_start <= line_end and stmt_end >= line_start): # Overlap\n                    statements.append(stmt)\n\n        if not statements:\n            return None\n\n        # Use asttokens to get the original source text for accuracy\n        try:\n            # Combine text ranges of the found statements\n            combined_text = \"\"\n            last_end_pos = None\n            for stmt in sorted(statements, key=lambda s: s.lineno):\n                # Get the text range for the statement\n                stmt_text = self.atok.get_text_range(stmt)\n                if last_end_pos is not None and stmt_text[0] > last_end_pos:\n                     # Add the original whitespace/newlines between statements\n                    combined_text += self.source_code[last_end_pos:stmt_text[0]]\n                combined_text += self.atok.get_text(stmt)\n                last_end_pos = stmt_text[1]\n            return combined_text.strip()\n        except Exception:\n            # Fallback if asttokens text retrieval fails\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in statements)\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except SyntaxError:\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body: # Ensure there's actual code body to replace with\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # Walk the tree to find the parent node containing the element to replace\n        for parent_node in ast.walk(self.tree):\n            if hasattr(parent_node, 'body') and isinstance(parent_node.body, list):\n                try:\n                    old_node = self.nodes[element_name]\n                    idx = parent_node.body.index(old_node)\n                    # Remove the old node\n                    parent_node.body.pop(idx)\n                    # Insert the new nodes\n                    for i, new_node in enumerate(new_code_body):\n                        parent_node.body.insert(idx + i, new_node)\n\n                    # Update the nodes map: remove old, add new top-level definitions\n                    del self.nodes[element_name]\n                    for n in new_code_body:\n                        if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                            self.nodes[n.name] = n\n                    return True\n                except (ValueError, KeyError):\n                    # ValueError from index(), KeyError from accessing self.nodes\n                    continue\n        return False # Element not found in any body\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n             return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except (SyntaxError, IndexError):\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body:\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # --- Determine insertion index ---\n\n        # Find the `if __name__ == \"__main__\":` block index\n        main_block_idx = -1\n        for i, node in enumerate(self.tree.body):\n            if (isinstance(node, ast.If) and\n                isinstance(getattr(node, 'test', None), ast.Compare) and\n                isinstance(getattr(node.test, 'left', None), ast.Name) and\n                node.test.left.id == '__name__' and\n                len(getattr(node.test, 'ops', [])) == 1 and isinstance(node.test.ops[0], ast.Eq) and\n                len(getattr(node.test, 'comparators', [])) == 1):\n\n                comp = node.test.comparators[0]\n                # Check for both ast.Constant ('__main__') and older ast.Str ('__main__')\n                if ((isinstance(comp, ast.Constant) and comp.value == '__main__') or\n                    (isinstance(comp, ast.Str) and comp.s == '__main__')): # type: ignore\n                    main_block_idx = i\n                    break\n\n        insertion_index = -1\n        if anchor_name:\n            # If anchor is specified, find its index\n            if anchor_name not in self.nodes:\n                return False\n            anchor_node = self.nodes[anchor_name]\n            try:\n                anchor_idx = self.tree.body.index(anchor_node)\n                proposed_index = anchor_idx if before else anchor_idx + 1\n                # Prefer to stay before the main block if possible\n                if main_block_idx != -1:\n                    insertion_index = min(proposed_index, main_block_idx)\n                else:\n                    insertion_index = proposed_index\n            except ValueError:\n                return False # Anchor node not found in tree body\n        elif main_block_idx != -1:\n            # If no anchor, but there's a main block, insert before it\n            insertion_index = main_block_idx\n        # If no anchor and no main block, insertion_index remains -1\n\n        # --- Perform the insertion ---\n        if insertion_index == -1:\n            # Append to the end\n            self.tree.body.extend(new_code_body)\n        else:\n            # Insert at the calculated position\n            for i, new_node in enumerate(new_code_body):\n                self.tree.body.insert(insertion_index + i, new_node)\n\n        # Update the nodes map with any new top-level definitions\n        for node in new_code_body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                self.nodes[node.name] = node # This might overwrite if names clash\n\n        return True\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return False\n\n        deleted = False\n        if element_name in self.nodes:\n            node_to_delete = self.nodes[element_name]\n            # Walk the tree to find the parent node containing the element\n            for node in ast.walk(self.tree):\n                if hasattr(node, 'body') and isinstance(node.body, list):\n                    try:\n                        node.body.remove(node_to_delete)\n                        deleted = True\n                        break # Assume element appears only once at top level\n                    except ValueError:\n                        continue # This parent doesn't contain the node\n            if deleted:\n                del self.nodes[element_name]\n                # Although nodes map is passed by ref in base __init__, we should call _map_nodes\n                # to ensure consistency after a direct tree modification.\n                self.nodes = self._map_nodes()\n                return True\n\n        # If not found by node reference, try to find by name pattern matching (vars/imports)\n        new_body = []\n        for node in self.tree.body:\n            if isinstance(node, ast.Assign):\n                match = False\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id == element_name:\n                        match = True\n                        deleted = True\n                        break\n                if not match: # Keep the node if it doesn't match\n                    new_body.append(node)\n            elif isinstance(node, ast.Import):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                    # Keep the node if none of its aliases match (should theoretically be the same as above)\n                     new_body.append(node)\n                else:\n                    deleted = True # The import node is being completely removed\n            elif isinstance(node, ast.ImportFrom):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                     new_body.append(node)\n                else:\n                    deleted = True\n            else:\n                new_body.append(node)\n\n        if deleted:\n            self.tree.body = new_body\n            # Remap nodes after structural changes\n            self.nodes = self._map_nodes()\n\n        return deleted\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        if element_name not in self.nodes:\n            return False\n\n        node = self.nodes[element_name]\n        # Ensure the node has a body to modify\n        if not hasattr(node, 'body') or not isinstance(node.body, list):\n            return False\n\n        # Parse the new code to get AST nodes for the replacement\n        try:\n             # Heuristic: If new code looks like a def/class, extract its body.\n             # Otherwise, treat as standalone statements.\n            if new_code.strip().startswith(('def ', 'class ', 'async def ')):\n                # Parse as if it's a module with a single function/class\n                temp_module = ast.parse(new_code)\n                if temp_module.body and hasattr(temp_module.body[0], 'body'):\n                    new_statements = temp_module.body[0].body # Get the inner body\n                else:\n                    return False # Malformed attempt to define a func/class\n            else:\n                # Parse as a module and take its body\n                new_ast_module = ast.parse(new_code)\n                new_statements = new_ast_module.body\n        except SyntaxError:\n            return False # Invalid new code\n\n        if not new_statements: # Nothing to insert\n            return False\n\n        # --- Determine what to replace based on parameters ---\n        if statement_index is not None:\n            # Replace by statement index\n            if 0 <= statement_index < len(node.body):\n                # Replace the single statement at index with the list of new statements\n                node.body[statement_index:statement_index+1] = new_statements\n                return True\n        elif line_start is not None:\n            # Replace by line number(s)\n            result = self._find_statement_in_body(node.body, line_start, line_end)\n            if result:\n                idx, _ = result\n                if line_end:\n                    # Find the last statement within the specified range to replace multiple\n                    end_idx = idx\n                    # Iterate from the found index forward\n                    for i in range(idx, len(node.body)):\n                        stmt = node.body[i]\n                        stmt_s_ln = getattr(stmt, 'lineno', None)\n                        stmt_e_ln = getattr(stmt, 'end_lineno', stmt_s_ln)\n                        if stmt_s_ln is not None and stmt_e_ln is not None:\n                            # Check if the statement ends within the range or starts within the range\n                            # This handles overlapping ranges correctly\n                             if stmt_e_ln <= line_end or stmt_s_ln <= line_end:\n                                 end_idx = i\n                             else:\n                                 break # Statement is past the end range\n                        else:\n                            break # Can't determine statement range\n                    node.body[idx:end_idx+1] = new_statements\n                else:\n                    # line_end not specified, only replace the statement at line_start\n                    node.body[idx:idx+1] = new_statements\n                return True\n\n        # If none of the conditions were met to perform a replacement\n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        if self.tree:\n            try:\n                return astor.to_source(self.tree)\n            except Exception as e:\n                 # Fallback error handling, should ideally not happen if tree is valid\n                 return f\"# Error generating source: {e}\\n{self.source_code}\"\n        else:\n            # If somehow the tree is None, return the original source\n            return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        # Ensure line endings are consistent for diffing, keepends=True preserves them\n        # If source_code had different line endings, this might still cause issues,\n        # but this is a standard approach.\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/python_ast_adapter.py"
  },
  {
    "id": 156,
    "hash": "2914352eefed9d60de098e021dd79b67",
    "content": "import os\nimport sys\nimport argparse\nfrom typing import List\nfrom rag_manager import RAGManager\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\ndef create_sample_data() ->List[str]:\n    \"\"\"Create sample documents for the RAG example.\"\"\"\n    return [\n        'RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with language generation.'\n        ,\n        'The RAG model retrieves relevant documents from a knowledge base and uses them to generate more accurate responses.'\n        ,\n        'FAISS is a library for efficient similarity search and clustering of dense vectors, often used in RAG systems.'\n        ,\n        'Sentence transformers are used to create embeddings for documents and queries in RAG systems.'\n        ,\n        'Retrieval-Augmented Generation improves language models by allowing them to access external knowledge sources.'\n        ,\n        'In RAG systems, documents are indexed and searchable by their semantic embeddings rather than just keywords.'\n        ,\n        'Python is a great language for implementing RAG systems due to libraries like sentence-transformers and faiss.'\n        ,\n        'The retrieval component of RAG is crucial for finding relevant information before generation.'\n        ]\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_cli_example.py"
  },
  {
    "id": 157,
    "hash": "c27b11d2eaa8e13cdf8e698417efb75e",
    "content": "import os\nimport sys\nfrom typing import List, Dict, Tuple\n\"\"\"\nExample script demonstrating RAG (Retrieval-Augmented Generation) usage.\n\nThis script shows how to use a simple RAG implementation to answer questions\nbased on a given context or knowledge base.\n\"\"\"\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\nclass SimpleRAG:\n    \"\"\"A simple RAG implementation for demonstration purposes.\"\"\"\n\n    def __init__(self, knowledge_base: List[str]):\n        \"\"\"\n        Initialize the RAG with a knowledge base.\n        \n        Args:\n            knowledge_base: A list of strings representing the knowledge base.\n        \"\"\"\n        self.knowledge_base = knowledge_base\n\n    def retrieve(self, query: str, top_k: int=3) ->List[str]:\n        \"\"\"\n        Retrieve relevant documents from the knowledge base.\n        \n        This is a simplified implementation using keyword matching.\n        In a real implementation, you would use embeddings and vector search.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            A list of relevant documents.\n        \"\"\"\n        query_words = set(query.lower().split())\n        scores = []\n        for doc in self.knowledge_base:\n            doc_words = set(doc.lower().split())\n            score = len(query_words.intersection(doc_words))\n            scores.append((score, doc))\n        scores.sort(reverse=True)\n        return [doc for score, doc in scores[:top_k]]\n\n    def generate(self, query: str, retrieved_docs: List[str]) ->str:\n        \"\"\"\n        Generate an answer based on the query and retrieved documents.\n        \n        In a real implementation, this would use an LLM to generate the response.\n        For this example, we'll create a simple template-based response.\n        \n        Args:\n            query: The query string.\n            retrieved_docs: The retrieved documents.\n            \n        Returns:\n            A generated answer.\n        \"\"\"\n        context = '\\n'.join(retrieved_docs)\n        prompt = f\"\"\"\n        Context information:\n        {context}\n        \n        Question: {query}\n        \n        Based on the context provided above, please answer the question.\n        If the context doesn't contain relevant information, say so.\n        \"\"\"\n        return self._simple_response_generator(query, retrieved_docs)\n\n    def _simple_response_generator(self, query: str, retrieved_docs: List[str]\n        ) ->str:\n        \"\"\"\n        A simple response generator for demonstration.\n        \"\"\"\n        for doc in retrieved_docs:\n            if 'example' in doc.lower():\n                return (\n                    f'Based on the context provided, I found information about examples. {query} relates to the examples in the knowledge base.'\n                    )\n        return (\n            f\"I couldn't find specific information about '{query}' in the provided context. Please provide more details or check the knowledge base.\"\n            )\n\n    def query(self, query: str, top_k: int=3) ->str:\n        \"\"\"\n        Process a query through the full RAG pipeline.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            The generated answer.\n        \"\"\"\n        retrieved_docs = self.retrieve(query, top_k)\n        answer = self.generate(query, retrieved_docs)\n        return answer\n\n\ndef main():\n    \"\"\"Main function demonstrating the RAG implementation.\"\"\"\n    knowledge_base = ['This is an example document about machine learning.',\n        'Natural language processing is a subfield of artificial intelligence.'\n        , 'Python is a popular programming language for data science.',\n        'The quick brown fox jumps over the lazy dog.',\n        'RAG stands for Retrieval-Augmented Generation.',\n        'Vector databases are used for similarity search in RAG systems.',\n        'Transformers are a type of neural network architecture.',\n        'This example shows how to implement a simple RAG system.']\n    rag = SimpleRAG(knowledge_base)\n    queries = ['What is RAG?', 'How is Python used in data science?',\n        'Tell me about machine learning']\n    print('Simple RAG Example')\n    print('=' * 50)\n    for query in queries:\n        print(f'\\nQuery: {query}')\n        answer = rag.query(query)\n        print(f'Answer: {answer}')\n        print('-' * 30)\n    print(\"\\nInteractive Mode (type 'quit' to exit):\")\n    while True:\n        try:\n            user_query = input('\\nEnter your question: ').strip()\n            if user_query.lower() in ['quit', 'exit', 'q']:\n                break\n            if user_query:\n                answer = rag.query(user_query)\n                print(f'Answer: {answer}')\n        except KeyboardInterrupt:\n            print('\\nGoodbye!')\n            break\n        except EOFError:\n            break\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_example.py"
  },
  {
    "id": 158,
    "hash": "f151986bf2efa7602242590a357fab83",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n    Initialize the RAG manager.\n\n    Args:\n        model_name: Name of the sentence transformer model to use\n        index_path: Path to save/load the FAISS index\n    \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the RAG manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n",
    "file": "/mnt/ProjectData/omni/rag_manager.py"
  },
  {
    "id": 159,
    "hash": "f59a27842056dbb0dc95d0f29c1c5de8",
    "content": "Hello! I'm OmniForge, an AI coding assistant. I can help you scan, understand, and refactor your codebase using local (Ollama) or remote (OpenRouter) LLMs.\n\nI see you've opened the OmniForge project directory. Some key things I can help with:\n\n1. **Project Analysis**: I can look at your files to understand the structure\n2. **Code Editing**: I can make precise edits to functions/classes using AST-based transformations\n3. **Refactoring**: I can perform multi-file architectural changes with a plan\n4. **File Creation**: I can generate new files based on instructions\n\nFor example:\n- `look .` to scan the project\n- `edit code_editor.py \"add docstrings to main methods\"`\n- `refactor \"extract git operations into a separate module\"`\n- `create new_module.py \"implement a simple HTTP client\"`\n\nWhat would you like to do with this project?",
    "file": "/mnt/ProjectData/omni/requirements.txt"
  },
  {
    "id": 160,
    "hash": "629e0568a11413444d2a924d1b912f05",
    "content": "from ast_adapter import ASTAdapter\nfrom typing import List, Optional, Dict, Any\n\"\"\"\nTextAdapter - Concrete AST adapter for plain text files.\n\nThis module implements the ASTAdapter interface specifically for plain text files,\ntreating the entire file content as a single element.\n\"\"\"\n\n\nclass TextAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for plain text files.\n\n    This adapter treats the entire text file content as a single element\n    that can be manipulated using the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the TextAdapter with the source code.\n\n        Args:\n            source_code: The text content as a string.\n        \"\"\"\n        self.source_code: str = source_code\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) ->None:\n        \"\"\"\n        Creates a simple mapping for the text content.\n\n        Args:\n            source_code: The text content string.\n        \"\"\"\n        self.nodes = {'content': source_code}\n\n    def list_elements(self) ->List[str]:\n        \"\"\"Lists the names of the main elements (just 'content' for text files).\"\"\"\n        return ['content']\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        if element_name == 'content':\n            return self.source_code\n        return None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        if element_name == 'content':\n            return {'name': element_name, 'type': 'TextContent',\n                'line_start': 1, 'line_end': len(self.source_code.\n                splitlines()), 'body_items': []}\n        return None\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        if element_name != 'content':\n            return None\n        lines = self.source_code.splitlines()\n        if 1 <= line_start <= len(lines) and 1 <= line_end <= len(lines\n            ) and line_start <= line_end:\n            return '\\n'.join(lines[line_start - 1:line_end])\n        return None\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name == 'content':\n            self.source_code = new_code\n            self._parse_and_map(new_code)\n            return True\n        return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"Adds a new element to the file (appends to content for text files).\"\"\"\n        if anchor_name is None or anchor_name == 'content':\n            if before:\n                self.source_code = new_code + self.source_code\n            else:\n                self.source_code = self.source_code + new_code\n            self._parse_and_map(self.source_code)\n            return True\n        return False\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if element_name == 'content':\n            self.source_code = ''\n            self._parse_and_map('')\n            return True\n        return False\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        if element_name != 'content':\n            return False\n        lines = self.source_code.splitlines()\n        if line_start is not None and 1 <= line_start <= len(lines):\n            start_idx = line_start - 1\n            end_idx = start_idx if line_end is None else min(line_end - 1, \n                len(lines) - 1)\n            new_lines = new_code.splitlines() if new_code else []\n            lines[start_idx:end_idx + 1] = new_lines\n            self.source_code = '\\n'.join(lines)\n            self._parse_and_map(self.source_code)\n            return True\n        return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"Returns the modified source code.\"\"\"\n        return self.source_code\n",
    "file": "/mnt/ProjectData/omni/text_adapter.py"
  },
  {
    "id": 161,
    "hash": "4b879b8e64b677ec78d27f19b384623a",
    "content": "from typing import List\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.text import Text\nfrom rich.status import Status\nfrom rich import box\nfrom contextlib import contextmanager\nfrom rich.markup import escape\nimport gc\n\ntry:\n    from prompt_toolkit import prompt\n    from prompt_toolkit.completion import WordCompleter\n    from prompt_toolkit.history import InMemoryHistory\n    from prompt_toolkit.styles import Style\nexcept ImportError:\n    print('[yellow]prompt_toolkit not installed. Falling back to basic input.[/]')\n    prompt = input\n\n\nclass UIManager:\n    \"\"\"Manages interactive text-based UI with rich for display and prompt_toolkit for input.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initializes the UI manager with a rich console and prompt_toolkit components.\"\"\"\n        self.console = Console()\n        self.history = InMemoryHistory()\n        self.completer = WordCompleter([\n            'send', 'look', 'look_all', 'create', 'edit', 'refactor', 'commit',\n            'save', 'list', 'run', 'history', 'memory', 'backend', 'models',\n            'set', 'personality', 'help', 'exit'\n        ], ignore_case=True)\n        self.prompt_style = Style.from_dict({'prompt': 'bold cyan'})\n\n    def get_user_input(self, prompt_text: str) -> str:\n        try:\n            return prompt(prompt_text, history=self.history, completer=self.completer, style=self.prompt_style)\n        except Exception:\n            self.console.print('[yellow]Warning: Falling back to basic input.[/]')\n            return input(prompt_text)\n\n    def display_history(self, history_text: str) -> None:\n        if not history_text.strip():\n            self.console.print('[dim]No history yet.[/]')\n            return\n        \n        lines = history_text.split('\\n')\n        colored_text = Text()\n        for line in lines:\n            if line.startswith('User:'):\n                colored_text.append(line + '\\n', style='bold blue')\n            elif line.startswith('AI:'):\n                colored_text.append(line + '\\n', style='bold green')\n            elif line.startswith('File '):\n                colored_text.append(line + '\\n', style='yellow')\n            else:\n                colored_text.append(line + '\\n')\n        \n        self.console.print(Panel(\n            colored_text, \n            title='[bold magenta]Chat History[/]', \n            border_style='magenta', \n            expand=False, \n            box=box.ROUNDED\n        ))\n\n    @contextmanager\n    def show_spinner(self, message: str):\n        \"\"\"\n        Context manager that displays a spinner with the given message.\n        Handles Rich LiveError by cleaning up stuck live displays and \n        ensuring proper cleanup on exceptions.\n        \n        Usage:\n            with ui_manager.show_spinner(\"Loading...\"):\n                # do work here\n        \"\"\"\n        # Initialize spinner state if not exists\n        if not hasattr(self, '_spinner_active'):\n            self._spinner_active = False\n        \n        # If spinner is already active, just yield without additional output\n        if self._spinner_active:\n            try:\n                yield\n            except Exception as e:\n                raise e\n            return\n        \n        # Clean up any stuck Rich live displays before starting\n        self._cleanup_stuck_rich_displays()\n        \n        # Mark spinner as active\n        self._spinner_active = True\n        status_context = None\n        \n        try:\n            # Try to use rich status, but with fallback\n            try:\n                status_context = self.console.status(f'[bold yellow]{message}[/]')\n                status_context.__enter__()\n            except Exception:\n                # If rich.status fails, fallback to static print\n                status_context = None\n                self.console.print(f'[bold yellow]{message}[/]')\n            \n            yield\n            \n        except Exception as e:\n            # Re-raise actual work errors\n            raise e\n            \n        finally:\n            # Always cleanup spinner state and rich display\n            self._spinner_active = False\n            if status_context is not None:\n                try:\n                    status_context.__exit__(None, None, None)\n                except:\n                    pass  # Suppress cleanup errors\n            \n            # Force cleanup any remaining rich displays\n            self._cleanup_stuck_rich_displays()\n\n    def _cleanup_stuck_rich_displays(self):\n        \"\"\"\n        Clean up stuck Rich live displays that prevent new ones from starting.\n        Based on solution from: https://github.com/DLR-RM/stable-baselines3/issues/1645\n        \"\"\"\n        try:\n            # Method 1: Reset console live display if exists\n            if hasattr(self.console, '_live') and self.console._live is not None:\n                try:\n                    self.console._live.stop()\n                    self.console._live = None\n                except:\n                    pass\n            \n            # Method 2: Find and close stuck rich/tqdm objects using garbage collection\n            rich_objects = [obj for obj in gc.get_objects() \n                        if hasattr(obj, '__class__') and \n                        ('live' in type(obj).__name__.lower() or \n                            'progress' in type(obj).__name__.lower() or\n                            'status' in type(obj).__name__.lower()) and\n                        hasattr(obj, 'stop')]\n            \n            for rich_obj in rich_objects:\n                try:\n                    if hasattr(rich_obj, 'stop'):\n                        rich_obj.stop()\n                    elif hasattr(rich_obj, 'close'):\n                        rich_obj.close()\n                except:\n                    pass  # Suppress cleanup errors\n                    \n        except:\n            pass  # Suppress all cleanup errors to avoid breaking the main flow\n\n    def display_status_panel(self, personality: str, backend: str, model: str, msg_count: int, look_count: int) -> None:\n        status_text = (\n            f'[bold]Personality:[/] [green]{personality}[/] | '\n            f'[bold]Backend:[/] [green]{backend}[/] | '\n            f'[bold]Model:[/] [green]{model}[/] | '\n            f'[bold]Memory:[/] {msg_count} messages, {look_count} files'\n        )\n        self.console.print(Panel(\n            status_text, \n            title='[bold cyan]Status[/]', \n            border_style='cyan', \n            expand=False, \n            box=box.MINIMAL\n        ))\n\n    def show_success(self, message: str) -> None:\n        self.console.print(f'[green]\u2705 {message}[/]')\n\n    def show_error(self, message: str) -> None:\n        \"\"\"\n        Displays an error message, escaping any markup in the message.\n        \"\"\"\n        safe_message = escape(str(message))\n        self.console.print(f'[red]\u274c {safe_message}[/]')",
    "file": "/mnt/ProjectData/omni/ui_manager.py"
  },
  {
    "id": 162,
    "hash": "dbd143839288b400cafdedb655258434",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n",
    "file": "/mnt/ProjectData/omni/vectordb_manager.py"
  },
  {
    "id": 163,
    "hash": "47a91d3ac272236378053b23515fc9b0",
    "content": "import tkinter as tk\nfrom tkinter import ttk\nfrom time import strftime\n\n\ndef update_time():\n    current_time = strftime('%H:%M:%S %p\\n%Y-%m-%d')\n    time_label.config(text=current_time)\n    time_label.after(1000, update_time)\n\n\ndef center_window(root):\n    root.update_idletasks()\n    screen_width = root.winfo_screenwidth()\n    screen_height = root.winfo_screenheight()\n    window_width = root.winfo_width() + 4\n    window_height = root.winfo_height() + 4\n    x = (screen_width - window_width) // 2\n    y = (screen_height - window_height) // 2\n    root.geometry(f'{window_width}x{window_height}+{x}+{y}')\n\n\ndef create_3d_border(parent):\n    border_frame = tk.Frame(parent, bg='#c0c0c0')\n    border_frame.pack(padx=2, pady=2, expand=True, fill=tk.BOTH)\n    tk.Frame(border_frame, height=1, bg='#808080').pack(side=tk.TOP, fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#808080').pack(side=tk.LEFT, fill=tk.Y)\n    tk.Frame(border_frame, height=1, bg='#ffffff').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#ffffff').pack(side=tk.RIGHT, fill=tk.Y\n        )\n    inner_container = tk.Frame(border_frame, bg='#c0c0c0')\n    inner_container.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1\n        )\n    tk.Frame(inner_container, height=1, bg='#ffffff').pack(side=tk.TOP,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#ffffff').pack(side=tk.LEFT,\n        fill=tk.Y)\n    tk.Frame(inner_container, height=1, bg='#808080').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#808080').pack(side=tk.RIGHT,\n        fill=tk.Y)\n    content_area = tk.Frame(inner_container, bg='#c0c0c0')\n    content_area.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1)\n    return content_area\n\n\nroot = tk.Tk()\nroot.title('Current Time')\nroot.configure(bg='#008080')\nmain_frame = create_3d_border(root)\nmain_frame.config(padx=4, pady=4)\ninner_frame = tk.Frame(main_frame, bg='#c0c0c0', padx=8, pady=8)\ninner_frame.pack()\ntime_label = tk.Label(inner_frame, bg='#c0c0c0', fg='#000000', font=(\n    'MS Sans Serif', 18, 'bold'), padx=12, pady=8)\ntime_label.pack()\nroot.after(100, lambda : center_window(root))\nupdate_time()\nroot.mainloop()\n",
    "file": "/mnt/ProjectData/omni/omni_saves/watch.py"
  },
  {
    "id": 164,
    "hash": "6774a805052356775d8c4f0367253dc1",
    "content": "# OmniForge\n\n**Project\u2011Aware AI CLI for AST\u2011Precise Edits (\u201cScalpel\u201d) & Multi\u2011File Refactors (\u201cBlueprint\u201d).**\n\n> *OmniForge (a.k.a. the \"DualForge\" engine) helps you **scan**, **understand**, and **reforge** your codebase with local (Ollama) or remote (OpenRouter) LLMs. It is an independent open\u2011source project not affiliated with other products using the name \u201cOmni.\u201d*\n\n---\n\n## Core Features\n\n* **Project\u2011Aware Refactoring (`refactor`)**: Provide a high\u2011level goal (e.g. *\u201cmove all DB logic into `db/` and centralize config\u201d*). OmniForge generates & shows a multi\u2011step plan before touching files.\n* **Surgical AST Editing (`edit`)**: Target a single function/class. OmniForge parses the file, locates the node, applies a structural change, and shows you a diff.\n* **Context Ingestion (`look`)**: Scan a directory or single file to build a project manifest (paths + hashes + size + language hints) that guides subsequent edits/refactors.\n* **Dual Backends**: Seamlessly switch between **`openrouter`** (remote models) and **`ollama`** (local models) via `backend <name>`.\n* **Interactive Model Picker (`models`)**: Filter by source/provider and select from an up\u2011to\u2011date model list inside the terminal.\n* **Session Memory & History**: `history` shows conversation / action log; `memory clear` resets the working context.\n* **Safe AST\u2011Based Transformations**: Reduces syntax breakage vs naive text substitution. New imports / dependencies are auto\u2011inserted when possible.\n* **Dry\u2011Run Transparency**: Every multi\u2011file refactor presents (1) a generated plan, (2) per\u2011file proposed changes, (3) a consolidated diff for confirmation.\n\n---\n\n## Conceptual Modes\n\n| Mode          | Command(s) | Purpose                                              | Analogy              |\n| ------------- | ---------- | ---------------------------------------------------- | -------------------- |\n| **Survey**    | `look`     | Index project / ingest context                       | Mapping the terrain  |\n| **Scalpel**   | `edit`     | Precise single\u2011file structural change                | Surgery              |\n| **Blueprint** | `refactor` | Multi\u2011file architectural transformation              | Architecture         |\n| **Cast**      | `run`      | Execute last generated runnable block (if supported) | Forging the artifact |\n\nYou can reference these terms in docs, help screens, or UI banners for clarity.\n\n---\n\n## Installation\n\n> Requires Python 3.10+ and a Unix\u2011like shell.\n\n```bash\n# 1. Clone\ngit clone https://github.com/Snawyyy/omniforge.git\ncd omniforge\n\n# 2. (Optional) Inspect requirements\ncat requirements.txt\n\n# 3. Run installer (creates venv + installs deps)\nchmod +x install.sh\n./install.sh\n\n# 4. Activate environment\nsource venv/bin/activate\n\n# 5. Run CLI (interactive shell)\n./omni        # or: python omni.py\n```\n\nIf you later package it, expose a script entry point named `omni` while keeping an internal package name like `omniforge` to avoid namespace collisions.\n\n---\n\n## Configuration\n\nCreate a `.env` file to supply secrets (e.g. OpenRouter API key).\n\n```bash\ncp .env.example .env   # if example exists; otherwise create manually\n```\n\nIn `.env`:\n\n```dotenv\nOPENROUTER_API_KEY=\"sk-or-...\"\n```\n\n(Do **not** commit real keys. Ensure `.env` is listed in `.gitignore`.)\n\nOptional future keys can include local model paths, default model name, or feature flags.\n\n---\n\n## Quick Start Workflow\n\n```text\n> look .\n(Index project: builds manifest)\n\n> refactor \"extract hardcoded API URL to config/settings.py and update all imports\"\n(Shows plan \u2192 ask for confirmation)\n\n> edit src/utils.py \"add a doctring for calculate_average explaining parameters and return value\"\n(Shows targeted diff \u2192 confirm or abort)\n\n> models openai\n(Choose a different model)\n\n> backend ollama\n(Switch to local inference)\n```\n\n---\n\n## Command Reference\n\n| Command               | Example                                         | Description                                                                 |\n| --------------------- | ----------------------------------------------- | --------------------------------------------------------------------------- |\n| `look <path>`         | `look .`                                        | Scan directory or file; update project context manifest.                    |\n| `edit <file> \"instr\"` | `edit utils.py \"add error handling\"`            | AST\u2011guided targeted modification of a single file element or whole file.    |\n| `refactor \"goal\"`     | `refactor \"split monolith api.py into package\"` | High\u2011level multi\u2011file transformation with plan + diff review.               |\n| `send <prompt>`       | `send summarize module layout`                  | Generic prompt to current model with current context summary.               |\n| `models [filter]`     | `models google`                                 | Interactive model selector (filter by provider/source).                     |\n| `backend <name>`      | `backend ollama`                                | Switch between `openrouter` / `ollama`.                                     |\n| `history`             | `history`                                       | Display session interaction log.                                            |\n| `memory clear`        | `memory clear`                                  | Clear internal AI context memory (project manifest may persist separately). |\n| `run`                 | `run`                                           | Execute the last generated runnable code snippet (if feature implemented).  |\n| `help`                | `help`                                          | Show help / usage summary.                                                  |\n\n---\n\n## How It Works (High Level)\n\n1. **Ingestion (`look`)**: Walks the directory (configurable ignore patterns), captures file metadata (path, size, language), optionally caches abbreviated content or hashes.\n2. **Prompt Construction**: Merges user instruction + contextual manifest + focused snippets (for `edit`) or diff summaries (for `refactor`).\n3. **AST Layer** (Python initially): Parses target file(s); identifies node(s) (function/class) based on name + heuristic similarity; applies transformations guided by model output (structured hints or patch templates) rather than raw blind overwrite.\n4. **Plan (Refactor)**: Model proposes steps (CREATE / MODIFY / RENAME / DELETE). User approves. Each step executed & validated; errors surface early.\n5. **Diff Presentation**: A unified colorized diff shown; user confirms to write changes.\n6. **Safety**: If AST parse fails or patch violates syntax, changes abort (or fallback to text patch with warning).\n\n---\n\n## Roadmap (Indicative)\n\n| Milestone | Features                                                                    |\n| --------- | --------------------------------------------------------------------------- |\n| 0.1.0     | Core commands (`look`, `edit`, `refactor`, `models`, `backend`, `history`). |\n| 0.2.0     | Config file (`omniforge.toml`), ignore patterns, improved diff viewer.      |\n| 0.3.0     | Multi-language AST adapters (JS/TS via `tree-sitter`).                      |\n| 0.4.0     | Test impact analysis & auto test file generation.                           |\n| 0.5.0     | Refactor preview metrics (LOC touched, complexity delta).                   |\n| 0.6.0     | Inline security / lint feedback integration.                                |\n| 0.7.0     | Partial GUI / TUI dashboard mode.                                           |\n\n(Adjust roadmap as project evolves.)\n\n---\n\n## Developer Notes\n\n* Keep `.env`, virtual environment dirs (`venv/`), caches, large artifacts in `.gitignore`.\n* Consider adding a thin `omniforge/` package directory now for future PyPI packaging.\n* Implement a pluggable *Model Adapter* layer to abstract provider differences (OpenRouter vs Ollama).\n* Logging: Provide `--verbose` or `OMNIFORGE_DEBUG=1` env flag.\n* Add a JSONL log of commands & decisions to enable replay or supervised improvements.\n\n---\n\n## Contributing\n\n1. Fork & create a feature branch: `git checkout -b feat/<short-name>`\n2. Run and add tests (if/when test harness exists in `tests/`).\n3. Ensure style/format (e.g. `ruff`, `black`) passes.\n4. Submit pull request with concise description + before/after examples.\n\nIssues / discussions welcome for architecture proposals, AST adapters, or performance improvements.\n\n---\n\n## License\n\nReleased under the **MIT License**. See `LICENSE` file for full text.\n\n---\n\n## Name & Trademark Disclaimer\n\n\u201cOmniForge\u201d is an independent open-source tool and not affiliated with The Omni Group or any other third-party products using similar names. If a future naming conflict arises, a soft alias strategy (keeping the `omni` CLI) will preserve user workflows.\n\n---\n\n## Example Session (Illustrative)\n\n```text\n$ ./omni\nOMNIFORGE 0.1.0  (backend=openrouter | model=anthropic/claude-3)\nType 'help' or 'look .' to begin.\n\n> look .\nIndexed 42 files (Python=30, Markdown=5, JSON=7)\n\n> refactor \"centralize logging into logging_util.py and update imports\"\nPlan:\n  [1] CREATE logging_util.py\n  [2] MODIFY app.py (replace inline log setup)\n  [3] MODIFY worker.py (import logging_util)\nProceed? (y/n) y\n... (diff preview) ...\nApply changes? (y/n) y\nRefactor complete in 3.2s.\n\n> edit worker.py \"add retry with exponential backoff to fetch_data\"\nParsed worker.py \u2713\nApplied modification (function: fetch_data)\nDiff shown. Accept? (y/n) y\nSaved.\n```\n\n---\n\n## Philosophy\n\n*The next wave of developer AI goes beyond paste\u2011in prompts.* OmniForge treats your repository as *structured material*, enabling incremental, auditable, and safer evolution rather than opaque code dumps. By combining **context scanning**, **AST precision**, and **human approval loops**, it aims to become a trustworthy co\u2011developer rather than an occasionally helpful code generator.\n\n---\n\n## Feedback / Support\n\nOpen a GitHub Issue for bugs & feature requests. For conceptual discussions (roadmap, design choices), use Discussions.\n\n---\n\nHappy forging!\n",
    "file": "/mnt/ProjectData/omni/README.md"
  },
  {
    "id": 165,
    "hash": "b6c2845489f64b6396aaf85e5fd5909e",
    "content": "from abc import ABC, abstractmethod\nfrom typing import List, Optional, Dict, Any, Union\nfrom typing import List, Optional, Dict\nASTNode = Any\nDiffContent = str\n\n\nclass ASTAdapter(ABC):\n    \"\"\"\n    Abstract base class defining the interface for language-specific AST adapters.\n\n    This interface allows the CodeEditor to interact with the AST/CST of different\n    programming languages in a uniform way. Concrete implementations will handle\n    the specifics of parsing, traversing, and modifying the AST/CST for their\n    respective languages (e.g., Python's `ast`/`astor`, JavaScript's `tree-sitter`).\n\n    The adapter is responsible for holding the parsed tree structure and any\n    necessary metadata for operations.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the adapter by parsing the provided source code.\n\n        Args:\n            source_code: The string content of the source file to be parsed.\n\n        Raises:\n            ValueError: If the source code cannot be parsed due to syntax errors.\n        \"\"\"\n        self.source_code: str = source_code\n        self.tree: Optional[ASTNode] = None\n        self.nodes: Dict[str, ASTNode] = {}\n        self._parse_and_map(source_code)\n\n    @abstractmethod\n    def _parse_and_map(self, source_code: str) ->None:\n        \"\"\"\n        Abstract method to parse the source code and populate `self.tree` and `self.nodes`.\n\n        This is the core method where language-specific parsing logic resides.\n        Implementations should:\n        1. Parse the `source_code` into an AST/CST representation.\n        2. Store the root of this representation in `self.tree`.\n        3. Identify key top-level elements (functions, classes, variables, imports)\n           and map their names to their nodes in `self.nodes`.\n\n        Args:\n            source_code: The string content to parse.\n\n        Raises:\n            ValueError: If the source code cannot be parsed.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_elements(self) ->List[str]:\n        \"\"\"\n        Abstract method to list the names of the main elements found in the code.\n\n        These are typically top-level functions, classes, variable assignments,\n        and imports that the adapter can identify and manipulate.\n\n        Returns:\n            A list of element names (strings).\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"\n        Abstract method to get the source code string for a specific element.\n\n        Args:\n            element_name: The name of the element (function, class, etc.).\n\n        Returns:\n            The source code string for the element, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"\n        Abstract method to get detailed structural information about an element.\n\n        This information can include type, line numbers, body items, etc., useful\n        for aiding the AI in understanding the code's layout.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            A dictionary containing structural details, or None if not found.\n            Example structure:\n            {\n                'name': 'func_name',\n                'type': 'FunctionDef', # or 'ClassDef', etc.\n                'line_start': 10,\n                'line_end': 25,\n                'body_items': [list of internal statement details...]\n            }\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"\n        Abstract method to extract a snippet of code from within an element's body.\n\n        Used for 'partial' edits where only a specific range of lines within\n        a function or class needs to be changed.\n\n        Args:\n            element_name: The name of the element containing the snippet.\n            line_start: The starting line number (1-based, absolute) of the snippet.\n            line_end: The ending line number (inclusive) of the snippet.\n\n        Returns:\n            The source code string for the specified lines within the element, or None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"\n        Abstract method to replace an entire named element.\n\n        This involves finding the old element in the tree and swapping it with\n        the representation of the `new_code`.\n\n        Args:\n            element_name: The name of the element to replace.\n            new_code: The new source code for the element (and potential helpers).\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"\n        Abstract method to add a new block of code (element) to the file.\n\n        This involves parsing the `new_code` and inserting its representation\n        into the tree at an appropriate location (e.g., end of file, near anchor).\n\n        Args:\n            new_code: The source code for the new element(s).\n            anchor_name: Optional name of an existing element to position relative to.\n            before: If True and `anchor_name` is provided, insert before the anchor.\n\n        Returns:\n            True if the element was added successfully, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"\n        Abstract method to delete a named element from the file.\n\n        This involves finding the element in the tree and removing its representation.\n\n        Args:\n            element_name: The name of the element to delete.\n\n        Returns:\n            True if the element was successfully deleted, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"\n        Abstract method for a 'surgical' edit within an element's body.\n\n        Replaces a specific statement or line range within the body of an element.\n\n        Args:\n            element_name: Name of the function/class to modify.\n            new_code: New code to insert (can be multiple statements).\n            line_start: Starting line number (absolute) within the element.\n            line_end: Ending line number (inclusive) within the element.\n            statement_index: Alternative to line numbers - replace the Nth statement.\n\n        Returns:\n            True if successful, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_modified_source(self) ->str:\n        \"\"\"\n        Abstract method to serialize the potentially modified AST/CST back to source code.\n\n        Returns:\n            The full source code string reflecting the current state of the tree.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_diff(self) ->str:\n        \"\"\"\n        Abstract method to generate a diff between the original source and the modified source.\n\n        Returns:\n            A string containing the unified diff.\n        \"\"\"\n        pass\n\n\n\"\"\"\nTextFileAdapter - Basic adapter for text files\n\nThis module provides a basic adapter for text files that implements\nthe ASTAdapter interface. It allows text files to be used with the\nCodeEditor class.\n\"\"\"\n\n\nclass TextFileAdapter(ASTAdapter):\n    \"\"\"\n    A basic adapter for text files that implements the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the TextFileAdapter.\n\n        Args:\n            source_code: The source code as a string.\n        \"\"\"\n        self.source_code = source_code\n        self.modified_source = source_code\n\n    def list_elements(self) ->List[str]:\n        \"\"\"\n        Lists top-level elements in the text file.\n        For text files, this returns a single \"content\" element.\n\n        Returns:\n            A list containing \"content\".\n        \"\"\"\n        return ['content']\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"\n        Gets the source code for a specific element.\n        For text files, this returns the entire file content.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            The source code of the entire file.\n        \"\"\"\n        if element_name == 'content':\n            return self.source_code\n        return None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"\n        Gets detailed structure information about an element.\n        For text files, this provides minimal structure information.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            A dictionary with basic structure information.\n        \"\"\"\n        if element_name == 'content':\n            lines = self.source_code.splitlines()\n            return {'name': element_name, 'type': 'text', 'line_count': len\n                (lines), 'character_count': len(self.source_code)}\n        return None\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"\n        Gets a snippet from within an element's body.\n        For text files, this returns lines between line_start and line_end.\n\n        Args:\n            element_name: The name of the element.\n            line_start: The starting line number (1-indexed).\n            line_end: The ending line number (1-indexed).\n\n        Returns:\n            A string containing the specified lines.\n        \"\"\"\n        if element_name != 'content':\n            return None\n        lines = self.source_code.splitlines()\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(lines), line_end)\n        if start_idx >= len(lines) or start_idx >= end_idx:\n            return None\n        return '\\n'.join(lines[start_idx:end_idx])\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"\n        Replaces a partial section of an element.\n        For text files, this replaces lines between line_start and line_end.\n\n        Args:\n            element_name: The name of the element.\n            new_code: The new code to insert.\n            line_start: The starting line number (1-indexed).\n            line_end: The ending line number (1-indexed).\n            statement_index: Not used for text files.\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        if element_name != 'content':\n            return False\n        if line_start is None or line_end is None:\n            return False\n        lines = self.modified_source.splitlines()\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(lines), line_end)\n        if start_idx > len(lines) or start_idx > end_idx:\n            return False\n        new_lines = self.modified_source.splitlines()\n        new_code_lines = new_code.splitlines()\n        new_lines[start_idx:end_idx] = new_code_lines\n        self.modified_source = '\\n'.join(new_lines)\n        return True\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"\n        Adds new content to the text file.\n        For text files, this appends or prepends content.\n\n        Args:\n            new_code: The new code to add.\n            anchor_name: Not used for text files.\n            before: If True, prepend; if False, append.\n\n        Returns:\n            True if the addition was successful, False otherwise.\n        \"\"\"\n        if before:\n            self.modified_source = new_code + '\\n' + self.modified_source\n        else:\n            self.modified_source = self.modified_source + '\\n' + new_code\n        return True\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"\n        Deletes an element by name.\n        For text files, this clears the entire content if element_name is \"content\".\n\n        Args:\n            element_name: The name of the element to delete.\n\n        Returns:\n            True if the deletion was successful, False otherwise.\n        \"\"\"\n        if element_name == 'content':\n            self.modified_source = ''\n            return True\n        return False\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"\n        Replaces a target element with new code.\n        For text files, this replaces the entire content if element_name is \"content\".\n\n        Args:\n            element_name: The name of the element to replace.\n            new_code: The new code.\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        if element_name == 'content':\n            self.modified_source = new_code\n            return True\n        return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"\n        Gets the modified source code.\n\n        Returns:\n            The modified source code.\n        \"\"\"\n        return self.modified_source\n\n    def get_diff(self) ->str:\n        \"\"\"\n        Generates a diff between the original source and the modified source.\n\n        Returns:\n            A string containing the diff.\n        \"\"\"\n        import difflib\n        return ''.join(difflib.unified_diff(self.source_code.splitlines(\n            keepends=True), self.modified_source.splitlines(keepends=True),\n            fromfile='original', tofile='modified'))\n",
    "file": "/mnt/ProjectData/omni/ast_adapter.py"
  },
  {
    "id": 166,
    "hash": "3fa6303779874a8e61c7a1a4ffc75e58",
    "content": "\"\"\"\nCodeEditor - Enhanced AST-based code manipulation tool\n\nThis module provides a class to programmatically parse, analyze,\nand edit source code. It has been refactored to use a pluggable\nASTAdapter system, allowing it to support multiple languages.\nCurrently, it defaults to Python's built-in `ast` module via\nPythonASTAdapter for backward compatibility during the transition.\n\"\"\"\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Union, Tuple, Type, Any\nfrom ast_adapter import ASTAdapter\nfrom python_ast_adapter import PythonASTAdapter\nimport os\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n\n\nclass CodeEditor:\n    \"\"\"\n    An enhanced class to safely edit files using AST/CST with partial edit support.\n    The core logic for interacting with the code structure is now delegated to\n    a language-specific ASTAdapter.\n    \"\"\"\n\n    def __init__(self, file_path: str, adapter_class: Optional[Type[\n        ASTAdapter]]=None):\n        \"\"\"\n        Initializes the CodeEditor.\n\n        Args:\n            file_path: The path to the source file.\n            adapter_class: The ASTAdapter subclass to use. If None, defaults to\n                           PythonASTAdapter for .py files.\n        \"\"\"\n        self.file_path = file_path\n        self.source_code = self._read_file()\n        self.adapter: Optional[ASTAdapter] = None\n        self.tree: Optional[ast.AST] = None\n        self.nodes: Dict[str, ast.AST] = {}\n        self.atok: Optional[Any] = None\n        if adapter_class is None:\n            file_extension = os.path.splitext(self.file_path)[1].lower()\n            if file_extension == '.py':\n                try:\n                    from python_ast_adapter import PythonASTAdapter\n                    self.adapter = PythonASTAdapter(self.source_code)\n                except ImportError as e:\n                    try:\n                        self.tree = self._parse_source()\n                        self.nodes = self._map_nodes()\n                        if ASTTOKENS_AVAILABLE:\n                            self.atok = asttokens.ASTTokens(self.\n                                source_code, parse=True)\n                    except Exception as parse_error:\n                        raise ValueError(\n                            f'Failed to parse Python file: {parse_error}')\n            elif file_extension == '.js':\n                try:\n                    from javascript_ast_adapter import JavaScriptASTAdapter\n                    self.adapter = JavaScriptASTAdapter(self.source_code)\n                except ImportError as e:\n                    raise ValueError(\n                        f'tree-sitter is required for JavaScript support but not available: {e}'\n                        )\n                except Exception as e:\n                    raise ValueError(\n                        f'Failed to initialize JavaScript adapter: {e}')\n            elif file_extension == '.txt':\n                pass\n            else:\n                raise ValueError(\n                    f'Unsupported file type: {file_extension}. Supported types: .py, .js, .txt'\n                    )\n        else:\n            try:\n                self.adapter = adapter_class(self.source_code)\n            except Exception as e:\n                raise ValueError(\n                    f'Failed to initialize adapter {adapter_class.__name__}: {e}'\n                    )\n\n    def _read_file(self) ->str:\n        \"\"\"Reads the source file.\"\"\"\n        try:\n            with open(self.file_path, 'r', encoding='utf-8') as f:\n                return f.read()\n        except FileNotFoundError:\n            raise ValueError(f'File not found: {self.file_path}')\n\n    def _parse_source(self) ->ast.AST:\n        \"\"\"Fallback parsing logic.\"\"\"\n        try:\n            return ast.parse(self.source_code)\n        except SyntaxError as e:\n            raise ValueError(f'Invalid Python syntax in {self.file_path}: {e}')\n\n    def list_elements(self) ->List[str]:\n        \"\"\"Lists top-level elements in the code.\"\"\"\n        if self.adapter:\n            return self.adapter.list_elements()\n        else:\n            return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"Gets the source code for a specific element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_source_of(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            return astor.to_source(node) if node else None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"Gets detailed structure information about an element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_structure(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            if not node:\n                return None\n            structure = {'name': element_name, 'type': node.__class__.\n                __name__, 'line_start': node.lineno if hasattr(node,\n                'lineno') else None, 'line_end': node.end_lineno if hasattr\n                (node, 'end_lineno') else None, 'body_items': []}\n            if hasattr(node, 'body'):\n                for i, item in enumerate(node.body):\n                    item_info = {'index': i, 'type': item.__class__.\n                        __name__, 'line_start': item.lineno if hasattr(item,\n                        'lineno') else None, 'line_end': item.end_lineno if\n                        hasattr(item, 'end_lineno') else None}\n                    if isinstance(item, ast.Assign) and item.targets:\n                        target = item.targets[0]\n                        if isinstance(target, ast.Name):\n                            item_info['assigns'] = target.id\n                    elif isinstance(item, (ast.If, ast.While, ast.For)):\n                        item_info['has_body'] = bool(item.body)\n                    elif isinstance(item, ast.Return):\n                        item_info['returns'] = True\n                    structure['body_items'].append(item_info)\n            return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"Gets a snippet from within an element's body.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_body_snippet(element_name,\n                line_start, line_end)\n        else:\n            if not self.atok:\n                return None\n            node = self.nodes.get(element_name)\n            if not node or not hasattr(node, 'body'):\n                return None\n            statements = []\n            for stmt in node.body:\n                if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                    if (line_start <= stmt.lineno <= line_end or line_start <=\n                        stmt.end_lineno <= line_end):\n                        statements.append(stmt)\n            if not statements:\n                return None\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in\n                statements)\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"Replaces a partial section of an element.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_partial(element_name, new_code,\n                line_start, line_end, statement_index)\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                if new_code.strip().startswith('def ') or new_code.strip(\n                    ).startswith('class '):\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body[0].body\n                else:\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if statement_index is not None:\n                if 0 <= statement_index < len(node.body):\n                    node.body[statement_index:statement_index + 1\n                        ] = new_statements\n                    return True\n            elif line_start is not None:\n                result = self._find_statement_in_body(node.body, line_start,\n                    line_end)\n                if result:\n                    idx, _ = result\n                    if line_end:\n                        end_idx = idx\n                        for i in range(idx + 1, len(node.body)):\n                            stmt = node.body[i]\n                            if hasattr(stmt, 'end_lineno'\n                                ) and stmt.end_lineno <= line_end:\n                                end_idx = i\n                            else:\n                                break\n                        node.body[idx:end_idx + 1] = new_statements\n                    else:\n                        node.body[idx:idx + 1] = new_statements\n                    return True\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"Adds a new block of code to the file.\"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name, before)\n        else:\n            try:\n                new_ast_module = ast.parse(new_code)\n            except (SyntaxError, IndexError):\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            insertion_index = -1\n            main_block_idx = -1\n            for i, _node in enumerate(self.tree.body):\n                if isinstance(_node, ast.If) and isinstance(_node.test, ast\n                    .Compare) and isinstance(_node.test.left, ast.Name\n                    ) and _node.test.left.id == '__name__' and len(_node.\n                    test.ops) == 1 and isinstance(_node.test.ops[0], ast.Eq\n                    ) and len(_node.test.comparators) == 1:\n                    comp = _node.test.comparators[0]\n                    if isinstance(comp, ast.Constant\n                        ) and comp.value == '__main__' or isinstance(comp,\n                        ast.Str) and comp.s == '__main__':\n                        main_block_idx = i\n                        break\n            if anchor_name:\n                if anchor_name not in self.nodes:\n                    return False\n                anchor_node = self.nodes[anchor_name]\n                try:\n                    anchor_idx = self.tree.body.index(anchor_node)\n                    proposed_index = anchor_idx if before else anchor_idx + 1\n                    if main_block_idx != -1:\n                        insertion_index = min(proposed_index, main_block_idx)\n                    else:\n                        insertion_index = proposed_index\n                except ValueError:\n                    return False\n            elif main_block_idx != -1:\n                insertion_index = main_block_idx\n            if insertion_index == -1:\n                self.tree.body.extend(new_code_body)\n            else:\n                for i, new_node in enumerate(new_code_body):\n                    self.tree.body.insert(insertion_index + i, new_node)\n            for _node in new_code_body:\n                if isinstance(_node, (ast.FunctionDef, ast.AsyncFunctionDef,\n                    ast.ClassDef)):\n                    self.nodes[_node.name] = _node\n            return True\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"Deletes an element by name.\"\"\"\n        if self.adapter:\n            return self.adapter.delete_element(element_name)\n        else:\n            deleted = False\n            if element_name in self.nodes:\n                node_to_delete = self.nodes[element_name]\n                for _node in ast.walk(self.tree):\n                    if hasattr(_node, 'body') and isinstance(_node.body, list):\n                        try:\n                            _node.body.remove(node_to_delete)\n                            deleted = True\n                            break\n                        except ValueError:\n                            continue\n                if deleted:\n                    del self.nodes[element_name]\n                    self.nodes = self._map_nodes()\n                    return True\n            new_body = []\n            for _node in self.tree.body:\n                if isinstance(_node, ast.Assign):\n                    match = False\n                    for target in _node.targets:\n                        if isinstance(target, ast.Name\n                            ) and target.id == element_name:\n                            match = True\n                            break\n                    if match:\n                        deleted = True\n                        continue\n                elif isinstance(_node, ast.Import):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                elif isinstance(_node, ast.ImportFrom):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                new_body.append(_node)\n            self.tree.body = new_body\n            if deleted:\n                self.nodes = self._map_nodes()\n            return deleted\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"Replaces a target element with new code.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_element(element_name, new_code)\n        else:\n            if element_name not in self.nodes:\n                return False\n            try:\n                new_ast_module = ast.parse(new_code)\n            except SyntaxError:\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            for _node in ast.walk(self.tree):\n                if hasattr(_node, 'body') and isinstance(_node.body, list):\n                    try:\n                        old_node = self.nodes[element_name]\n                        idx = _node.body.index(old_node)\n                        _node.body.pop(idx)\n                        for i, new_node in enumerate(new_code_body):\n                            _node.body.insert(idx + i, new_node)\n                        del self.nodes[element_name]\n                        for n in new_code_body:\n                            if isinstance(n, (ast.FunctionDef, ast.\n                                AsyncFunctionDef, ast.ClassDef)):\n                                self.nodes[n.name] = n\n                        return True\n                    except (ValueError, KeyError):\n                        continue\n            return False\n\n    def insert_in_element(self, element_name: str, new_code: str, position:\n        str='end', after_line: Optional[int]=None, before_line: Optional[\n        int]=None) ->bool:\n        \"\"\"\n        Insert new code into an element without replacing existing code.\n        This is an internal/helper method, delegating to adapter OR using fallback.\n        \"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name=\n                element_name, before=position == 'start')\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                new_ast = ast.parse(new_code)\n                new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if position == 'start':\n                node.body[0:0] = new_statements\n            elif position == 'end':\n                node.body.extend(new_statements)\n            elif after_line:\n                result = self._find_statement_in_body(node.body, after_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx + 1:idx + 1] = new_statements\n                else:\n                    return False\n            elif before_line:\n                result = self._find_statement_in_body(node.body, before_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx:idx] = new_statements\n                else:\n                    return False\n            else:\n                return False\n            return True\n\n    def _map_nodes(self) ->Dict[str, ast.AST]:\n        \"\"\"Fallback node mapping logic for Python AST.\"\"\"\n        nodes = {}\n        for node in ast.walk(self.tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast\n                .ClassDef)):\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int,\n        line_end: Optional[int]=None) ->Optional[Tuple[int, ast.AST]]:\n        \"\"\"Fallback statement finding logic for Python AST.\"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = stmt.end_lineno if hasattr(stmt, 'end_lineno'\n                        ) else stmt.lineno\n                    if (stmt.lineno <= line_start <= stmt_end or stmt.\n                        lineno <= line_end <= stmt_end):\n                        return i, stmt\n                elif stmt.lineno == line_start:\n                    return i, stmt\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.\n        ImportFrom]]) ->None:\n        \"\"\"Fallback logic to add imports to the top of the Python AST.\"\"\"\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                existing_imports_str.add(astor.to_source(node).strip())\n                last_import_index = i\n        for new_import in reversed(new_import_nodes):\n            new_import_str = astor.to_source(new_import).strip()\n            if new_import_str not in existing_imports_str:\n                self.tree.body.insert(last_import_index + 1, new_import)\n\n    def apply_arbitrary_change(self, new_source_code: str) ->bool:\n        \"\"\"\n        Rewrites the entire file's AST from a new source string.\n        This method resets the adapter if one exists, or uses fallback.\n        \"\"\"\n        if self.adapter:\n            try:\n                adapter_class = type(self.adapter)\n                self.adapter = adapter_class(new_source_code)\n                return True\n            except Exception:\n                return False\n        else:\n            try:\n                new_tree = ast.parse(new_source_code)\n                self.tree = new_tree\n                self.nodes = self._map_nodes()\n                if ASTTOKENS_AVAILABLE:\n                    self.source_code = new_source_code\n                    self.atok = asttokens.ASTTokens(self.source_code, parse\n                        =True)\n                return True\n            except SyntaxError:\n                return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"Serializes the potentially modified code structure back to source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_modified_source()\n        else:\n            return astor.to_source(self.tree)\n\n    def get_diff(self) ->str:\n        \"\"\"Generates a diff between the original source and the modified source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_diff()\n        else:\n            modified_source = self.get_modified_source()\n            return ''.join(difflib.unified_diff(self.source_code.splitlines\n                (keepends=True), modified_source.splitlines(keepends=True),\n                fromfile=f'{self.file_path} (original)', tofile=\n                f'{self.file_path} (modified)'))\n\n    def save_changes(self) ->None:\n        \"\"\"Saves the modified source code back to the file.\"\"\"\n        modified_source = self.get_modified_source()\n        with open(self.file_path, 'w', encoding='utf-8') as f:\n            f.write(modified_source)\n",
    "file": "/mnt/ProjectData/omni/code_editor.py"
  },
  {
    "id": 167,
    "hash": "cc52aa524d0929867d5d2ea3697229e6",
    "content": "\"\"\"\nGenerated file.\n\"\"\"\nimport os\n\"\"\"\nFileCreator - A utility for creating files.\n\nThis module provides a simple, encapsulated way to create files,\nensuring that their parent directories exist before writing.\n\"\"\"\n\n\nclass FileCreator:\n    \"\"\"\n    A utility class to handle the creation of new files.\n    \"\"\"\n\n    @staticmethod\n    def create(file_path: str, content: str) ->None:\n        \"\"\"\n        Creates a file at the specified path with the given content.\n\n        This method will automatically create any necessary parent\n        directories for the file path.\n\n        Args:\n            file_path: The full path where the file should be created.\n            content: The string content to write to the file.\n\n        Raises:\n            IOError: If there is an error creating the directories or writing the file.\n        \"\"\"\n        try:\n            directory = os.path.dirname(file_path)\n            if directory:\n                os.makedirs(directory, exist_ok=True)\n            with open(file_path, 'w', encoding='utf-8') as f:\n                f.write(content)\n        except (IOError, OSError) as e:\n            raise IOError(f\"Failed to create file '{file_path}': {e}\") from e\n",
    "file": "/mnt/ProjectData/omni/file_creator.py"
  },
  {
    "id": 168,
    "hash": "04a24ceab008bd649d0530d309c72e42",
    "content": "import subprocess\nimport os\nfrom typing import List, Optional, Union\n\n\nclass GitManager:\n    \"\"\"\n    Encapsulates Git-related logic for a specific repository.\n\n    This class provides methods to perform common Git operations such as\n    checking status, getting diffs, staging, committing, and pushing changes.\n    It relies on the Git command-line tool being installed and accessible\n    in the system's PATH.\n    \"\"\"\n\n    def __init__(self, repo_path: str):\n        \"\"\"\n        Initializes the GitManager for a given repository path.\n\n        Args:\n            repo_path: The absolute or relative path to the Git repository.\n\n        Raises:\n            ValueError: If the provided path is not a valid Git repository.\n        \"\"\"\n        if not os.path.isdir(os.path.join(repo_path, '.git')):\n            raise ValueError(\n                f\"The path '{repo_path}' is not a valid Git repository.\")\n        self.repo_path = repo_path\n\n    def _run_command(self, command: List[str]) ->str:\n        \"\"\"\n        Executes a Git command in the repository's directory.\n\n        Args:\n            command: A list of command arguments, starting with 'git'.\n\n        Returns:\n            The standard output of the command as a string.\n\n        Raises:\n            subprocess.CalledProcessError: If the command returns a non-zero exit code.\n        \"\"\"\n        try:\n            result = subprocess.run(command, cwd=self.repo_path, check=True,\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True,\n                encoding='utf-8')\n            return result.stdout.strip()\n        except subprocess.CalledProcessError as e:\n            error_message = (\n                f\"Git command failed: {' '.join(command)}\\nError: {e.stderr.strip()}\"\n                )\n            raise subprocess.CalledProcessError(e.returncode, e.cmd, output\n                =e.stdout, stderr=error_message) from e\n\n    def get_status(self) ->str:\n        \"\"\"\n        Gets the repository status in a condensed format.\n\n        Uses `git status --porcelain` for a machine-readable output.\n\n        Returns:\n            A string representing the repository's status.\n        \"\"\"\n        return self._run_command(['git', 'status', '--porcelain'])\n        \n    def get_changed_files(self) -> List[str]:\n        \"\"\"\n        Gets a list of all changed (modified, added, deleted, untracked, renamed, or copied) files.\n\n        This parses the output of `git status --porcelain`, which provides a stable,\n        machine-readable format.\n\n        Returns:\n            A list of file paths relative to the repository root. For renamed or\n            copied files, it returns the new path.\n        \"\"\"\n        status_output = self.get_status()\n        if not status_output:\n            return []\n        \n        changed_files = []\n        for line in status_output.splitlines():\n            if len(line) < 3:  # Skip malformed lines\n                continue\n                \n            # Git status porcelain format: XY filename\n            # X = index status, Y = working tree status\n            index_status = line[0]\n            worktree_status = line[1]\n            \n            # The filename starts after the two status characters and a space\n            # But let's be more defensive about finding where the filename actually starts\n            filename_start = 2\n            while filename_start < len(line) and line[filename_start] == ' ':\n                filename_start += 1\n                \n            if filename_start >= len(line):\n                continue  # Skip if no filename found\n                \n            path_info = line[filename_start:]\n            \n            # Check if either index or working tree status indicates rename/copy\n            if index_status in ('R', 'C') or worktree_status in ('R', 'C'):\n                if ' -> ' in path_info:\n                    _, new_path = path_info.split(' -> ', 1)  # Use maxsplit=1 for safety\n                    changed_files.append(new_path.strip())\n                else:\n                    # Fallback if format is unexpected\n                    changed_files.append(path_info.strip())\n            else:\n                changed_files.append(path_info.strip())\n        \n        # Remove duplicates while preserving order\n        return list(dict.fromkeys(changed_files))\n\n    def get_diff(self, file_path: Optional[str]=None, staged: bool=False\n        ) ->str:\n        \"\"\"\n        Gets the diff of changes in the repository.\n\n        Args:\n            file_path: Optional. Path to a specific file to diff.\n            staged: If True, shows the diff for staged changes (`--cached`).\n                    Otherwise, shows the diff for unstaged changes.\n\n        Returns:\n            The git diff output as a string.\n        \"\"\"\n        cmd = ['git', 'diff']\n        if staged:\n            cmd.append('--cached')\n        if file_path:\n            cmd.append('--')\n            cmd.append(file_path)\n        return self._run_command(cmd)\n\n    def add(self, files: Union[str, List[str]]) ->None:\n        \"\"\"\n    Stages one or more files, handling each one individually for robustness.\n\n    This approach prevents a single invalid file path from causing the\n    entire 'git add' operation to fail. Warnings will be printed for any\n    files that could not be staged.\n\n    Args:\n        files: A single file path or a list of file paths to stage.\n               Can also be '.' to stage all changes.\n    \"\"\"\n        if isinstance(files, str):\n            files = [files]\n        for file_path in files:\n            try:\n                cmd = ['git', 'add', '--', file_path]\n                self._run_command(cmd)\n            except subprocess.CalledProcessError as e:\n                print(\n                    f\"Warning: Could not stage file '{file_path}'. Git reported: {e.stderr}\"\n                    )\n\n    def commit(self, message: str) ->str:\n        \"\"\"\n        Commits staged changes with a given message.\n\n        Args:\n            message: The commit message.\n\n        Returns:\n            The stdout from the git commit command.\n        \"\"\"\n        return self._run_command(['git', 'commit', '-m', message])\n\n    def push(self, remote: str='origin', branch: Optional[str]=None) ->str:\n        \"\"\"\n        Pushes commits to a remote repository.\n\n        Args:\n            remote: The name of the remote to push to (default: 'origin').\n            branch: The branch to push. If None, uses the current branch.\n\n        Returns:\n            The stdout from the git push command.\n        \"\"\"\n        if branch is None:\n            branch = self.get_current_branch()\n        return self._run_command(['git', 'push', remote, branch])\n\n    def get_current_branch(self) ->str:\n        \"\"\"\n        Determines the current active branch name.\n\n        Returns:\n            The name of the current branch.\n        \"\"\"\n        return self._run_command(['git', 'rev-parse', '--abbrev-ref', 'HEAD'])\n",
    "file": "/mnt/ProjectData/omni/git_manager.py"
  },
  {
    "id": 169,
    "hash": "f3f7ab448ad3e233539c4e4bddcd64f4",
    "content": "# javascript_ast_adapter.py\n\n\"\"\"\nJavaScriptASTAdapter - Concrete AST adapter for JavaScript using tree-sitter.\n\nThis module implements the ASTAdapter interface specifically for JavaScript,\nleveraging the tree-sitter library for parsing and manipulation.\n\"\"\"\n\nimport difflib\nimport re\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for tree-sitter\ntry:\n    import tree_sitter\n    import tree_sitter_languages\n    TREETSITTER_AVAILABLE = True\nexcept ImportError:\n    TREETSITTER_AVAILABLE = False\n    # This will cause an error during initialization if the adapter is used\n\n\nclass JavaScriptASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for JavaScript source code.\n\n    This adapter uses tree-sitter to parse and manipulate JavaScript code.\n    It holds the parsed tree-sitter Tree and provides methods to interact\n    with it according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the JavaScriptASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The JavaScript source code as a string.\n\n        Raises:\n            ValueError: If tree-sitter libraries are not available or if\n                        the source code has invalid JavaScript syntax.\n        \"\"\"\n        if not TREETSITTER_AVAILABLE:\n            raise ValueError(\"tree-sitter and tree-sitter-languages are required for JavaScript support.\")\n            \n        # Store source code for diffing and manipulation\n        self.source_code: str = source_code\n        # Will hold the parsed tree-sitter tree\n        self.tree: Optional[tree_sitter.Tree] = None\n        # Will hold a mapping of element names to their tree-sitter nodes\n        self.nodes: Dict[str, tree_sitter.Node] = {}\n        # Tree-sitter language parser\n        self.language = tree_sitter_languages.get_language(\"javascript\")\n        self.parser = tree_sitter.Parser(self.language)\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the JavaScript source code and maps elements.\n\n        Args:\n            source_code: The JavaScript source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid JavaScript syntax.\n        \"\"\"\n        try:\n            # Encode the source code in bytes as required by tree-sitter\n            self.tree = self.parser.parse(bytes(source_code, \"utf-8\"))\n        except Exception as e:\n            raise ValueError(f\"Failed to parse JavaScript source: {e}\") from e\n\n        self.nodes = self._map_nodes()\n\n    def _map_nodes(self) -> Dict[str, tree_sitter.Node]:\n        \"\"\"\n        Walks the tree and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their tree-sitter nodes.\n        \"\"\"\n        nodes: Dict[str, tree_sitter.Node] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        # Define the types of nodes we're interested in\n        target_types = {\n            \"function_declaration\", \"class_declaration\", \n            \"variable_declarator\", \"import_statement\"\n        }\n        \n        # Walk the tree using a stack-based approach\n        stack = [self.tree.root_node]\n        while stack:\n            node = stack.pop()\n            \n            # Check if this is a target node type\n            if node.type in target_types:\n                # Extract the name for different node types\n                name = self._get_node_name(node)\n                if name and name not in nodes:\n                    nodes[name] = node\n            \n            # Add children to the stack for further processing\n            for child in reversed(node.children):  # Reverse to maintain order when popping\n                stack.append(child)\n                \n        return nodes\n    \n    def _get_node_name(self, node: tree_sitter.Node) -> Optional[str]:\n        \"\"\"\n        Extracts the name of a node based on its type.\n        \n        Args:\n            node: The tree-sitter node to extract the name from.\n            \n        Returns:\n            The name of the node, or None if no name could be found.\n        \"\"\"\n        if node.type == \"function_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"class_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"variable_declarator\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"import_statement\":\n            # This is a more complex case - for now, we'll use a simplified approach\n            # Extract the module name from the import statement\n            # e.g., in \"import foo from 'bar'\", we want \"foo\"\n            # This is a simplified implementation and might need refinement\n            import_clause = None\n            for child in node.children:\n                if child.type == \"import_clause\":\n                    import_clause = child\n                    break\n            \n            if import_clause:\n                # Check for a simple identifier\n                for child in import_clause.children:\n                    if child.type == \"identifier\":\n                        return child.text.decode(\"utf-8\")\n                    elif child.type == \"named_imports\":\n                        # Handle named imports like { foo, bar }\n                        # For simplicity, we'll just return a placeholder\n                        # A more complete implementation would extract all names\n                        return f\"import_from_{hash(node.text.decode('utf-8')) % 10000}\"\n        \n        return None\n\n    def _find_node_by_position(self, start_point: Tuple[int, int], \n                              end_point: Optional[Tuple[int, int]] = None) -> Optional[tree_sitter.Node]:\n        \"\"\"\n        Finds a node in the tree that corresponds to a given range.\n        \n        Args:\n            start_point: A (row, column) tuple indicating the start position.\n            end_point: A (row, column) tuple indicating the end position.\n            \n        Returns:\n            The tree-sitter node that corresponds to the range, or None if not found.\n        \"\"\"\n        if not self.tree:\n            return None\n            \n        # A simple approach: find the smallest node that contains the range\n        # This is a simplified implementation and might need refinement\n        def contains_range(node):\n            node_start = (node.start_point[0], node.start_point[1])\n            node_end = (node.end_point[0], node.end_point[1])\n            if end_point:\n                return (node_start <= start_point and node_end >= end_point)\n            else:\n                return node_start <= start_point <= node_end\n        \n        # Walk the tree to find matching nodes\n        stack = [self.tree.root_node]\n        candidates = []\n        \n        while stack:\n            current_node = stack.pop()\n            if contains_range(current_node):\n                candidates.append(current_node)\n                # Add children to continue searching for smaller nodes\n                stack.extend(current_node.children)\n        \n        # Return the smallest (last) candidate\n        return candidates[-1] if candidates else None\n    \n    def _get_line_info_from_point(self, point: Tuple[int, int]) -> Dict[str, Any]:\n        \"\"\"\n        Converts a tree-sitter point to line information.\n        \n        Args:\n            point: A (row, column) tuple from tree-sitter.\n            \n        Returns:\n            A dictionary with line_start and line_end information.\n        \"\"\"\n        # Tree-sitter uses 0-based indexing for rows\n        return {\n            'line_start': point[0] + 1,  # Convert to 1-based\n            'line_end': point[0] + 1\n        }\n\n    def _reparse_tree(self, new_source: str) -> None:\n        \"\"\"\n        Re-parses the tree with new source code.\n        \n        This is necessary because tree-sitter trees are immutable.\n        \n        Args:\n            new_source: The new source code to parse.\n        \"\"\"\n        self.source_code = new_source\n        self.tree = self.parser.parse(bytes(new_source, \"utf-8\"))\n        self.nodes = self._map_nodes()\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return node.text.decode(\"utf-8\")\n            except Exception:\n                # Handle potential decoding issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.type,\n            'line_start': node.start_point[0] + 1,  # Convert to 1-based\n            'line_end': node.end_point[0] + 1,\n            'body_items': []\n        }\n\n        # Add body items for functions and classes\n        if node.type in (\"function_declaration\", \"class_declaration\"):\n            # Find the body block\n            body_node = None\n            for child in node.children:\n                if child.type == \"statement_block\":\n                    body_node = child\n                    break\n            \n            if body_node:\n                # Process statements in the body\n                for i, item in enumerate(body_node.children):\n                    # Skip '{' and '}' tokens\n                    if item.type in (\"{\", \"}\"):\n                        continue\n                    \n                    item_info = {\n                        'index': i,\n                        'type': item.type,\n                        'line_start': item.start_point[0] + 1,\n                        'line_end': item.end_point[0] + 1\n                    }\n                    \n                    # Add more specific information based on type\n                    if item.type == \"variable_declaration\":\n                        item_info['declares'] = \"variable\"\n                    elif item.type == \"return_statement\":\n                        item_info['returns'] = True\n                    elif item.type in (\"if_statement\", \"for_statement\", \"while_statement\"):\n                        item_info['has_body'] = True\n                    \n                    structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n            \n        # A simplified approach to extracting a snippet by line numbers\n        # This would need to be more sophisticated for production use\n        source_lines = self.source_code.split('\\n')\n        # Adjust for 0-based indexing\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(source_lines), line_end)\n        \n        if start_idx < end_idx:\n            return '\\n'.join(source_lines[start_idx:end_idx])\n        \n        return None\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Replace the node's text in the source code\n        new_source = self.source_code[:start_byte] + new_code + self.source_code[end_byte:]\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass  # If we can't even re-parse the original, we're in trouble\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree:\n            return False\n            \n        # For simplicity, we'll add the new code at the end of the file\n        # A more sophisticated implementation would handle the anchor and positioning\n        new_source = self.source_code.rstrip() + \"\\n\\n\" + new_code + \"\\n\"\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Find the full lines that contain the node\n        # This is a simplified approach to avoid leaving partial lines\n        source_lines = self.source_code.split('\\n')\n        start_line = node.start_point[0]\n        end_line = node.end_point[0]\n        \n        # Create new source without those lines\n        new_lines = source_lines[:start_line] + source_lines[end_line+1:]\n        new_source = '\\n'.join(new_lines)\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        # This is a complex operation that would require more sophisticated\n        # tree navigation and manipulation than what's shown here.\n        # For now, we'll provide a basic implementation.\n        \n        node = self.nodes.get(element_name)\n        if not node:\n            return False\n            \n        # Handle line-based replacement\n        if line_start is not None:\n            # Convert to 0-based indexing\n            start_idx = max(0, line_start - 1)\n            end_idx = line_end if line_end is not None else start_idx + 1\n            \n            source_lines = self.source_code.split('\\n')\n            if start_idx < len(source_lines):\n                # Replace the specified lines\n                end_idx = min(end_idx, len(source_lines))\n                new_lines = source_lines[:start_idx] + [new_code] + source_lines[end_idx:]\n                new_source = '\\n'.join(new_lines)\n                \n                # Re-parse the tree with the new source\n                try:\n                    self._reparse_tree(new_source)\n                    return True\n                except Exception:\n                    # If parsing fails, revert to the original source\n                    try:\n                        self._reparse_tree(self.source_code)\n                    except Exception:\n                        pass\n        \n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        # For tree-sitter, the source code is already maintained separately\n        return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        \n        # Ensure line endings are consistent for diffing\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/javascript_ast_adapter.py"
  },
  {
    "id": 170,
    "hash": "89fa0c06ca34019316daa58ce8fa9a20",
    "content": "import json\nimport os\nfrom typing import List, Dict, Optional\nfrom rag_manager import RAGManager\n\n\nclass MemoryManager:\n    \"\"\"Manages persistent chat memory, look data, and RAG integration via JSON.\"\"\"\n\n    def __init__(self, memory_file: str):\n        self.memory_file = memory_file\n        self.memory: Dict[str, List] = self.load_memory()\n        self.rag_manager = RAGManager()\n\n    def load_memory(self) ->Dict[str, List]:\n        try:\n            with open(self.memory_file, 'r') as f:\n                return json.load(f)\n        except FileNotFoundError:\n            default = {'chat': [], 'look': []}\n            self.save_memory(default)\n            return default\n        except json.JSONDecodeError:\n            print('[yellow]Invalid memory file. Resetting.[/]')\n            return {'chat': [], 'look': []}\n\n    def save_memory(self, memory: Optional[Dict[str, List]]=None) ->None:\n        if memory is None:\n            memory = self.memory\n        with open(self.memory_file, 'w') as f:\n            json.dump(memory, f, indent=4)\n\n    def add_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.memory['chat'].append({'role': role, 'content': content})\n        self.save_memory()\n\n    def add_chat_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        This is an alias for add_message to maintain compatibility.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.add_message(role, content)\n\n    def add_look_data(self, file_path: str, content: str) ->None:\n        \"\"\"\n    Adds a watched item (directory or file) to memory, distinguishing its type.\n\n    This method stores structured data that differentiates between a project\n    directory (containing a manifest) and a single file (containing its content).\n    It also prevents duplicate entries by updating existing ones.\n\n    Args:\n        file_path: The path to the directory or file.\n        content: The manifest for a directory or the content for a file.\n    \"\"\"\n        item_type = 'directory' if os.path.isdir(file_path) else 'file'\n        for item in self.memory['look']:\n            if item.get('file') == file_path:\n                item['content'] = content\n                item['type'] = item_type\n                self.save_memory()\n                return\n        self.memory['look'].append({'type': item_type, 'file': file_path,\n            'content': content})\n        self.save_memory()\n        if item_type == 'file':\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    file_content = f.read()\n                self.rag_manager.add_documents([file_content], [{'file':\n                    file_path}])\n            except Exception as e:\n                print(\n                    f'[yellow]Warning: Could not add {file_path} to RAG index: {e}[/]'\n                    )\n\n    def get_project_root(self) ->Optional[str]:\n        \"\"\"\n        Finds the root directory of the project currently in memory.\n\n        The project root is defined as the first item in the 'look' memory\n        that is of type 'directory'.\n\n        Returns:\n            The absolute path to the project root directory, or None if not found.\n        \"\"\"\n        for item in self.memory.get('look', []):\n            if item.get('type') == 'directory':\n                return item.get('file')\n        return None\n\n    def get_memory_context(self) ->str:\n        \"\"\"\n        Dynamically builds the context using RAG and chat history.\n\n        It retrieves relevant file content from the RAG index based on the latest\n        user query, includes project manifests for directories, and appends the\n        recent chat history.\n        \"\"\"\n        context = ''\n        for look in self.memory.get('look', []):\n            path = look.get('file')\n            if path and os.path.isdir(path):\n                content = look.get('content', '')\n                context += (\n                    f'--- Project Manifest for {path} ---\\n{content}\\n\\n')\n        last_user_message = next((msg['content'] for msg in reversed(self.\n            memory.get('chat', [])) if msg['role'] == 'user'), None)\n        if last_user_message:\n            rag_results = self.search_rag(last_user_message, k=3)\n            if rag_results:\n                context += '--- Relevant context from RAG ---\\n'\n                for doc, score, meta in rag_results:\n                    file_path = meta.get('file', 'Unknown source')\n                    context += f'Source: {file_path} (Score: {score:.4f})\\n'\n                    context += f'Content: {doc}\\n---\\n'\n                context += '\\n'\n        for msg in self.memory.get('chat', []):\n            context += f\"{msg['role'].capitalize()}: {msg['content']}\\n\"\n        return context.strip()\n\n    def clear_memory(self) ->None:\n        self.memory = {'chat': [], 'look': []}\n        self.save_memory()\n        self.rag_manager.clear_index()\n\n    def search_rag(self, query: str, k: int=3) ->List[tuple]:\n        \"\"\"\n        Search the RAG index for relevant documents.\n        \n        Args:\n            query: The search query\n            k: Number of results to return\n            \n        Returns:\n            List of (document_content, score, metadata) tuples\n        \"\"\"\n        return self.rag_manager.search(query, k)\n",
    "file": "/mnt/ProjectData/omni/memory_manager.py"
  },
  {
    "id": 171,
    "hash": "fefce358bada61faf78f7880c778938c",
    "content": "\"\"\"\nOmni - AI-powered code generation and project-aware editing CLI tool\n\nIntegrates modular UI, memory, personality, and AST-based code editing.\n\"\"\"\nimport os\nimport subprocess\nimport requests\nimport json\nimport sys\nimport re\nimport argparse\nimport ast\nfrom datetime import datetime\nimport threading\nimport queue as Queue\nimport time\nfrom typing import List, Dict, Optional\nfrom rich import print\nfrom rich.panel import Panel\nfrom rich.console import Console\nfrom rich.tree import Tree\nfrom ui_manager import UIManager\nfrom personality_manager import PersonalityManager\nfrom memory_manager import MemoryManager\nfrom code_editor import CodeEditor\nfrom file_creator import FileCreator\nfrom git_manager import GitManager\nimport traceback\nDEFAULT_BACKEND = 'openrouter'\nOLLAMA_MODEL = 'phi4-reasoning'\nOPENROUTER_MODEL = 'qwen/qwen3-coder'\nDEFAULT_SAVE_DIR = os.path.expanduser('/mnt/ProjectData/omni/omni_saves/')\nCONFIG_FILE = 'config.json'\nMEMORY_FILE = 'memory.json'\nOLLAMA_API_URL = 'http://localhost:11434/api/generate'\nOPENROUTER_API_URL = 'https://openrouter.ai/api/v1/chat/completions'\nOPENROUTER_MODELS_API_URL = 'https://openrouter.ai/api/v1/models'\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\ncurrent_backend = DEFAULT_BACKEND\ncurrent_model = (OLLAMA_MODEL if DEFAULT_BACKEND == 'ollama' else\n    OPENROUTER_MODEL)\nOLLAMA_MODELS = {'deepseek': 'deepseek-coder:6.7b', 'codellama':\n    'codellama:13b', 'mistral': 'mistral:latest', 'llama2': 'llama2:latest',\n    'phind': 'phind-codellama:34b'}\nos.makedirs(DEFAULT_SAVE_DIR, exist_ok=True)\nTEMPLATES = {'flask':\n    \"\"\"from flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/')\ndef home():\n    return '<h1>Hello, Flask!</h1>'\n\nif __name__ == '__main__':\n    app.run(debug=True)\"\"\"\n    , 'html5':\n    \"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>New Page</title>\n</head>\n<body>\n    <h1>Hello World</h1>\n</body>\n</html>\"\"\"\n    , 'scraper':\n    \"\"\"import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        print(soup.title.text)\n    except Exception as e:\n        print(f\"[bold red]Error scraping {url}:[/] {e}\")\n\nif __name__ == \"__main__\":\n    scrape(\"https://example.com\")\"\"\"\n    }\nconsole = Console()\npersonality_manager = PersonalityManager(CONFIG_FILE)\nmemory_manager = MemoryManager(MEMORY_FILE)\nui_manager = UIManager()\nlast_query: Optional[str] = None\nlast_response: Optional[str] = None\nlast_code: Optional[str] = None\n\n\ndef start_ollama_server() ->None:\n    if current_backend != 'ollama':\n        return\n    try:\n        requests.get('http://localhost:11434', timeout=1)\n    except requests.exceptions.ConnectionError:\n        print('[cyan]Starting Ollama server...[/]')\n        subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL)\n\n\ndef query_llm(prompt: str) ->str:\n    personality = personality_manager.get_current_personality()\n    system_prompt = personality.get('system_prompt', '') if personality else ''\n    memory_context = memory_manager.get_memory_context()\n    rag_context = ''\n    try:\n        from rag_manager import RAGManager\n        project_root = memory_manager.get_project_root()\n        if project_root:\n            rag_manager = RAGManager()\n            if rag_manager.get_document_count() > 0:\n                results = rag_manager.search(prompt, k=3)\n                if results:\n                    rag_context = '\\n\\nRelevant context from codebase:\\n'\n                    for i, (doc, score, meta) in enumerate(results, 1):\n                        file_path = meta.get('file', 'Unknown')\n                        rag_context += f'{i}. [{file_path}] {doc}\\n'\n    except Exception:\n        pass\n    full_prompt = (\n        f'{system_prompt}\\n\\n{memory_context}{rag_context}\\n\\nUser: {prompt}')\n    with ui_manager.show_spinner('AI is listening and thinking...'):\n        if current_backend == 'ollama':\n            response = query_ollama(full_prompt)\n        elif current_backend == 'openrouter':\n            response = query_openrouter(full_prompt)\n        else:\n            response = '[bold red]Error:[/] Unknown backend'\n    return response\n\n\ndef query_openrouter(prompt: str) ->str:\n    if not OPENROUTER_API_KEY:\n        return '[bold red]Error:[/] OPENROUTER_API_KEY not set.'\n    headers = {'Authorization': f'Bearer {OPENROUTER_API_KEY}',\n        'Content-Type': 'application/json'}\n    payload = {'model': current_model, 'messages': [{'role': 'user',\n        'content': prompt}]}\n    try:\n        response = requests.post(OPENROUTER_API_URL, headers=headers, json=\n            payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['choices'][0]['message']['content']\n    except Exception as e:\n        error_details = ''\n        try:\n            error_details = response.json()\n        except:\n            error_details = response.text if hasattr(response, 'text'\n                ) else str(e)\n        return (\n            f'[bold red]OpenRouter Error:[/] {e}\\n[dim]Details: {error_details}[/dim]'\n            )\n\n\ndef query_ollama(prompt: str) ->str:\n    payload = {'model': current_model, 'prompt': prompt, 'stream': False}\n    try:\n        response = requests.post(OLLAMA_API_URL, json=payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['response']\n    except Exception as e:\n        return f'[bold red]Ollama Error:[/] {e}'\n\n\ndef extract_code(text: str) ->List[tuple[str, str]]:\n    matches = re.findall('```(\\\\w*)\\\\n([\\\\s\\\\S]*?)```', text)\n    return [(lang or 'text', code.strip()) for lang, code in matches\n        ] if matches else []\n\n\ndef list_models(args: list=None) ->None:\n    if current_backend == 'ollama':\n        print('[bold cyan]Popular Ollama Models:[/]')\n        for name, model_id in OLLAMA_MODELS.items():\n            print(\n                f\"{'\u2b50' if model_id == current_model else '  '} [yellow]{name:12}[/] \u2192 {model_id}\"\n                )\n    elif current_backend == 'openrouter':\n        list_openrouter_models(args or [])\n\n\ndef list_openrouter_models(args: list):\n    try:\n        from simple_term_menu import TerminalMenu\n    except ImportError:\n        ui_manager.show_error(\n            \"'simple-term-menu' is required. `pip install simple-term-menu`\")\n        return\n    try:\n        with ui_manager.show_spinner('Fetching models...'):\n            response = requests.get(OPENROUTER_MODELS_API_URL)\n            response.raise_for_status()\n        api_models_data = response.json().get('data', [])\n    except requests.RequestException as e:\n        ui_manager.show_error(f'Error fetching models: {e}')\n        return\n    all_models, sources = [], set()\n    for model_data in api_models_data:\n        if (model_id := model_data.get('id')):\n            sources.add(model_id.split('/')[0])\n            pricing = model_data.get('pricing', {})\n            is_free = pricing.get('prompt') == '0' and pricing.get('completion'\n                ) == '0'\n            all_models.append({'id': model_id, 'name': model_data.get(\n                'name'), 'source': model_id.split('/')[0], 'is_free': is_free})\n    all_models.sort(key=lambda x: (x['source'], x['name']))\n    if args and args[0].lower() == 'sources':\n        print('[bold cyan]Available Model Sources:[/]')\n        [print(f'  [yellow]{s}[/]') for s in sorted(list(sources))]\n        return\n    models_to_display, title = all_models, 'Select an OpenRouter Model'\n    if args:\n        filter_keyword = args[0].lower()\n        title = f\"Select a Model from '{filter_keyword}'\"\n        models_to_display = [m for m in all_models if filter_keyword in m[\n            'source'].lower()]\n        if not models_to_display:\n            ui_manager.show_error(f\"No models for source: '{filter_keyword}'\")\n            return\n    menu_entries = [\n        f\"{'\u2b50' if m['id'] == current_model else '  '} {m['name']} [dim]({m['id']}){' [green](FREE)[/]' if m['is_free'] else ''}[/dim]\"\n         for m in models_to_display]\n    try:\n        cursor_idx = next((i for i, m in enumerate(models_to_display) if m[\n            'id'] == current_model), 0)\n        chosen_index = TerminalMenu(menu_entries, title=f'{title}',\n            cursor_index=cursor_idx, cycle_cursor=True, clear_screen=True\n            ).show()\n        if chosen_index is not None:\n            set_model(models_to_display[chosen_index]['id'])\n        else:\n            print('Model selection cancelled.')\n    except Exception as e:\n        ui_manager.show_error(f'Menu display error: {e}')\n\n\ndef set_model(model_id: str) ->None:\n    global current_model\n    current_model = model_id\n    ui_manager.show_success(f'Model set to: {current_model}')\n\n\ndef switch_backend(backend_name: str) ->None:\n    global current_backend, current_model\n    backend_name = backend_name.lower()\n    if backend_name not in ['ollama', 'openrouter']:\n        ui_manager.show_error(f'Unknown backend: {backend_name}')\n        return\n    current_backend = backend_name\n    current_model = (OLLAMA_MODEL if backend_name == 'ollama' else\n        OPENROUTER_MODEL)\n    ui_manager.show_success(\n        f'Switched to {backend_name} backend with model: {current_model}')\n    if backend_name == 'ollama':\n        start_ollama_server()\n\n\ndef generate_project_manifest(path: str) ->tuple[str, List[str]]:\n    manifest = ''\n    file_paths = []\n    tree = Tree(f'[bold cyan]Project: {os.path.basename(path)}[/]')\n    exclude_dirs = {'__pycache__', '.git', 'venv', 'node_modules', '.idea',\n        'ollama'}\n    for root, dirs, files in os.walk(path):\n        dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.\n            startswith('.')]\n        relative_path = os.path.relpath(root, path)\n        branch = tree\n        if relative_path != '.':\n            parts = relative_path.split(os.sep)\n            for part in parts:\n                child = next((c for c in branch.children if c.label ==\n                    f'[magenta]{part}[/]'), None)\n                if not child:\n                    child = branch.add(f'[magenta]{part}[/]')\n                branch = child\n        for fname in sorted(files):\n            ext = os.path.splitext(fname)[1]\n            if ext not in ('.py', '.js', '.html', '.css', '.md', '.txt'):\n                continue\n            rel_path = os.path.join(relative_path, fname\n                ) if relative_path != '.' else fname\n            file_paths.append(rel_path)\n            branch.add(f'[green]{fname}[/]' if ext == '.py' else\n                f'[dim]{fname}[/]')\n            manifest += f'File: {rel_path}\\n\\n'\n    console.print(tree)\n    return manifest.strip(), file_paths\n\n\ndef look_command(path: str) ->None:\n    \"\"\"\n    Scans a directory or file and loads it into memory. It can resolve paths\n    relative to the current working directory or the project root in memory.\n    If a new directory is scanned, the previous 'look' context is cleared\n    to ensure the context remains relevant.\n    \"\"\"\n    resolved_path = resolve_file_path(path)\n    if not resolved_path:\n        ui_manager.show_error(f'\u274c Path not found: {path}')\n        return\n    if resolved_path != os.path.abspath(path):\n        ui_manager.show_success(\n            f\"Found '{path}' in project. Using: {resolved_path}\")\n    if os.path.isdir(resolved_path):\n        ui_manager.show_success(\n            \"New project directory detected. Clearing previous 'look' context.\"\n            )\n        memory_manager.memory['look'] = []\n        with ui_manager.show_spinner('Generating project manifest...'):\n            manifest = generate_project_manifest(resolved_path)\n        memory_manager.add_look_data(resolved_path, manifest)\n        ui_manager.show_success('\u2705 Project manifest added to memory.')\n    else:\n        try:\n            with ui_manager.show_spinner('Loading file...'):\n                with open(resolved_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n            for item in memory_manager.memory['look']:\n                if item.get('file') == resolved_path:\n                    item['content'] = content\n                    memory_manager.save_memory()\n                    ui_manager.show_success(\n                        '\u2705 Refreshed file content in memory.')\n                    return\n            memory_manager.add_look_data(resolved_path, content)\n            ui_manager.show_success('\u2705 File content added to memory.')\n        except Exception as e:\n            ui_manager.show_error(f'\u274c Error reading file: {e}')\n\n\ndef resolve_file_path(path: str) ->Optional[str]:\n    \"\"\"Resolves a file path, checking CWD first, then against project root in memory.\"\"\"\n    if os.path.exists(path):\n        return os.path.abspath(path)\n    project_root = memory_manager.get_project_root()\n    if project_root:\n        full_path = os.path.join(project_root, path)\n        if os.path.exists(full_path):\n            return full_path\n    return None\n\n\ndef _create_prompt_for_file_creation(file_name: str, instruction: str) ->str:\n    \"\"\"\n    Generate a robust prompt for file creation that instructs the AI to act as an expert,\n    produce complete and clean code, and avoid any extra commentary.\n    \"\"\"\n    return f\"\"\"You are an expert programmer tasked with creating a new file. Your goal is to generate complete, production-ready content based on the user's instruction.\n\nIMPORTANT RULES:\n- Provide ONLY the raw file content - no explanations, notes, or commentary outside the file itself\n- Include all necessary imports, boilerplate, and complete implementations\n- If creating code, ensure it's syntactically correct and follows best practices\n- For configuration files, use appropriate formatting (JSON, YAML, etc.)\n- For documentation files, use proper markdown formatting\n\nFile to create: {file_name}\nUser instruction: {instruction}\n\nGenerate the complete file content now:\"\"\"\n\n\ndef handle_file_create_command(file_path: str, instruction: str):\n    \"\"\"\n    Uses the LLM to generate content for a new file based on an instruction.\n    \"\"\"\n    global last_code\n    if os.path.exists(file_path):\n        if ui_manager.get_user_input(\n            f\"File '{file_path}' already exists. Overwrite? (y/n): \").lower(\n            ) not in ['yes', 'y']:\n            ui_manager.show_error('File creation cancelled.')\n            return\n    prompt = _create_prompt_for_file_creation(os.path.basename(file_path),\n        instruction)\n    with ui_manager.show_spinner(\n        f\"AI is generating content for '{file_path}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    if code_blocks:\n        new_content = code_blocks[0][1]\n    else:\n        new_content = response.strip()\n    if not new_content:\n        ui_manager.show_error('AI did not return any content.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    print(Panel(new_content, title=\n        f'[bold yellow]Proposed content for {file_path}[/]', border_style=\n        'yellow'))\n    if ui_manager.get_user_input('Create this file? (y/n): ').lower() in ['yes'\n        , 'y']:\n        try:\n            FileCreator.create(file_path, new_content)\n            last_code = new_content\n            ui_manager.show_success(f'File created successfully: {file_path}')\n        except IOError as e:\n            ui_manager.show_error(f'Error creating file: {e}')\n    else:\n        ui_manager.show_error('File creation cancelled.')\n\n\ndef look_all_command() ->None:\n    \"\"\"\n    Finds the project manifest in memory, reads every file listed, and adds their content to memory.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first to generate a manifest.\"\n            )\n        return\n    manifest_data = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and item.get('type'\n            ) == 'directory':\n            manifest_data = item.get('content')\n            break\n    if not manifest_data or not isinstance(manifest_data, (list, tuple)\n        ) or len(manifest_data) != 2:\n        ui_manager.show_error(\n            \"Could not find a valid project manifest in memory. Please run 'look <directory>' again.\"\n            )\n        return\n    file_paths = manifest_data[1]\n    if not file_paths:\n        ui_manager.show_error('No files found in the project manifest.')\n        return\n    total_files = len(file_paths)\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Loading {total_files} files from project manifest...'):\n        for file_path_relative in file_paths:\n            full_path = os.path.join(project_root, file_path_relative)\n            if os.path.isfile(full_path):\n                try:\n                    with open(full_path, 'r', encoding='utf-8') as f:\n                        content = f.read().strip()\n                    if not any(look['file'] == full_path for look in\n                        memory_manager.memory['look']):\n                        memory_manager.add_look_data(full_path, content)\n                        loaded_count += 1\n                except Exception as e:\n                    print(\n                        f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\"\n                        )\n    ui_manager.show_success(\n        f'\u2705 Loaded content for {loaded_count} new files into memory.')\n\n\ndef _load_all_project_files_if_needed():\n    \"\"\"\n    Checks if a project is loaded and automatically loads any files from its\n    manifest that are not already in the 'look' memory. This ensures a\n    complete context for editing and refactoring commands.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        return\n    manifest_content = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and 'File:' in item.get('content',\n            ''):\n            manifest_content = item['content']\n            break\n    if not manifest_content:\n        return\n    existing_file_paths = {item['file'] for item in memory_manager.memory.\n        get('look', []) if item.get('type') == 'file'}\n    file_paths_relative = re.findall('File: (.*)', manifest_content)\n    files_to_load = []\n    for rel_path in file_paths_relative:\n        full_path = os.path.join(project_root, rel_path)\n        if full_path not in existing_file_paths and os.path.isfile(full_path):\n            files_to_load.append((full_path, rel_path))\n    if not files_to_load:\n        return\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Auto-loading {len(files_to_load)} project files for context...'):\n        for full_path, file_path_relative in files_to_load:\n            try:\n                with open(full_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n                memory_manager.add_look_data(full_path, content)\n                loaded_count += 1\n            except Exception as e:\n                print(f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\")\n    if loaded_count > 0:\n        ui_manager.show_success(\n            f'\u2705 Loaded {loaded_count} new file(s) into memory for full project context.'\n            )\n\n\ndef _create_prompt_for_element_selection(file_name: str, instruction: str,\n    elements: List[str], element_structures: Dict[str, Dict]) ->str:\n    \"\"\"\n    Create a helper for the first stage of the 'edit' command. This prompt asks the AI\n    to analyze the user's instruction and intelligently select the most relevant code element to modify.\n    \"\"\"\n    element_details = []\n    for elem in elements:\n        if elem in element_structures:\n            struct = element_structures[elem]\n            detail = (\n                f\"{elem} ({struct['type']}, lines {struct['line_start']}-{struct['line_end']})\"\n                )\n            element_details.append(detail)\n        else:\n            element_details.append(elem)\n    elements_str = ', '.join(element_details) if element_details else 'None'\n    return f\"\"\"You are an expert code analyzer. Your task is to identify what should be modified based on the user's instruction.\n\nFile: {file_name}\nAvailable elements: {elements_str}\n\nUser instruction: {instruction}\n\nRESPONSE FORMAT:\nChoose one of these response types:\n1. \"ELEMENT: <element_name>\" - to edit an entire function/class\n2. \"PARTIAL: <element_name> LINES: <start>-<end>\" - to edit specific lines within an element\n3. \"FILE\" - to edit the entire file or multiple elements\n\nVALID ELEMENT NAMES:\n{chr(10).join(f'- {elem}' for elem in elements) if elements else 'None'}\n\nRULES:\n- If the instruction mentions specific line numbers or a specific part of a function, use PARTIAL\n- If the instruction targets an entire function/class, use ELEMENT\n- If the instruction requires changes to multiple elements or file structure, use FILE\n- For PARTIAL edits, provide absolute line numbers from the original file\n- ONLY use element names from the \"Available elements\" list above\n- If no suitable element exists, use \"FILE\"\n- NEVER return an element name that is not in the available list\n\nWhat should be edited?\"\"\"\n\n\ndef _create_prompt_for_element_rewrite(file_name: str, element_name: str,\n    instruction: str, original_code: str, is_full_file: bool=False) ->str:\n    \"\"\"\n    Create a helper for the second stage of the 'edit' command. This prompt instructs the AI\n    to rewrite a specific code element (or the whole file) based on the user's request,\n    demanding a complete and syntactically correct code block as output.\n    \"\"\"\n    if is_full_file:\n        return f\"\"\"You are an expert programmer. Rewrite the entire file to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the entire file\n- Ensure all syntax is correct and the code is ready to run\n- Preserve existing functionality unless explicitly asked to change it\n- Include all necessary imports and maintain the file's structure\n- Do NOT include any explanations or comments outside the code\n\nFile: {file_name}\nTask: {instruction}\n\nCurrent file content:\n```python\n{original_code}\n```\n\nGenerate the complete updated file now:\"\"\"\n    else:\n        return f\"\"\"You are an expert programmer. Rewrite the specified element to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the element\n- Include any necessary imports at the top of your code block\n- Ensure the code is syntactically correct and maintains the same interface\n- Do NOT include explanations or comments outside the code block\n- The code must be a drop-in replacement for the original element\n\nFile: {file_name}\nElement to modify: {element_name}\nTask: {instruction}\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the complete updated element now:\"\"\"\n\n\ndef _create_prompt_for_partial_edit(file_name: str, element_name: str,\n    instruction: str, original_snippet: str, line_start: int, line_end: int,\n    full_element_code: str) ->str:\n    \"\"\"\n    Create a prompt for partial edits within a function or class.\n    This allows surgical changes to specific parts of code.\n    \"\"\"\n    return f\"\"\"You are an expert programmer. Make a surgical edit to a specific part of a function/class.\n\nCONTEXT:\n- File: {file_name}\n- Element: {element_name}\n- Lines to modify: {line_start}-{line_end}\n- Task: {instruction}\n\nIMPORTANT RULES:\n- Provide ONLY the code that will replace lines {line_start}-{line_end}\n- Your code must fit seamlessly into the existing function\n- Maintain proper indentation (the code will be auto-indented)\n- Do NOT include the function definition or other parts\n- Do NOT include explanations outside the code\n\nFull element for context:\n```python\n{full_element_code}\n```\n\nCode section to replace (lines {line_start}-{line_end}):\n```python\n{original_snippet}\n```\n\nGenerate ONLY the replacement code for the specified lines:\"\"\"\n\n\ndef handle_file_edit_command(file_path: str, instruction: str):\n    \"\"\"\n    Handles the entire workflow for editing a single file, ensuring full\n    project context is loaded before the AI makes any decisions.\n    Now supports partial edits within functions.\n    \"\"\"\n    global last_code\n    _load_all_project_files_if_needed()\n    resolved_path = resolve_file_path(file_path)\n    if not resolved_path:\n        ui_manager.show_error(f'File not found: {file_path}')\n        return\n    if resolved_path != os.path.abspath(file_path):\n        ui_manager.show_success(\n            f\"Found '{file_path}' in project. Using: {resolved_path}\")\n    try:\n        editor = CodeEditor(resolved_path)\n    except (ValueError, FileNotFoundError) as e:\n        ui_manager.show_error(str(e))\n        return\n    elements = editor.list_elements()\n    element_structures = {}\n    for elem in elements:\n        struct = editor.get_element_structure(elem)\n        if struct:\n            element_structures[elem] = struct\n    prompt1 = _create_prompt_for_element_selection(os.path.basename(\n        resolved_path), instruction, elements, element_structures)\n    with ui_manager.show_spinner('AI is analyzing file...'):\n        ai_response = query_llm(prompt1).strip()\n    if ai_response.upper() == 'FILE':\n        ui_manager.show_success('AI has chosen to edit the entire file.')\n        original_snippet = editor.source_code\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), 'entire file', instruction, original_snippet,\n            is_full_file=True)\n        edit_type = 'FILE'\n        element_to_edit = None\n        line_range = None\n    elif ai_response.startswith('PARTIAL:'):\n        parts = ai_response.split()\n        element_to_edit = parts[1]\n        if 'LINES:' in ai_response:\n            line_part = ai_response.split('LINES:')[1].strip()\n            if '-' in line_part:\n                line_start, line_end = map(int, line_part.split('-'))\n                line_range = line_start, line_end\n            else:\n                ui_manager.show_error('Invalid line range format')\n                return\n        else:\n            ui_manager.show_error('Missing line range for partial edit')\n            return\n        if element_to_edit not in elements:\n            ui_manager.show_error(f\"Element '{element_to_edit}' not found\")\n            return\n        ui_manager.show_success(\n            f\"AI selected partial edit of '{element_to_edit}' (lines {line_start}-{line_end})\"\n            )\n        original_snippet = editor.get_element_body_snippet(element_to_edit,\n            line_start, line_end)\n        if not original_snippet:\n            original_snippet = editor.get_source_of(element_to_edit)\n        full_element_code = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_partial_edit(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet,\n            line_start, line_end, full_element_code)\n        edit_type = 'PARTIAL'\n    elif ai_response.startswith('ELEMENT:'):\n        element_to_edit = ai_response.split(':', 1)[1].strip()\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    else:\n        element_to_edit = ai_response.splitlines()[0]\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    with ui_manager.show_spinner(f'AI is editing...'):\n        response = query_llm(prompt2)\n    code_blocks = extract_code(response)\n    if not code_blocks:\n        ui_manager.show_error('AI did not return a valid code block.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    new_code = code_blocks[0][1]\n    success = False\n    if edit_type == 'FILE':\n        try:\n            editor.tree = ast.parse(new_code)\n            success = True\n        except SyntaxError as e:\n            ui_manager.show_error(f'AI returned invalid Python syntax: {e}')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    elif edit_type == 'PARTIAL':\n        success = editor.replace_partial(element_to_edit, new_code,\n            line_start=line_range[0], line_end=line_range[1])\n        if not success:\n            ui_manager.show_error('Failed to apply partial edit.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    else:\n        success = editor.replace_element(element_to_edit, new_code)\n        if not success:\n            ui_manager.show_error(\n                'AI returned invalid code; could not be parsed or applied.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    if not (diff := editor.get_diff()):\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(diff, title=\n        f'[bold yellow]Proposed Changes for {resolved_path}[/]'))\n    if ui_manager.get_user_input('Apply changes? (y/n): ').lower() in ['yes',\n        'y']:\n        editor.save_changes()\n        last_code = editor.get_modified_source()\n        ui_manager.show_success(f'Changes saved to {resolved_path}.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_plan(instruction: str, memory_context: str\n    ) ->str:\n    \"\"\"\n    Create a specialized prompt-generation function for the 'refactor' command.\n    This prompt will explicitly define the required JSON structure for the plan\n    and instruct the AI to act as an expert project manager.\n    \"\"\"\n    return f\"\"\"You are an expert project manager and software architect. Analyze the project context and create a detailed refactoring plan.\n\nYour plan must be a valid JSON object with this exact structure:\n{{\n    \"actions\": [\n        {{\n            \"type\": \"MODIFY\" | \"CREATE\" | \"DELETE\" | \"PARTIAL\",\n            \"file\": \"relative/path/to/file.py\",\n            \"element\": \"function_or_class_name\",  // For MODIFY/DELETE/PARTIAL\n            \"element_name\": \"new_element_name\",    // For CREATE\n            \"line_start\": 10,                      // For PARTIAL only\n            \"line_end\": 20,                        // For PARTIAL only\n            \"reason\": \"Clear explanation of why this change is needed\",\n            \"description\": \"What this action will accomplish\",\n            \"anchor_element\": \"optional_anchor\",   // Optional for CREATE\n            \"position\": \"before\" | \"after\"         // Optional for CREATE\n        }}\n    ]\n}}\n\nACTION TYPES:\n- MODIFY: Change an entire function, class, or method\n- PARTIAL: Change specific lines within a function/class (requires line_start and line_end)\n- CREATE: Add new functions, classes, or files\n- DELETE: Remove functions, classes, variables, or imports\n\nRULES FOR YOUR PLAN:\n- Use PARTIAL when you only need to change a small part of a function\n- Use MODIFY when restructuring an entire function or class\n- Each action must have all required fields based on its type\n- File paths must be relative to the project root\n- Be specific and surgical - avoid unnecessary changes\n- Consider dependencies between changes\n- Order actions logically (e.g., create dependencies before using them)\n\n### Project Context ###\n{memory_context}\n\n### Refactoring Request ###\n{instruction}\n\nGenerate ONLY the JSON plan - no explanations or markdown:\"\"\"\n\n\ndef _get_refactor_plan(instruction: str) ->Optional[List[Dict]]:\n    \"\"\"\n    Generates a refactoring plan from the LLM.\n\n    This function encapsulates the logic for checking project context,\n    constructing a prompt, querying the LLM, and parsing the resulting\n    JSON plan for a refactoring task.\n\n    Args:\n        instruction: The user's high-level refactoring instruction.\n\n    Returns:\n        A list of action dictionaries if a valid plan is generated,\n        otherwise None.\n    \"\"\"\n    if not memory_manager.get_project_root():\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return None\n    memory_context = memory_manager.get_memory_context()\n    plan_prompt = _create_prompt_for_refactor_plan(instruction, memory_context)\n    with ui_manager.show_spinner('AI is creating an execution plan...'):\n        plan_str = query_llm(plan_prompt)\n    try:\n        match = re.search('\\\\{.*\\\\}', plan_str, re.DOTALL)\n        if not match:\n            raise ValueError('No JSON object found in the response.')\n        plan = json.loads(match.group(0))\n        actions = plan.get('actions', [])\n        if not actions:\n            raise ValueError(\"No 'actions' key found in plan or plan is empty.\"\n                )\n        return actions\n    except (json.JSONDecodeError, ValueError) as e:\n        ui_manager.show_error(f'AI failed to generate a valid plan: {e}')\n        print(Panel(plan_str, title=\"[yellow]AI's Invalid Plan Response[/]\",\n            border_style='yellow'))\n        return None\n\n\ndef _display_and_confirm_plan(plan: Dict) ->bool:\n    \"\"\"\n    Displays the generated execution plan to the user and asks for confirmation.\n\n    This helper function separates the UI interaction of plan confirmation from\n    the main refactoring logic.\n\n    Args:\n        plan: A dictionary, expected to contain an 'actions' key with a list of action dicts.\n\n    Returns:\n        True if the user confirms the plan, False otherwise.\n    \"\"\"\n    actions = plan.get('actions', [])\n    if not actions:\n        ui_manager.show_error('The generated plan is empty. Aborting.')\n        return False\n    ui_manager.show_success('AI has created a plan:')\n    for i, action in enumerate(actions):\n        action_type = action.get('type', 'N/A')\n        element = action.get('element') or action.get('element_name', 'N/A')\n        reason = action.get('reason') or action.get('description', '')\n        file_path = action.get('file', '')\n        if action_type == 'PARTIAL':\n            line_start = action.get('line_start', '?')\n            line_end = action.get('line_end', '?')\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} (lines {line_start}-{line_end}) - {reason}'\n                )\n        else:\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} - {reason}'\n                )\n    if ui_manager.get_user_input('\\nProceed with this plan? (y/n): ').lower(\n        ) in ['yes', 'y']:\n        return True\n    else:\n        ui_manager.show_error('Execution aborted by user.')\n        return False\n\n\ndef _apply_refactor_changes(editors: Dict[str, CodeEditor]) ->None:\n    \"\"\"\n    Consolidates changes from multiple CodeEditor instances, shows a unified\n    diff, and prompts the user to apply them.\n    \n    This helper function abstracts the final step of a refactor, ensuring\n    all proposed modifications are presented to the user for a final review\n    before any files are written to disk.\n\n    Args:\n        editors: A dictionary mapping absolute file paths to their\n                 corresponding CodeEditor instances which hold the\n                 proposed changes in their AST.\n    \"\"\"\n    full_diff = ''\n    for editor in editors.values():\n        diff = editor.get_diff()\n        if diff:\n            full_diff += diff + '\\n'\n    if not full_diff.strip():\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(full_diff, title=\n        '[bold yellow]Proposed Project-Wide Changes[/]'))\n    if ui_manager.get_user_input('Apply all changes? (y/n): ').lower() in [\n        'yes', 'y']:\n        for editor in editors.values():\n            editor.save_changes()\n        ui_manager.show_success('\u2705 Project changes applied successfully.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_action(action_type: str, file_path: str,\n    action_details: Dict) ->str:\n    \"\"\"\n    Create a helper to generate prompts for individual 'CREATE' or 'MODIFY' steps\n    within a refactor plan. This ensures the AI produces code for the specific\n    sub-task in the correct context.\n    \"\"\"\n    if action_type == 'MODIFY':\n        element_name = action_details['element_name']\n        reason = action_details['reason']\n        original_code = action_details['original_code']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- Element: {element_name}\n- Reason for change: {reason}\n\nRULES:\n- Provide ONLY the complete updated code for the element\n- Include any necessary imports at the top\n- Ensure the code integrates properly with the rest of the file\n- Maintain the same function/class signature unless the change requires otherwise\n- No explanations outside the code block\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the updated element code:\"\"\"\n    elif action_type == 'CREATE':\n        element_name = action_details['element_name']\n        description = action_details['description']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- New element to create: {element_name}\n- Purpose: {description}\n\nRULES:\n- Provide ONLY the complete code for the new element\n- Include all necessary imports at the top\n- Follow the coding style and patterns used in the project\n- Ensure the code is production-ready and well-structured\n- For non-Python files, provide the complete file content\n- No explanations outside the code block\n\nGenerate the new element code:\"\"\"\n\n\ndef _process_refactor_action(action: Dict, project_base_path: str, editors:\n    Dict) ->bool:\n    \"\"\"\n    Processes a single refactoring action from the plan.\n\n    This function handles the execution of a single action from the refactoring plan,\n    including LLM code generation and applying changes to in-memory editors or files.\n\n    Args:\n        action: A dictionary containing action details (type, file, element, etc.)\n        project_base_path: The absolute path to the project root\n        editors: Dictionary mapping file paths to their CodeEditor instances\n\n    Returns:\n        True if the action was processed successfully, False otherwise\n    \"\"\"\n    file_path_relative = action.get('file')\n    if not file_path_relative:\n        ui_manager.show_error(\n            f\"Action is missing 'file' key. Skipping: {action}\")\n        return False\n    file_path_absolute = os.path.join(project_base_path, file_path_relative)\n    action_type = action.get('type', '').upper()\n    prompt, element_name = '', ''\n    if action_type == 'MODIFY':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_source_of(element_name)\n            if not original_snippet:\n                ui_manager.show_error(\n                    f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                    )\n                return False\n            action_details = {'element_name': element_name, 'reason':\n                reason, 'original_code': original_snippet}\n            prompt = _create_prompt_for_refactor_action('MODIFY',\n                file_path_relative, action_details)\n    elif action_type == 'PARTIAL':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        line_start = action.get('line_start')\n        line_end = action.get('line_end')\n        if not all([element_name, line_start, line_end]):\n            ui_manager.show_error(\n                f'PARTIAL action missing required fields. Skipping: {action}')\n            return False\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_element_body_snippet(element_name,\n                line_start, line_end)\n            if not original_snippet:\n                original_snippet = editor.get_source_of(element_name)\n                if not original_snippet:\n                    ui_manager.show_error(\n                        f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                        )\n                    return False\n            full_element_code = editor.get_source_of(element_name)\n            prompt = _create_prompt_for_partial_edit(file_path_relative,\n                element_name, reason, original_snippet, line_start,\n                line_end, full_element_code)\n    elif action_type == 'CREATE':\n        element_name = action.get('element_name')\n        description = action.get('description')\n        action_details = {'element_name': element_name, 'description':\n            description}\n        prompt = _create_prompt_for_refactor_action('CREATE',\n            file_path_relative, action_details)\n    else:\n        ui_manager.show_error(f\"Invalid action type '{action_type}'. Skipping.\"\n            )\n        return False\n    with ui_manager.show_spinner(\n        f\"AI: {action_type} on '{element_name or file_path_relative}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    new_content = code_blocks[0][1] if code_blocks else response.strip()\n    if not new_content:\n        ui_manager.show_error(\n            f'AI failed to generate content for action: {action}')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return False\n    if not file_path_relative.endswith('.py'):\n        try:\n            FileCreator.create(file_path_absolute, new_content)\n            ui_manager.show_success(\n                f\"File '{file_path_relative}' created/updated.\")\n            return True\n        except IOError as e:\n            ui_manager.show_error(\n                f\"Failed to create file '{file_path_relative}': {e}\")\n            return False\n    if file_path_absolute not in editors:\n        try:\n            if not os.path.exists(file_path_absolute):\n                os.makedirs(os.path.dirname(file_path_absolute), exist_ok=True)\n                with open(file_path_absolute, 'w') as f:\n                    f.write('')\n            editors[file_path_absolute] = CodeEditor(file_path_absolute)\n        except Exception as e:\n            ui_manager.show_error(\n                f'Error loading file {file_path_absolute}: {e}')\n            return False\n    editor = editors[file_path_absolute]\n    if action_type == 'MODIFY':\n        if not editor.replace_element(element_name, new_content):\n            ui_manager.show_error(\n                f\"Failed to apply MODIFY change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic MODIFY Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'PARTIAL':\n        if not editor.replace_partial(element_name, new_content, line_start,\n            line_end):\n            ui_manager.show_error(\n                f\"Failed to apply PARTIAL change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic PARTIAL Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'CREATE':\n        anchor = action.get('anchor_element')\n        position = action.get('position', 'after')\n        if not editor.add_element(new_content, anchor_name=anchor, before=\n            position == 'before'):\n            ui_manager.show_error(\n                f\"Failed to apply CREATE change for '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic CREATE Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    return True\n\n\ndef handle_project_refactor_command(instruction: str):\n    \"\"\"\n    Orchestrates a multi-file, multi-step code refactoring process.\n    \n    This function serves as a high-level orchestrator that delegates specific tasks\n    to helper functions, improving readability, modularity, and maintainability.\n    \"\"\"\n    _load_all_project_files_if_needed()\n    actions = _get_refactor_plan(instruction)\n    if not actions:\n        return\n    plan = {'actions': actions}\n    if not _display_and_confirm_plan(plan):\n        return\n    editors: Dict[str, CodeEditor] = {}\n    project_base_path = memory_manager.get_project_root()\n    successful_actions = 0\n    total_actions = len(actions)\n    for i, action in enumerate(actions, 1):\n        ui_manager.show_success(f'Processing action {i}/{total_actions}...')\n        action_type = action.get('type', '').upper()\n        file_path_relative = action.get('file')\n        if not file_path_relative:\n            ui_manager.show_error(\n                f\"Action is missing 'file' key. Skipping: {action}\")\n            continue\n        file_path_absolute = os.path.join(project_base_path, file_path_relative\n            )\n        if action_type == 'DELETE':\n            element_name = action.get('element')\n            if not element_name:\n                ui_manager.show_error(\n                    f\"DELETE action missing 'element' key. Skipping: {action}\")\n                continue\n            if not file_path_relative.endswith('.py'):\n                ui_manager.show_error(\n                    f'DELETE actions are only supported for Python files. Skipping.'\n                    )\n                continue\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    continue\n            editor = editors[file_path_absolute]\n            if editor.delete_element(element_name):\n                successful_actions += 1\n                ui_manager.show_success(\n                    f\"Successfully deleted '{element_name}' from '{file_path_relative}'.\"\n                    )\n            else:\n                ui_manager.show_error(\n                    f\"Failed to delete '{element_name}' from '{file_path_relative}'.\"\n                    )\n        elif _process_refactor_action(action, project_base_path, editors):\n            successful_actions += 1\n        else:\n            ui_manager.show_error(\n                f'Action {i} failed, continuing with remaining actions...')\n    if successful_actions == 0:\n        ui_manager.show_error('No actions were successfully executed.')\n        return\n    elif successful_actions < total_actions:\n        ui_manager.show_error(\n            f'Only {successful_actions}/{total_actions} actions completed successfully.'\n            )\n    else:\n        ui_manager.show_success(\n            f'All {total_actions} actions completed successfully.')\n    _apply_refactor_changes(editors)\n\n\ndef _create_prompt_for_commit_message(diff: str) ->str:\n    \"\"\"\n    Create a dedicated prompt function for the 'commit' command. This prompt will\n    instruct the AI to analyze a git diff and generate a concise commit message\n    following the Conventional Commits standard.\n    \"\"\"\n    return f\"\"\"You are an expert developer writing a Git commit message. Your task is to analyze the provided git diff and create a professional commit message.\n\nCOMMIT MESSAGE RULES:\n- Follow the Conventional Commits specification\n- Format: <type>(<optional scope>): <subject>\n- Types: feat, fix, docs, style, refactor, perf, test, build, ci, chore, revert\n- Subject line: max 50 characters, imperative mood, no period\n- Optional body: explain what and why (not how), wrap at 72 characters\n- Be specific and concise\n- Focus on the intent and impact of the changes\n\nEXAMPLES OF GOOD COMMIT MESSAGES:\n- feat(auth): add OAuth2 integration for Google login\n- fix(api): handle null response in user endpoint\n- refactor(database): optimize query performance for large datasets\n- docs(readme): update installation instructions for Windows\n\nRespond with ONLY the commit message - no markdown, quotes, or explanations.\n\n--- GIT DIFF TO ANALYZE ---\n{diff}\n\nGenerate the commit message:\"\"\"\n\n\ndef handle_commit_command():\n    \"\"\"\n    Orchestrates an AI-assisted Git commit workflow with improved error handling.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return\n    try:\n        git_manager = GitManager(project_root)\n    except ValueError as e:\n        ui_manager.show_error(str(e))\n        return\n    changed_files = git_manager.get_changed_files()\n    if not changed_files:\n        ui_manager.show_success(\n            'No changes to commit. Everything is up to date.')\n        return\n    staged_diff = git_manager.get_diff(staged=True)\n    unstaged_diff = git_manager.get_diff()\n    full_diff = f'{staged_diff}\\n{unstaged_diff}'.strip()\n    if not full_diff.strip():\n        ui_manager.show_success(\n            'No content changes detected (e.g., only file mode changes).')\n        return\n    prompt = _create_prompt_for_commit_message(full_diff)\n    commit_message = query_llm(prompt).strip()\n    if not commit_message:\n        ui_manager.show_error(\n            'AI failed to generate a commit message. Aborting.')\n        return\n    files_to_commit_str = '\\n'.join(f'- {f}' for f in changed_files)\n    plan_panel_content = f\"\"\"[bold]Files to be staged:[/]\n[yellow]{files_to_commit_str}[/]\n\n[bold]AI-Generated Commit Message:[/]\n[green]{commit_message}[/]\"\"\"\n    print(Panel(plan_panel_content, title='[bold cyan]Commit Plan[/]',\n        border_style='cyan'))\n    if ui_manager.get_user_input('\\nProceed with commit? (y/n): ').lower() in [\n        'yes', 'y']:\n        try:\n            git_manager.add(changed_files)\n            ui_manager.show_success('\u2705 Files staged.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Staging failed: {e.stderr}')\n            return\n        try:\n            git_manager.commit(commit_message)\n            ui_manager.show_success('\u2705 Commit successful.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Commit failed: {e.stderr}')\n            return\n        if ui_manager.get_user_input('Push changes to remote? (y/n): ').lower(\n            ) in ['yes', 'y']:\n            try:\n                git_manager.push()\n                ui_manager.show_success('\u2705 Push successful.')\n            except subprocess.CalledProcessError as e:\n                ui_manager.show_error(f'Push failed: {e.stderr}')\n        else:\n            ui_manager.show_error('Push cancelled.')\n    else:\n        ui_manager.show_error('Commit aborted by user.')\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef interactive_mode() ->None:\n    global last_query, last_response, last_code\n    try:\n        from Testing.overlay_engine import show_sequential_popup\n        gui_available = True\n    except ImportError:\n        gui_available = False\n    print(Panel(\n        \"\"\"[bold cyan]Omni Interactive Mode[/]\n[dim]Type 'help' for commands, 'exit' to quit.[/dim]\"\"\"\n        , border_style='cyan'))\n    personality_name = personality_manager.get_current_personality().get('name'\n        , 'Default')\n    gui_enabled = False\n    if gui_available:\n        try:\n            with open(CONFIG_FILE, 'r') as f:\n                config = json.load(f)\n                if config.get('gui_enabled', False):\n                    gui_enabled = True\n        except (FileNotFoundError, json.JSONDecodeError):\n            pass\n    refresh_status_panel(personality_name)\n    while True:\n        try:\n            user_input = ui_manager.get_user_input('\\n> ')\n            if not user_input:\n                continue\n            command, *args = user_input.split(maxsplit=1)\n            arg_str = args[0] if args else ''\n            if command == 'exit':\n                memory_manager.save_memory()\n                print('[bold cyan]Goodbye![/]')\n                break\n            elif command == 'help':\n                print(\n                    \"\"\"[bold]Commands:[/]\n\n  [bold cyan]Core & Project Commands[/]\n  [yellow]send <prompt>[/]        - Ask the LLM a question.\n  [yellow]look <path>[/]          - Read file or scan directory into memory.\n  [yellow]look_all[/]            - Recursively scan the project directory into memory.\n  [yellow]create <file> \"instr\"[/] - Create a new file using AI.\n  [yellow]edit <file> \"instr\"[/]   - Edit a specific file using AI.\n  [yellow]refactor \"instr\"[/]      - Refactor project in memory based on instruction.\n  [yellow]commit[/]               - Commit changes with an AI-generated message.\n  [yellow]rag <query>[/]         - Query the RAG system for context retrieval.\n\n  [bold cyan]File & Code Management[/]\n  [yellow]save <filename>[/]     - Save last AI response to a file.\n  [yellow]list[/]               - List saved files.\n  [yellow]run[/]                 - Run the last generated Python code.\n\n  [bold cyan]Session & Config[/]\n  [yellow]history[/]             - Show the full chat history.\n  [yellow]memory clear[/]        - Clear the chat and file memory.\n  [yellow]backend <name>[/]      - Switch AI backend (e.g., openrouter, ollama).\n  [yellow]models [src][/]        - Interactively list and select models.\n  [yellow]set model <id>[/]      - Set the model directly by its ID.\n  [yellow]personality <cmd>[/]   - Manage AI personalities ('list', 'set', 'add').\n\"\"\"\n                    )\n            elif command == 'send':\n                last_query = arg_str\n                response = query_llm(arg_str)\n                last_response = response\n                memory_manager.add_chat_message('user', last_query)\n                memory_manager.add_chat_message('assistant', last_response)\n                if gui_enabled:\n                    threading.Thread(target=show_sequential_popup, args=(\n                        100, 100, response, f'Omni - {personality_name}'),\n                        daemon=True).start()\n                print(Panel(response, title='[cyan]Response[/]'))\n                if (code_blocks := extract_code(response)):\n                    last_code = code_blocks[0][1]\n            elif command == 'look':\n                look_command(arg_str)\n            elif command == 'look_all':\n                look_all_command()\n            elif command == 'create':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_create_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: create <file_path> \"<instruction>\"')\n            elif command == 'edit':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_edit_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: edit <file_path> \"<instruction>\"')\n            elif command == 'refactor':\n                if not arg_str:\n                    ui_manager.show_error('Usage: refactor \"<instruction>\"')\n                else:\n                    handle_project_refactor_command(arg_str.strip('\"'))\n            elif command == 'commit':\n                handle_commit_command()\n            elif command == 'models':\n                list_models(arg_str.split())\n            elif command == 'set' and arg_str.startswith('model '):\n                set_model(arg_str[6:])\n            elif command == 'backend':\n                switch_backend(arg_str)\n            elif command == 'history':\n                ui_manager.display_history(memory_manager.get_memory_context())\n            elif command == 'memory' and arg_str == 'clear':\n                memory_manager.clear_memory()\n                ui_manager.show_success('\u2705 Memory cleared')\n            elif command == 'personality':\n                p_args = arg_str.split(maxsplit=1)\n                cmd = p_args[0] if p_args else ''\n                p_arg_str = p_args[1] if len(p_args) > 1 else ''\n                if cmd == 'list':\n                    for p in personality_manager.list_personalities():\n                        print(f\"- {p['name']}: {p['description']}\")\n                elif cmd == 'set' and p_arg_str:\n                    if personality_manager.set_current_personality(p_arg_str):\n                        personality_name = p_arg_str\n                        ui_manager.show_success(\n                            f'Set personality to {personality_name}')\n                    else:\n                        ui_manager.show_error('Personality not found.')\n                else:\n                    ui_manager.show_error(\n                        \"Invalid personality command. Use 'list' or 'set <name>'.\"\n                        )\n            elif command == 'run':\n                run_python_code()\n            elif command == 'save':\n                if last_response:\n                    save_code(last_response, arg_str or\n                        f\"omni_save_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n                        )\n                else:\n                    ui_manager.show_error('No response to save.')\n            elif command == 'list':\n                files = sorted(os.listdir(DEFAULT_SAVE_DIR))\n                print('\\n'.join(f'  - {f}' for f in files) if files else\n                    '[yellow]No saved files.[/]')\n            elif command == 'rag':\n                if not arg_str:\n                    ui_manager.show_error('Usage: rag \"<query>\"')\n                else:\n                    from rag_manager import RAGManager\n                    project_root = memory_manager.get_project_root()\n                    if not project_root:\n                        ui_manager.show_error(\n                            \"No project context in memory. Use 'look <directory>' first.\"\n                            )\n                        continue\n                    rag = RAGManager()\n                    if rag.get_document_count() == 0:\n                        ui_manager.show_error(\n                            'RAG index is empty. Please add documents first.')\n                        continue\n                    results = rag.search(arg_str, k=3)\n                    if not results:\n                        ui_manager.show_error('No relevant documents found.')\n                        continue\n                    print(Panel('[bold]RAG Results:[/]', title=\n                        '[cyan]Retrieval-Augmented Generation[/]'))\n                    for i, (content, score, metadata) in enumerate(results, 1):\n                        file_path = metadata.get('file', 'Unknown')\n                        print(\n                            f'[bold cyan]{i}. {file_path}[/] (Score: {score:.4f})'\n                            )\n                        print(Panel(content[:500] + '...' if len(content) >\n                            500 else content, border_style='dim'))\n                    follow_up = ui_manager.get_user_input(\n                        \"\"\"\nWould you like to ask a follow-up question with this context? (y/n): \"\"\"\n                        )\n                    if follow_up.lower() in ['y', 'yes']:\n                        follow_up_query = ui_manager.get_user_input(\n                            'Follow-up query: ')\n                        if follow_up_query:\n                            context_parts = [\n                                f'Document {i} (Score: {score:.4f}):\\n{content}'\n                                 for i, (content, score, _) in enumerate(\n                                results, 1)]\n                            context = '\\n\\n'.join(context_parts)\n                            rag_prompt = f\"\"\"Based on the following context, please answer the question.\n\nContext:\n{context}\n\nQuestion: {follow_up_query}\"\"\"\n                            response = query_llm(rag_prompt)\n                            print(Panel(response, title=\n                                '[cyan]RAG-Augmented Response[/]'))\n            else:\n                ui_manager.show_error(\"Unknown command. Type 'help'.\")\n            refresh_status_panel(personality_name)\n        except KeyboardInterrupt:\n            memory_manager.save_memory()\n            print('\\n[bold cyan]Goodbye![/]')\n            break\n        except Exception as e:\n            ui_manager.show_error(f'An unexpected error occurred: {e}')\n\n\ndef run_python_code() ->None:\n    global last_code\n    if not last_code:\n        ui_manager.show_error('No Python code in memory to run.')\n        return\n    temp_file = os.path.join(DEFAULT_SAVE_DIR, 'temp_run.py')\n    try:\n        with open(temp_file, 'w') as f:\n            f.write(last_code)\n        print('[bold cyan]\\n--- Running Code ---\\n[/]')\n        subprocess.run([sys.executable, temp_file], check=True)\n        print('[bold cyan]\\n--- Code Finished ---\\n[/]')\n    except Exception as e:\n        ui_manager.show_error(f'Error running code: {e}')\n    finally:\n        if os.path.exists(temp_file):\n            os.remove(temp_file)\n\n\ndef save_code(content: str, filename: str) ->None:\n    filepath = os.path.join(DEFAULT_SAVE_DIR, filename)\n    try:\n        with open(filepath, 'w') as f:\n            f.write(content)\n        ui_manager.show_success(f'Saved to: {filepath}')\n    except IOError as e:\n        ui_manager.show_error(f'Error saving file: {e}')\n\n\ndef main() ->None:\n    try:\n        import astor\n    except ImportError:\n        print(\"[bold red]Error:[/] 'astor' is required. `pip install astor`\")\n        sys.exit(1)\n    try:\n        import simple_term_menu\n    except ImportError:\n        print(\n            \"[bold red]Error:[/] 'simple-term-menu' is required. `pip install simple-term-menu`\"\n            )\n        sys.exit(1)\n    parser = argparse.ArgumentParser(description=\n        'Omni - AI-powered code tool', add_help=False)\n    parser.add_argument('command', nargs='?', help='Main command.')\n    parser.add_argument('args', nargs='*', help='Arguments for the command.')\n    parser.add_argument('-h', '--help', action='store_true')\n    args, _ = parser.parse_known_args()\n    if args.help or not args.command:\n        interactive_mode()\n    elif args.command == 'look' and args.args:\n        look_command(args.args[0])\n    elif args.command == 'edit' and len(args.args) >= 2:\n        handle_file_edit_command(args.args[0], ' '.join(args.args[1:]))\n    elif args.command == 'models':\n        list_models(args.args)\n    else:\n        interactive_mode()\n\n\ndef refresh_status_panel(personality_name: str) ->None:\n    ui_manager.display_status_panel(personality_name, current_backend,\n        current_model, len(memory_manager.memory.get('chat', [])), len(\n        memory_manager.memory.get('look', [])))\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/omni.py"
  },
  {
    "id": 172,
    "hash": "db1585da7840e9dc17f3ab8c0a19f6f2",
    "content": "import json\nfrom typing import Dict, List, Optional\n\nclass PersonalityManager:\n    \"\"\"Manages AI personalities via JSON config.\"\"\"\n\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.personalities: List[Dict[str, str]] = self.load_personalities()\n        self.current_personality: Optional[str] = \"default\"  # Default\n\n    def load_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"Load personalities from JSON; auto-create if missing.\"\"\"\n        default = [{\"name\": \"default\", \"description\": \"Helpful assistant\", \"system_prompt\": \"You are a helpful AI assistant.\"}]\n        default_gui = {\n            \"gui_enabled\": True,\n            \"wake_word\": \"Jarvis\",\n            \"overlay_opacity\": 0.8,\n            \"font_size\": 16\n        }\n        try:\n            with open(self.config_file, 'r') as f:\n                data = json.load(f)\n                if \"personalities\" not in data:\n                    data[\"personalities\"] = default\n                if \"gui_enabled\" not in data:\n                    data.update(default_gui)\n                    self.save_personalities(data[\"personalities\"])  # Save with defaults\n                \n                return data[\"personalities\"]\n        except FileNotFoundError:\n            self.save_personalities(default)\n            return default\n        except json.JSONDecodeError:\n            print(\"[yellow]Invalid config. Resetting to default.[/]\")\n            self.save_personalities(default)\n            return default\n\n    def save_personalities(self, personalities: List[Dict[str, str]]) -> None:\n        \"\"\"Save with GUI config.\"\"\"\n        data = {\"personalities\": personalities}\n        data.update({\"gui_enabled\": True, \"wake_word\": \"Jarvis\", \"overlay_opacity\": 0.8, \"font_size\": 16})  # Defaults\n        with open(self.config_file, 'w') as f:\n            json.dump(data, f, indent=4)\n\n    def add_personality(self, name: str, description: str, system_prompt: str) -> None:\n        \"\"\"Add a new personality.\"\"\"\n        self.personalities.append({\"name\": name, \"description\": description, \"system_prompt\": system_prompt})\n        self.save_personalities(self.personalities)\n\n    def list_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"List all personalities.\"\"\"\n        return self.personalities\n\n    def set_current_personality(self, name: str) -> bool:\n        \"\"\"Set the current personality.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == name:\n                self.current_personality = name\n                return True\n        return False\n\n    def get_current_personality(self) -> Dict[str, str]:\n        \"\"\"Get the current personality dict.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == self.current_personality:\n                return p\n        return {}  # Fallback",
    "file": "/mnt/ProjectData/omni/personality_manager.py"
  },
  {
    "id": 173,
    "hash": "da963f141c557fe12f1a26374f3e5ff4",
    "content": "# python_ast_adapter.py\n\n\"\"\"\nPythonASTAdapter - Concrete AST adapter for Python using built-in `ast` and `astor`.\n\nThis module implements the ASTAdapter interface specifically for Python,\nleveraging the standard library's `ast` module for parsing and\nmanipulation, and `astor` for code generation.\n\"\"\"\n\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for asttokens (for enhanced partial edits)\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n    # print(\"Warning: asttokens not installed. Partial edits will be limited.\")\n\n\nclass PythonASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for Python source code.\n\n    This adapter uses Python's built-in `ast` module to parse and manipulate\n    the code, and `astor` for code generation and source-to-source transformations.\n    It holds the parsed AST tree and provides methods to interact with it\n    according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the PythonASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The Python source code as a string.\n        \"\"\"\n        # Store source code for diffing and potential asttokens use\n        self.source_code: str = source_code\n        # Will hold the parsed AST tree\n        self.tree: Optional[ast.AST] = None\n        # Will hold a mapping of element names to their AST nodes\n        self.nodes: Dict[str, ast.AST] = {}\n        # asttokens instance for enhanced source mapping (if available)\n        self.atok: Optional[asttokens.ASTTokens] = None\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the Python source code and maps elements.\n\n        Args:\n            source_code: The Python source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid Python syntax.\n        \"\"\"\n        try:\n            self.tree = ast.parse(source_code)\n        except SyntaxError as e:\n            raise ValueError(f\"Invalid Python syntax: {e}\") from e\n\n        self.nodes = self._map_nodes()\n        if ASTTOKENS_AVAILABLE:\n            try:\n                self.atok = asttokens.ASTTokens(source_code, parse=True)\n            except Exception:\n                # If asttokens fails for any reason, continue without it\n                self.atok = None\n        else:\n            self.atok = None\n\n    def _map_nodes(self) -> Dict[str, ast.AST]:\n        \"\"\"\n        Walks the AST and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their AST nodes.\n        \"\"\"\n        nodes: Dict[str, ast.AST] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        for node in ast.walk(self.tree):\n            # Map functions and classes by name\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                # Use 'not in' to prioritize top-level definitions in case of conflicts\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            # Map assignments by target variable name(s)\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            # Map imports by their alias or original name\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int, line_end: Optional[int] = None) -> Optional[Tuple[int, ast.AST]]:\n        \"\"\"\n        Finds a statement within a body based on line numbers.\n\n        Args:\n            body: The list of AST nodes representing the body.\n            line_start: The starting line number to search for.\n            line_end: The optional ending line number.\n\n        Returns:\n            A tuple of (index, statement node) if found, otherwise None.\n        \"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = getattr(stmt, 'end_lineno', stmt.lineno)\n                    # Check for overlap or containment\n                    if (stmt.lineno <= line_start <= stmt_end) or (stmt.lineno <= line_end <= stmt_end) or \\\n                       (line_start <= stmt.lineno and line_end >= stmt_end):\n                        return (i, stmt)\n                else:\n                    if stmt.lineno == line_start:\n                        return (i, stmt)\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.ImportFrom]]) -> None:\n        \"\"\"\n        Adds new import nodes to the file's AST, typically at the top.\n\n        Args:\n            new_import_nodes: A list of ast.Import or ast.ImportFrom nodes.\n        \"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return # Cannot add imports without a valid module tree\n\n        # Get string representations of existing imports to avoid duplicates\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                try:\n                    existing_imports_str.add(astor.to_source(node).strip())\n                except Exception:\n                    # If astor fails, skip adding to set (might lead to potential duplicate, but safer)\n                    pass\n                last_import_index = i\n\n        # Insert new imports after the last existing import\n        # Reverse them so they are inserted in the correct order\n        for new_import in reversed(new_import_nodes):\n            try:\n                new_import_str = astor.to_source(new_import).strip()\n                if new_import_str not in existing_imports_str:\n                    self.tree.body.insert(last_import_index + 1, new_import)\n                    last_import_index += 1 # Update index for next insertion\n            except Exception:\n                # If we can't generate source, we can't check for duplicates, skip\n                self.tree.body.insert(last_import_index + 1, new_import)\n                last_import_index += 1\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return astor.to_source(node)\n            except Exception:\n                # Handle potential astor issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.__class__.__name__,\n            'line_start': getattr(node, 'lineno', None),\n            'line_end': getattr(node, 'end_lineno', None),\n            'body_items': []\n        }\n\n        if hasattr(node, 'body'):\n            for i, item in enumerate(node.body):\n                item_info = {\n                    'index': i,\n                    'type': item.__class__.__name__,\n                    'line_start': getattr(item, 'lineno', None),\n                    'line_end': getattr(item, 'end_lineno', None)\n                }\n\n                if isinstance(item, ast.Assign) and item.targets:\n                    target = item.targets[0]\n                    if isinstance(target, ast.Name):\n                        item_info['assigns'] = target.id\n                elif isinstance(item, (ast.If, ast.While, ast.For)):\n                    item_info['has_body'] = bool(getattr(item, 'body', None))\n                elif isinstance(item, ast.Return):\n                    item_info['returns'] = True\n\n                structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        if not self.atok:\n            return None # asttokens is required for precise original source retrieval\n\n        node = self.nodes.get(element_name)\n        if not node or not hasattr(node, 'body'):\n            return None\n\n        statements = []\n        for stmt in node.body:\n            if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                 # Check for overlap or containment of the statement within the requested range\n                stmt_start = stmt.lineno\n                stmt_end = stmt.end_lineno\n                if (stmt_start >= line_start and stmt_end <= line_end) or \\\n                   (stmt_start <= line_end and stmt_end >= line_start): # Overlap\n                    statements.append(stmt)\n\n        if not statements:\n            return None\n\n        # Use asttokens to get the original source text for accuracy\n        try:\n            # Combine text ranges of the found statements\n            combined_text = \"\"\n            last_end_pos = None\n            for stmt in sorted(statements, key=lambda s: s.lineno):\n                # Get the text range for the statement\n                stmt_text = self.atok.get_text_range(stmt)\n                if last_end_pos is not None and stmt_text[0] > last_end_pos:\n                     # Add the original whitespace/newlines between statements\n                    combined_text += self.source_code[last_end_pos:stmt_text[0]]\n                combined_text += self.atok.get_text(stmt)\n                last_end_pos = stmt_text[1]\n            return combined_text.strip()\n        except Exception:\n            # Fallback if asttokens text retrieval fails\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in statements)\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except SyntaxError:\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body: # Ensure there's actual code body to replace with\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # Walk the tree to find the parent node containing the element to replace\n        for parent_node in ast.walk(self.tree):\n            if hasattr(parent_node, 'body') and isinstance(parent_node.body, list):\n                try:\n                    old_node = self.nodes[element_name]\n                    idx = parent_node.body.index(old_node)\n                    # Remove the old node\n                    parent_node.body.pop(idx)\n                    # Insert the new nodes\n                    for i, new_node in enumerate(new_code_body):\n                        parent_node.body.insert(idx + i, new_node)\n\n                    # Update the nodes map: remove old, add new top-level definitions\n                    del self.nodes[element_name]\n                    for n in new_code_body:\n                        if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                            self.nodes[n.name] = n\n                    return True\n                except (ValueError, KeyError):\n                    # ValueError from index(), KeyError from accessing self.nodes\n                    continue\n        return False # Element not found in any body\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n             return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except (SyntaxError, IndexError):\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body:\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # --- Determine insertion index ---\n\n        # Find the `if __name__ == \"__main__\":` block index\n        main_block_idx = -1\n        for i, node in enumerate(self.tree.body):\n            if (isinstance(node, ast.If) and\n                isinstance(getattr(node, 'test', None), ast.Compare) and\n                isinstance(getattr(node.test, 'left', None), ast.Name) and\n                node.test.left.id == '__name__' and\n                len(getattr(node.test, 'ops', [])) == 1 and isinstance(node.test.ops[0], ast.Eq) and\n                len(getattr(node.test, 'comparators', [])) == 1):\n\n                comp = node.test.comparators[0]\n                # Check for both ast.Constant ('__main__') and older ast.Str ('__main__')\n                if ((isinstance(comp, ast.Constant) and comp.value == '__main__') or\n                    (isinstance(comp, ast.Str) and comp.s == '__main__')): # type: ignore\n                    main_block_idx = i\n                    break\n\n        insertion_index = -1\n        if anchor_name:\n            # If anchor is specified, find its index\n            if anchor_name not in self.nodes:\n                return False\n            anchor_node = self.nodes[anchor_name]\n            try:\n                anchor_idx = self.tree.body.index(anchor_node)\n                proposed_index = anchor_idx if before else anchor_idx + 1\n                # Prefer to stay before the main block if possible\n                if main_block_idx != -1:\n                    insertion_index = min(proposed_index, main_block_idx)\n                else:\n                    insertion_index = proposed_index\n            except ValueError:\n                return False # Anchor node not found in tree body\n        elif main_block_idx != -1:\n            # If no anchor, but there's a main block, insert before it\n            insertion_index = main_block_idx\n        # If no anchor and no main block, insertion_index remains -1\n\n        # --- Perform the insertion ---\n        if insertion_index == -1:\n            # Append to the end\n            self.tree.body.extend(new_code_body)\n        else:\n            # Insert at the calculated position\n            for i, new_node in enumerate(new_code_body):\n                self.tree.body.insert(insertion_index + i, new_node)\n\n        # Update the nodes map with any new top-level definitions\n        for node in new_code_body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                self.nodes[node.name] = node # This might overwrite if names clash\n\n        return True\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return False\n\n        deleted = False\n        if element_name in self.nodes:\n            node_to_delete = self.nodes[element_name]\n            # Walk the tree to find the parent node containing the element\n            for node in ast.walk(self.tree):\n                if hasattr(node, 'body') and isinstance(node.body, list):\n                    try:\n                        node.body.remove(node_to_delete)\n                        deleted = True\n                        break # Assume element appears only once at top level\n                    except ValueError:\n                        continue # This parent doesn't contain the node\n            if deleted:\n                del self.nodes[element_name]\n                # Although nodes map is passed by ref in base __init__, we should call _map_nodes\n                # to ensure consistency after a direct tree modification.\n                self.nodes = self._map_nodes()\n                return True\n\n        # If not found by node reference, try to find by name pattern matching (vars/imports)\n        new_body = []\n        for node in self.tree.body:\n            if isinstance(node, ast.Assign):\n                match = False\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id == element_name:\n                        match = True\n                        deleted = True\n                        break\n                if not match: # Keep the node if it doesn't match\n                    new_body.append(node)\n            elif isinstance(node, ast.Import):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                    # Keep the node if none of its aliases match (should theoretically be the same as above)\n                     new_body.append(node)\n                else:\n                    deleted = True # The import node is being completely removed\n            elif isinstance(node, ast.ImportFrom):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                     new_body.append(node)\n                else:\n                    deleted = True\n            else:\n                new_body.append(node)\n\n        if deleted:\n            self.tree.body = new_body\n            # Remap nodes after structural changes\n            self.nodes = self._map_nodes()\n\n        return deleted\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        if element_name not in self.nodes:\n            return False\n\n        node = self.nodes[element_name]\n        # Ensure the node has a body to modify\n        if not hasattr(node, 'body') or not isinstance(node.body, list):\n            return False\n\n        # Parse the new code to get AST nodes for the replacement\n        try:\n             # Heuristic: If new code looks like a def/class, extract its body.\n             # Otherwise, treat as standalone statements.\n            if new_code.strip().startswith(('def ', 'class ', 'async def ')):\n                # Parse as if it's a module with a single function/class\n                temp_module = ast.parse(new_code)\n                if temp_module.body and hasattr(temp_module.body[0], 'body'):\n                    new_statements = temp_module.body[0].body # Get the inner body\n                else:\n                    return False # Malformed attempt to define a func/class\n            else:\n                # Parse as a module and take its body\n                new_ast_module = ast.parse(new_code)\n                new_statements = new_ast_module.body\n        except SyntaxError:\n            return False # Invalid new code\n\n        if not new_statements: # Nothing to insert\n            return False\n\n        # --- Determine what to replace based on parameters ---\n        if statement_index is not None:\n            # Replace by statement index\n            if 0 <= statement_index < len(node.body):\n                # Replace the single statement at index with the list of new statements\n                node.body[statement_index:statement_index+1] = new_statements\n                return True\n        elif line_start is not None:\n            # Replace by line number(s)\n            result = self._find_statement_in_body(node.body, line_start, line_end)\n            if result:\n                idx, _ = result\n                if line_end:\n                    # Find the last statement within the specified range to replace multiple\n                    end_idx = idx\n                    # Iterate from the found index forward\n                    for i in range(idx, len(node.body)):\n                        stmt = node.body[i]\n                        stmt_s_ln = getattr(stmt, 'lineno', None)\n                        stmt_e_ln = getattr(stmt, 'end_lineno', stmt_s_ln)\n                        if stmt_s_ln is not None and stmt_e_ln is not None:\n                            # Check if the statement ends within the range or starts within the range\n                            # This handles overlapping ranges correctly\n                             if stmt_e_ln <= line_end or stmt_s_ln <= line_end:\n                                 end_idx = i\n                             else:\n                                 break # Statement is past the end range\n                        else:\n                            break # Can't determine statement range\n                    node.body[idx:end_idx+1] = new_statements\n                else:\n                    # line_end not specified, only replace the statement at line_start\n                    node.body[idx:idx+1] = new_statements\n                return True\n\n        # If none of the conditions were met to perform a replacement\n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        if self.tree:\n            try:\n                return astor.to_source(self.tree)\n            except Exception as e:\n                 # Fallback error handling, should ideally not happen if tree is valid\n                 return f\"# Error generating source: {e}\\n{self.source_code}\"\n        else:\n            # If somehow the tree is None, return the original source\n            return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        # Ensure line endings are consistent for diffing, keepends=True preserves them\n        # If source_code had different line endings, this might still cause issues,\n        # but this is a standard approach.\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/python_ast_adapter.py"
  },
  {
    "id": 174,
    "hash": "2914352eefed9d60de098e021dd79b67",
    "content": "import os\nimport sys\nimport argparse\nfrom typing import List\nfrom rag_manager import RAGManager\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\ndef create_sample_data() ->List[str]:\n    \"\"\"Create sample documents for the RAG example.\"\"\"\n    return [\n        'RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with language generation.'\n        ,\n        'The RAG model retrieves relevant documents from a knowledge base and uses them to generate more accurate responses.'\n        ,\n        'FAISS is a library for efficient similarity search and clustering of dense vectors, often used in RAG systems.'\n        ,\n        'Sentence transformers are used to create embeddings for documents and queries in RAG systems.'\n        ,\n        'Retrieval-Augmented Generation improves language models by allowing them to access external knowledge sources.'\n        ,\n        'In RAG systems, documents are indexed and searchable by their semantic embeddings rather than just keywords.'\n        ,\n        'Python is a great language for implementing RAG systems due to libraries like sentence-transformers and faiss.'\n        ,\n        'The retrieval component of RAG is crucial for finding relevant information before generation.'\n        ]\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_cli_example.py"
  },
  {
    "id": 175,
    "hash": "c27b11d2eaa8e13cdf8e698417efb75e",
    "content": "import os\nimport sys\nfrom typing import List, Dict, Tuple\n\"\"\"\nExample script demonstrating RAG (Retrieval-Augmented Generation) usage.\n\nThis script shows how to use a simple RAG implementation to answer questions\nbased on a given context or knowledge base.\n\"\"\"\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\nclass SimpleRAG:\n    \"\"\"A simple RAG implementation for demonstration purposes.\"\"\"\n\n    def __init__(self, knowledge_base: List[str]):\n        \"\"\"\n        Initialize the RAG with a knowledge base.\n        \n        Args:\n            knowledge_base: A list of strings representing the knowledge base.\n        \"\"\"\n        self.knowledge_base = knowledge_base\n\n    def retrieve(self, query: str, top_k: int=3) ->List[str]:\n        \"\"\"\n        Retrieve relevant documents from the knowledge base.\n        \n        This is a simplified implementation using keyword matching.\n        In a real implementation, you would use embeddings and vector search.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            A list of relevant documents.\n        \"\"\"\n        query_words = set(query.lower().split())\n        scores = []\n        for doc in self.knowledge_base:\n            doc_words = set(doc.lower().split())\n            score = len(query_words.intersection(doc_words))\n            scores.append((score, doc))\n        scores.sort(reverse=True)\n        return [doc for score, doc in scores[:top_k]]\n\n    def generate(self, query: str, retrieved_docs: List[str]) ->str:\n        \"\"\"\n        Generate an answer based on the query and retrieved documents.\n        \n        In a real implementation, this would use an LLM to generate the response.\n        For this example, we'll create a simple template-based response.\n        \n        Args:\n            query: The query string.\n            retrieved_docs: The retrieved documents.\n            \n        Returns:\n            A generated answer.\n        \"\"\"\n        context = '\\n'.join(retrieved_docs)\n        prompt = f\"\"\"\n        Context information:\n        {context}\n        \n        Question: {query}\n        \n        Based on the context provided above, please answer the question.\n        If the context doesn't contain relevant information, say so.\n        \"\"\"\n        return self._simple_response_generator(query, retrieved_docs)\n\n    def _simple_response_generator(self, query: str, retrieved_docs: List[str]\n        ) ->str:\n        \"\"\"\n        A simple response generator for demonstration.\n        \"\"\"\n        for doc in retrieved_docs:\n            if 'example' in doc.lower():\n                return (\n                    f'Based on the context provided, I found information about examples. {query} relates to the examples in the knowledge base.'\n                    )\n        return (\n            f\"I couldn't find specific information about '{query}' in the provided context. Please provide more details or check the knowledge base.\"\n            )\n\n    def query(self, query: str, top_k: int=3) ->str:\n        \"\"\"\n        Process a query through the full RAG pipeline.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            The generated answer.\n        \"\"\"\n        retrieved_docs = self.retrieve(query, top_k)\n        answer = self.generate(query, retrieved_docs)\n        return answer\n\n\ndef main():\n    \"\"\"Main function demonstrating the RAG implementation.\"\"\"\n    knowledge_base = ['This is an example document about machine learning.',\n        'Natural language processing is a subfield of artificial intelligence.'\n        , 'Python is a popular programming language for data science.',\n        'The quick brown fox jumps over the lazy dog.',\n        'RAG stands for Retrieval-Augmented Generation.',\n        'Vector databases are used for similarity search in RAG systems.',\n        'Transformers are a type of neural network architecture.',\n        'This example shows how to implement a simple RAG system.']\n    rag = SimpleRAG(knowledge_base)\n    queries = ['What is RAG?', 'How is Python used in data science?',\n        'Tell me about machine learning']\n    print('Simple RAG Example')\n    print('=' * 50)\n    for query in queries:\n        print(f'\\nQuery: {query}')\n        answer = rag.query(query)\n        print(f'Answer: {answer}')\n        print('-' * 30)\n    print(\"\\nInteractive Mode (type 'quit' to exit):\")\n    while True:\n        try:\n            user_query = input('\\nEnter your question: ').strip()\n            if user_query.lower() in ['quit', 'exit', 'q']:\n                break\n            if user_query:\n                answer = rag.query(user_query)\n                print(f'Answer: {answer}')\n        except KeyboardInterrupt:\n            print('\\nGoodbye!')\n            break\n        except EOFError:\n            break\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_example.py"
  },
  {
    "id": 176,
    "hash": "f151986bf2efa7602242590a357fab83",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n    Initialize the RAG manager.\n\n    Args:\n        model_name: Name of the sentence transformer model to use\n        index_path: Path to save/load the FAISS index\n    \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the RAG manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n",
    "file": "/mnt/ProjectData/omni/rag_manager.py"
  },
  {
    "id": 177,
    "hash": "f59a27842056dbb0dc95d0f29c1c5de8",
    "content": "Hello! I'm OmniForge, an AI coding assistant. I can help you scan, understand, and refactor your codebase using local (Ollama) or remote (OpenRouter) LLMs.\n\nI see you've opened the OmniForge project directory. Some key things I can help with:\n\n1. **Project Analysis**: I can look at your files to understand the structure\n2. **Code Editing**: I can make precise edits to functions/classes using AST-based transformations\n3. **Refactoring**: I can perform multi-file architectural changes with a plan\n4. **File Creation**: I can generate new files based on instructions\n\nFor example:\n- `look .` to scan the project\n- `edit code_editor.py \"add docstrings to main methods\"`\n- `refactor \"extract git operations into a separate module\"`\n- `create new_module.py \"implement a simple HTTP client\"`\n\nWhat would you like to do with this project?",
    "file": "/mnt/ProjectData/omni/requirements.txt"
  },
  {
    "id": 178,
    "hash": "629e0568a11413444d2a924d1b912f05",
    "content": "from ast_adapter import ASTAdapter\nfrom typing import List, Optional, Dict, Any\n\"\"\"\nTextAdapter - Concrete AST adapter for plain text files.\n\nThis module implements the ASTAdapter interface specifically for plain text files,\ntreating the entire file content as a single element.\n\"\"\"\n\n\nclass TextAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for plain text files.\n\n    This adapter treats the entire text file content as a single element\n    that can be manipulated using the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the TextAdapter with the source code.\n\n        Args:\n            source_code: The text content as a string.\n        \"\"\"\n        self.source_code: str = source_code\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) ->None:\n        \"\"\"\n        Creates a simple mapping for the text content.\n\n        Args:\n            source_code: The text content string.\n        \"\"\"\n        self.nodes = {'content': source_code}\n\n    def list_elements(self) ->List[str]:\n        \"\"\"Lists the names of the main elements (just 'content' for text files).\"\"\"\n        return ['content']\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        if element_name == 'content':\n            return self.source_code\n        return None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        if element_name == 'content':\n            return {'name': element_name, 'type': 'TextContent',\n                'line_start': 1, 'line_end': len(self.source_code.\n                splitlines()), 'body_items': []}\n        return None\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        if element_name != 'content':\n            return None\n        lines = self.source_code.splitlines()\n        if 1 <= line_start <= len(lines) and 1 <= line_end <= len(lines\n            ) and line_start <= line_end:\n            return '\\n'.join(lines[line_start - 1:line_end])\n        return None\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name == 'content':\n            self.source_code = new_code\n            self._parse_and_map(new_code)\n            return True\n        return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"Adds a new element to the file (appends to content for text files).\"\"\"\n        if anchor_name is None or anchor_name == 'content':\n            if before:\n                self.source_code = new_code + self.source_code\n            else:\n                self.source_code = self.source_code + new_code\n            self._parse_and_map(self.source_code)\n            return True\n        return False\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if element_name == 'content':\n            self.source_code = ''\n            self._parse_and_map('')\n            return True\n        return False\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        if element_name != 'content':\n            return False\n        lines = self.source_code.splitlines()\n        if line_start is not None and 1 <= line_start <= len(lines):\n            start_idx = line_start - 1\n            end_idx = start_idx if line_end is None else min(line_end - 1, \n                len(lines) - 1)\n            new_lines = new_code.splitlines() if new_code else []\n            lines[start_idx:end_idx + 1] = new_lines\n            self.source_code = '\\n'.join(lines)\n            self._parse_and_map(self.source_code)\n            return True\n        return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"Returns the modified source code.\"\"\"\n        return self.source_code\n",
    "file": "/mnt/ProjectData/omni/text_adapter.py"
  },
  {
    "id": 179,
    "hash": "4b879b8e64b677ec78d27f19b384623a",
    "content": "from typing import List\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.text import Text\nfrom rich.status import Status\nfrom rich import box\nfrom contextlib import contextmanager\nfrom rich.markup import escape\nimport gc\n\ntry:\n    from prompt_toolkit import prompt\n    from prompt_toolkit.completion import WordCompleter\n    from prompt_toolkit.history import InMemoryHistory\n    from prompt_toolkit.styles import Style\nexcept ImportError:\n    print('[yellow]prompt_toolkit not installed. Falling back to basic input.[/]')\n    prompt = input\n\n\nclass UIManager:\n    \"\"\"Manages interactive text-based UI with rich for display and prompt_toolkit for input.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initializes the UI manager with a rich console and prompt_toolkit components.\"\"\"\n        self.console = Console()\n        self.history = InMemoryHistory()\n        self.completer = WordCompleter([\n            'send', 'look', 'look_all', 'create', 'edit', 'refactor', 'commit',\n            'save', 'list', 'run', 'history', 'memory', 'backend', 'models',\n            'set', 'personality', 'help', 'exit'\n        ], ignore_case=True)\n        self.prompt_style = Style.from_dict({'prompt': 'bold cyan'})\n\n    def get_user_input(self, prompt_text: str) -> str:\n        try:\n            return prompt(prompt_text, history=self.history, completer=self.completer, style=self.prompt_style)\n        except Exception:\n            self.console.print('[yellow]Warning: Falling back to basic input.[/]')\n            return input(prompt_text)\n\n    def display_history(self, history_text: str) -> None:\n        if not history_text.strip():\n            self.console.print('[dim]No history yet.[/]')\n            return\n        \n        lines = history_text.split('\\n')\n        colored_text = Text()\n        for line in lines:\n            if line.startswith('User:'):\n                colored_text.append(line + '\\n', style='bold blue')\n            elif line.startswith('AI:'):\n                colored_text.append(line + '\\n', style='bold green')\n            elif line.startswith('File '):\n                colored_text.append(line + '\\n', style='yellow')\n            else:\n                colored_text.append(line + '\\n')\n        \n        self.console.print(Panel(\n            colored_text, \n            title='[bold magenta]Chat History[/]', \n            border_style='magenta', \n            expand=False, \n            box=box.ROUNDED\n        ))\n\n    @contextmanager\n    def show_spinner(self, message: str):\n        \"\"\"\n        Context manager that displays a spinner with the given message.\n        Handles Rich LiveError by cleaning up stuck live displays and \n        ensuring proper cleanup on exceptions.\n        \n        Usage:\n            with ui_manager.show_spinner(\"Loading...\"):\n                # do work here\n        \"\"\"\n        # Initialize spinner state if not exists\n        if not hasattr(self, '_spinner_active'):\n            self._spinner_active = False\n        \n        # If spinner is already active, just yield without additional output\n        if self._spinner_active:\n            try:\n                yield\n            except Exception as e:\n                raise e\n            return\n        \n        # Clean up any stuck Rich live displays before starting\n        self._cleanup_stuck_rich_displays()\n        \n        # Mark spinner as active\n        self._spinner_active = True\n        status_context = None\n        \n        try:\n            # Try to use rich status, but with fallback\n            try:\n                status_context = self.console.status(f'[bold yellow]{message}[/]')\n                status_context.__enter__()\n            except Exception:\n                # If rich.status fails, fallback to static print\n                status_context = None\n                self.console.print(f'[bold yellow]{message}[/]')\n            \n            yield\n            \n        except Exception as e:\n            # Re-raise actual work errors\n            raise e\n            \n        finally:\n            # Always cleanup spinner state and rich display\n            self._spinner_active = False\n            if status_context is not None:\n                try:\n                    status_context.__exit__(None, None, None)\n                except:\n                    pass  # Suppress cleanup errors\n            \n            # Force cleanup any remaining rich displays\n            self._cleanup_stuck_rich_displays()\n\n    def _cleanup_stuck_rich_displays(self):\n        \"\"\"\n        Clean up stuck Rich live displays that prevent new ones from starting.\n        Based on solution from: https://github.com/DLR-RM/stable-baselines3/issues/1645\n        \"\"\"\n        try:\n            # Method 1: Reset console live display if exists\n            if hasattr(self.console, '_live') and self.console._live is not None:\n                try:\n                    self.console._live.stop()\n                    self.console._live = None\n                except:\n                    pass\n            \n            # Method 2: Find and close stuck rich/tqdm objects using garbage collection\n            rich_objects = [obj for obj in gc.get_objects() \n                        if hasattr(obj, '__class__') and \n                        ('live' in type(obj).__name__.lower() or \n                            'progress' in type(obj).__name__.lower() or\n                            'status' in type(obj).__name__.lower()) and\n                        hasattr(obj, 'stop')]\n            \n            for rich_obj in rich_objects:\n                try:\n                    if hasattr(rich_obj, 'stop'):\n                        rich_obj.stop()\n                    elif hasattr(rich_obj, 'close'):\n                        rich_obj.close()\n                except:\n                    pass  # Suppress cleanup errors\n                    \n        except:\n            pass  # Suppress all cleanup errors to avoid breaking the main flow\n\n    def display_status_panel(self, personality: str, backend: str, model: str, msg_count: int, look_count: int) -> None:\n        status_text = (\n            f'[bold]Personality:[/] [green]{personality}[/] | '\n            f'[bold]Backend:[/] [green]{backend}[/] | '\n            f'[bold]Model:[/] [green]{model}[/] | '\n            f'[bold]Memory:[/] {msg_count} messages, {look_count} files'\n        )\n        self.console.print(Panel(\n            status_text, \n            title='[bold cyan]Status[/]', \n            border_style='cyan', \n            expand=False, \n            box=box.MINIMAL\n        ))\n\n    def show_success(self, message: str) -> None:\n        self.console.print(f'[green]\u2705 {message}[/]')\n\n    def show_error(self, message: str) -> None:\n        \"\"\"\n        Displays an error message, escaping any markup in the message.\n        \"\"\"\n        safe_message = escape(str(message))\n        self.console.print(f'[red]\u274c {safe_message}[/]')",
    "file": "/mnt/ProjectData/omni/ui_manager.py"
  },
  {
    "id": 180,
    "hash": "dbd143839288b400cafdedb655258434",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n",
    "file": "/mnt/ProjectData/omni/vectordb_manager.py"
  },
  {
    "id": 181,
    "hash": "47a91d3ac272236378053b23515fc9b0",
    "content": "import tkinter as tk\nfrom tkinter import ttk\nfrom time import strftime\n\n\ndef update_time():\n    current_time = strftime('%H:%M:%S %p\\n%Y-%m-%d')\n    time_label.config(text=current_time)\n    time_label.after(1000, update_time)\n\n\ndef center_window(root):\n    root.update_idletasks()\n    screen_width = root.winfo_screenwidth()\n    screen_height = root.winfo_screenheight()\n    window_width = root.winfo_width() + 4\n    window_height = root.winfo_height() + 4\n    x = (screen_width - window_width) // 2\n    y = (screen_height - window_height) // 2\n    root.geometry(f'{window_width}x{window_height}+{x}+{y}')\n\n\ndef create_3d_border(parent):\n    border_frame = tk.Frame(parent, bg='#c0c0c0')\n    border_frame.pack(padx=2, pady=2, expand=True, fill=tk.BOTH)\n    tk.Frame(border_frame, height=1, bg='#808080').pack(side=tk.TOP, fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#808080').pack(side=tk.LEFT, fill=tk.Y)\n    tk.Frame(border_frame, height=1, bg='#ffffff').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#ffffff').pack(side=tk.RIGHT, fill=tk.Y\n        )\n    inner_container = tk.Frame(border_frame, bg='#c0c0c0')\n    inner_container.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1\n        )\n    tk.Frame(inner_container, height=1, bg='#ffffff').pack(side=tk.TOP,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#ffffff').pack(side=tk.LEFT,\n        fill=tk.Y)\n    tk.Frame(inner_container, height=1, bg='#808080').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#808080').pack(side=tk.RIGHT,\n        fill=tk.Y)\n    content_area = tk.Frame(inner_container, bg='#c0c0c0')\n    content_area.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1)\n    return content_area\n\n\nroot = tk.Tk()\nroot.title('Current Time')\nroot.configure(bg='#008080')\nmain_frame = create_3d_border(root)\nmain_frame.config(padx=4, pady=4)\ninner_frame = tk.Frame(main_frame, bg='#c0c0c0', padx=8, pady=8)\ninner_frame.pack()\ntime_label = tk.Label(inner_frame, bg='#c0c0c0', fg='#000000', font=(\n    'MS Sans Serif', 18, 'bold'), padx=12, pady=8)\ntime_label.pack()\nroot.after(100, lambda : center_window(root))\nupdate_time()\nroot.mainloop()\n",
    "file": "/mnt/ProjectData/omni/omni_saves/watch.py"
  },
  {
    "id": 182,
    "hash": "6774a805052356775d8c4f0367253dc1",
    "content": "# OmniForge\n\n**Project\u2011Aware AI CLI for AST\u2011Precise Edits (\u201cScalpel\u201d) & Multi\u2011File Refactors (\u201cBlueprint\u201d).**\n\n> *OmniForge (a.k.a. the \"DualForge\" engine) helps you **scan**, **understand**, and **reforge** your codebase with local (Ollama) or remote (OpenRouter) LLMs. It is an independent open\u2011source project not affiliated with other products using the name \u201cOmni.\u201d*\n\n---\n\n## Core Features\n\n* **Project\u2011Aware Refactoring (`refactor`)**: Provide a high\u2011level goal (e.g. *\u201cmove all DB logic into `db/` and centralize config\u201d*). OmniForge generates & shows a multi\u2011step plan before touching files.\n* **Surgical AST Editing (`edit`)**: Target a single function/class. OmniForge parses the file, locates the node, applies a structural change, and shows you a diff.\n* **Context Ingestion (`look`)**: Scan a directory or single file to build a project manifest (paths + hashes + size + language hints) that guides subsequent edits/refactors.\n* **Dual Backends**: Seamlessly switch between **`openrouter`** (remote models) and **`ollama`** (local models) via `backend <name>`.\n* **Interactive Model Picker (`models`)**: Filter by source/provider and select from an up\u2011to\u2011date model list inside the terminal.\n* **Session Memory & History**: `history` shows conversation / action log; `memory clear` resets the working context.\n* **Safe AST\u2011Based Transformations**: Reduces syntax breakage vs naive text substitution. New imports / dependencies are auto\u2011inserted when possible.\n* **Dry\u2011Run Transparency**: Every multi\u2011file refactor presents (1) a generated plan, (2) per\u2011file proposed changes, (3) a consolidated diff for confirmation.\n\n---\n\n## Conceptual Modes\n\n| Mode          | Command(s) | Purpose                                              | Analogy              |\n| ------------- | ---------- | ---------------------------------------------------- | -------------------- |\n| **Survey**    | `look`     | Index project / ingest context                       | Mapping the terrain  |\n| **Scalpel**   | `edit`     | Precise single\u2011file structural change                | Surgery              |\n| **Blueprint** | `refactor` | Multi\u2011file architectural transformation              | Architecture         |\n| **Cast**      | `run`      | Execute last generated runnable block (if supported) | Forging the artifact |\n\nYou can reference these terms in docs, help screens, or UI banners for clarity.\n\n---\n\n## Installation\n\n> Requires Python 3.10+ and a Unix\u2011like shell.\n\n```bash\n# 1. Clone\ngit clone https://github.com/Snawyyy/omniforge.git\ncd omniforge\n\n# 2. (Optional) Inspect requirements\ncat requirements.txt\n\n# 3. Run installer (creates venv + installs deps)\nchmod +x install.sh\n./install.sh\n\n# 4. Activate environment\nsource venv/bin/activate\n\n# 5. Run CLI (interactive shell)\n./omni        # or: python omni.py\n```\n\nIf you later package it, expose a script entry point named `omni` while keeping an internal package name like `omniforge` to avoid namespace collisions.\n\n---\n\n## Configuration\n\nCreate a `.env` file to supply secrets (e.g. OpenRouter API key).\n\n```bash\ncp .env.example .env   # if example exists; otherwise create manually\n```\n\nIn `.env`:\n\n```dotenv\nOPENROUTER_API_KEY=\"sk-or-...\"\n```\n\n(Do **not** commit real keys. Ensure `.env` is listed in `.gitignore`.)\n\nOptional future keys can include local model paths, default model name, or feature flags.\n\n---\n\n## Quick Start Workflow\n\n```text\n> look .\n(Index project: builds manifest)\n\n> refactor \"extract hardcoded API URL to config/settings.py and update all imports\"\n(Shows plan \u2192 ask for confirmation)\n\n> edit src/utils.py \"add a doctring for calculate_average explaining parameters and return value\"\n(Shows targeted diff \u2192 confirm or abort)\n\n> models openai\n(Choose a different model)\n\n> backend ollama\n(Switch to local inference)\n```\n\n---\n\n## Command Reference\n\n| Command               | Example                                         | Description                                                                 |\n| --------------------- | ----------------------------------------------- | --------------------------------------------------------------------------- |\n| `look <path>`         | `look .`                                        | Scan directory or file; update project context manifest.                    |\n| `edit <file> \"instr\"` | `edit utils.py \"add error handling\"`            | AST\u2011guided targeted modification of a single file element or whole file.    |\n| `refactor \"goal\"`     | `refactor \"split monolith api.py into package\"` | High\u2011level multi\u2011file transformation with plan + diff review.               |\n| `send <prompt>`       | `send summarize module layout`                  | Generic prompt to current model with current context summary.               |\n| `models [filter]`     | `models google`                                 | Interactive model selector (filter by provider/source).                     |\n| `backend <name>`      | `backend ollama`                                | Switch between `openrouter` / `ollama`.                                     |\n| `history`             | `history`                                       | Display session interaction log.                                            |\n| `memory clear`        | `memory clear`                                  | Clear internal AI context memory (project manifest may persist separately). |\n| `run`                 | `run`                                           | Execute the last generated runnable code snippet (if feature implemented).  |\n| `help`                | `help`                                          | Show help / usage summary.                                                  |\n\n---\n\n## How It Works (High Level)\n\n1. **Ingestion (`look`)**: Walks the directory (configurable ignore patterns), captures file metadata (path, size, language), optionally caches abbreviated content or hashes.\n2. **Prompt Construction**: Merges user instruction + contextual manifest + focused snippets (for `edit`) or diff summaries (for `refactor`).\n3. **AST Layer** (Python initially): Parses target file(s); identifies node(s) (function/class) based on name + heuristic similarity; applies transformations guided by model output (structured hints or patch templates) rather than raw blind overwrite.\n4. **Plan (Refactor)**: Model proposes steps (CREATE / MODIFY / RENAME / DELETE). User approves. Each step executed & validated; errors surface early.\n5. **Diff Presentation**: A unified colorized diff shown; user confirms to write changes.\n6. **Safety**: If AST parse fails or patch violates syntax, changes abort (or fallback to text patch with warning).\n\n---\n\n## Roadmap (Indicative)\n\n| Milestone | Features                                                                    |\n| --------- | --------------------------------------------------------------------------- |\n| 0.1.0     | Core commands (`look`, `edit`, `refactor`, `models`, `backend`, `history`). |\n| 0.2.0     | Config file (`omniforge.toml`), ignore patterns, improved diff viewer.      |\n| 0.3.0     | Multi-language AST adapters (JS/TS via `tree-sitter`).                      |\n| 0.4.0     | Test impact analysis & auto test file generation.                           |\n| 0.5.0     | Refactor preview metrics (LOC touched, complexity delta).                   |\n| 0.6.0     | Inline security / lint feedback integration.                                |\n| 0.7.0     | Partial GUI / TUI dashboard mode.                                           |\n\n(Adjust roadmap as project evolves.)\n\n---\n\n## Developer Notes\n\n* Keep `.env`, virtual environment dirs (`venv/`), caches, large artifacts in `.gitignore`.\n* Consider adding a thin `omniforge/` package directory now for future PyPI packaging.\n* Implement a pluggable *Model Adapter* layer to abstract provider differences (OpenRouter vs Ollama).\n* Logging: Provide `--verbose` or `OMNIFORGE_DEBUG=1` env flag.\n* Add a JSONL log of commands & decisions to enable replay or supervised improvements.\n\n---\n\n## Contributing\n\n1. Fork & create a feature branch: `git checkout -b feat/<short-name>`\n2. Run and add tests (if/when test harness exists in `tests/`).\n3. Ensure style/format (e.g. `ruff`, `black`) passes.\n4. Submit pull request with concise description + before/after examples.\n\nIssues / discussions welcome for architecture proposals, AST adapters, or performance improvements.\n\n---\n\n## License\n\nReleased under the **MIT License**. See `LICENSE` file for full text.\n\n---\n\n## Name & Trademark Disclaimer\n\n\u201cOmniForge\u201d is an independent open-source tool and not affiliated with The Omni Group or any other third-party products using similar names. If a future naming conflict arises, a soft alias strategy (keeping the `omni` CLI) will preserve user workflows.\n\n---\n\n## Example Session (Illustrative)\n\n```text\n$ ./omni\nOMNIFORGE 0.1.0  (backend=openrouter | model=anthropic/claude-3)\nType 'help' or 'look .' to begin.\n\n> look .\nIndexed 42 files (Python=30, Markdown=5, JSON=7)\n\n> refactor \"centralize logging into logging_util.py and update imports\"\nPlan:\n  [1] CREATE logging_util.py\n  [2] MODIFY app.py (replace inline log setup)\n  [3] MODIFY worker.py (import logging_util)\nProceed? (y/n) y\n... (diff preview) ...\nApply changes? (y/n) y\nRefactor complete in 3.2s.\n\n> edit worker.py \"add retry with exponential backoff to fetch_data\"\nParsed worker.py \u2713\nApplied modification (function: fetch_data)\nDiff shown. Accept? (y/n) y\nSaved.\n```\n\n---\n\n## Philosophy\n\n*The next wave of developer AI goes beyond paste\u2011in prompts.* OmniForge treats your repository as *structured material*, enabling incremental, auditable, and safer evolution rather than opaque code dumps. By combining **context scanning**, **AST precision**, and **human approval loops**, it aims to become a trustworthy co\u2011developer rather than an occasionally helpful code generator.\n\n---\n\n## Feedback / Support\n\nOpen a GitHub Issue for bugs & feature requests. For conceptual discussions (roadmap, design choices), use Discussions.\n\n---\n\nHappy forging!\n",
    "file": "/mnt/ProjectData/omni/README.md"
  },
  {
    "id": 183,
    "hash": "b6c2845489f64b6396aaf85e5fd5909e",
    "content": "from abc import ABC, abstractmethod\nfrom typing import List, Optional, Dict, Any, Union\nfrom typing import List, Optional, Dict\nASTNode = Any\nDiffContent = str\n\n\nclass ASTAdapter(ABC):\n    \"\"\"\n    Abstract base class defining the interface for language-specific AST adapters.\n\n    This interface allows the CodeEditor to interact with the AST/CST of different\n    programming languages in a uniform way. Concrete implementations will handle\n    the specifics of parsing, traversing, and modifying the AST/CST for their\n    respective languages (e.g., Python's `ast`/`astor`, JavaScript's `tree-sitter`).\n\n    The adapter is responsible for holding the parsed tree structure and any\n    necessary metadata for operations.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the adapter by parsing the provided source code.\n\n        Args:\n            source_code: The string content of the source file to be parsed.\n\n        Raises:\n            ValueError: If the source code cannot be parsed due to syntax errors.\n        \"\"\"\n        self.source_code: str = source_code\n        self.tree: Optional[ASTNode] = None\n        self.nodes: Dict[str, ASTNode] = {}\n        self._parse_and_map(source_code)\n\n    @abstractmethod\n    def _parse_and_map(self, source_code: str) ->None:\n        \"\"\"\n        Abstract method to parse the source code and populate `self.tree` and `self.nodes`.\n\n        This is the core method where language-specific parsing logic resides.\n        Implementations should:\n        1. Parse the `source_code` into an AST/CST representation.\n        2. Store the root of this representation in `self.tree`.\n        3. Identify key top-level elements (functions, classes, variables, imports)\n           and map their names to their nodes in `self.nodes`.\n\n        Args:\n            source_code: The string content to parse.\n\n        Raises:\n            ValueError: If the source code cannot be parsed.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_elements(self) ->List[str]:\n        \"\"\"\n        Abstract method to list the names of the main elements found in the code.\n\n        These are typically top-level functions, classes, variable assignments,\n        and imports that the adapter can identify and manipulate.\n\n        Returns:\n            A list of element names (strings).\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"\n        Abstract method to get the source code string for a specific element.\n\n        Args:\n            element_name: The name of the element (function, class, etc.).\n\n        Returns:\n            The source code string for the element, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"\n        Abstract method to get detailed structural information about an element.\n\n        This information can include type, line numbers, body items, etc., useful\n        for aiding the AI in understanding the code's layout.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            A dictionary containing structural details, or None if not found.\n            Example structure:\n            {\n                'name': 'func_name',\n                'type': 'FunctionDef', # or 'ClassDef', etc.\n                'line_start': 10,\n                'line_end': 25,\n                'body_items': [list of internal statement details...]\n            }\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"\n        Abstract method to extract a snippet of code from within an element's body.\n\n        Used for 'partial' edits where only a specific range of lines within\n        a function or class needs to be changed.\n\n        Args:\n            element_name: The name of the element containing the snippet.\n            line_start: The starting line number (1-based, absolute) of the snippet.\n            line_end: The ending line number (inclusive) of the snippet.\n\n        Returns:\n            The source code string for the specified lines within the element, or None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"\n        Abstract method to replace an entire named element.\n\n        This involves finding the old element in the tree and swapping it with\n        the representation of the `new_code`.\n\n        Args:\n            element_name: The name of the element to replace.\n            new_code: The new source code for the element (and potential helpers).\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"\n        Abstract method to add a new block of code (element) to the file.\n\n        This involves parsing the `new_code` and inserting its representation\n        into the tree at an appropriate location (e.g., end of file, near anchor).\n\n        Args:\n            new_code: The source code for the new element(s).\n            anchor_name: Optional name of an existing element to position relative to.\n            before: If True and `anchor_name` is provided, insert before the anchor.\n\n        Returns:\n            True if the element was added successfully, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"\n        Abstract method to delete a named element from the file.\n\n        This involves finding the element in the tree and removing its representation.\n\n        Args:\n            element_name: The name of the element to delete.\n\n        Returns:\n            True if the element was successfully deleted, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"\n        Abstract method for a 'surgical' edit within an element's body.\n\n        Replaces a specific statement or line range within the body of an element.\n\n        Args:\n            element_name: Name of the function/class to modify.\n            new_code: New code to insert (can be multiple statements).\n            line_start: Starting line number (absolute) within the element.\n            line_end: Ending line number (inclusive) within the element.\n            statement_index: Alternative to line numbers - replace the Nth statement.\n\n        Returns:\n            True if successful, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_modified_source(self) ->str:\n        \"\"\"\n        Abstract method to serialize the potentially modified AST/CST back to source code.\n\n        Returns:\n            The full source code string reflecting the current state of the tree.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_diff(self) ->str:\n        \"\"\"\n        Abstract method to generate a diff between the original source and the modified source.\n\n        Returns:\n            A string containing the unified diff.\n        \"\"\"\n        pass\n\n\n\"\"\"\nTextFileAdapter - Basic adapter for text files\n\nThis module provides a basic adapter for text files that implements\nthe ASTAdapter interface. It allows text files to be used with the\nCodeEditor class.\n\"\"\"\n\n\nclass TextFileAdapter(ASTAdapter):\n    \"\"\"\n    A basic adapter for text files that implements the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the TextFileAdapter.\n\n        Args:\n            source_code: The source code as a string.\n        \"\"\"\n        self.source_code = source_code\n        self.modified_source = source_code\n\n    def list_elements(self) ->List[str]:\n        \"\"\"\n        Lists top-level elements in the text file.\n        For text files, this returns a single \"content\" element.\n\n        Returns:\n            A list containing \"content\".\n        \"\"\"\n        return ['content']\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"\n        Gets the source code for a specific element.\n        For text files, this returns the entire file content.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            The source code of the entire file.\n        \"\"\"\n        if element_name == 'content':\n            return self.source_code\n        return None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"\n        Gets detailed structure information about an element.\n        For text files, this provides minimal structure information.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            A dictionary with basic structure information.\n        \"\"\"\n        if element_name == 'content':\n            lines = self.source_code.splitlines()\n            return {'name': element_name, 'type': 'text', 'line_count': len\n                (lines), 'character_count': len(self.source_code)}\n        return None\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"\n        Gets a snippet from within an element's body.\n        For text files, this returns lines between line_start and line_end.\n\n        Args:\n            element_name: The name of the element.\n            line_start: The starting line number (1-indexed).\n            line_end: The ending line number (1-indexed).\n\n        Returns:\n            A string containing the specified lines.\n        \"\"\"\n        if element_name != 'content':\n            return None\n        lines = self.source_code.splitlines()\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(lines), line_end)\n        if start_idx >= len(lines) or start_idx >= end_idx:\n            return None\n        return '\\n'.join(lines[start_idx:end_idx])\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"\n        Replaces a partial section of an element.\n        For text files, this replaces lines between line_start and line_end.\n\n        Args:\n            element_name: The name of the element.\n            new_code: The new code to insert.\n            line_start: The starting line number (1-indexed).\n            line_end: The ending line number (1-indexed).\n            statement_index: Not used for text files.\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        if element_name != 'content':\n            return False\n        if line_start is None or line_end is None:\n            return False\n        lines = self.modified_source.splitlines()\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(lines), line_end)\n        if start_idx > len(lines) or start_idx > end_idx:\n            return False\n        new_lines = self.modified_source.splitlines()\n        new_code_lines = new_code.splitlines()\n        new_lines[start_idx:end_idx] = new_code_lines\n        self.modified_source = '\\n'.join(new_lines)\n        return True\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"\n        Adds new content to the text file.\n        For text files, this appends or prepends content.\n\n        Args:\n            new_code: The new code to add.\n            anchor_name: Not used for text files.\n            before: If True, prepend; if False, append.\n\n        Returns:\n            True if the addition was successful, False otherwise.\n        \"\"\"\n        if before:\n            self.modified_source = new_code + '\\n' + self.modified_source\n        else:\n            self.modified_source = self.modified_source + '\\n' + new_code\n        return True\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"\n        Deletes an element by name.\n        For text files, this clears the entire content if element_name is \"content\".\n\n        Args:\n            element_name: The name of the element to delete.\n\n        Returns:\n            True if the deletion was successful, False otherwise.\n        \"\"\"\n        if element_name == 'content':\n            self.modified_source = ''\n            return True\n        return False\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"\n        Replaces a target element with new code.\n        For text files, this replaces the entire content if element_name is \"content\".\n\n        Args:\n            element_name: The name of the element to replace.\n            new_code: The new code.\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        if element_name == 'content':\n            self.modified_source = new_code\n            return True\n        return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"\n        Gets the modified source code.\n\n        Returns:\n            The modified source code.\n        \"\"\"\n        return self.modified_source\n\n    def get_diff(self) ->str:\n        \"\"\"\n        Generates a diff between the original source and the modified source.\n\n        Returns:\n            A string containing the diff.\n        \"\"\"\n        import difflib\n        return ''.join(difflib.unified_diff(self.source_code.splitlines(\n            keepends=True), self.modified_source.splitlines(keepends=True),\n            fromfile='original', tofile='modified'))\n",
    "file": "/mnt/ProjectData/omni/ast_adapter.py"
  },
  {
    "id": 184,
    "hash": "3fa6303779874a8e61c7a1a4ffc75e58",
    "content": "\"\"\"\nCodeEditor - Enhanced AST-based code manipulation tool\n\nThis module provides a class to programmatically parse, analyze,\nand edit source code. It has been refactored to use a pluggable\nASTAdapter system, allowing it to support multiple languages.\nCurrently, it defaults to Python's built-in `ast` module via\nPythonASTAdapter for backward compatibility during the transition.\n\"\"\"\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Union, Tuple, Type, Any\nfrom ast_adapter import ASTAdapter\nfrom python_ast_adapter import PythonASTAdapter\nimport os\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n\n\nclass CodeEditor:\n    \"\"\"\n    An enhanced class to safely edit files using AST/CST with partial edit support.\n    The core logic for interacting with the code structure is now delegated to\n    a language-specific ASTAdapter.\n    \"\"\"\n\n    def __init__(self, file_path: str, adapter_class: Optional[Type[\n        ASTAdapter]]=None):\n        \"\"\"\n        Initializes the CodeEditor.\n\n        Args:\n            file_path: The path to the source file.\n            adapter_class: The ASTAdapter subclass to use. If None, defaults to\n                           PythonASTAdapter for .py files.\n        \"\"\"\n        self.file_path = file_path\n        self.source_code = self._read_file()\n        self.adapter: Optional[ASTAdapter] = None\n        self.tree: Optional[ast.AST] = None\n        self.nodes: Dict[str, ast.AST] = {}\n        self.atok: Optional[Any] = None\n        if adapter_class is None:\n            file_extension = os.path.splitext(self.file_path)[1].lower()\n            if file_extension == '.py':\n                try:\n                    from python_ast_adapter import PythonASTAdapter\n                    self.adapter = PythonASTAdapter(self.source_code)\n                except ImportError as e:\n                    try:\n                        self.tree = self._parse_source()\n                        self.nodes = self._map_nodes()\n                        if ASTTOKENS_AVAILABLE:\n                            self.atok = asttokens.ASTTokens(self.\n                                source_code, parse=True)\n                    except Exception as parse_error:\n                        raise ValueError(\n                            f'Failed to parse Python file: {parse_error}')\n            elif file_extension == '.js':\n                try:\n                    from javascript_ast_adapter import JavaScriptASTAdapter\n                    self.adapter = JavaScriptASTAdapter(self.source_code)\n                except ImportError as e:\n                    raise ValueError(\n                        f'tree-sitter is required for JavaScript support but not available: {e}'\n                        )\n                except Exception as e:\n                    raise ValueError(\n                        f'Failed to initialize JavaScript adapter: {e}')\n            elif file_extension == '.txt':\n                pass\n            else:\n                raise ValueError(\n                    f'Unsupported file type: {file_extension}. Supported types: .py, .js, .txt'\n                    )\n        else:\n            try:\n                self.adapter = adapter_class(self.source_code)\n            except Exception as e:\n                raise ValueError(\n                    f'Failed to initialize adapter {adapter_class.__name__}: {e}'\n                    )\n\n    def _read_file(self) ->str:\n        \"\"\"Reads the source file.\"\"\"\n        try:\n            with open(self.file_path, 'r', encoding='utf-8') as f:\n                return f.read()\n        except FileNotFoundError:\n            raise ValueError(f'File not found: {self.file_path}')\n\n    def _parse_source(self) ->ast.AST:\n        \"\"\"Fallback parsing logic.\"\"\"\n        try:\n            return ast.parse(self.source_code)\n        except SyntaxError as e:\n            raise ValueError(f'Invalid Python syntax in {self.file_path}: {e}')\n\n    def list_elements(self) ->List[str]:\n        \"\"\"Lists top-level elements in the code.\"\"\"\n        if self.adapter:\n            return self.adapter.list_elements()\n        else:\n            return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"Gets the source code for a specific element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_source_of(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            return astor.to_source(node) if node else None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"Gets detailed structure information about an element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_structure(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            if not node:\n                return None\n            structure = {'name': element_name, 'type': node.__class__.\n                __name__, 'line_start': node.lineno if hasattr(node,\n                'lineno') else None, 'line_end': node.end_lineno if hasattr\n                (node, 'end_lineno') else None, 'body_items': []}\n            if hasattr(node, 'body'):\n                for i, item in enumerate(node.body):\n                    item_info = {'index': i, 'type': item.__class__.\n                        __name__, 'line_start': item.lineno if hasattr(item,\n                        'lineno') else None, 'line_end': item.end_lineno if\n                        hasattr(item, 'end_lineno') else None}\n                    if isinstance(item, ast.Assign) and item.targets:\n                        target = item.targets[0]\n                        if isinstance(target, ast.Name):\n                            item_info['assigns'] = target.id\n                    elif isinstance(item, (ast.If, ast.While, ast.For)):\n                        item_info['has_body'] = bool(item.body)\n                    elif isinstance(item, ast.Return):\n                        item_info['returns'] = True\n                    structure['body_items'].append(item_info)\n            return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"Gets a snippet from within an element's body.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_body_snippet(element_name,\n                line_start, line_end)\n        else:\n            if not self.atok:\n                return None\n            node = self.nodes.get(element_name)\n            if not node or not hasattr(node, 'body'):\n                return None\n            statements = []\n            for stmt in node.body:\n                if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                    if (line_start <= stmt.lineno <= line_end or line_start <=\n                        stmt.end_lineno <= line_end):\n                        statements.append(stmt)\n            if not statements:\n                return None\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in\n                statements)\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"Replaces a partial section of an element.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_partial(element_name, new_code,\n                line_start, line_end, statement_index)\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                if new_code.strip().startswith('def ') or new_code.strip(\n                    ).startswith('class '):\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body[0].body\n                else:\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if statement_index is not None:\n                if 0 <= statement_index < len(node.body):\n                    node.body[statement_index:statement_index + 1\n                        ] = new_statements\n                    return True\n            elif line_start is not None:\n                result = self._find_statement_in_body(node.body, line_start,\n                    line_end)\n                if result:\n                    idx, _ = result\n                    if line_end:\n                        end_idx = idx\n                        for i in range(idx + 1, len(node.body)):\n                            stmt = node.body[i]\n                            if hasattr(stmt, 'end_lineno'\n                                ) and stmt.end_lineno <= line_end:\n                                end_idx = i\n                            else:\n                                break\n                        node.body[idx:end_idx + 1] = new_statements\n                    else:\n                        node.body[idx:idx + 1] = new_statements\n                    return True\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"Adds a new block of code to the file.\"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name, before)\n        else:\n            try:\n                new_ast_module = ast.parse(new_code)\n            except (SyntaxError, IndexError):\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            insertion_index = -1\n            main_block_idx = -1\n            for i, _node in enumerate(self.tree.body):\n                if isinstance(_node, ast.If) and isinstance(_node.test, ast\n                    .Compare) and isinstance(_node.test.left, ast.Name\n                    ) and _node.test.left.id == '__name__' and len(_node.\n                    test.ops) == 1 and isinstance(_node.test.ops[0], ast.Eq\n                    ) and len(_node.test.comparators) == 1:\n                    comp = _node.test.comparators[0]\n                    if isinstance(comp, ast.Constant\n                        ) and comp.value == '__main__' or isinstance(comp,\n                        ast.Str) and comp.s == '__main__':\n                        main_block_idx = i\n                        break\n            if anchor_name:\n                if anchor_name not in self.nodes:\n                    return False\n                anchor_node = self.nodes[anchor_name]\n                try:\n                    anchor_idx = self.tree.body.index(anchor_node)\n                    proposed_index = anchor_idx if before else anchor_idx + 1\n                    if main_block_idx != -1:\n                        insertion_index = min(proposed_index, main_block_idx)\n                    else:\n                        insertion_index = proposed_index\n                except ValueError:\n                    return False\n            elif main_block_idx != -1:\n                insertion_index = main_block_idx\n            if insertion_index == -1:\n                self.tree.body.extend(new_code_body)\n            else:\n                for i, new_node in enumerate(new_code_body):\n                    self.tree.body.insert(insertion_index + i, new_node)\n            for _node in new_code_body:\n                if isinstance(_node, (ast.FunctionDef, ast.AsyncFunctionDef,\n                    ast.ClassDef)):\n                    self.nodes[_node.name] = _node\n            return True\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"Deletes an element by name.\"\"\"\n        if self.adapter:\n            return self.adapter.delete_element(element_name)\n        else:\n            deleted = False\n            if element_name in self.nodes:\n                node_to_delete = self.nodes[element_name]\n                for _node in ast.walk(self.tree):\n                    if hasattr(_node, 'body') and isinstance(_node.body, list):\n                        try:\n                            _node.body.remove(node_to_delete)\n                            deleted = True\n                            break\n                        except ValueError:\n                            continue\n                if deleted:\n                    del self.nodes[element_name]\n                    self.nodes = self._map_nodes()\n                    return True\n            new_body = []\n            for _node in self.tree.body:\n                if isinstance(_node, ast.Assign):\n                    match = False\n                    for target in _node.targets:\n                        if isinstance(target, ast.Name\n                            ) and target.id == element_name:\n                            match = True\n                            break\n                    if match:\n                        deleted = True\n                        continue\n                elif isinstance(_node, ast.Import):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                elif isinstance(_node, ast.ImportFrom):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                new_body.append(_node)\n            self.tree.body = new_body\n            if deleted:\n                self.nodes = self._map_nodes()\n            return deleted\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"Replaces a target element with new code.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_element(element_name, new_code)\n        else:\n            if element_name not in self.nodes:\n                return False\n            try:\n                new_ast_module = ast.parse(new_code)\n            except SyntaxError:\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            for _node in ast.walk(self.tree):\n                if hasattr(_node, 'body') and isinstance(_node.body, list):\n                    try:\n                        old_node = self.nodes[element_name]\n                        idx = _node.body.index(old_node)\n                        _node.body.pop(idx)\n                        for i, new_node in enumerate(new_code_body):\n                            _node.body.insert(idx + i, new_node)\n                        del self.nodes[element_name]\n                        for n in new_code_body:\n                            if isinstance(n, (ast.FunctionDef, ast.\n                                AsyncFunctionDef, ast.ClassDef)):\n                                self.nodes[n.name] = n\n                        return True\n                    except (ValueError, KeyError):\n                        continue\n            return False\n\n    def insert_in_element(self, element_name: str, new_code: str, position:\n        str='end', after_line: Optional[int]=None, before_line: Optional[\n        int]=None) ->bool:\n        \"\"\"\n        Insert new code into an element without replacing existing code.\n        This is an internal/helper method, delegating to adapter OR using fallback.\n        \"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name=\n                element_name, before=position == 'start')\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                new_ast = ast.parse(new_code)\n                new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if position == 'start':\n                node.body[0:0] = new_statements\n            elif position == 'end':\n                node.body.extend(new_statements)\n            elif after_line:\n                result = self._find_statement_in_body(node.body, after_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx + 1:idx + 1] = new_statements\n                else:\n                    return False\n            elif before_line:\n                result = self._find_statement_in_body(node.body, before_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx:idx] = new_statements\n                else:\n                    return False\n            else:\n                return False\n            return True\n\n    def _map_nodes(self) ->Dict[str, ast.AST]:\n        \"\"\"Fallback node mapping logic for Python AST.\"\"\"\n        nodes = {}\n        for node in ast.walk(self.tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast\n                .ClassDef)):\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int,\n        line_end: Optional[int]=None) ->Optional[Tuple[int, ast.AST]]:\n        \"\"\"Fallback statement finding logic for Python AST.\"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = stmt.end_lineno if hasattr(stmt, 'end_lineno'\n                        ) else stmt.lineno\n                    if (stmt.lineno <= line_start <= stmt_end or stmt.\n                        lineno <= line_end <= stmt_end):\n                        return i, stmt\n                elif stmt.lineno == line_start:\n                    return i, stmt\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.\n        ImportFrom]]) ->None:\n        \"\"\"Fallback logic to add imports to the top of the Python AST.\"\"\"\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                existing_imports_str.add(astor.to_source(node).strip())\n                last_import_index = i\n        for new_import in reversed(new_import_nodes):\n            new_import_str = astor.to_source(new_import).strip()\n            if new_import_str not in existing_imports_str:\n                self.tree.body.insert(last_import_index + 1, new_import)\n\n    def apply_arbitrary_change(self, new_source_code: str) ->bool:\n        \"\"\"\n        Rewrites the entire file's AST from a new source string.\n        This method resets the adapter if one exists, or uses fallback.\n        \"\"\"\n        if self.adapter:\n            try:\n                adapter_class = type(self.adapter)\n                self.adapter = adapter_class(new_source_code)\n                return True\n            except Exception:\n                return False\n        else:\n            try:\n                new_tree = ast.parse(new_source_code)\n                self.tree = new_tree\n                self.nodes = self._map_nodes()\n                if ASTTOKENS_AVAILABLE:\n                    self.source_code = new_source_code\n                    self.atok = asttokens.ASTTokens(self.source_code, parse\n                        =True)\n                return True\n            except SyntaxError:\n                return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"Serializes the potentially modified code structure back to source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_modified_source()\n        else:\n            return astor.to_source(self.tree)\n\n    def get_diff(self) ->str:\n        \"\"\"Generates a diff between the original source and the modified source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_diff()\n        else:\n            modified_source = self.get_modified_source()\n            return ''.join(difflib.unified_diff(self.source_code.splitlines\n                (keepends=True), modified_source.splitlines(keepends=True),\n                fromfile=f'{self.file_path} (original)', tofile=\n                f'{self.file_path} (modified)'))\n\n    def save_changes(self) ->None:\n        \"\"\"Saves the modified source code back to the file.\"\"\"\n        modified_source = self.get_modified_source()\n        with open(self.file_path, 'w', encoding='utf-8') as f:\n            f.write(modified_source)\n",
    "file": "/mnt/ProjectData/omni/code_editor.py"
  },
  {
    "id": 185,
    "hash": "cc52aa524d0929867d5d2ea3697229e6",
    "content": "\"\"\"\nGenerated file.\n\"\"\"\nimport os\n\"\"\"\nFileCreator - A utility for creating files.\n\nThis module provides a simple, encapsulated way to create files,\nensuring that their parent directories exist before writing.\n\"\"\"\n\n\nclass FileCreator:\n    \"\"\"\n    A utility class to handle the creation of new files.\n    \"\"\"\n\n    @staticmethod\n    def create(file_path: str, content: str) ->None:\n        \"\"\"\n        Creates a file at the specified path with the given content.\n\n        This method will automatically create any necessary parent\n        directories for the file path.\n\n        Args:\n            file_path: The full path where the file should be created.\n            content: The string content to write to the file.\n\n        Raises:\n            IOError: If there is an error creating the directories or writing the file.\n        \"\"\"\n        try:\n            directory = os.path.dirname(file_path)\n            if directory:\n                os.makedirs(directory, exist_ok=True)\n            with open(file_path, 'w', encoding='utf-8') as f:\n                f.write(content)\n        except (IOError, OSError) as e:\n            raise IOError(f\"Failed to create file '{file_path}': {e}\") from e\n",
    "file": "/mnt/ProjectData/omni/file_creator.py"
  },
  {
    "id": 186,
    "hash": "04a24ceab008bd649d0530d309c72e42",
    "content": "import subprocess\nimport os\nfrom typing import List, Optional, Union\n\n\nclass GitManager:\n    \"\"\"\n    Encapsulates Git-related logic for a specific repository.\n\n    This class provides methods to perform common Git operations such as\n    checking status, getting diffs, staging, committing, and pushing changes.\n    It relies on the Git command-line tool being installed and accessible\n    in the system's PATH.\n    \"\"\"\n\n    def __init__(self, repo_path: str):\n        \"\"\"\n        Initializes the GitManager for a given repository path.\n\n        Args:\n            repo_path: The absolute or relative path to the Git repository.\n\n        Raises:\n            ValueError: If the provided path is not a valid Git repository.\n        \"\"\"\n        if not os.path.isdir(os.path.join(repo_path, '.git')):\n            raise ValueError(\n                f\"The path '{repo_path}' is not a valid Git repository.\")\n        self.repo_path = repo_path\n\n    def _run_command(self, command: List[str]) ->str:\n        \"\"\"\n        Executes a Git command in the repository's directory.\n\n        Args:\n            command: A list of command arguments, starting with 'git'.\n\n        Returns:\n            The standard output of the command as a string.\n\n        Raises:\n            subprocess.CalledProcessError: If the command returns a non-zero exit code.\n        \"\"\"\n        try:\n            result = subprocess.run(command, cwd=self.repo_path, check=True,\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True,\n                encoding='utf-8')\n            return result.stdout.strip()\n        except subprocess.CalledProcessError as e:\n            error_message = (\n                f\"Git command failed: {' '.join(command)}\\nError: {e.stderr.strip()}\"\n                )\n            raise subprocess.CalledProcessError(e.returncode, e.cmd, output\n                =e.stdout, stderr=error_message) from e\n\n    def get_status(self) ->str:\n        \"\"\"\n        Gets the repository status in a condensed format.\n\n        Uses `git status --porcelain` for a machine-readable output.\n\n        Returns:\n            A string representing the repository's status.\n        \"\"\"\n        return self._run_command(['git', 'status', '--porcelain'])\n        \n    def get_changed_files(self) -> List[str]:\n        \"\"\"\n        Gets a list of all changed (modified, added, deleted, untracked, renamed, or copied) files.\n\n        This parses the output of `git status --porcelain`, which provides a stable,\n        machine-readable format.\n\n        Returns:\n            A list of file paths relative to the repository root. For renamed or\n            copied files, it returns the new path.\n        \"\"\"\n        status_output = self.get_status()\n        if not status_output:\n            return []\n        \n        changed_files = []\n        for line in status_output.splitlines():\n            if len(line) < 3:  # Skip malformed lines\n                continue\n                \n            # Git status porcelain format: XY filename\n            # X = index status, Y = working tree status\n            index_status = line[0]\n            worktree_status = line[1]\n            \n            # The filename starts after the two status characters and a space\n            # But let's be more defensive about finding where the filename actually starts\n            filename_start = 2\n            while filename_start < len(line) and line[filename_start] == ' ':\n                filename_start += 1\n                \n            if filename_start >= len(line):\n                continue  # Skip if no filename found\n                \n            path_info = line[filename_start:]\n            \n            # Check if either index or working tree status indicates rename/copy\n            if index_status in ('R', 'C') or worktree_status in ('R', 'C'):\n                if ' -> ' in path_info:\n                    _, new_path = path_info.split(' -> ', 1)  # Use maxsplit=1 for safety\n                    changed_files.append(new_path.strip())\n                else:\n                    # Fallback if format is unexpected\n                    changed_files.append(path_info.strip())\n            else:\n                changed_files.append(path_info.strip())\n        \n        # Remove duplicates while preserving order\n        return list(dict.fromkeys(changed_files))\n\n    def get_diff(self, file_path: Optional[str]=None, staged: bool=False\n        ) ->str:\n        \"\"\"\n        Gets the diff of changes in the repository.\n\n        Args:\n            file_path: Optional. Path to a specific file to diff.\n            staged: If True, shows the diff for staged changes (`--cached`).\n                    Otherwise, shows the diff for unstaged changes.\n\n        Returns:\n            The git diff output as a string.\n        \"\"\"\n        cmd = ['git', 'diff']\n        if staged:\n            cmd.append('--cached')\n        if file_path:\n            cmd.append('--')\n            cmd.append(file_path)\n        return self._run_command(cmd)\n\n    def add(self, files: Union[str, List[str]]) ->None:\n        \"\"\"\n    Stages one or more files, handling each one individually for robustness.\n\n    This approach prevents a single invalid file path from causing the\n    entire 'git add' operation to fail. Warnings will be printed for any\n    files that could not be staged.\n\n    Args:\n        files: A single file path or a list of file paths to stage.\n               Can also be '.' to stage all changes.\n    \"\"\"\n        if isinstance(files, str):\n            files = [files]\n        for file_path in files:\n            try:\n                cmd = ['git', 'add', '--', file_path]\n                self._run_command(cmd)\n            except subprocess.CalledProcessError as e:\n                print(\n                    f\"Warning: Could not stage file '{file_path}'. Git reported: {e.stderr}\"\n                    )\n\n    def commit(self, message: str) ->str:\n        \"\"\"\n        Commits staged changes with a given message.\n\n        Args:\n            message: The commit message.\n\n        Returns:\n            The stdout from the git commit command.\n        \"\"\"\n        return self._run_command(['git', 'commit', '-m', message])\n\n    def push(self, remote: str='origin', branch: Optional[str]=None) ->str:\n        \"\"\"\n        Pushes commits to a remote repository.\n\n        Args:\n            remote: The name of the remote to push to (default: 'origin').\n            branch: The branch to push. If None, uses the current branch.\n\n        Returns:\n            The stdout from the git push command.\n        \"\"\"\n        if branch is None:\n            branch = self.get_current_branch()\n        return self._run_command(['git', 'push', remote, branch])\n\n    def get_current_branch(self) ->str:\n        \"\"\"\n        Determines the current active branch name.\n\n        Returns:\n            The name of the current branch.\n        \"\"\"\n        return self._run_command(['git', 'rev-parse', '--abbrev-ref', 'HEAD'])\n",
    "file": "/mnt/ProjectData/omni/git_manager.py"
  },
  {
    "id": 187,
    "hash": "f3f7ab448ad3e233539c4e4bddcd64f4",
    "content": "# javascript_ast_adapter.py\n\n\"\"\"\nJavaScriptASTAdapter - Concrete AST adapter for JavaScript using tree-sitter.\n\nThis module implements the ASTAdapter interface specifically for JavaScript,\nleveraging the tree-sitter library for parsing and manipulation.\n\"\"\"\n\nimport difflib\nimport re\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for tree-sitter\ntry:\n    import tree_sitter\n    import tree_sitter_languages\n    TREETSITTER_AVAILABLE = True\nexcept ImportError:\n    TREETSITTER_AVAILABLE = False\n    # This will cause an error during initialization if the adapter is used\n\n\nclass JavaScriptASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for JavaScript source code.\n\n    This adapter uses tree-sitter to parse and manipulate JavaScript code.\n    It holds the parsed tree-sitter Tree and provides methods to interact\n    with it according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the JavaScriptASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The JavaScript source code as a string.\n\n        Raises:\n            ValueError: If tree-sitter libraries are not available or if\n                        the source code has invalid JavaScript syntax.\n        \"\"\"\n        if not TREETSITTER_AVAILABLE:\n            raise ValueError(\"tree-sitter and tree-sitter-languages are required for JavaScript support.\")\n            \n        # Store source code for diffing and manipulation\n        self.source_code: str = source_code\n        # Will hold the parsed tree-sitter tree\n        self.tree: Optional[tree_sitter.Tree] = None\n        # Will hold a mapping of element names to their tree-sitter nodes\n        self.nodes: Dict[str, tree_sitter.Node] = {}\n        # Tree-sitter language parser\n        self.language = tree_sitter_languages.get_language(\"javascript\")\n        self.parser = tree_sitter.Parser(self.language)\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the JavaScript source code and maps elements.\n\n        Args:\n            source_code: The JavaScript source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid JavaScript syntax.\n        \"\"\"\n        try:\n            # Encode the source code in bytes as required by tree-sitter\n            self.tree = self.parser.parse(bytes(source_code, \"utf-8\"))\n        except Exception as e:\n            raise ValueError(f\"Failed to parse JavaScript source: {e}\") from e\n\n        self.nodes = self._map_nodes()\n\n    def _map_nodes(self) -> Dict[str, tree_sitter.Node]:\n        \"\"\"\n        Walks the tree and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their tree-sitter nodes.\n        \"\"\"\n        nodes: Dict[str, tree_sitter.Node] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        # Define the types of nodes we're interested in\n        target_types = {\n            \"function_declaration\", \"class_declaration\", \n            \"variable_declarator\", \"import_statement\"\n        }\n        \n        # Walk the tree using a stack-based approach\n        stack = [self.tree.root_node]\n        while stack:\n            node = stack.pop()\n            \n            # Check if this is a target node type\n            if node.type in target_types:\n                # Extract the name for different node types\n                name = self._get_node_name(node)\n                if name and name not in nodes:\n                    nodes[name] = node\n            \n            # Add children to the stack for further processing\n            for child in reversed(node.children):  # Reverse to maintain order when popping\n                stack.append(child)\n                \n        return nodes\n    \n    def _get_node_name(self, node: tree_sitter.Node) -> Optional[str]:\n        \"\"\"\n        Extracts the name of a node based on its type.\n        \n        Args:\n            node: The tree-sitter node to extract the name from.\n            \n        Returns:\n            The name of the node, or None if no name could be found.\n        \"\"\"\n        if node.type == \"function_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"class_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"variable_declarator\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"import_statement\":\n            # This is a more complex case - for now, we'll use a simplified approach\n            # Extract the module name from the import statement\n            # e.g., in \"import foo from 'bar'\", we want \"foo\"\n            # This is a simplified implementation and might need refinement\n            import_clause = None\n            for child in node.children:\n                if child.type == \"import_clause\":\n                    import_clause = child\n                    break\n            \n            if import_clause:\n                # Check for a simple identifier\n                for child in import_clause.children:\n                    if child.type == \"identifier\":\n                        return child.text.decode(\"utf-8\")\n                    elif child.type == \"named_imports\":\n                        # Handle named imports like { foo, bar }\n                        # For simplicity, we'll just return a placeholder\n                        # A more complete implementation would extract all names\n                        return f\"import_from_{hash(node.text.decode('utf-8')) % 10000}\"\n        \n        return None\n\n    def _find_node_by_position(self, start_point: Tuple[int, int], \n                              end_point: Optional[Tuple[int, int]] = None) -> Optional[tree_sitter.Node]:\n        \"\"\"\n        Finds a node in the tree that corresponds to a given range.\n        \n        Args:\n            start_point: A (row, column) tuple indicating the start position.\n            end_point: A (row, column) tuple indicating the end position.\n            \n        Returns:\n            The tree-sitter node that corresponds to the range, or None if not found.\n        \"\"\"\n        if not self.tree:\n            return None\n            \n        # A simple approach: find the smallest node that contains the range\n        # This is a simplified implementation and might need refinement\n        def contains_range(node):\n            node_start = (node.start_point[0], node.start_point[1])\n            node_end = (node.end_point[0], node.end_point[1])\n            if end_point:\n                return (node_start <= start_point and node_end >= end_point)\n            else:\n                return node_start <= start_point <= node_end\n        \n        # Walk the tree to find matching nodes\n        stack = [self.tree.root_node]\n        candidates = []\n        \n        while stack:\n            current_node = stack.pop()\n            if contains_range(current_node):\n                candidates.append(current_node)\n                # Add children to continue searching for smaller nodes\n                stack.extend(current_node.children)\n        \n        # Return the smallest (last) candidate\n        return candidates[-1] if candidates else None\n    \n    def _get_line_info_from_point(self, point: Tuple[int, int]) -> Dict[str, Any]:\n        \"\"\"\n        Converts a tree-sitter point to line information.\n        \n        Args:\n            point: A (row, column) tuple from tree-sitter.\n            \n        Returns:\n            A dictionary with line_start and line_end information.\n        \"\"\"\n        # Tree-sitter uses 0-based indexing for rows\n        return {\n            'line_start': point[0] + 1,  # Convert to 1-based\n            'line_end': point[0] + 1\n        }\n\n    def _reparse_tree(self, new_source: str) -> None:\n        \"\"\"\n        Re-parses the tree with new source code.\n        \n        This is necessary because tree-sitter trees are immutable.\n        \n        Args:\n            new_source: The new source code to parse.\n        \"\"\"\n        self.source_code = new_source\n        self.tree = self.parser.parse(bytes(new_source, \"utf-8\"))\n        self.nodes = self._map_nodes()\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return node.text.decode(\"utf-8\")\n            except Exception:\n                # Handle potential decoding issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.type,\n            'line_start': node.start_point[0] + 1,  # Convert to 1-based\n            'line_end': node.end_point[0] + 1,\n            'body_items': []\n        }\n\n        # Add body items for functions and classes\n        if node.type in (\"function_declaration\", \"class_declaration\"):\n            # Find the body block\n            body_node = None\n            for child in node.children:\n                if child.type == \"statement_block\":\n                    body_node = child\n                    break\n            \n            if body_node:\n                # Process statements in the body\n                for i, item in enumerate(body_node.children):\n                    # Skip '{' and '}' tokens\n                    if item.type in (\"{\", \"}\"):\n                        continue\n                    \n                    item_info = {\n                        'index': i,\n                        'type': item.type,\n                        'line_start': item.start_point[0] + 1,\n                        'line_end': item.end_point[0] + 1\n                    }\n                    \n                    # Add more specific information based on type\n                    if item.type == \"variable_declaration\":\n                        item_info['declares'] = \"variable\"\n                    elif item.type == \"return_statement\":\n                        item_info['returns'] = True\n                    elif item.type in (\"if_statement\", \"for_statement\", \"while_statement\"):\n                        item_info['has_body'] = True\n                    \n                    structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n            \n        # A simplified approach to extracting a snippet by line numbers\n        # This would need to be more sophisticated for production use\n        source_lines = self.source_code.split('\\n')\n        # Adjust for 0-based indexing\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(source_lines), line_end)\n        \n        if start_idx < end_idx:\n            return '\\n'.join(source_lines[start_idx:end_idx])\n        \n        return None\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Replace the node's text in the source code\n        new_source = self.source_code[:start_byte] + new_code + self.source_code[end_byte:]\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass  # If we can't even re-parse the original, we're in trouble\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree:\n            return False\n            \n        # For simplicity, we'll add the new code at the end of the file\n        # A more sophisticated implementation would handle the anchor and positioning\n        new_source = self.source_code.rstrip() + \"\\n\\n\" + new_code + \"\\n\"\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Find the full lines that contain the node\n        # This is a simplified approach to avoid leaving partial lines\n        source_lines = self.source_code.split('\\n')\n        start_line = node.start_point[0]\n        end_line = node.end_point[0]\n        \n        # Create new source without those lines\n        new_lines = source_lines[:start_line] + source_lines[end_line+1:]\n        new_source = '\\n'.join(new_lines)\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        # This is a complex operation that would require more sophisticated\n        # tree navigation and manipulation than what's shown here.\n        # For now, we'll provide a basic implementation.\n        \n        node = self.nodes.get(element_name)\n        if not node:\n            return False\n            \n        # Handle line-based replacement\n        if line_start is not None:\n            # Convert to 0-based indexing\n            start_idx = max(0, line_start - 1)\n            end_idx = line_end if line_end is not None else start_idx + 1\n            \n            source_lines = self.source_code.split('\\n')\n            if start_idx < len(source_lines):\n                # Replace the specified lines\n                end_idx = min(end_idx, len(source_lines))\n                new_lines = source_lines[:start_idx] + [new_code] + source_lines[end_idx:]\n                new_source = '\\n'.join(new_lines)\n                \n                # Re-parse the tree with the new source\n                try:\n                    self._reparse_tree(new_source)\n                    return True\n                except Exception:\n                    # If parsing fails, revert to the original source\n                    try:\n                        self._reparse_tree(self.source_code)\n                    except Exception:\n                        pass\n        \n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        # For tree-sitter, the source code is already maintained separately\n        return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        \n        # Ensure line endings are consistent for diffing\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/javascript_ast_adapter.py"
  },
  {
    "id": 188,
    "hash": "89fa0c06ca34019316daa58ce8fa9a20",
    "content": "import json\nimport os\nfrom typing import List, Dict, Optional\nfrom rag_manager import RAGManager\n\n\nclass MemoryManager:\n    \"\"\"Manages persistent chat memory, look data, and RAG integration via JSON.\"\"\"\n\n    def __init__(self, memory_file: str):\n        self.memory_file = memory_file\n        self.memory: Dict[str, List] = self.load_memory()\n        self.rag_manager = RAGManager()\n\n    def load_memory(self) ->Dict[str, List]:\n        try:\n            with open(self.memory_file, 'r') as f:\n                return json.load(f)\n        except FileNotFoundError:\n            default = {'chat': [], 'look': []}\n            self.save_memory(default)\n            return default\n        except json.JSONDecodeError:\n            print('[yellow]Invalid memory file. Resetting.[/]')\n            return {'chat': [], 'look': []}\n\n    def save_memory(self, memory: Optional[Dict[str, List]]=None) ->None:\n        if memory is None:\n            memory = self.memory\n        with open(self.memory_file, 'w') as f:\n            json.dump(memory, f, indent=4)\n\n    def add_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.memory['chat'].append({'role': role, 'content': content})\n        self.save_memory()\n\n    def add_chat_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        This is an alias for add_message to maintain compatibility.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.add_message(role, content)\n\n    def add_look_data(self, file_path: str, content: str) ->None:\n        \"\"\"\n    Adds a watched item (directory or file) to memory, distinguishing its type.\n\n    This method stores structured data that differentiates between a project\n    directory (containing a manifest) and a single file (containing its content).\n    It also prevents duplicate entries by updating existing ones.\n\n    Args:\n        file_path: The path to the directory or file.\n        content: The manifest for a directory or the content for a file.\n    \"\"\"\n        item_type = 'directory' if os.path.isdir(file_path) else 'file'\n        for item in self.memory['look']:\n            if item.get('file') == file_path:\n                item['content'] = content\n                item['type'] = item_type\n                self.save_memory()\n                return\n        self.memory['look'].append({'type': item_type, 'file': file_path,\n            'content': content})\n        self.save_memory()\n        if item_type == 'file':\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    file_content = f.read()\n                self.rag_manager.add_documents([file_content], [{'file':\n                    file_path}])\n            except Exception as e:\n                print(\n                    f'[yellow]Warning: Could not add {file_path} to RAG index: {e}[/]'\n                    )\n\n    def get_project_root(self) ->Optional[str]:\n        \"\"\"\n        Finds the root directory of the project currently in memory.\n\n        The project root is defined as the first item in the 'look' memory\n        that is of type 'directory'.\n\n        Returns:\n            The absolute path to the project root directory, or None if not found.\n        \"\"\"\n        for item in self.memory.get('look', []):\n            if item.get('type') == 'directory':\n                return item.get('file')\n        return None\n\n    def get_memory_context(self) ->str:\n        \"\"\"\n        Dynamically builds the context using RAG and chat history.\n\n        It retrieves relevant file content from the RAG index based on the latest\n        user query, includes project manifests for directories, and appends the\n        recent chat history.\n        \"\"\"\n        context = ''\n        for look in self.memory.get('look', []):\n            path = look.get('file')\n            if path and os.path.isdir(path):\n                content = look.get('content', '')\n                context += (\n                    f'--- Project Manifest for {path} ---\\n{content}\\n\\n')\n        last_user_message = next((msg['content'] for msg in reversed(self.\n            memory.get('chat', [])) if msg['role'] == 'user'), None)\n        if last_user_message:\n            rag_results = self.search_rag(last_user_message, k=3)\n            if rag_results:\n                context += '--- Relevant context from RAG ---\\n'\n                for doc, score, meta in rag_results:\n                    file_path = meta.get('file', 'Unknown source')\n                    context += f'Source: {file_path} (Score: {score:.4f})\\n'\n                    context += f'Content: {doc}\\n---\\n'\n                context += '\\n'\n        for msg in self.memory.get('chat', []):\n            context += f\"{msg['role'].capitalize()}: {msg['content']}\\n\"\n        return context.strip()\n\n    def clear_memory(self) ->None:\n        self.memory = {'chat': [], 'look': []}\n        self.save_memory()\n        self.rag_manager.clear_index()\n\n    def search_rag(self, query: str, k: int=3) ->List[tuple]:\n        \"\"\"\n        Search the RAG index for relevant documents.\n        \n        Args:\n            query: The search query\n            k: Number of results to return\n            \n        Returns:\n            List of (document_content, score, metadata) tuples\n        \"\"\"\n        return self.rag_manager.search(query, k)\n",
    "file": "/mnt/ProjectData/omni/memory_manager.py"
  },
  {
    "id": 189,
    "hash": "fefce358bada61faf78f7880c778938c",
    "content": "\"\"\"\nOmni - AI-powered code generation and project-aware editing CLI tool\n\nIntegrates modular UI, memory, personality, and AST-based code editing.\n\"\"\"\nimport os\nimport subprocess\nimport requests\nimport json\nimport sys\nimport re\nimport argparse\nimport ast\nfrom datetime import datetime\nimport threading\nimport queue as Queue\nimport time\nfrom typing import List, Dict, Optional\nfrom rich import print\nfrom rich.panel import Panel\nfrom rich.console import Console\nfrom rich.tree import Tree\nfrom ui_manager import UIManager\nfrom personality_manager import PersonalityManager\nfrom memory_manager import MemoryManager\nfrom code_editor import CodeEditor\nfrom file_creator import FileCreator\nfrom git_manager import GitManager\nimport traceback\nDEFAULT_BACKEND = 'openrouter'\nOLLAMA_MODEL = 'phi4-reasoning'\nOPENROUTER_MODEL = 'qwen/qwen3-coder'\nDEFAULT_SAVE_DIR = os.path.expanduser('/mnt/ProjectData/omni/omni_saves/')\nCONFIG_FILE = 'config.json'\nMEMORY_FILE = 'memory.json'\nOLLAMA_API_URL = 'http://localhost:11434/api/generate'\nOPENROUTER_API_URL = 'https://openrouter.ai/api/v1/chat/completions'\nOPENROUTER_MODELS_API_URL = 'https://openrouter.ai/api/v1/models'\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\ncurrent_backend = DEFAULT_BACKEND\ncurrent_model = (OLLAMA_MODEL if DEFAULT_BACKEND == 'ollama' else\n    OPENROUTER_MODEL)\nOLLAMA_MODELS = {'deepseek': 'deepseek-coder:6.7b', 'codellama':\n    'codellama:13b', 'mistral': 'mistral:latest', 'llama2': 'llama2:latest',\n    'phind': 'phind-codellama:34b'}\nos.makedirs(DEFAULT_SAVE_DIR, exist_ok=True)\nTEMPLATES = {'flask':\n    \"\"\"from flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/')\ndef home():\n    return '<h1>Hello, Flask!</h1>'\n\nif __name__ == '__main__':\n    app.run(debug=True)\"\"\"\n    , 'html5':\n    \"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>New Page</title>\n</head>\n<body>\n    <h1>Hello World</h1>\n</body>\n</html>\"\"\"\n    , 'scraper':\n    \"\"\"import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        print(soup.title.text)\n    except Exception as e:\n        print(f\"[bold red]Error scraping {url}:[/] {e}\")\n\nif __name__ == \"__main__\":\n    scrape(\"https://example.com\")\"\"\"\n    }\nconsole = Console()\npersonality_manager = PersonalityManager(CONFIG_FILE)\nmemory_manager = MemoryManager(MEMORY_FILE)\nui_manager = UIManager()\nlast_query: Optional[str] = None\nlast_response: Optional[str] = None\nlast_code: Optional[str] = None\n\n\ndef start_ollama_server() ->None:\n    if current_backend != 'ollama':\n        return\n    try:\n        requests.get('http://localhost:11434', timeout=1)\n    except requests.exceptions.ConnectionError:\n        print('[cyan]Starting Ollama server...[/]')\n        subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL)\n\n\ndef query_llm(prompt: str) ->str:\n    personality = personality_manager.get_current_personality()\n    system_prompt = personality.get('system_prompt', '') if personality else ''\n    memory_context = memory_manager.get_memory_context()\n    rag_context = ''\n    try:\n        from rag_manager import RAGManager\n        project_root = memory_manager.get_project_root()\n        if project_root:\n            rag_manager = RAGManager()\n            if rag_manager.get_document_count() > 0:\n                results = rag_manager.search(prompt, k=3)\n                if results:\n                    rag_context = '\\n\\nRelevant context from codebase:\\n'\n                    for i, (doc, score, meta) in enumerate(results, 1):\n                        file_path = meta.get('file', 'Unknown')\n                        rag_context += f'{i}. [{file_path}] {doc}\\n'\n    except Exception:\n        pass\n    full_prompt = (\n        f'{system_prompt}\\n\\n{memory_context}{rag_context}\\n\\nUser: {prompt}')\n    with ui_manager.show_spinner('AI is listening and thinking...'):\n        if current_backend == 'ollama':\n            response = query_ollama(full_prompt)\n        elif current_backend == 'openrouter':\n            response = query_openrouter(full_prompt)\n        else:\n            response = '[bold red]Error:[/] Unknown backend'\n    return response\n\n\ndef query_openrouter(prompt: str) ->str:\n    if not OPENROUTER_API_KEY:\n        return '[bold red]Error:[/] OPENROUTER_API_KEY not set.'\n    headers = {'Authorization': f'Bearer {OPENROUTER_API_KEY}',\n        'Content-Type': 'application/json'}\n    payload = {'model': current_model, 'messages': [{'role': 'user',\n        'content': prompt}]}\n    try:\n        response = requests.post(OPENROUTER_API_URL, headers=headers, json=\n            payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['choices'][0]['message']['content']\n    except Exception as e:\n        error_details = ''\n        try:\n            error_details = response.json()\n        except:\n            error_details = response.text if hasattr(response, 'text'\n                ) else str(e)\n        return (\n            f'[bold red]OpenRouter Error:[/] {e}\\n[dim]Details: {error_details}[/dim]'\n            )\n\n\ndef query_ollama(prompt: str) ->str:\n    payload = {'model': current_model, 'prompt': prompt, 'stream': False}\n    try:\n        response = requests.post(OLLAMA_API_URL, json=payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['response']\n    except Exception as e:\n        return f'[bold red]Ollama Error:[/] {e}'\n\n\ndef extract_code(text: str) ->List[tuple[str, str]]:\n    matches = re.findall('```(\\\\w*)\\\\n([\\\\s\\\\S]*?)```', text)\n    return [(lang or 'text', code.strip()) for lang, code in matches\n        ] if matches else []\n\n\ndef list_models(args: list=None) ->None:\n    if current_backend == 'ollama':\n        print('[bold cyan]Popular Ollama Models:[/]')\n        for name, model_id in OLLAMA_MODELS.items():\n            print(\n                f\"{'\u2b50' if model_id == current_model else '  '} [yellow]{name:12}[/] \u2192 {model_id}\"\n                )\n    elif current_backend == 'openrouter':\n        list_openrouter_models(args or [])\n\n\ndef list_openrouter_models(args: list):\n    try:\n        from simple_term_menu import TerminalMenu\n    except ImportError:\n        ui_manager.show_error(\n            \"'simple-term-menu' is required. `pip install simple-term-menu`\")\n        return\n    try:\n        with ui_manager.show_spinner('Fetching models...'):\n            response = requests.get(OPENROUTER_MODELS_API_URL)\n            response.raise_for_status()\n        api_models_data = response.json().get('data', [])\n    except requests.RequestException as e:\n        ui_manager.show_error(f'Error fetching models: {e}')\n        return\n    all_models, sources = [], set()\n    for model_data in api_models_data:\n        if (model_id := model_data.get('id')):\n            sources.add(model_id.split('/')[0])\n            pricing = model_data.get('pricing', {})\n            is_free = pricing.get('prompt') == '0' and pricing.get('completion'\n                ) == '0'\n            all_models.append({'id': model_id, 'name': model_data.get(\n                'name'), 'source': model_id.split('/')[0], 'is_free': is_free})\n    all_models.sort(key=lambda x: (x['source'], x['name']))\n    if args and args[0].lower() == 'sources':\n        print('[bold cyan]Available Model Sources:[/]')\n        [print(f'  [yellow]{s}[/]') for s in sorted(list(sources))]\n        return\n    models_to_display, title = all_models, 'Select an OpenRouter Model'\n    if args:\n        filter_keyword = args[0].lower()\n        title = f\"Select a Model from '{filter_keyword}'\"\n        models_to_display = [m for m in all_models if filter_keyword in m[\n            'source'].lower()]\n        if not models_to_display:\n            ui_manager.show_error(f\"No models for source: '{filter_keyword}'\")\n            return\n    menu_entries = [\n        f\"{'\u2b50' if m['id'] == current_model else '  '} {m['name']} [dim]({m['id']}){' [green](FREE)[/]' if m['is_free'] else ''}[/dim]\"\n         for m in models_to_display]\n    try:\n        cursor_idx = next((i for i, m in enumerate(models_to_display) if m[\n            'id'] == current_model), 0)\n        chosen_index = TerminalMenu(menu_entries, title=f'{title}',\n            cursor_index=cursor_idx, cycle_cursor=True, clear_screen=True\n            ).show()\n        if chosen_index is not None:\n            set_model(models_to_display[chosen_index]['id'])\n        else:\n            print('Model selection cancelled.')\n    except Exception as e:\n        ui_manager.show_error(f'Menu display error: {e}')\n\n\ndef set_model(model_id: str) ->None:\n    global current_model\n    current_model = model_id\n    ui_manager.show_success(f'Model set to: {current_model}')\n\n\ndef switch_backend(backend_name: str) ->None:\n    global current_backend, current_model\n    backend_name = backend_name.lower()\n    if backend_name not in ['ollama', 'openrouter']:\n        ui_manager.show_error(f'Unknown backend: {backend_name}')\n        return\n    current_backend = backend_name\n    current_model = (OLLAMA_MODEL if backend_name == 'ollama' else\n        OPENROUTER_MODEL)\n    ui_manager.show_success(\n        f'Switched to {backend_name} backend with model: {current_model}')\n    if backend_name == 'ollama':\n        start_ollama_server()\n\n\ndef generate_project_manifest(path: str) ->tuple[str, List[str]]:\n    manifest = ''\n    file_paths = []\n    tree = Tree(f'[bold cyan]Project: {os.path.basename(path)}[/]')\n    exclude_dirs = {'__pycache__', '.git', 'venv', 'node_modules', '.idea',\n        'ollama'}\n    for root, dirs, files in os.walk(path):\n        dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.\n            startswith('.')]\n        relative_path = os.path.relpath(root, path)\n        branch = tree\n        if relative_path != '.':\n            parts = relative_path.split(os.sep)\n            for part in parts:\n                child = next((c for c in branch.children if c.label ==\n                    f'[magenta]{part}[/]'), None)\n                if not child:\n                    child = branch.add(f'[magenta]{part}[/]')\n                branch = child\n        for fname in sorted(files):\n            ext = os.path.splitext(fname)[1]\n            if ext not in ('.py', '.js', '.html', '.css', '.md', '.txt'):\n                continue\n            rel_path = os.path.join(relative_path, fname\n                ) if relative_path != '.' else fname\n            file_paths.append(rel_path)\n            branch.add(f'[green]{fname}[/]' if ext == '.py' else\n                f'[dim]{fname}[/]')\n            manifest += f'File: {rel_path}\\n\\n'\n    console.print(tree)\n    return manifest.strip(), file_paths\n\n\ndef look_command(path: str) ->None:\n    \"\"\"\n    Scans a directory or file and loads it into memory. It can resolve paths\n    relative to the current working directory or the project root in memory.\n    If a new directory is scanned, the previous 'look' context is cleared\n    to ensure the context remains relevant.\n    \"\"\"\n    resolved_path = resolve_file_path(path)\n    if not resolved_path:\n        ui_manager.show_error(f'\u274c Path not found: {path}')\n        return\n    if resolved_path != os.path.abspath(path):\n        ui_manager.show_success(\n            f\"Found '{path}' in project. Using: {resolved_path}\")\n    if os.path.isdir(resolved_path):\n        ui_manager.show_success(\n            \"New project directory detected. Clearing previous 'look' context.\"\n            )\n        memory_manager.memory['look'] = []\n        with ui_manager.show_spinner('Generating project manifest...'):\n            manifest = generate_project_manifest(resolved_path)\n        memory_manager.add_look_data(resolved_path, manifest)\n        ui_manager.show_success('\u2705 Project manifest added to memory.')\n    else:\n        try:\n            with ui_manager.show_spinner('Loading file...'):\n                with open(resolved_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n            for item in memory_manager.memory['look']:\n                if item.get('file') == resolved_path:\n                    item['content'] = content\n                    memory_manager.save_memory()\n                    ui_manager.show_success(\n                        '\u2705 Refreshed file content in memory.')\n                    return\n            memory_manager.add_look_data(resolved_path, content)\n            ui_manager.show_success('\u2705 File content added to memory.')\n        except Exception as e:\n            ui_manager.show_error(f'\u274c Error reading file: {e}')\n\n\ndef resolve_file_path(path: str) ->Optional[str]:\n    \"\"\"Resolves a file path, checking CWD first, then against project root in memory.\"\"\"\n    if os.path.exists(path):\n        return os.path.abspath(path)\n    project_root = memory_manager.get_project_root()\n    if project_root:\n        full_path = os.path.join(project_root, path)\n        if os.path.exists(full_path):\n            return full_path\n    return None\n\n\ndef _create_prompt_for_file_creation(file_name: str, instruction: str) ->str:\n    \"\"\"\n    Generate a robust prompt for file creation that instructs the AI to act as an expert,\n    produce complete and clean code, and avoid any extra commentary.\n    \"\"\"\n    return f\"\"\"You are an expert programmer tasked with creating a new file. Your goal is to generate complete, production-ready content based on the user's instruction.\n\nIMPORTANT RULES:\n- Provide ONLY the raw file content - no explanations, notes, or commentary outside the file itself\n- Include all necessary imports, boilerplate, and complete implementations\n- If creating code, ensure it's syntactically correct and follows best practices\n- For configuration files, use appropriate formatting (JSON, YAML, etc.)\n- For documentation files, use proper markdown formatting\n\nFile to create: {file_name}\nUser instruction: {instruction}\n\nGenerate the complete file content now:\"\"\"\n\n\ndef handle_file_create_command(file_path: str, instruction: str):\n    \"\"\"\n    Uses the LLM to generate content for a new file based on an instruction.\n    \"\"\"\n    global last_code\n    if os.path.exists(file_path):\n        if ui_manager.get_user_input(\n            f\"File '{file_path}' already exists. Overwrite? (y/n): \").lower(\n            ) not in ['yes', 'y']:\n            ui_manager.show_error('File creation cancelled.')\n            return\n    prompt = _create_prompt_for_file_creation(os.path.basename(file_path),\n        instruction)\n    with ui_manager.show_spinner(\n        f\"AI is generating content for '{file_path}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    if code_blocks:\n        new_content = code_blocks[0][1]\n    else:\n        new_content = response.strip()\n    if not new_content:\n        ui_manager.show_error('AI did not return any content.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    print(Panel(new_content, title=\n        f'[bold yellow]Proposed content for {file_path}[/]', border_style=\n        'yellow'))\n    if ui_manager.get_user_input('Create this file? (y/n): ').lower() in ['yes'\n        , 'y']:\n        try:\n            FileCreator.create(file_path, new_content)\n            last_code = new_content\n            ui_manager.show_success(f'File created successfully: {file_path}')\n        except IOError as e:\n            ui_manager.show_error(f'Error creating file: {e}')\n    else:\n        ui_manager.show_error('File creation cancelled.')\n\n\ndef look_all_command() ->None:\n    \"\"\"\n    Finds the project manifest in memory, reads every file listed, and adds their content to memory.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first to generate a manifest.\"\n            )\n        return\n    manifest_data = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and item.get('type'\n            ) == 'directory':\n            manifest_data = item.get('content')\n            break\n    if not manifest_data or not isinstance(manifest_data, (list, tuple)\n        ) or len(manifest_data) != 2:\n        ui_manager.show_error(\n            \"Could not find a valid project manifest in memory. Please run 'look <directory>' again.\"\n            )\n        return\n    file_paths = manifest_data[1]\n    if not file_paths:\n        ui_manager.show_error('No files found in the project manifest.')\n        return\n    total_files = len(file_paths)\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Loading {total_files} files from project manifest...'):\n        for file_path_relative in file_paths:\n            full_path = os.path.join(project_root, file_path_relative)\n            if os.path.isfile(full_path):\n                try:\n                    with open(full_path, 'r', encoding='utf-8') as f:\n                        content = f.read().strip()\n                    if not any(look['file'] == full_path for look in\n                        memory_manager.memory['look']):\n                        memory_manager.add_look_data(full_path, content)\n                        loaded_count += 1\n                except Exception as e:\n                    print(\n                        f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\"\n                        )\n    ui_manager.show_success(\n        f'\u2705 Loaded content for {loaded_count} new files into memory.')\n\n\ndef _load_all_project_files_if_needed():\n    \"\"\"\n    Checks if a project is loaded and automatically loads any files from its\n    manifest that are not already in the 'look' memory. This ensures a\n    complete context for editing and refactoring commands.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        return\n    manifest_content = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and 'File:' in item.get('content',\n            ''):\n            manifest_content = item['content']\n            break\n    if not manifest_content:\n        return\n    existing_file_paths = {item['file'] for item in memory_manager.memory.\n        get('look', []) if item.get('type') == 'file'}\n    file_paths_relative = re.findall('File: (.*)', manifest_content)\n    files_to_load = []\n    for rel_path in file_paths_relative:\n        full_path = os.path.join(project_root, rel_path)\n        if full_path not in existing_file_paths and os.path.isfile(full_path):\n            files_to_load.append((full_path, rel_path))\n    if not files_to_load:\n        return\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Auto-loading {len(files_to_load)} project files for context...'):\n        for full_path, file_path_relative in files_to_load:\n            try:\n                with open(full_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n                memory_manager.add_look_data(full_path, content)\n                loaded_count += 1\n            except Exception as e:\n                print(f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\")\n    if loaded_count > 0:\n        ui_manager.show_success(\n            f'\u2705 Loaded {loaded_count} new file(s) into memory for full project context.'\n            )\n\n\ndef _create_prompt_for_element_selection(file_name: str, instruction: str,\n    elements: List[str], element_structures: Dict[str, Dict]) ->str:\n    \"\"\"\n    Create a helper for the first stage of the 'edit' command. This prompt asks the AI\n    to analyze the user's instruction and intelligently select the most relevant code element to modify.\n    \"\"\"\n    element_details = []\n    for elem in elements:\n        if elem in element_structures:\n            struct = element_structures[elem]\n            detail = (\n                f\"{elem} ({struct['type']}, lines {struct['line_start']}-{struct['line_end']})\"\n                )\n            element_details.append(detail)\n        else:\n            element_details.append(elem)\n    elements_str = ', '.join(element_details) if element_details else 'None'\n    return f\"\"\"You are an expert code analyzer. Your task is to identify what should be modified based on the user's instruction.\n\nFile: {file_name}\nAvailable elements: {elements_str}\n\nUser instruction: {instruction}\n\nRESPONSE FORMAT:\nChoose one of these response types:\n1. \"ELEMENT: <element_name>\" - to edit an entire function/class\n2. \"PARTIAL: <element_name> LINES: <start>-<end>\" - to edit specific lines within an element\n3. \"FILE\" - to edit the entire file or multiple elements\n\nVALID ELEMENT NAMES:\n{chr(10).join(f'- {elem}' for elem in elements) if elements else 'None'}\n\nRULES:\n- If the instruction mentions specific line numbers or a specific part of a function, use PARTIAL\n- If the instruction targets an entire function/class, use ELEMENT\n- If the instruction requires changes to multiple elements or file structure, use FILE\n- For PARTIAL edits, provide absolute line numbers from the original file\n- ONLY use element names from the \"Available elements\" list above\n- If no suitable element exists, use \"FILE\"\n- NEVER return an element name that is not in the available list\n\nWhat should be edited?\"\"\"\n\n\ndef _create_prompt_for_element_rewrite(file_name: str, element_name: str,\n    instruction: str, original_code: str, is_full_file: bool=False) ->str:\n    \"\"\"\n    Create a helper for the second stage of the 'edit' command. This prompt instructs the AI\n    to rewrite a specific code element (or the whole file) based on the user's request,\n    demanding a complete and syntactically correct code block as output.\n    \"\"\"\n    if is_full_file:\n        return f\"\"\"You are an expert programmer. Rewrite the entire file to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the entire file\n- Ensure all syntax is correct and the code is ready to run\n- Preserve existing functionality unless explicitly asked to change it\n- Include all necessary imports and maintain the file's structure\n- Do NOT include any explanations or comments outside the code\n\nFile: {file_name}\nTask: {instruction}\n\nCurrent file content:\n```python\n{original_code}\n```\n\nGenerate the complete updated file now:\"\"\"\n    else:\n        return f\"\"\"You are an expert programmer. Rewrite the specified element to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the element\n- Include any necessary imports at the top of your code block\n- Ensure the code is syntactically correct and maintains the same interface\n- Do NOT include explanations or comments outside the code block\n- The code must be a drop-in replacement for the original element\n\nFile: {file_name}\nElement to modify: {element_name}\nTask: {instruction}\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the complete updated element now:\"\"\"\n\n\ndef _create_prompt_for_partial_edit(file_name: str, element_name: str,\n    instruction: str, original_snippet: str, line_start: int, line_end: int,\n    full_element_code: str) ->str:\n    \"\"\"\n    Create a prompt for partial edits within a function or class.\n    This allows surgical changes to specific parts of code.\n    \"\"\"\n    return f\"\"\"You are an expert programmer. Make a surgical edit to a specific part of a function/class.\n\nCONTEXT:\n- File: {file_name}\n- Element: {element_name}\n- Lines to modify: {line_start}-{line_end}\n- Task: {instruction}\n\nIMPORTANT RULES:\n- Provide ONLY the code that will replace lines {line_start}-{line_end}\n- Your code must fit seamlessly into the existing function\n- Maintain proper indentation (the code will be auto-indented)\n- Do NOT include the function definition or other parts\n- Do NOT include explanations outside the code\n\nFull element for context:\n```python\n{full_element_code}\n```\n\nCode section to replace (lines {line_start}-{line_end}):\n```python\n{original_snippet}\n```\n\nGenerate ONLY the replacement code for the specified lines:\"\"\"\n\n\ndef handle_file_edit_command(file_path: str, instruction: str):\n    \"\"\"\n    Handles the entire workflow for editing a single file, ensuring full\n    project context is loaded before the AI makes any decisions.\n    Now supports partial edits within functions.\n    \"\"\"\n    global last_code\n    _load_all_project_files_if_needed()\n    resolved_path = resolve_file_path(file_path)\n    if not resolved_path:\n        ui_manager.show_error(f'File not found: {file_path}')\n        return\n    if resolved_path != os.path.abspath(file_path):\n        ui_manager.show_success(\n            f\"Found '{file_path}' in project. Using: {resolved_path}\")\n    try:\n        editor = CodeEditor(resolved_path)\n    except (ValueError, FileNotFoundError) as e:\n        ui_manager.show_error(str(e))\n        return\n    elements = editor.list_elements()\n    element_structures = {}\n    for elem in elements:\n        struct = editor.get_element_structure(elem)\n        if struct:\n            element_structures[elem] = struct\n    prompt1 = _create_prompt_for_element_selection(os.path.basename(\n        resolved_path), instruction, elements, element_structures)\n    with ui_manager.show_spinner('AI is analyzing file...'):\n        ai_response = query_llm(prompt1).strip()\n    if ai_response.upper() == 'FILE':\n        ui_manager.show_success('AI has chosen to edit the entire file.')\n        original_snippet = editor.source_code\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), 'entire file', instruction, original_snippet,\n            is_full_file=True)\n        edit_type = 'FILE'\n        element_to_edit = None\n        line_range = None\n    elif ai_response.startswith('PARTIAL:'):\n        parts = ai_response.split()\n        element_to_edit = parts[1]\n        if 'LINES:' in ai_response:\n            line_part = ai_response.split('LINES:')[1].strip()\n            if '-' in line_part:\n                line_start, line_end = map(int, line_part.split('-'))\n                line_range = line_start, line_end\n            else:\n                ui_manager.show_error('Invalid line range format')\n                return\n        else:\n            ui_manager.show_error('Missing line range for partial edit')\n            return\n        if element_to_edit not in elements:\n            ui_manager.show_error(f\"Element '{element_to_edit}' not found\")\n            return\n        ui_manager.show_success(\n            f\"AI selected partial edit of '{element_to_edit}' (lines {line_start}-{line_end})\"\n            )\n        original_snippet = editor.get_element_body_snippet(element_to_edit,\n            line_start, line_end)\n        if not original_snippet:\n            original_snippet = editor.get_source_of(element_to_edit)\n        full_element_code = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_partial_edit(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet,\n            line_start, line_end, full_element_code)\n        edit_type = 'PARTIAL'\n    elif ai_response.startswith('ELEMENT:'):\n        element_to_edit = ai_response.split(':', 1)[1].strip()\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    else:\n        element_to_edit = ai_response.splitlines()[0]\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    with ui_manager.show_spinner(f'AI is editing...'):\n        response = query_llm(prompt2)\n    code_blocks = extract_code(response)\n    if not code_blocks:\n        ui_manager.show_error('AI did not return a valid code block.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    new_code = code_blocks[0][1]\n    success = False\n    if edit_type == 'FILE':\n        try:\n            editor.tree = ast.parse(new_code)\n            success = True\n        except SyntaxError as e:\n            ui_manager.show_error(f'AI returned invalid Python syntax: {e}')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    elif edit_type == 'PARTIAL':\n        success = editor.replace_partial(element_to_edit, new_code,\n            line_start=line_range[0], line_end=line_range[1])\n        if not success:\n            ui_manager.show_error('Failed to apply partial edit.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    else:\n        success = editor.replace_element(element_to_edit, new_code)\n        if not success:\n            ui_manager.show_error(\n                'AI returned invalid code; could not be parsed or applied.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    if not (diff := editor.get_diff()):\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(diff, title=\n        f'[bold yellow]Proposed Changes for {resolved_path}[/]'))\n    if ui_manager.get_user_input('Apply changes? (y/n): ').lower() in ['yes',\n        'y']:\n        editor.save_changes()\n        last_code = editor.get_modified_source()\n        ui_manager.show_success(f'Changes saved to {resolved_path}.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_plan(instruction: str, memory_context: str\n    ) ->str:\n    \"\"\"\n    Create a specialized prompt-generation function for the 'refactor' command.\n    This prompt will explicitly define the required JSON structure for the plan\n    and instruct the AI to act as an expert project manager.\n    \"\"\"\n    return f\"\"\"You are an expert project manager and software architect. Analyze the project context and create a detailed refactoring plan.\n\nYour plan must be a valid JSON object with this exact structure:\n{{\n    \"actions\": [\n        {{\n            \"type\": \"MODIFY\" | \"CREATE\" | \"DELETE\" | \"PARTIAL\",\n            \"file\": \"relative/path/to/file.py\",\n            \"element\": \"function_or_class_name\",  // For MODIFY/DELETE/PARTIAL\n            \"element_name\": \"new_element_name\",    // For CREATE\n            \"line_start\": 10,                      // For PARTIAL only\n            \"line_end\": 20,                        // For PARTIAL only\n            \"reason\": \"Clear explanation of why this change is needed\",\n            \"description\": \"What this action will accomplish\",\n            \"anchor_element\": \"optional_anchor\",   // Optional for CREATE\n            \"position\": \"before\" | \"after\"         // Optional for CREATE\n        }}\n    ]\n}}\n\nACTION TYPES:\n- MODIFY: Change an entire function, class, or method\n- PARTIAL: Change specific lines within a function/class (requires line_start and line_end)\n- CREATE: Add new functions, classes, or files\n- DELETE: Remove functions, classes, variables, or imports\n\nRULES FOR YOUR PLAN:\n- Use PARTIAL when you only need to change a small part of a function\n- Use MODIFY when restructuring an entire function or class\n- Each action must have all required fields based on its type\n- File paths must be relative to the project root\n- Be specific and surgical - avoid unnecessary changes\n- Consider dependencies between changes\n- Order actions logically (e.g., create dependencies before using them)\n\n### Project Context ###\n{memory_context}\n\n### Refactoring Request ###\n{instruction}\n\nGenerate ONLY the JSON plan - no explanations or markdown:\"\"\"\n\n\ndef _get_refactor_plan(instruction: str) ->Optional[List[Dict]]:\n    \"\"\"\n    Generates a refactoring plan from the LLM.\n\n    This function encapsulates the logic for checking project context,\n    constructing a prompt, querying the LLM, and parsing the resulting\n    JSON plan for a refactoring task.\n\n    Args:\n        instruction: The user's high-level refactoring instruction.\n\n    Returns:\n        A list of action dictionaries if a valid plan is generated,\n        otherwise None.\n    \"\"\"\n    if not memory_manager.get_project_root():\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return None\n    memory_context = memory_manager.get_memory_context()\n    plan_prompt = _create_prompt_for_refactor_plan(instruction, memory_context)\n    with ui_manager.show_spinner('AI is creating an execution plan...'):\n        plan_str = query_llm(plan_prompt)\n    try:\n        match = re.search('\\\\{.*\\\\}', plan_str, re.DOTALL)\n        if not match:\n            raise ValueError('No JSON object found in the response.')\n        plan = json.loads(match.group(0))\n        actions = plan.get('actions', [])\n        if not actions:\n            raise ValueError(\"No 'actions' key found in plan or plan is empty.\"\n                )\n        return actions\n    except (json.JSONDecodeError, ValueError) as e:\n        ui_manager.show_error(f'AI failed to generate a valid plan: {e}')\n        print(Panel(plan_str, title=\"[yellow]AI's Invalid Plan Response[/]\",\n            border_style='yellow'))\n        return None\n\n\ndef _display_and_confirm_plan(plan: Dict) ->bool:\n    \"\"\"\n    Displays the generated execution plan to the user and asks for confirmation.\n\n    This helper function separates the UI interaction of plan confirmation from\n    the main refactoring logic.\n\n    Args:\n        plan: A dictionary, expected to contain an 'actions' key with a list of action dicts.\n\n    Returns:\n        True if the user confirms the plan, False otherwise.\n    \"\"\"\n    actions = plan.get('actions', [])\n    if not actions:\n        ui_manager.show_error('The generated plan is empty. Aborting.')\n        return False\n    ui_manager.show_success('AI has created a plan:')\n    for i, action in enumerate(actions):\n        action_type = action.get('type', 'N/A')\n        element = action.get('element') or action.get('element_name', 'N/A')\n        reason = action.get('reason') or action.get('description', '')\n        file_path = action.get('file', '')\n        if action_type == 'PARTIAL':\n            line_start = action.get('line_start', '?')\n            line_end = action.get('line_end', '?')\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} (lines {line_start}-{line_end}) - {reason}'\n                )\n        else:\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} - {reason}'\n                )\n    if ui_manager.get_user_input('\\nProceed with this plan? (y/n): ').lower(\n        ) in ['yes', 'y']:\n        return True\n    else:\n        ui_manager.show_error('Execution aborted by user.')\n        return False\n\n\ndef _apply_refactor_changes(editors: Dict[str, CodeEditor]) ->None:\n    \"\"\"\n    Consolidates changes from multiple CodeEditor instances, shows a unified\n    diff, and prompts the user to apply them.\n    \n    This helper function abstracts the final step of a refactor, ensuring\n    all proposed modifications are presented to the user for a final review\n    before any files are written to disk.\n\n    Args:\n        editors: A dictionary mapping absolute file paths to their\n                 corresponding CodeEditor instances which hold the\n                 proposed changes in their AST.\n    \"\"\"\n    full_diff = ''\n    for editor in editors.values():\n        diff = editor.get_diff()\n        if diff:\n            full_diff += diff + '\\n'\n    if not full_diff.strip():\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(full_diff, title=\n        '[bold yellow]Proposed Project-Wide Changes[/]'))\n    if ui_manager.get_user_input('Apply all changes? (y/n): ').lower() in [\n        'yes', 'y']:\n        for editor in editors.values():\n            editor.save_changes()\n        ui_manager.show_success('\u2705 Project changes applied successfully.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_action(action_type: str, file_path: str,\n    action_details: Dict) ->str:\n    \"\"\"\n    Create a helper to generate prompts for individual 'CREATE' or 'MODIFY' steps\n    within a refactor plan. This ensures the AI produces code for the specific\n    sub-task in the correct context.\n    \"\"\"\n    if action_type == 'MODIFY':\n        element_name = action_details['element_name']\n        reason = action_details['reason']\n        original_code = action_details['original_code']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- Element: {element_name}\n- Reason for change: {reason}\n\nRULES:\n- Provide ONLY the complete updated code for the element\n- Include any necessary imports at the top\n- Ensure the code integrates properly with the rest of the file\n- Maintain the same function/class signature unless the change requires otherwise\n- No explanations outside the code block\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the updated element code:\"\"\"\n    elif action_type == 'CREATE':\n        element_name = action_details['element_name']\n        description = action_details['description']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- New element to create: {element_name}\n- Purpose: {description}\n\nRULES:\n- Provide ONLY the complete code for the new element\n- Include all necessary imports at the top\n- Follow the coding style and patterns used in the project\n- Ensure the code is production-ready and well-structured\n- For non-Python files, provide the complete file content\n- No explanations outside the code block\n\nGenerate the new element code:\"\"\"\n\n\ndef _process_refactor_action(action: Dict, project_base_path: str, editors:\n    Dict) ->bool:\n    \"\"\"\n    Processes a single refactoring action from the plan.\n\n    This function handles the execution of a single action from the refactoring plan,\n    including LLM code generation and applying changes to in-memory editors or files.\n\n    Args:\n        action: A dictionary containing action details (type, file, element, etc.)\n        project_base_path: The absolute path to the project root\n        editors: Dictionary mapping file paths to their CodeEditor instances\n\n    Returns:\n        True if the action was processed successfully, False otherwise\n    \"\"\"\n    file_path_relative = action.get('file')\n    if not file_path_relative:\n        ui_manager.show_error(\n            f\"Action is missing 'file' key. Skipping: {action}\")\n        return False\n    file_path_absolute = os.path.join(project_base_path, file_path_relative)\n    action_type = action.get('type', '').upper()\n    prompt, element_name = '', ''\n    if action_type == 'MODIFY':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_source_of(element_name)\n            if not original_snippet:\n                ui_manager.show_error(\n                    f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                    )\n                return False\n            action_details = {'element_name': element_name, 'reason':\n                reason, 'original_code': original_snippet}\n            prompt = _create_prompt_for_refactor_action('MODIFY',\n                file_path_relative, action_details)\n    elif action_type == 'PARTIAL':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        line_start = action.get('line_start')\n        line_end = action.get('line_end')\n        if not all([element_name, line_start, line_end]):\n            ui_manager.show_error(\n                f'PARTIAL action missing required fields. Skipping: {action}')\n            return False\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_element_body_snippet(element_name,\n                line_start, line_end)\n            if not original_snippet:\n                original_snippet = editor.get_source_of(element_name)\n                if not original_snippet:\n                    ui_manager.show_error(\n                        f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                        )\n                    return False\n            full_element_code = editor.get_source_of(element_name)\n            prompt = _create_prompt_for_partial_edit(file_path_relative,\n                element_name, reason, original_snippet, line_start,\n                line_end, full_element_code)\n    elif action_type == 'CREATE':\n        element_name = action.get('element_name')\n        description = action.get('description')\n        action_details = {'element_name': element_name, 'description':\n            description}\n        prompt = _create_prompt_for_refactor_action('CREATE',\n            file_path_relative, action_details)\n    else:\n        ui_manager.show_error(f\"Invalid action type '{action_type}'. Skipping.\"\n            )\n        return False\n    with ui_manager.show_spinner(\n        f\"AI: {action_type} on '{element_name or file_path_relative}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    new_content = code_blocks[0][1] if code_blocks else response.strip()\n    if not new_content:\n        ui_manager.show_error(\n            f'AI failed to generate content for action: {action}')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return False\n    if not file_path_relative.endswith('.py'):\n        try:\n            FileCreator.create(file_path_absolute, new_content)\n            ui_manager.show_success(\n                f\"File '{file_path_relative}' created/updated.\")\n            return True\n        except IOError as e:\n            ui_manager.show_error(\n                f\"Failed to create file '{file_path_relative}': {e}\")\n            return False\n    if file_path_absolute not in editors:\n        try:\n            if not os.path.exists(file_path_absolute):\n                os.makedirs(os.path.dirname(file_path_absolute), exist_ok=True)\n                with open(file_path_absolute, 'w') as f:\n                    f.write('')\n            editors[file_path_absolute] = CodeEditor(file_path_absolute)\n        except Exception as e:\n            ui_manager.show_error(\n                f'Error loading file {file_path_absolute}: {e}')\n            return False\n    editor = editors[file_path_absolute]\n    if action_type == 'MODIFY':\n        if not editor.replace_element(element_name, new_content):\n            ui_manager.show_error(\n                f\"Failed to apply MODIFY change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic MODIFY Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'PARTIAL':\n        if not editor.replace_partial(element_name, new_content, line_start,\n            line_end):\n            ui_manager.show_error(\n                f\"Failed to apply PARTIAL change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic PARTIAL Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'CREATE':\n        anchor = action.get('anchor_element')\n        position = action.get('position', 'after')\n        if not editor.add_element(new_content, anchor_name=anchor, before=\n            position == 'before'):\n            ui_manager.show_error(\n                f\"Failed to apply CREATE change for '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic CREATE Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    return True\n\n\ndef handle_project_refactor_command(instruction: str):\n    \"\"\"\n    Orchestrates a multi-file, multi-step code refactoring process.\n    \n    This function serves as a high-level orchestrator that delegates specific tasks\n    to helper functions, improving readability, modularity, and maintainability.\n    \"\"\"\n    _load_all_project_files_if_needed()\n    actions = _get_refactor_plan(instruction)\n    if not actions:\n        return\n    plan = {'actions': actions}\n    if not _display_and_confirm_plan(plan):\n        return\n    editors: Dict[str, CodeEditor] = {}\n    project_base_path = memory_manager.get_project_root()\n    successful_actions = 0\n    total_actions = len(actions)\n    for i, action in enumerate(actions, 1):\n        ui_manager.show_success(f'Processing action {i}/{total_actions}...')\n        action_type = action.get('type', '').upper()\n        file_path_relative = action.get('file')\n        if not file_path_relative:\n            ui_manager.show_error(\n                f\"Action is missing 'file' key. Skipping: {action}\")\n            continue\n        file_path_absolute = os.path.join(project_base_path, file_path_relative\n            )\n        if action_type == 'DELETE':\n            element_name = action.get('element')\n            if not element_name:\n                ui_manager.show_error(\n                    f\"DELETE action missing 'element' key. Skipping: {action}\")\n                continue\n            if not file_path_relative.endswith('.py'):\n                ui_manager.show_error(\n                    f'DELETE actions are only supported for Python files. Skipping.'\n                    )\n                continue\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    continue\n            editor = editors[file_path_absolute]\n            if editor.delete_element(element_name):\n                successful_actions += 1\n                ui_manager.show_success(\n                    f\"Successfully deleted '{element_name}' from '{file_path_relative}'.\"\n                    )\n            else:\n                ui_manager.show_error(\n                    f\"Failed to delete '{element_name}' from '{file_path_relative}'.\"\n                    )\n        elif _process_refactor_action(action, project_base_path, editors):\n            successful_actions += 1\n        else:\n            ui_manager.show_error(\n                f'Action {i} failed, continuing with remaining actions...')\n    if successful_actions == 0:\n        ui_manager.show_error('No actions were successfully executed.')\n        return\n    elif successful_actions < total_actions:\n        ui_manager.show_error(\n            f'Only {successful_actions}/{total_actions} actions completed successfully.'\n            )\n    else:\n        ui_manager.show_success(\n            f'All {total_actions} actions completed successfully.')\n    _apply_refactor_changes(editors)\n\n\ndef _create_prompt_for_commit_message(diff: str) ->str:\n    \"\"\"\n    Create a dedicated prompt function for the 'commit' command. This prompt will\n    instruct the AI to analyze a git diff and generate a concise commit message\n    following the Conventional Commits standard.\n    \"\"\"\n    return f\"\"\"You are an expert developer writing a Git commit message. Your task is to analyze the provided git diff and create a professional commit message.\n\nCOMMIT MESSAGE RULES:\n- Follow the Conventional Commits specification\n- Format: <type>(<optional scope>): <subject>\n- Types: feat, fix, docs, style, refactor, perf, test, build, ci, chore, revert\n- Subject line: max 50 characters, imperative mood, no period\n- Optional body: explain what and why (not how), wrap at 72 characters\n- Be specific and concise\n- Focus on the intent and impact of the changes\n\nEXAMPLES OF GOOD COMMIT MESSAGES:\n- feat(auth): add OAuth2 integration for Google login\n- fix(api): handle null response in user endpoint\n- refactor(database): optimize query performance for large datasets\n- docs(readme): update installation instructions for Windows\n\nRespond with ONLY the commit message - no markdown, quotes, or explanations.\n\n--- GIT DIFF TO ANALYZE ---\n{diff}\n\nGenerate the commit message:\"\"\"\n\n\ndef handle_commit_command():\n    \"\"\"\n    Orchestrates an AI-assisted Git commit workflow with improved error handling.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return\n    try:\n        git_manager = GitManager(project_root)\n    except ValueError as e:\n        ui_manager.show_error(str(e))\n        return\n    changed_files = git_manager.get_changed_files()\n    if not changed_files:\n        ui_manager.show_success(\n            'No changes to commit. Everything is up to date.')\n        return\n    staged_diff = git_manager.get_diff(staged=True)\n    unstaged_diff = git_manager.get_diff()\n    full_diff = f'{staged_diff}\\n{unstaged_diff}'.strip()\n    if not full_diff.strip():\n        ui_manager.show_success(\n            'No content changes detected (e.g., only file mode changes).')\n        return\n    prompt = _create_prompt_for_commit_message(full_diff)\n    commit_message = query_llm(prompt).strip()\n    if not commit_message:\n        ui_manager.show_error(\n            'AI failed to generate a commit message. Aborting.')\n        return\n    files_to_commit_str = '\\n'.join(f'- {f}' for f in changed_files)\n    plan_panel_content = f\"\"\"[bold]Files to be staged:[/]\n[yellow]{files_to_commit_str}[/]\n\n[bold]AI-Generated Commit Message:[/]\n[green]{commit_message}[/]\"\"\"\n    print(Panel(plan_panel_content, title='[bold cyan]Commit Plan[/]',\n        border_style='cyan'))\n    if ui_manager.get_user_input('\\nProceed with commit? (y/n): ').lower() in [\n        'yes', 'y']:\n        try:\n            git_manager.add(changed_files)\n            ui_manager.show_success('\u2705 Files staged.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Staging failed: {e.stderr}')\n            return\n        try:\n            git_manager.commit(commit_message)\n            ui_manager.show_success('\u2705 Commit successful.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Commit failed: {e.stderr}')\n            return\n        if ui_manager.get_user_input('Push changes to remote? (y/n): ').lower(\n            ) in ['yes', 'y']:\n            try:\n                git_manager.push()\n                ui_manager.show_success('\u2705 Push successful.')\n            except subprocess.CalledProcessError as e:\n                ui_manager.show_error(f'Push failed: {e.stderr}')\n        else:\n            ui_manager.show_error('Push cancelled.')\n    else:\n        ui_manager.show_error('Commit aborted by user.')\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef interactive_mode() ->None:\n    global last_query, last_response, last_code\n    try:\n        from Testing.overlay_engine import show_sequential_popup\n        gui_available = True\n    except ImportError:\n        gui_available = False\n    print(Panel(\n        \"\"\"[bold cyan]Omni Interactive Mode[/]\n[dim]Type 'help' for commands, 'exit' to quit.[/dim]\"\"\"\n        , border_style='cyan'))\n    personality_name = personality_manager.get_current_personality().get('name'\n        , 'Default')\n    gui_enabled = False\n    if gui_available:\n        try:\n            with open(CONFIG_FILE, 'r') as f:\n                config = json.load(f)\n                if config.get('gui_enabled', False):\n                    gui_enabled = True\n        except (FileNotFoundError, json.JSONDecodeError):\n            pass\n    refresh_status_panel(personality_name)\n    while True:\n        try:\n            user_input = ui_manager.get_user_input('\\n> ')\n            if not user_input:\n                continue\n            command, *args = user_input.split(maxsplit=1)\n            arg_str = args[0] if args else ''\n            if command == 'exit':\n                memory_manager.save_memory()\n                print('[bold cyan]Goodbye![/]')\n                break\n            elif command == 'help':\n                print(\n                    \"\"\"[bold]Commands:[/]\n\n  [bold cyan]Core & Project Commands[/]\n  [yellow]send <prompt>[/]        - Ask the LLM a question.\n  [yellow]look <path>[/]          - Read file or scan directory into memory.\n  [yellow]look_all[/]            - Recursively scan the project directory into memory.\n  [yellow]create <file> \"instr\"[/] - Create a new file using AI.\n  [yellow]edit <file> \"instr\"[/]   - Edit a specific file using AI.\n  [yellow]refactor \"instr\"[/]      - Refactor project in memory based on instruction.\n  [yellow]commit[/]               - Commit changes with an AI-generated message.\n  [yellow]rag <query>[/]         - Query the RAG system for context retrieval.\n\n  [bold cyan]File & Code Management[/]\n  [yellow]save <filename>[/]     - Save last AI response to a file.\n  [yellow]list[/]               - List saved files.\n  [yellow]run[/]                 - Run the last generated Python code.\n\n  [bold cyan]Session & Config[/]\n  [yellow]history[/]             - Show the full chat history.\n  [yellow]memory clear[/]        - Clear the chat and file memory.\n  [yellow]backend <name>[/]      - Switch AI backend (e.g., openrouter, ollama).\n  [yellow]models [src][/]        - Interactively list and select models.\n  [yellow]set model <id>[/]      - Set the model directly by its ID.\n  [yellow]personality <cmd>[/]   - Manage AI personalities ('list', 'set', 'add').\n\"\"\"\n                    )\n            elif command == 'send':\n                last_query = arg_str\n                response = query_llm(arg_str)\n                last_response = response\n                memory_manager.add_chat_message('user', last_query)\n                memory_manager.add_chat_message('assistant', last_response)\n                if gui_enabled:\n                    threading.Thread(target=show_sequential_popup, args=(\n                        100, 100, response, f'Omni - {personality_name}'),\n                        daemon=True).start()\n                print(Panel(response, title='[cyan]Response[/]'))\n                if (code_blocks := extract_code(response)):\n                    last_code = code_blocks[0][1]\n            elif command == 'look':\n                look_command(arg_str)\n            elif command == 'look_all':\n                look_all_command()\n            elif command == 'create':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_create_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: create <file_path> \"<instruction>\"')\n            elif command == 'edit':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_edit_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: edit <file_path> \"<instruction>\"')\n            elif command == 'refactor':\n                if not arg_str:\n                    ui_manager.show_error('Usage: refactor \"<instruction>\"')\n                else:\n                    handle_project_refactor_command(arg_str.strip('\"'))\n            elif command == 'commit':\n                handle_commit_command()\n            elif command == 'models':\n                list_models(arg_str.split())\n            elif command == 'set' and arg_str.startswith('model '):\n                set_model(arg_str[6:])\n            elif command == 'backend':\n                switch_backend(arg_str)\n            elif command == 'history':\n                ui_manager.display_history(memory_manager.get_memory_context())\n            elif command == 'memory' and arg_str == 'clear':\n                memory_manager.clear_memory()\n                ui_manager.show_success('\u2705 Memory cleared')\n            elif command == 'personality':\n                p_args = arg_str.split(maxsplit=1)\n                cmd = p_args[0] if p_args else ''\n                p_arg_str = p_args[1] if len(p_args) > 1 else ''\n                if cmd == 'list':\n                    for p in personality_manager.list_personalities():\n                        print(f\"- {p['name']}: {p['description']}\")\n                elif cmd == 'set' and p_arg_str:\n                    if personality_manager.set_current_personality(p_arg_str):\n                        personality_name = p_arg_str\n                        ui_manager.show_success(\n                            f'Set personality to {personality_name}')\n                    else:\n                        ui_manager.show_error('Personality not found.')\n                else:\n                    ui_manager.show_error(\n                        \"Invalid personality command. Use 'list' or 'set <name>'.\"\n                        )\n            elif command == 'run':\n                run_python_code()\n            elif command == 'save':\n                if last_response:\n                    save_code(last_response, arg_str or\n                        f\"omni_save_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n                        )\n                else:\n                    ui_manager.show_error('No response to save.')\n            elif command == 'list':\n                files = sorted(os.listdir(DEFAULT_SAVE_DIR))\n                print('\\n'.join(f'  - {f}' for f in files) if files else\n                    '[yellow]No saved files.[/]')\n            elif command == 'rag':\n                if not arg_str:\n                    ui_manager.show_error('Usage: rag \"<query>\"')\n                else:\n                    from rag_manager import RAGManager\n                    project_root = memory_manager.get_project_root()\n                    if not project_root:\n                        ui_manager.show_error(\n                            \"No project context in memory. Use 'look <directory>' first.\"\n                            )\n                        continue\n                    rag = RAGManager()\n                    if rag.get_document_count() == 0:\n                        ui_manager.show_error(\n                            'RAG index is empty. Please add documents first.')\n                        continue\n                    results = rag.search(arg_str, k=3)\n                    if not results:\n                        ui_manager.show_error('No relevant documents found.')\n                        continue\n                    print(Panel('[bold]RAG Results:[/]', title=\n                        '[cyan]Retrieval-Augmented Generation[/]'))\n                    for i, (content, score, metadata) in enumerate(results, 1):\n                        file_path = metadata.get('file', 'Unknown')\n                        print(\n                            f'[bold cyan]{i}. {file_path}[/] (Score: {score:.4f})'\n                            )\n                        print(Panel(content[:500] + '...' if len(content) >\n                            500 else content, border_style='dim'))\n                    follow_up = ui_manager.get_user_input(\n                        \"\"\"\nWould you like to ask a follow-up question with this context? (y/n): \"\"\"\n                        )\n                    if follow_up.lower() in ['y', 'yes']:\n                        follow_up_query = ui_manager.get_user_input(\n                            'Follow-up query: ')\n                        if follow_up_query:\n                            context_parts = [\n                                f'Document {i} (Score: {score:.4f}):\\n{content}'\n                                 for i, (content, score, _) in enumerate(\n                                results, 1)]\n                            context = '\\n\\n'.join(context_parts)\n                            rag_prompt = f\"\"\"Based on the following context, please answer the question.\n\nContext:\n{context}\n\nQuestion: {follow_up_query}\"\"\"\n                            response = query_llm(rag_prompt)\n                            print(Panel(response, title=\n                                '[cyan]RAG-Augmented Response[/]'))\n            else:\n                ui_manager.show_error(\"Unknown command. Type 'help'.\")\n            refresh_status_panel(personality_name)\n        except KeyboardInterrupt:\n            memory_manager.save_memory()\n            print('\\n[bold cyan]Goodbye![/]')\n            break\n        except Exception as e:\n            ui_manager.show_error(f'An unexpected error occurred: {e}')\n\n\ndef run_python_code() ->None:\n    global last_code\n    if not last_code:\n        ui_manager.show_error('No Python code in memory to run.')\n        return\n    temp_file = os.path.join(DEFAULT_SAVE_DIR, 'temp_run.py')\n    try:\n        with open(temp_file, 'w') as f:\n            f.write(last_code)\n        print('[bold cyan]\\n--- Running Code ---\\n[/]')\n        subprocess.run([sys.executable, temp_file], check=True)\n        print('[bold cyan]\\n--- Code Finished ---\\n[/]')\n    except Exception as e:\n        ui_manager.show_error(f'Error running code: {e}')\n    finally:\n        if os.path.exists(temp_file):\n            os.remove(temp_file)\n\n\ndef save_code(content: str, filename: str) ->None:\n    filepath = os.path.join(DEFAULT_SAVE_DIR, filename)\n    try:\n        with open(filepath, 'w') as f:\n            f.write(content)\n        ui_manager.show_success(f'Saved to: {filepath}')\n    except IOError as e:\n        ui_manager.show_error(f'Error saving file: {e}')\n\n\ndef main() ->None:\n    try:\n        import astor\n    except ImportError:\n        print(\"[bold red]Error:[/] 'astor' is required. `pip install astor`\")\n        sys.exit(1)\n    try:\n        import simple_term_menu\n    except ImportError:\n        print(\n            \"[bold red]Error:[/] 'simple-term-menu' is required. `pip install simple-term-menu`\"\n            )\n        sys.exit(1)\n    parser = argparse.ArgumentParser(description=\n        'Omni - AI-powered code tool', add_help=False)\n    parser.add_argument('command', nargs='?', help='Main command.')\n    parser.add_argument('args', nargs='*', help='Arguments for the command.')\n    parser.add_argument('-h', '--help', action='store_true')\n    args, _ = parser.parse_known_args()\n    if args.help or not args.command:\n        interactive_mode()\n    elif args.command == 'look' and args.args:\n        look_command(args.args[0])\n    elif args.command == 'edit' and len(args.args) >= 2:\n        handle_file_edit_command(args.args[0], ' '.join(args.args[1:]))\n    elif args.command == 'models':\n        list_models(args.args)\n    else:\n        interactive_mode()\n\n\ndef refresh_status_panel(personality_name: str) ->None:\n    ui_manager.display_status_panel(personality_name, current_backend,\n        current_model, len(memory_manager.memory.get('chat', [])), len(\n        memory_manager.memory.get('look', [])))\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/omni.py"
  },
  {
    "id": 190,
    "hash": "db1585da7840e9dc17f3ab8c0a19f6f2",
    "content": "import json\nfrom typing import Dict, List, Optional\n\nclass PersonalityManager:\n    \"\"\"Manages AI personalities via JSON config.\"\"\"\n\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.personalities: List[Dict[str, str]] = self.load_personalities()\n        self.current_personality: Optional[str] = \"default\"  # Default\n\n    def load_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"Load personalities from JSON; auto-create if missing.\"\"\"\n        default = [{\"name\": \"default\", \"description\": \"Helpful assistant\", \"system_prompt\": \"You are a helpful AI assistant.\"}]\n        default_gui = {\n            \"gui_enabled\": True,\n            \"wake_word\": \"Jarvis\",\n            \"overlay_opacity\": 0.8,\n            \"font_size\": 16\n        }\n        try:\n            with open(self.config_file, 'r') as f:\n                data = json.load(f)\n                if \"personalities\" not in data:\n                    data[\"personalities\"] = default\n                if \"gui_enabled\" not in data:\n                    data.update(default_gui)\n                    self.save_personalities(data[\"personalities\"])  # Save with defaults\n                \n                return data[\"personalities\"]\n        except FileNotFoundError:\n            self.save_personalities(default)\n            return default\n        except json.JSONDecodeError:\n            print(\"[yellow]Invalid config. Resetting to default.[/]\")\n            self.save_personalities(default)\n            return default\n\n    def save_personalities(self, personalities: List[Dict[str, str]]) -> None:\n        \"\"\"Save with GUI config.\"\"\"\n        data = {\"personalities\": personalities}\n        data.update({\"gui_enabled\": True, \"wake_word\": \"Jarvis\", \"overlay_opacity\": 0.8, \"font_size\": 16})  # Defaults\n        with open(self.config_file, 'w') as f:\n            json.dump(data, f, indent=4)\n\n    def add_personality(self, name: str, description: str, system_prompt: str) -> None:\n        \"\"\"Add a new personality.\"\"\"\n        self.personalities.append({\"name\": name, \"description\": description, \"system_prompt\": system_prompt})\n        self.save_personalities(self.personalities)\n\n    def list_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"List all personalities.\"\"\"\n        return self.personalities\n\n    def set_current_personality(self, name: str) -> bool:\n        \"\"\"Set the current personality.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == name:\n                self.current_personality = name\n                return True\n        return False\n\n    def get_current_personality(self) -> Dict[str, str]:\n        \"\"\"Get the current personality dict.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == self.current_personality:\n                return p\n        return {}  # Fallback",
    "file": "/mnt/ProjectData/omni/personality_manager.py"
  },
  {
    "id": 191,
    "hash": "da963f141c557fe12f1a26374f3e5ff4",
    "content": "# python_ast_adapter.py\n\n\"\"\"\nPythonASTAdapter - Concrete AST adapter for Python using built-in `ast` and `astor`.\n\nThis module implements the ASTAdapter interface specifically for Python,\nleveraging the standard library's `ast` module for parsing and\nmanipulation, and `astor` for code generation.\n\"\"\"\n\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for asttokens (for enhanced partial edits)\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n    # print(\"Warning: asttokens not installed. Partial edits will be limited.\")\n\n\nclass PythonASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for Python source code.\n\n    This adapter uses Python's built-in `ast` module to parse and manipulate\n    the code, and `astor` for code generation and source-to-source transformations.\n    It holds the parsed AST tree and provides methods to interact with it\n    according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the PythonASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The Python source code as a string.\n        \"\"\"\n        # Store source code for diffing and potential asttokens use\n        self.source_code: str = source_code\n        # Will hold the parsed AST tree\n        self.tree: Optional[ast.AST] = None\n        # Will hold a mapping of element names to their AST nodes\n        self.nodes: Dict[str, ast.AST] = {}\n        # asttokens instance for enhanced source mapping (if available)\n        self.atok: Optional[asttokens.ASTTokens] = None\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the Python source code and maps elements.\n\n        Args:\n            source_code: The Python source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid Python syntax.\n        \"\"\"\n        try:\n            self.tree = ast.parse(source_code)\n        except SyntaxError as e:\n            raise ValueError(f\"Invalid Python syntax: {e}\") from e\n\n        self.nodes = self._map_nodes()\n        if ASTTOKENS_AVAILABLE:\n            try:\n                self.atok = asttokens.ASTTokens(source_code, parse=True)\n            except Exception:\n                # If asttokens fails for any reason, continue without it\n                self.atok = None\n        else:\n            self.atok = None\n\n    def _map_nodes(self) -> Dict[str, ast.AST]:\n        \"\"\"\n        Walks the AST and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their AST nodes.\n        \"\"\"\n        nodes: Dict[str, ast.AST] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        for node in ast.walk(self.tree):\n            # Map functions and classes by name\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                # Use 'not in' to prioritize top-level definitions in case of conflicts\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            # Map assignments by target variable name(s)\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            # Map imports by their alias or original name\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int, line_end: Optional[int] = None) -> Optional[Tuple[int, ast.AST]]:\n        \"\"\"\n        Finds a statement within a body based on line numbers.\n\n        Args:\n            body: The list of AST nodes representing the body.\n            line_start: The starting line number to search for.\n            line_end: The optional ending line number.\n\n        Returns:\n            A tuple of (index, statement node) if found, otherwise None.\n        \"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = getattr(stmt, 'end_lineno', stmt.lineno)\n                    # Check for overlap or containment\n                    if (stmt.lineno <= line_start <= stmt_end) or (stmt.lineno <= line_end <= stmt_end) or \\\n                       (line_start <= stmt.lineno and line_end >= stmt_end):\n                        return (i, stmt)\n                else:\n                    if stmt.lineno == line_start:\n                        return (i, stmt)\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.ImportFrom]]) -> None:\n        \"\"\"\n        Adds new import nodes to the file's AST, typically at the top.\n\n        Args:\n            new_import_nodes: A list of ast.Import or ast.ImportFrom nodes.\n        \"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return # Cannot add imports without a valid module tree\n\n        # Get string representations of existing imports to avoid duplicates\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                try:\n                    existing_imports_str.add(astor.to_source(node).strip())\n                except Exception:\n                    # If astor fails, skip adding to set (might lead to potential duplicate, but safer)\n                    pass\n                last_import_index = i\n\n        # Insert new imports after the last existing import\n        # Reverse them so they are inserted in the correct order\n        for new_import in reversed(new_import_nodes):\n            try:\n                new_import_str = astor.to_source(new_import).strip()\n                if new_import_str not in existing_imports_str:\n                    self.tree.body.insert(last_import_index + 1, new_import)\n                    last_import_index += 1 # Update index for next insertion\n            except Exception:\n                # If we can't generate source, we can't check for duplicates, skip\n                self.tree.body.insert(last_import_index + 1, new_import)\n                last_import_index += 1\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return astor.to_source(node)\n            except Exception:\n                # Handle potential astor issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.__class__.__name__,\n            'line_start': getattr(node, 'lineno', None),\n            'line_end': getattr(node, 'end_lineno', None),\n            'body_items': []\n        }\n\n        if hasattr(node, 'body'):\n            for i, item in enumerate(node.body):\n                item_info = {\n                    'index': i,\n                    'type': item.__class__.__name__,\n                    'line_start': getattr(item, 'lineno', None),\n                    'line_end': getattr(item, 'end_lineno', None)\n                }\n\n                if isinstance(item, ast.Assign) and item.targets:\n                    target = item.targets[0]\n                    if isinstance(target, ast.Name):\n                        item_info['assigns'] = target.id\n                elif isinstance(item, (ast.If, ast.While, ast.For)):\n                    item_info['has_body'] = bool(getattr(item, 'body', None))\n                elif isinstance(item, ast.Return):\n                    item_info['returns'] = True\n\n                structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        if not self.atok:\n            return None # asttokens is required for precise original source retrieval\n\n        node = self.nodes.get(element_name)\n        if not node or not hasattr(node, 'body'):\n            return None\n\n        statements = []\n        for stmt in node.body:\n            if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                 # Check for overlap or containment of the statement within the requested range\n                stmt_start = stmt.lineno\n                stmt_end = stmt.end_lineno\n                if (stmt_start >= line_start and stmt_end <= line_end) or \\\n                   (stmt_start <= line_end and stmt_end >= line_start): # Overlap\n                    statements.append(stmt)\n\n        if not statements:\n            return None\n\n        # Use asttokens to get the original source text for accuracy\n        try:\n            # Combine text ranges of the found statements\n            combined_text = \"\"\n            last_end_pos = None\n            for stmt in sorted(statements, key=lambda s: s.lineno):\n                # Get the text range for the statement\n                stmt_text = self.atok.get_text_range(stmt)\n                if last_end_pos is not None and stmt_text[0] > last_end_pos:\n                     # Add the original whitespace/newlines between statements\n                    combined_text += self.source_code[last_end_pos:stmt_text[0]]\n                combined_text += self.atok.get_text(stmt)\n                last_end_pos = stmt_text[1]\n            return combined_text.strip()\n        except Exception:\n            # Fallback if asttokens text retrieval fails\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in statements)\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except SyntaxError:\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body: # Ensure there's actual code body to replace with\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # Walk the tree to find the parent node containing the element to replace\n        for parent_node in ast.walk(self.tree):\n            if hasattr(parent_node, 'body') and isinstance(parent_node.body, list):\n                try:\n                    old_node = self.nodes[element_name]\n                    idx = parent_node.body.index(old_node)\n                    # Remove the old node\n                    parent_node.body.pop(idx)\n                    # Insert the new nodes\n                    for i, new_node in enumerate(new_code_body):\n                        parent_node.body.insert(idx + i, new_node)\n\n                    # Update the nodes map: remove old, add new top-level definitions\n                    del self.nodes[element_name]\n                    for n in new_code_body:\n                        if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                            self.nodes[n.name] = n\n                    return True\n                except (ValueError, KeyError):\n                    # ValueError from index(), KeyError from accessing self.nodes\n                    continue\n        return False # Element not found in any body\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n             return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except (SyntaxError, IndexError):\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body:\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # --- Determine insertion index ---\n\n        # Find the `if __name__ == \"__main__\":` block index\n        main_block_idx = -1\n        for i, node in enumerate(self.tree.body):\n            if (isinstance(node, ast.If) and\n                isinstance(getattr(node, 'test', None), ast.Compare) and\n                isinstance(getattr(node.test, 'left', None), ast.Name) and\n                node.test.left.id == '__name__' and\n                len(getattr(node.test, 'ops', [])) == 1 and isinstance(node.test.ops[0], ast.Eq) and\n                len(getattr(node.test, 'comparators', [])) == 1):\n\n                comp = node.test.comparators[0]\n                # Check for both ast.Constant ('__main__') and older ast.Str ('__main__')\n                if ((isinstance(comp, ast.Constant) and comp.value == '__main__') or\n                    (isinstance(comp, ast.Str) and comp.s == '__main__')): # type: ignore\n                    main_block_idx = i\n                    break\n\n        insertion_index = -1\n        if anchor_name:\n            # If anchor is specified, find its index\n            if anchor_name not in self.nodes:\n                return False\n            anchor_node = self.nodes[anchor_name]\n            try:\n                anchor_idx = self.tree.body.index(anchor_node)\n                proposed_index = anchor_idx if before else anchor_idx + 1\n                # Prefer to stay before the main block if possible\n                if main_block_idx != -1:\n                    insertion_index = min(proposed_index, main_block_idx)\n                else:\n                    insertion_index = proposed_index\n            except ValueError:\n                return False # Anchor node not found in tree body\n        elif main_block_idx != -1:\n            # If no anchor, but there's a main block, insert before it\n            insertion_index = main_block_idx\n        # If no anchor and no main block, insertion_index remains -1\n\n        # --- Perform the insertion ---\n        if insertion_index == -1:\n            # Append to the end\n            self.tree.body.extend(new_code_body)\n        else:\n            # Insert at the calculated position\n            for i, new_node in enumerate(new_code_body):\n                self.tree.body.insert(insertion_index + i, new_node)\n\n        # Update the nodes map with any new top-level definitions\n        for node in new_code_body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                self.nodes[node.name] = node # This might overwrite if names clash\n\n        return True\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return False\n\n        deleted = False\n        if element_name in self.nodes:\n            node_to_delete = self.nodes[element_name]\n            # Walk the tree to find the parent node containing the element\n            for node in ast.walk(self.tree):\n                if hasattr(node, 'body') and isinstance(node.body, list):\n                    try:\n                        node.body.remove(node_to_delete)\n                        deleted = True\n                        break # Assume element appears only once at top level\n                    except ValueError:\n                        continue # This parent doesn't contain the node\n            if deleted:\n                del self.nodes[element_name]\n                # Although nodes map is passed by ref in base __init__, we should call _map_nodes\n                # to ensure consistency after a direct tree modification.\n                self.nodes = self._map_nodes()\n                return True\n\n        # If not found by node reference, try to find by name pattern matching (vars/imports)\n        new_body = []\n        for node in self.tree.body:\n            if isinstance(node, ast.Assign):\n                match = False\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id == element_name:\n                        match = True\n                        deleted = True\n                        break\n                if not match: # Keep the node if it doesn't match\n                    new_body.append(node)\n            elif isinstance(node, ast.Import):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                    # Keep the node if none of its aliases match (should theoretically be the same as above)\n                     new_body.append(node)\n                else:\n                    deleted = True # The import node is being completely removed\n            elif isinstance(node, ast.ImportFrom):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                     new_body.append(node)\n                else:\n                    deleted = True\n            else:\n                new_body.append(node)\n\n        if deleted:\n            self.tree.body = new_body\n            # Remap nodes after structural changes\n            self.nodes = self._map_nodes()\n\n        return deleted\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        if element_name not in self.nodes:\n            return False\n\n        node = self.nodes[element_name]\n        # Ensure the node has a body to modify\n        if not hasattr(node, 'body') or not isinstance(node.body, list):\n            return False\n\n        # Parse the new code to get AST nodes for the replacement\n        try:\n             # Heuristic: If new code looks like a def/class, extract its body.\n             # Otherwise, treat as standalone statements.\n            if new_code.strip().startswith(('def ', 'class ', 'async def ')):\n                # Parse as if it's a module with a single function/class\n                temp_module = ast.parse(new_code)\n                if temp_module.body and hasattr(temp_module.body[0], 'body'):\n                    new_statements = temp_module.body[0].body # Get the inner body\n                else:\n                    return False # Malformed attempt to define a func/class\n            else:\n                # Parse as a module and take its body\n                new_ast_module = ast.parse(new_code)\n                new_statements = new_ast_module.body\n        except SyntaxError:\n            return False # Invalid new code\n\n        if not new_statements: # Nothing to insert\n            return False\n\n        # --- Determine what to replace based on parameters ---\n        if statement_index is not None:\n            # Replace by statement index\n            if 0 <= statement_index < len(node.body):\n                # Replace the single statement at index with the list of new statements\n                node.body[statement_index:statement_index+1] = new_statements\n                return True\n        elif line_start is not None:\n            # Replace by line number(s)\n            result = self._find_statement_in_body(node.body, line_start, line_end)\n            if result:\n                idx, _ = result\n                if line_end:\n                    # Find the last statement within the specified range to replace multiple\n                    end_idx = idx\n                    # Iterate from the found index forward\n                    for i in range(idx, len(node.body)):\n                        stmt = node.body[i]\n                        stmt_s_ln = getattr(stmt, 'lineno', None)\n                        stmt_e_ln = getattr(stmt, 'end_lineno', stmt_s_ln)\n                        if stmt_s_ln is not None and stmt_e_ln is not None:\n                            # Check if the statement ends within the range or starts within the range\n                            # This handles overlapping ranges correctly\n                             if stmt_e_ln <= line_end or stmt_s_ln <= line_end:\n                                 end_idx = i\n                             else:\n                                 break # Statement is past the end range\n                        else:\n                            break # Can't determine statement range\n                    node.body[idx:end_idx+1] = new_statements\n                else:\n                    # line_end not specified, only replace the statement at line_start\n                    node.body[idx:idx+1] = new_statements\n                return True\n\n        # If none of the conditions were met to perform a replacement\n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        if self.tree:\n            try:\n                return astor.to_source(self.tree)\n            except Exception as e:\n                 # Fallback error handling, should ideally not happen if tree is valid\n                 return f\"# Error generating source: {e}\\n{self.source_code}\"\n        else:\n            # If somehow the tree is None, return the original source\n            return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        # Ensure line endings are consistent for diffing, keepends=True preserves them\n        # If source_code had different line endings, this might still cause issues,\n        # but this is a standard approach.\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/python_ast_adapter.py"
  },
  {
    "id": 192,
    "hash": "2914352eefed9d60de098e021dd79b67",
    "content": "import os\nimport sys\nimport argparse\nfrom typing import List\nfrom rag_manager import RAGManager\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\ndef create_sample_data() ->List[str]:\n    \"\"\"Create sample documents for the RAG example.\"\"\"\n    return [\n        'RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with language generation.'\n        ,\n        'The RAG model retrieves relevant documents from a knowledge base and uses them to generate more accurate responses.'\n        ,\n        'FAISS is a library for efficient similarity search and clustering of dense vectors, often used in RAG systems.'\n        ,\n        'Sentence transformers are used to create embeddings for documents and queries in RAG systems.'\n        ,\n        'Retrieval-Augmented Generation improves language models by allowing them to access external knowledge sources.'\n        ,\n        'In RAG systems, documents are indexed and searchable by their semantic embeddings rather than just keywords.'\n        ,\n        'Python is a great language for implementing RAG systems due to libraries like sentence-transformers and faiss.'\n        ,\n        'The retrieval component of RAG is crucial for finding relevant information before generation.'\n        ]\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_cli_example.py"
  },
  {
    "id": 193,
    "hash": "c27b11d2eaa8e13cdf8e698417efb75e",
    "content": "import os\nimport sys\nfrom typing import List, Dict, Tuple\n\"\"\"\nExample script demonstrating RAG (Retrieval-Augmented Generation) usage.\n\nThis script shows how to use a simple RAG implementation to answer questions\nbased on a given context or knowledge base.\n\"\"\"\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\nclass SimpleRAG:\n    \"\"\"A simple RAG implementation for demonstration purposes.\"\"\"\n\n    def __init__(self, knowledge_base: List[str]):\n        \"\"\"\n        Initialize the RAG with a knowledge base.\n        \n        Args:\n            knowledge_base: A list of strings representing the knowledge base.\n        \"\"\"\n        self.knowledge_base = knowledge_base\n\n    def retrieve(self, query: str, top_k: int=3) ->List[str]:\n        \"\"\"\n        Retrieve relevant documents from the knowledge base.\n        \n        This is a simplified implementation using keyword matching.\n        In a real implementation, you would use embeddings and vector search.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            A list of relevant documents.\n        \"\"\"\n        query_words = set(query.lower().split())\n        scores = []\n        for doc in self.knowledge_base:\n            doc_words = set(doc.lower().split())\n            score = len(query_words.intersection(doc_words))\n            scores.append((score, doc))\n        scores.sort(reverse=True)\n        return [doc for score, doc in scores[:top_k]]\n\n    def generate(self, query: str, retrieved_docs: List[str]) ->str:\n        \"\"\"\n        Generate an answer based on the query and retrieved documents.\n        \n        In a real implementation, this would use an LLM to generate the response.\n        For this example, we'll create a simple template-based response.\n        \n        Args:\n            query: The query string.\n            retrieved_docs: The retrieved documents.\n            \n        Returns:\n            A generated answer.\n        \"\"\"\n        context = '\\n'.join(retrieved_docs)\n        prompt = f\"\"\"\n        Context information:\n        {context}\n        \n        Question: {query}\n        \n        Based on the context provided above, please answer the question.\n        If the context doesn't contain relevant information, say so.\n        \"\"\"\n        return self._simple_response_generator(query, retrieved_docs)\n\n    def _simple_response_generator(self, query: str, retrieved_docs: List[str]\n        ) ->str:\n        \"\"\"\n        A simple response generator for demonstration.\n        \"\"\"\n        for doc in retrieved_docs:\n            if 'example' in doc.lower():\n                return (\n                    f'Based on the context provided, I found information about examples. {query} relates to the examples in the knowledge base.'\n                    )\n        return (\n            f\"I couldn't find specific information about '{query}' in the provided context. Please provide more details or check the knowledge base.\"\n            )\n\n    def query(self, query: str, top_k: int=3) ->str:\n        \"\"\"\n        Process a query through the full RAG pipeline.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            The generated answer.\n        \"\"\"\n        retrieved_docs = self.retrieve(query, top_k)\n        answer = self.generate(query, retrieved_docs)\n        return answer\n\n\ndef main():\n    \"\"\"Main function demonstrating the RAG implementation.\"\"\"\n    knowledge_base = ['This is an example document about machine learning.',\n        'Natural language processing is a subfield of artificial intelligence.'\n        , 'Python is a popular programming language for data science.',\n        'The quick brown fox jumps over the lazy dog.',\n        'RAG stands for Retrieval-Augmented Generation.',\n        'Vector databases are used for similarity search in RAG systems.',\n        'Transformers are a type of neural network architecture.',\n        'This example shows how to implement a simple RAG system.']\n    rag = SimpleRAG(knowledge_base)\n    queries = ['What is RAG?', 'How is Python used in data science?',\n        'Tell me about machine learning']\n    print('Simple RAG Example')\n    print('=' * 50)\n    for query in queries:\n        print(f'\\nQuery: {query}')\n        answer = rag.query(query)\n        print(f'Answer: {answer}')\n        print('-' * 30)\n    print(\"\\nInteractive Mode (type 'quit' to exit):\")\n    while True:\n        try:\n            user_query = input('\\nEnter your question: ').strip()\n            if user_query.lower() in ['quit', 'exit', 'q']:\n                break\n            if user_query:\n                answer = rag.query(user_query)\n                print(f'Answer: {answer}')\n        except KeyboardInterrupt:\n            print('\\nGoodbye!')\n            break\n        except EOFError:\n            break\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_example.py"
  },
  {
    "id": 194,
    "hash": "f151986bf2efa7602242590a357fab83",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n    Initialize the RAG manager.\n\n    Args:\n        model_name: Name of the sentence transformer model to use\n        index_path: Path to save/load the FAISS index\n    \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the RAG manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n",
    "file": "/mnt/ProjectData/omni/rag_manager.py"
  },
  {
    "id": 195,
    "hash": "f59a27842056dbb0dc95d0f29c1c5de8",
    "content": "Hello! I'm OmniForge, an AI coding assistant. I can help you scan, understand, and refactor your codebase using local (Ollama) or remote (OpenRouter) LLMs.\n\nI see you've opened the OmniForge project directory. Some key things I can help with:\n\n1. **Project Analysis**: I can look at your files to understand the structure\n2. **Code Editing**: I can make precise edits to functions/classes using AST-based transformations\n3. **Refactoring**: I can perform multi-file architectural changes with a plan\n4. **File Creation**: I can generate new files based on instructions\n\nFor example:\n- `look .` to scan the project\n- `edit code_editor.py \"add docstrings to main methods\"`\n- `refactor \"extract git operations into a separate module\"`\n- `create new_module.py \"implement a simple HTTP client\"`\n\nWhat would you like to do with this project?",
    "file": "/mnt/ProjectData/omni/requirements.txt"
  },
  {
    "id": 196,
    "hash": "629e0568a11413444d2a924d1b912f05",
    "content": "from ast_adapter import ASTAdapter\nfrom typing import List, Optional, Dict, Any\n\"\"\"\nTextAdapter - Concrete AST adapter for plain text files.\n\nThis module implements the ASTAdapter interface specifically for plain text files,\ntreating the entire file content as a single element.\n\"\"\"\n\n\nclass TextAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for plain text files.\n\n    This adapter treats the entire text file content as a single element\n    that can be manipulated using the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the TextAdapter with the source code.\n\n        Args:\n            source_code: The text content as a string.\n        \"\"\"\n        self.source_code: str = source_code\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) ->None:\n        \"\"\"\n        Creates a simple mapping for the text content.\n\n        Args:\n            source_code: The text content string.\n        \"\"\"\n        self.nodes = {'content': source_code}\n\n    def list_elements(self) ->List[str]:\n        \"\"\"Lists the names of the main elements (just 'content' for text files).\"\"\"\n        return ['content']\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        if element_name == 'content':\n            return self.source_code\n        return None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        if element_name == 'content':\n            return {'name': element_name, 'type': 'TextContent',\n                'line_start': 1, 'line_end': len(self.source_code.\n                splitlines()), 'body_items': []}\n        return None\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        if element_name != 'content':\n            return None\n        lines = self.source_code.splitlines()\n        if 1 <= line_start <= len(lines) and 1 <= line_end <= len(lines\n            ) and line_start <= line_end:\n            return '\\n'.join(lines[line_start - 1:line_end])\n        return None\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name == 'content':\n            self.source_code = new_code\n            self._parse_and_map(new_code)\n            return True\n        return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"Adds a new element to the file (appends to content for text files).\"\"\"\n        if anchor_name is None or anchor_name == 'content':\n            if before:\n                self.source_code = new_code + self.source_code\n            else:\n                self.source_code = self.source_code + new_code\n            self._parse_and_map(self.source_code)\n            return True\n        return False\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if element_name == 'content':\n            self.source_code = ''\n            self._parse_and_map('')\n            return True\n        return False\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        if element_name != 'content':\n            return False\n        lines = self.source_code.splitlines()\n        if line_start is not None and 1 <= line_start <= len(lines):\n            start_idx = line_start - 1\n            end_idx = start_idx if line_end is None else min(line_end - 1, \n                len(lines) - 1)\n            new_lines = new_code.splitlines() if new_code else []\n            lines[start_idx:end_idx + 1] = new_lines\n            self.source_code = '\\n'.join(lines)\n            self._parse_and_map(self.source_code)\n            return True\n        return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"Returns the modified source code.\"\"\"\n        return self.source_code\n",
    "file": "/mnt/ProjectData/omni/text_adapter.py"
  },
  {
    "id": 197,
    "hash": "4b879b8e64b677ec78d27f19b384623a",
    "content": "from typing import List\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.text import Text\nfrom rich.status import Status\nfrom rich import box\nfrom contextlib import contextmanager\nfrom rich.markup import escape\nimport gc\n\ntry:\n    from prompt_toolkit import prompt\n    from prompt_toolkit.completion import WordCompleter\n    from prompt_toolkit.history import InMemoryHistory\n    from prompt_toolkit.styles import Style\nexcept ImportError:\n    print('[yellow]prompt_toolkit not installed. Falling back to basic input.[/]')\n    prompt = input\n\n\nclass UIManager:\n    \"\"\"Manages interactive text-based UI with rich for display and prompt_toolkit for input.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initializes the UI manager with a rich console and prompt_toolkit components.\"\"\"\n        self.console = Console()\n        self.history = InMemoryHistory()\n        self.completer = WordCompleter([\n            'send', 'look', 'look_all', 'create', 'edit', 'refactor', 'commit',\n            'save', 'list', 'run', 'history', 'memory', 'backend', 'models',\n            'set', 'personality', 'help', 'exit'\n        ], ignore_case=True)\n        self.prompt_style = Style.from_dict({'prompt': 'bold cyan'})\n\n    def get_user_input(self, prompt_text: str) -> str:\n        try:\n            return prompt(prompt_text, history=self.history, completer=self.completer, style=self.prompt_style)\n        except Exception:\n            self.console.print('[yellow]Warning: Falling back to basic input.[/]')\n            return input(prompt_text)\n\n    def display_history(self, history_text: str) -> None:\n        if not history_text.strip():\n            self.console.print('[dim]No history yet.[/]')\n            return\n        \n        lines = history_text.split('\\n')\n        colored_text = Text()\n        for line in lines:\n            if line.startswith('User:'):\n                colored_text.append(line + '\\n', style='bold blue')\n            elif line.startswith('AI:'):\n                colored_text.append(line + '\\n', style='bold green')\n            elif line.startswith('File '):\n                colored_text.append(line + '\\n', style='yellow')\n            else:\n                colored_text.append(line + '\\n')\n        \n        self.console.print(Panel(\n            colored_text, \n            title='[bold magenta]Chat History[/]', \n            border_style='magenta', \n            expand=False, \n            box=box.ROUNDED\n        ))\n\n    @contextmanager\n    def show_spinner(self, message: str):\n        \"\"\"\n        Context manager that displays a spinner with the given message.\n        Handles Rich LiveError by cleaning up stuck live displays and \n        ensuring proper cleanup on exceptions.\n        \n        Usage:\n            with ui_manager.show_spinner(\"Loading...\"):\n                # do work here\n        \"\"\"\n        # Initialize spinner state if not exists\n        if not hasattr(self, '_spinner_active'):\n            self._spinner_active = False\n        \n        # If spinner is already active, just yield without additional output\n        if self._spinner_active:\n            try:\n                yield\n            except Exception as e:\n                raise e\n            return\n        \n        # Clean up any stuck Rich live displays before starting\n        self._cleanup_stuck_rich_displays()\n        \n        # Mark spinner as active\n        self._spinner_active = True\n        status_context = None\n        \n        try:\n            # Try to use rich status, but with fallback\n            try:\n                status_context = self.console.status(f'[bold yellow]{message}[/]')\n                status_context.__enter__()\n            except Exception:\n                # If rich.status fails, fallback to static print\n                status_context = None\n                self.console.print(f'[bold yellow]{message}[/]')\n            \n            yield\n            \n        except Exception as e:\n            # Re-raise actual work errors\n            raise e\n            \n        finally:\n            # Always cleanup spinner state and rich display\n            self._spinner_active = False\n            if status_context is not None:\n                try:\n                    status_context.__exit__(None, None, None)\n                except:\n                    pass  # Suppress cleanup errors\n            \n            # Force cleanup any remaining rich displays\n            self._cleanup_stuck_rich_displays()\n\n    def _cleanup_stuck_rich_displays(self):\n        \"\"\"\n        Clean up stuck Rich live displays that prevent new ones from starting.\n        Based on solution from: https://github.com/DLR-RM/stable-baselines3/issues/1645\n        \"\"\"\n        try:\n            # Method 1: Reset console live display if exists\n            if hasattr(self.console, '_live') and self.console._live is not None:\n                try:\n                    self.console._live.stop()\n                    self.console._live = None\n                except:\n                    pass\n            \n            # Method 2: Find and close stuck rich/tqdm objects using garbage collection\n            rich_objects = [obj for obj in gc.get_objects() \n                        if hasattr(obj, '__class__') and \n                        ('live' in type(obj).__name__.lower() or \n                            'progress' in type(obj).__name__.lower() or\n                            'status' in type(obj).__name__.lower()) and\n                        hasattr(obj, 'stop')]\n            \n            for rich_obj in rich_objects:\n                try:\n                    if hasattr(rich_obj, 'stop'):\n                        rich_obj.stop()\n                    elif hasattr(rich_obj, 'close'):\n                        rich_obj.close()\n                except:\n                    pass  # Suppress cleanup errors\n                    \n        except:\n            pass  # Suppress all cleanup errors to avoid breaking the main flow\n\n    def display_status_panel(self, personality: str, backend: str, model: str, msg_count: int, look_count: int) -> None:\n        status_text = (\n            f'[bold]Personality:[/] [green]{personality}[/] | '\n            f'[bold]Backend:[/] [green]{backend}[/] | '\n            f'[bold]Model:[/] [green]{model}[/] | '\n            f'[bold]Memory:[/] {msg_count} messages, {look_count} files'\n        )\n        self.console.print(Panel(\n            status_text, \n            title='[bold cyan]Status[/]', \n            border_style='cyan', \n            expand=False, \n            box=box.MINIMAL\n        ))\n\n    def show_success(self, message: str) -> None:\n        self.console.print(f'[green]\u2705 {message}[/]')\n\n    def show_error(self, message: str) -> None:\n        \"\"\"\n        Displays an error message, escaping any markup in the message.\n        \"\"\"\n        safe_message = escape(str(message))\n        self.console.print(f'[red]\u274c {safe_message}[/]')",
    "file": "/mnt/ProjectData/omni/ui_manager.py"
  },
  {
    "id": 198,
    "hash": "dbd143839288b400cafdedb655258434",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n",
    "file": "/mnt/ProjectData/omni/vectordb_manager.py"
  },
  {
    "id": 199,
    "hash": "47a91d3ac272236378053b23515fc9b0",
    "content": "import tkinter as tk\nfrom tkinter import ttk\nfrom time import strftime\n\n\ndef update_time():\n    current_time = strftime('%H:%M:%S %p\\n%Y-%m-%d')\n    time_label.config(text=current_time)\n    time_label.after(1000, update_time)\n\n\ndef center_window(root):\n    root.update_idletasks()\n    screen_width = root.winfo_screenwidth()\n    screen_height = root.winfo_screenheight()\n    window_width = root.winfo_width() + 4\n    window_height = root.winfo_height() + 4\n    x = (screen_width - window_width) // 2\n    y = (screen_height - window_height) // 2\n    root.geometry(f'{window_width}x{window_height}+{x}+{y}')\n\n\ndef create_3d_border(parent):\n    border_frame = tk.Frame(parent, bg='#c0c0c0')\n    border_frame.pack(padx=2, pady=2, expand=True, fill=tk.BOTH)\n    tk.Frame(border_frame, height=1, bg='#808080').pack(side=tk.TOP, fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#808080').pack(side=tk.LEFT, fill=tk.Y)\n    tk.Frame(border_frame, height=1, bg='#ffffff').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#ffffff').pack(side=tk.RIGHT, fill=tk.Y\n        )\n    inner_container = tk.Frame(border_frame, bg='#c0c0c0')\n    inner_container.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1\n        )\n    tk.Frame(inner_container, height=1, bg='#ffffff').pack(side=tk.TOP,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#ffffff').pack(side=tk.LEFT,\n        fill=tk.Y)\n    tk.Frame(inner_container, height=1, bg='#808080').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#808080').pack(side=tk.RIGHT,\n        fill=tk.Y)\n    content_area = tk.Frame(inner_container, bg='#c0c0c0')\n    content_area.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1)\n    return content_area\n\n\nroot = tk.Tk()\nroot.title('Current Time')\nroot.configure(bg='#008080')\nmain_frame = create_3d_border(root)\nmain_frame.config(padx=4, pady=4)\ninner_frame = tk.Frame(main_frame, bg='#c0c0c0', padx=8, pady=8)\ninner_frame.pack()\ntime_label = tk.Label(inner_frame, bg='#c0c0c0', fg='#000000', font=(\n    'MS Sans Serif', 18, 'bold'), padx=12, pady=8)\ntime_label.pack()\nroot.after(100, lambda : center_window(root))\nupdate_time()\nroot.mainloop()\n",
    "file": "/mnt/ProjectData/omni/omni_saves/watch.py"
  },
  {
    "id": 200,
    "hash": "6774a805052356775d8c4f0367253dc1",
    "content": "# OmniForge\n\n**Project\u2011Aware AI CLI for AST\u2011Precise Edits (\u201cScalpel\u201d) & Multi\u2011File Refactors (\u201cBlueprint\u201d).**\n\n> *OmniForge (a.k.a. the \"DualForge\" engine) helps you **scan**, **understand**, and **reforge** your codebase with local (Ollama) or remote (OpenRouter) LLMs. It is an independent open\u2011source project not affiliated with other products using the name \u201cOmni.\u201d*\n\n---\n\n## Core Features\n\n* **Project\u2011Aware Refactoring (`refactor`)**: Provide a high\u2011level goal (e.g. *\u201cmove all DB logic into `db/` and centralize config\u201d*). OmniForge generates & shows a multi\u2011step plan before touching files.\n* **Surgical AST Editing (`edit`)**: Target a single function/class. OmniForge parses the file, locates the node, applies a structural change, and shows you a diff.\n* **Context Ingestion (`look`)**: Scan a directory or single file to build a project manifest (paths + hashes + size + language hints) that guides subsequent edits/refactors.\n* **Dual Backends**: Seamlessly switch between **`openrouter`** (remote models) and **`ollama`** (local models) via `backend <name>`.\n* **Interactive Model Picker (`models`)**: Filter by source/provider and select from an up\u2011to\u2011date model list inside the terminal.\n* **Session Memory & History**: `history` shows conversation / action log; `memory clear` resets the working context.\n* **Safe AST\u2011Based Transformations**: Reduces syntax breakage vs naive text substitution. New imports / dependencies are auto\u2011inserted when possible.\n* **Dry\u2011Run Transparency**: Every multi\u2011file refactor presents (1) a generated plan, (2) per\u2011file proposed changes, (3) a consolidated diff for confirmation.\n\n---\n\n## Conceptual Modes\n\n| Mode          | Command(s) | Purpose                                              | Analogy              |\n| ------------- | ---------- | ---------------------------------------------------- | -------------------- |\n| **Survey**    | `look`     | Index project / ingest context                       | Mapping the terrain  |\n| **Scalpel**   | `edit`     | Precise single\u2011file structural change                | Surgery              |\n| **Blueprint** | `refactor` | Multi\u2011file architectural transformation              | Architecture         |\n| **Cast**      | `run`      | Execute last generated runnable block (if supported) | Forging the artifact |\n\nYou can reference these terms in docs, help screens, or UI banners for clarity.\n\n---\n\n## Installation\n\n> Requires Python 3.10+ and a Unix\u2011like shell.\n\n```bash\n# 1. Clone\ngit clone https://github.com/Snawyyy/omniforge.git\ncd omniforge\n\n# 2. (Optional) Inspect requirements\ncat requirements.txt\n\n# 3. Run installer (creates venv + installs deps)\nchmod +x install.sh\n./install.sh\n\n# 4. Activate environment\nsource venv/bin/activate\n\n# 5. Run CLI (interactive shell)\n./omni        # or: python omni.py\n```\n\nIf you later package it, expose a script entry point named `omni` while keeping an internal package name like `omniforge` to avoid namespace collisions.\n\n---\n\n## Configuration\n\nCreate a `.env` file to supply secrets (e.g. OpenRouter API key).\n\n```bash\ncp .env.example .env   # if example exists; otherwise create manually\n```\n\nIn `.env`:\n\n```dotenv\nOPENROUTER_API_KEY=\"sk-or-...\"\n```\n\n(Do **not** commit real keys. Ensure `.env` is listed in `.gitignore`.)\n\nOptional future keys can include local model paths, default model name, or feature flags.\n\n---\n\n## Quick Start Workflow\n\n```text\n> look .\n(Index project: builds manifest)\n\n> refactor \"extract hardcoded API URL to config/settings.py and update all imports\"\n(Shows plan \u2192 ask for confirmation)\n\n> edit src/utils.py \"add a doctring for calculate_average explaining parameters and return value\"\n(Shows targeted diff \u2192 confirm or abort)\n\n> models openai\n(Choose a different model)\n\n> backend ollama\n(Switch to local inference)\n```\n\n---\n\n## Command Reference\n\n| Command               | Example                                         | Description                                                                 |\n| --------------------- | ----------------------------------------------- | --------------------------------------------------------------------------- |\n| `look <path>`         | `look .`                                        | Scan directory or file; update project context manifest.                    |\n| `edit <file> \"instr\"` | `edit utils.py \"add error handling\"`            | AST\u2011guided targeted modification of a single file element or whole file.    |\n| `refactor \"goal\"`     | `refactor \"split monolith api.py into package\"` | High\u2011level multi\u2011file transformation with plan + diff review.               |\n| `send <prompt>`       | `send summarize module layout`                  | Generic prompt to current model with current context summary.               |\n| `models [filter]`     | `models google`                                 | Interactive model selector (filter by provider/source).                     |\n| `backend <name>`      | `backend ollama`                                | Switch between `openrouter` / `ollama`.                                     |\n| `history`             | `history`                                       | Display session interaction log.                                            |\n| `memory clear`        | `memory clear`                                  | Clear internal AI context memory (project manifest may persist separately). |\n| `run`                 | `run`                                           | Execute the last generated runnable code snippet (if feature implemented).  |\n| `help`                | `help`                                          | Show help / usage summary.                                                  |\n\n---\n\n## How It Works (High Level)\n\n1. **Ingestion (`look`)**: Walks the directory (configurable ignore patterns), captures file metadata (path, size, language), optionally caches abbreviated content or hashes.\n2. **Prompt Construction**: Merges user instruction + contextual manifest + focused snippets (for `edit`) or diff summaries (for `refactor`).\n3. **AST Layer** (Python initially): Parses target file(s); identifies node(s) (function/class) based on name + heuristic similarity; applies transformations guided by model output (structured hints or patch templates) rather than raw blind overwrite.\n4. **Plan (Refactor)**: Model proposes steps (CREATE / MODIFY / RENAME / DELETE). User approves. Each step executed & validated; errors surface early.\n5. **Diff Presentation**: A unified colorized diff shown; user confirms to write changes.\n6. **Safety**: If AST parse fails or patch violates syntax, changes abort (or fallback to text patch with warning).\n\n---\n\n## Roadmap (Indicative)\n\n| Milestone | Features                                                                    |\n| --------- | --------------------------------------------------------------------------- |\n| 0.1.0     | Core commands (`look`, `edit`, `refactor`, `models`, `backend`, `history`). |\n| 0.2.0     | Config file (`omniforge.toml`), ignore patterns, improved diff viewer.      |\n| 0.3.0     | Multi-language AST adapters (JS/TS via `tree-sitter`).                      |\n| 0.4.0     | Test impact analysis & auto test file generation.                           |\n| 0.5.0     | Refactor preview metrics (LOC touched, complexity delta).                   |\n| 0.6.0     | Inline security / lint feedback integration.                                |\n| 0.7.0     | Partial GUI / TUI dashboard mode.                                           |\n\n(Adjust roadmap as project evolves.)\n\n---\n\n## Developer Notes\n\n* Keep `.env`, virtual environment dirs (`venv/`), caches, large artifacts in `.gitignore`.\n* Consider adding a thin `omniforge/` package directory now for future PyPI packaging.\n* Implement a pluggable *Model Adapter* layer to abstract provider differences (OpenRouter vs Ollama).\n* Logging: Provide `--verbose` or `OMNIFORGE_DEBUG=1` env flag.\n* Add a JSONL log of commands & decisions to enable replay or supervised improvements.\n\n---\n\n## Contributing\n\n1. Fork & create a feature branch: `git checkout -b feat/<short-name>`\n2. Run and add tests (if/when test harness exists in `tests/`).\n3. Ensure style/format (e.g. `ruff`, `black`) passes.\n4. Submit pull request with concise description + before/after examples.\n\nIssues / discussions welcome for architecture proposals, AST adapters, or performance improvements.\n\n---\n\n## License\n\nReleased under the **MIT License**. See `LICENSE` file for full text.\n\n---\n\n## Name & Trademark Disclaimer\n\n\u201cOmniForge\u201d is an independent open-source tool and not affiliated with The Omni Group or any other third-party products using similar names. If a future naming conflict arises, a soft alias strategy (keeping the `omni` CLI) will preserve user workflows.\n\n---\n\n## Example Session (Illustrative)\n\n```text\n$ ./omni\nOMNIFORGE 0.1.0  (backend=openrouter | model=anthropic/claude-3)\nType 'help' or 'look .' to begin.\n\n> look .\nIndexed 42 files (Python=30, Markdown=5, JSON=7)\n\n> refactor \"centralize logging into logging_util.py and update imports\"\nPlan:\n  [1] CREATE logging_util.py\n  [2] MODIFY app.py (replace inline log setup)\n  [3] MODIFY worker.py (import logging_util)\nProceed? (y/n) y\n... (diff preview) ...\nApply changes? (y/n) y\nRefactor complete in 3.2s.\n\n> edit worker.py \"add retry with exponential backoff to fetch_data\"\nParsed worker.py \u2713\nApplied modification (function: fetch_data)\nDiff shown. Accept? (y/n) y\nSaved.\n```\n\n---\n\n## Philosophy\n\n*The next wave of developer AI goes beyond paste\u2011in prompts.* OmniForge treats your repository as *structured material*, enabling incremental, auditable, and safer evolution rather than opaque code dumps. By combining **context scanning**, **AST precision**, and **human approval loops**, it aims to become a trustworthy co\u2011developer rather than an occasionally helpful code generator.\n\n---\n\n## Feedback / Support\n\nOpen a GitHub Issue for bugs & feature requests. For conceptual discussions (roadmap, design choices), use Discussions.\n\n---\n\nHappy forging!\n",
    "file": "/mnt/ProjectData/omni/README.md"
  },
  {
    "id": 201,
    "hash": "b6c2845489f64b6396aaf85e5fd5909e",
    "content": "from abc import ABC, abstractmethod\nfrom typing import List, Optional, Dict, Any, Union\nfrom typing import List, Optional, Dict\nASTNode = Any\nDiffContent = str\n\n\nclass ASTAdapter(ABC):\n    \"\"\"\n    Abstract base class defining the interface for language-specific AST adapters.\n\n    This interface allows the CodeEditor to interact with the AST/CST of different\n    programming languages in a uniform way. Concrete implementations will handle\n    the specifics of parsing, traversing, and modifying the AST/CST for their\n    respective languages (e.g., Python's `ast`/`astor`, JavaScript's `tree-sitter`).\n\n    The adapter is responsible for holding the parsed tree structure and any\n    necessary metadata for operations.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the adapter by parsing the provided source code.\n\n        Args:\n            source_code: The string content of the source file to be parsed.\n\n        Raises:\n            ValueError: If the source code cannot be parsed due to syntax errors.\n        \"\"\"\n        self.source_code: str = source_code\n        self.tree: Optional[ASTNode] = None\n        self.nodes: Dict[str, ASTNode] = {}\n        self._parse_and_map(source_code)\n\n    @abstractmethod\n    def _parse_and_map(self, source_code: str) ->None:\n        \"\"\"\n        Abstract method to parse the source code and populate `self.tree` and `self.nodes`.\n\n        This is the core method where language-specific parsing logic resides.\n        Implementations should:\n        1. Parse the `source_code` into an AST/CST representation.\n        2. Store the root of this representation in `self.tree`.\n        3. Identify key top-level elements (functions, classes, variables, imports)\n           and map their names to their nodes in `self.nodes`.\n\n        Args:\n            source_code: The string content to parse.\n\n        Raises:\n            ValueError: If the source code cannot be parsed.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_elements(self) ->List[str]:\n        \"\"\"\n        Abstract method to list the names of the main elements found in the code.\n\n        These are typically top-level functions, classes, variable assignments,\n        and imports that the adapter can identify and manipulate.\n\n        Returns:\n            A list of element names (strings).\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"\n        Abstract method to get the source code string for a specific element.\n\n        Args:\n            element_name: The name of the element (function, class, etc.).\n\n        Returns:\n            The source code string for the element, or None if not found.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"\n        Abstract method to get detailed structural information about an element.\n\n        This information can include type, line numbers, body items, etc., useful\n        for aiding the AI in understanding the code's layout.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            A dictionary containing structural details, or None if not found.\n            Example structure:\n            {\n                'name': 'func_name',\n                'type': 'FunctionDef', # or 'ClassDef', etc.\n                'line_start': 10,\n                'line_end': 25,\n                'body_items': [list of internal statement details...]\n            }\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"\n        Abstract method to extract a snippet of code from within an element's body.\n\n        Used for 'partial' edits where only a specific range of lines within\n        a function or class needs to be changed.\n\n        Args:\n            element_name: The name of the element containing the snippet.\n            line_start: The starting line number (1-based, absolute) of the snippet.\n            line_end: The ending line number (inclusive) of the snippet.\n\n        Returns:\n            The source code string for the specified lines within the element, or None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"\n        Abstract method to replace an entire named element.\n\n        This involves finding the old element in the tree and swapping it with\n        the representation of the `new_code`.\n\n        Args:\n            element_name: The name of the element to replace.\n            new_code: The new source code for the element (and potential helpers).\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"\n        Abstract method to add a new block of code (element) to the file.\n\n        This involves parsing the `new_code` and inserting its representation\n        into the tree at an appropriate location (e.g., end of file, near anchor).\n\n        Args:\n            new_code: The source code for the new element(s).\n            anchor_name: Optional name of an existing element to position relative to.\n            before: If True and `anchor_name` is provided, insert before the anchor.\n\n        Returns:\n            True if the element was added successfully, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"\n        Abstract method to delete a named element from the file.\n\n        This involves finding the element in the tree and removing its representation.\n\n        Args:\n            element_name: The name of the element to delete.\n\n        Returns:\n            True if the element was successfully deleted, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"\n        Abstract method for a 'surgical' edit within an element's body.\n\n        Replaces a specific statement or line range within the body of an element.\n\n        Args:\n            element_name: Name of the function/class to modify.\n            new_code: New code to insert (can be multiple statements).\n            line_start: Starting line number (absolute) within the element.\n            line_end: Ending line number (inclusive) within the element.\n            statement_index: Alternative to line numbers - replace the Nth statement.\n\n        Returns:\n            True if successful, False otherwise.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_modified_source(self) ->str:\n        \"\"\"\n        Abstract method to serialize the potentially modified AST/CST back to source code.\n\n        Returns:\n            The full source code string reflecting the current state of the tree.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_diff(self) ->str:\n        \"\"\"\n        Abstract method to generate a diff between the original source and the modified source.\n\n        Returns:\n            A string containing the unified diff.\n        \"\"\"\n        pass\n\n\n\"\"\"\nTextFileAdapter - Basic adapter for text files\n\nThis module provides a basic adapter for text files that implements\nthe ASTAdapter interface. It allows text files to be used with the\nCodeEditor class.\n\"\"\"\n\n\nclass TextFileAdapter(ASTAdapter):\n    \"\"\"\n    A basic adapter for text files that implements the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the TextFileAdapter.\n\n        Args:\n            source_code: The source code as a string.\n        \"\"\"\n        self.source_code = source_code\n        self.modified_source = source_code\n\n    def list_elements(self) ->List[str]:\n        \"\"\"\n        Lists top-level elements in the text file.\n        For text files, this returns a single \"content\" element.\n\n        Returns:\n            A list containing \"content\".\n        \"\"\"\n        return ['content']\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"\n        Gets the source code for a specific element.\n        For text files, this returns the entire file content.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            The source code of the entire file.\n        \"\"\"\n        if element_name == 'content':\n            return self.source_code\n        return None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"\n        Gets detailed structure information about an element.\n        For text files, this provides minimal structure information.\n\n        Args:\n            element_name: The name of the element.\n\n        Returns:\n            A dictionary with basic structure information.\n        \"\"\"\n        if element_name == 'content':\n            lines = self.source_code.splitlines()\n            return {'name': element_name, 'type': 'text', 'line_count': len\n                (lines), 'character_count': len(self.source_code)}\n        return None\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"\n        Gets a snippet from within an element's body.\n        For text files, this returns lines between line_start and line_end.\n\n        Args:\n            element_name: The name of the element.\n            line_start: The starting line number (1-indexed).\n            line_end: The ending line number (1-indexed).\n\n        Returns:\n            A string containing the specified lines.\n        \"\"\"\n        if element_name != 'content':\n            return None\n        lines = self.source_code.splitlines()\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(lines), line_end)\n        if start_idx >= len(lines) or start_idx >= end_idx:\n            return None\n        return '\\n'.join(lines[start_idx:end_idx])\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"\n        Replaces a partial section of an element.\n        For text files, this replaces lines between line_start and line_end.\n\n        Args:\n            element_name: The name of the element.\n            new_code: The new code to insert.\n            line_start: The starting line number (1-indexed).\n            line_end: The ending line number (1-indexed).\n            statement_index: Not used for text files.\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        if element_name != 'content':\n            return False\n        if line_start is None or line_end is None:\n            return False\n        lines = self.modified_source.splitlines()\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(lines), line_end)\n        if start_idx > len(lines) or start_idx > end_idx:\n            return False\n        new_lines = self.modified_source.splitlines()\n        new_code_lines = new_code.splitlines()\n        new_lines[start_idx:end_idx] = new_code_lines\n        self.modified_source = '\\n'.join(new_lines)\n        return True\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"\n        Adds new content to the text file.\n        For text files, this appends or prepends content.\n\n        Args:\n            new_code: The new code to add.\n            anchor_name: Not used for text files.\n            before: If True, prepend; if False, append.\n\n        Returns:\n            True if the addition was successful, False otherwise.\n        \"\"\"\n        if before:\n            self.modified_source = new_code + '\\n' + self.modified_source\n        else:\n            self.modified_source = self.modified_source + '\\n' + new_code\n        return True\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"\n        Deletes an element by name.\n        For text files, this clears the entire content if element_name is \"content\".\n\n        Args:\n            element_name: The name of the element to delete.\n\n        Returns:\n            True if the deletion was successful, False otherwise.\n        \"\"\"\n        if element_name == 'content':\n            self.modified_source = ''\n            return True\n        return False\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"\n        Replaces a target element with new code.\n        For text files, this replaces the entire content if element_name is \"content\".\n\n        Args:\n            element_name: The name of the element to replace.\n            new_code: The new code.\n\n        Returns:\n            True if the replacement was successful, False otherwise.\n        \"\"\"\n        if element_name == 'content':\n            self.modified_source = new_code\n            return True\n        return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"\n        Gets the modified source code.\n\n        Returns:\n            The modified source code.\n        \"\"\"\n        return self.modified_source\n\n    def get_diff(self) ->str:\n        \"\"\"\n        Generates a diff between the original source and the modified source.\n\n        Returns:\n            A string containing the diff.\n        \"\"\"\n        import difflib\n        return ''.join(difflib.unified_diff(self.source_code.splitlines(\n            keepends=True), self.modified_source.splitlines(keepends=True),\n            fromfile='original', tofile='modified'))\n",
    "file": "/mnt/ProjectData/omni/ast_adapter.py"
  },
  {
    "id": 202,
    "hash": "3fa6303779874a8e61c7a1a4ffc75e58",
    "content": "\"\"\"\nCodeEditor - Enhanced AST-based code manipulation tool\n\nThis module provides a class to programmatically parse, analyze,\nand edit source code. It has been refactored to use a pluggable\nASTAdapter system, allowing it to support multiple languages.\nCurrently, it defaults to Python's built-in `ast` module via\nPythonASTAdapter for backward compatibility during the transition.\n\"\"\"\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Union, Tuple, Type, Any\nfrom ast_adapter import ASTAdapter\nfrom python_ast_adapter import PythonASTAdapter\nimport os\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n\n\nclass CodeEditor:\n    \"\"\"\n    An enhanced class to safely edit files using AST/CST with partial edit support.\n    The core logic for interacting with the code structure is now delegated to\n    a language-specific ASTAdapter.\n    \"\"\"\n\n    def __init__(self, file_path: str, adapter_class: Optional[Type[\n        ASTAdapter]]=None):\n        \"\"\"\n        Initializes the CodeEditor.\n\n        Args:\n            file_path: The path to the source file.\n            adapter_class: The ASTAdapter subclass to use. If None, defaults to\n                           PythonASTAdapter for .py files.\n        \"\"\"\n        self.file_path = file_path\n        self.source_code = self._read_file()\n        self.adapter: Optional[ASTAdapter] = None\n        self.tree: Optional[ast.AST] = None\n        self.nodes: Dict[str, ast.AST] = {}\n        self.atok: Optional[Any] = None\n        if adapter_class is None:\n            file_extension = os.path.splitext(self.file_path)[1].lower()\n            if file_extension == '.py':\n                try:\n                    from python_ast_adapter import PythonASTAdapter\n                    self.adapter = PythonASTAdapter(self.source_code)\n                except ImportError as e:\n                    try:\n                        self.tree = self._parse_source()\n                        self.nodes = self._map_nodes()\n                        if ASTTOKENS_AVAILABLE:\n                            self.atok = asttokens.ASTTokens(self.\n                                source_code, parse=True)\n                    except Exception as parse_error:\n                        raise ValueError(\n                            f'Failed to parse Python file: {parse_error}')\n            elif file_extension == '.js':\n                try:\n                    from javascript_ast_adapter import JavaScriptASTAdapter\n                    self.adapter = JavaScriptASTAdapter(self.source_code)\n                except ImportError as e:\n                    raise ValueError(\n                        f'tree-sitter is required for JavaScript support but not available: {e}'\n                        )\n                except Exception as e:\n                    raise ValueError(\n                        f'Failed to initialize JavaScript adapter: {e}')\n            elif file_extension == '.txt':\n                pass\n            else:\n                raise ValueError(\n                    f'Unsupported file type: {file_extension}. Supported types: .py, .js, .txt'\n                    )\n        else:\n            try:\n                self.adapter = adapter_class(self.source_code)\n            except Exception as e:\n                raise ValueError(\n                    f'Failed to initialize adapter {adapter_class.__name__}: {e}'\n                    )\n\n    def _read_file(self) ->str:\n        \"\"\"Reads the source file.\"\"\"\n        try:\n            with open(self.file_path, 'r', encoding='utf-8') as f:\n                return f.read()\n        except FileNotFoundError:\n            raise ValueError(f'File not found: {self.file_path}')\n\n    def _parse_source(self) ->ast.AST:\n        \"\"\"Fallback parsing logic.\"\"\"\n        try:\n            return ast.parse(self.source_code)\n        except SyntaxError as e:\n            raise ValueError(f'Invalid Python syntax in {self.file_path}: {e}')\n\n    def list_elements(self) ->List[str]:\n        \"\"\"Lists top-level elements in the code.\"\"\"\n        if self.adapter:\n            return self.adapter.list_elements()\n        else:\n            return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"Gets the source code for a specific element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_source_of(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            return astor.to_source(node) if node else None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"Gets detailed structure information about an element.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_structure(element_name)\n        else:\n            node = self.nodes.get(element_name)\n            if not node:\n                return None\n            structure = {'name': element_name, 'type': node.__class__.\n                __name__, 'line_start': node.lineno if hasattr(node,\n                'lineno') else None, 'line_end': node.end_lineno if hasattr\n                (node, 'end_lineno') else None, 'body_items': []}\n            if hasattr(node, 'body'):\n                for i, item in enumerate(node.body):\n                    item_info = {'index': i, 'type': item.__class__.\n                        __name__, 'line_start': item.lineno if hasattr(item,\n                        'lineno') else None, 'line_end': item.end_lineno if\n                        hasattr(item, 'end_lineno') else None}\n                    if isinstance(item, ast.Assign) and item.targets:\n                        target = item.targets[0]\n                        if isinstance(target, ast.Name):\n                            item_info['assigns'] = target.id\n                    elif isinstance(item, (ast.If, ast.While, ast.For)):\n                        item_info['has_body'] = bool(item.body)\n                    elif isinstance(item, ast.Return):\n                        item_info['returns'] = True\n                    structure['body_items'].append(item_info)\n            return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"Gets a snippet from within an element's body.\"\"\"\n        if self.adapter:\n            return self.adapter.get_element_body_snippet(element_name,\n                line_start, line_end)\n        else:\n            if not self.atok:\n                return None\n            node = self.nodes.get(element_name)\n            if not node or not hasattr(node, 'body'):\n                return None\n            statements = []\n            for stmt in node.body:\n                if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                    if (line_start <= stmt.lineno <= line_end or line_start <=\n                        stmt.end_lineno <= line_end):\n                        statements.append(stmt)\n            if not statements:\n                return None\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in\n                statements)\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"Replaces a partial section of an element.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_partial(element_name, new_code,\n                line_start, line_end, statement_index)\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                if new_code.strip().startswith('def ') or new_code.strip(\n                    ).startswith('class '):\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body[0].body\n                else:\n                    new_ast = ast.parse(new_code)\n                    new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if statement_index is not None:\n                if 0 <= statement_index < len(node.body):\n                    node.body[statement_index:statement_index + 1\n                        ] = new_statements\n                    return True\n            elif line_start is not None:\n                result = self._find_statement_in_body(node.body, line_start,\n                    line_end)\n                if result:\n                    idx, _ = result\n                    if line_end:\n                        end_idx = idx\n                        for i in range(idx + 1, len(node.body)):\n                            stmt = node.body[i]\n                            if hasattr(stmt, 'end_lineno'\n                                ) and stmt.end_lineno <= line_end:\n                                end_idx = i\n                            else:\n                                break\n                        node.body[idx:end_idx + 1] = new_statements\n                    else:\n                        node.body[idx:idx + 1] = new_statements\n                    return True\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"Adds a new block of code to the file.\"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name, before)\n        else:\n            try:\n                new_ast_module = ast.parse(new_code)\n            except (SyntaxError, IndexError):\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            insertion_index = -1\n            main_block_idx = -1\n            for i, _node in enumerate(self.tree.body):\n                if isinstance(_node, ast.If) and isinstance(_node.test, ast\n                    .Compare) and isinstance(_node.test.left, ast.Name\n                    ) and _node.test.left.id == '__name__' and len(_node.\n                    test.ops) == 1 and isinstance(_node.test.ops[0], ast.Eq\n                    ) and len(_node.test.comparators) == 1:\n                    comp = _node.test.comparators[0]\n                    if isinstance(comp, ast.Constant\n                        ) and comp.value == '__main__' or isinstance(comp,\n                        ast.Str) and comp.s == '__main__':\n                        main_block_idx = i\n                        break\n            if anchor_name:\n                if anchor_name not in self.nodes:\n                    return False\n                anchor_node = self.nodes[anchor_name]\n                try:\n                    anchor_idx = self.tree.body.index(anchor_node)\n                    proposed_index = anchor_idx if before else anchor_idx + 1\n                    if main_block_idx != -1:\n                        insertion_index = min(proposed_index, main_block_idx)\n                    else:\n                        insertion_index = proposed_index\n                except ValueError:\n                    return False\n            elif main_block_idx != -1:\n                insertion_index = main_block_idx\n            if insertion_index == -1:\n                self.tree.body.extend(new_code_body)\n            else:\n                for i, new_node in enumerate(new_code_body):\n                    self.tree.body.insert(insertion_index + i, new_node)\n            for _node in new_code_body:\n                if isinstance(_node, (ast.FunctionDef, ast.AsyncFunctionDef,\n                    ast.ClassDef)):\n                    self.nodes[_node.name] = _node\n            return True\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"Deletes an element by name.\"\"\"\n        if self.adapter:\n            return self.adapter.delete_element(element_name)\n        else:\n            deleted = False\n            if element_name in self.nodes:\n                node_to_delete = self.nodes[element_name]\n                for _node in ast.walk(self.tree):\n                    if hasattr(_node, 'body') and isinstance(_node.body, list):\n                        try:\n                            _node.body.remove(node_to_delete)\n                            deleted = True\n                            break\n                        except ValueError:\n                            continue\n                if deleted:\n                    del self.nodes[element_name]\n                    self.nodes = self._map_nodes()\n                    return True\n            new_body = []\n            for _node in self.tree.body:\n                if isinstance(_node, ast.Assign):\n                    match = False\n                    for target in _node.targets:\n                        if isinstance(target, ast.Name\n                            ) and target.id == element_name:\n                            match = True\n                            break\n                    if match:\n                        deleted = True\n                        continue\n                elif isinstance(_node, ast.Import):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                elif isinstance(_node, ast.ImportFrom):\n                    new_aliases = []\n                    for alias in _node.names:\n                        if not (alias.name == element_name or alias.asname ==\n                            element_name):\n                            new_aliases.append(alias)\n                        else:\n                            deleted = True\n                    if new_aliases:\n                        _node.names = new_aliases\n                    elif deleted:\n                        continue\n                new_body.append(_node)\n            self.tree.body = new_body\n            if deleted:\n                self.nodes = self._map_nodes()\n            return deleted\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"Replaces a target element with new code.\"\"\"\n        if self.adapter:\n            return self.adapter.replace_element(element_name, new_code)\n        else:\n            if element_name not in self.nodes:\n                return False\n            try:\n                new_ast_module = ast.parse(new_code)\n            except SyntaxError:\n                return False\n            new_imports = [n for n in new_ast_module.body if isinstance(n,\n                (ast.Import, ast.ImportFrom))]\n            new_code_body = [n for n in new_ast_module.body if not\n                isinstance(n, (ast.Import, ast.ImportFrom))]\n            if not new_code_body:\n                return False\n            if new_imports:\n                self._add_imports(new_imports)\n            for _node in ast.walk(self.tree):\n                if hasattr(_node, 'body') and isinstance(_node.body, list):\n                    try:\n                        old_node = self.nodes[element_name]\n                        idx = _node.body.index(old_node)\n                        _node.body.pop(idx)\n                        for i, new_node in enumerate(new_code_body):\n                            _node.body.insert(idx + i, new_node)\n                        del self.nodes[element_name]\n                        for n in new_code_body:\n                            if isinstance(n, (ast.FunctionDef, ast.\n                                AsyncFunctionDef, ast.ClassDef)):\n                                self.nodes[n.name] = n\n                        return True\n                    except (ValueError, KeyError):\n                        continue\n            return False\n\n    def insert_in_element(self, element_name: str, new_code: str, position:\n        str='end', after_line: Optional[int]=None, before_line: Optional[\n        int]=None) ->bool:\n        \"\"\"\n        Insert new code into an element without replacing existing code.\n        This is an internal/helper method, delegating to adapter OR using fallback.\n        \"\"\"\n        if self.adapter:\n            return self.adapter.add_element(new_code, anchor_name=\n                element_name, before=position == 'start')\n        else:\n            if element_name not in self.nodes:\n                return False\n            node = self.nodes[element_name]\n            if not hasattr(node, 'body') or not isinstance(node.body, list):\n                return False\n            try:\n                new_ast = ast.parse(new_code)\n                new_statements = new_ast.body\n            except SyntaxError:\n                return False\n            if not new_statements:\n                return False\n            if position == 'start':\n                node.body[0:0] = new_statements\n            elif position == 'end':\n                node.body.extend(new_statements)\n            elif after_line:\n                result = self._find_statement_in_body(node.body, after_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx + 1:idx + 1] = new_statements\n                else:\n                    return False\n            elif before_line:\n                result = self._find_statement_in_body(node.body, before_line)\n                if result:\n                    idx, _ = result\n                    node.body[idx:idx] = new_statements\n                else:\n                    return False\n            else:\n                return False\n            return True\n\n    def _map_nodes(self) ->Dict[str, ast.AST]:\n        \"\"\"Fallback node mapping logic for Python AST.\"\"\"\n        nodes = {}\n        for node in ast.walk(self.tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast\n                .ClassDef)):\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int,\n        line_end: Optional[int]=None) ->Optional[Tuple[int, ast.AST]]:\n        \"\"\"Fallback statement finding logic for Python AST.\"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = stmt.end_lineno if hasattr(stmt, 'end_lineno'\n                        ) else stmt.lineno\n                    if (stmt.lineno <= line_start <= stmt_end or stmt.\n                        lineno <= line_end <= stmt_end):\n                        return i, stmt\n                elif stmt.lineno == line_start:\n                    return i, stmt\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.\n        ImportFrom]]) ->None:\n        \"\"\"Fallback logic to add imports to the top of the Python AST.\"\"\"\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                existing_imports_str.add(astor.to_source(node).strip())\n                last_import_index = i\n        for new_import in reversed(new_import_nodes):\n            new_import_str = astor.to_source(new_import).strip()\n            if new_import_str not in existing_imports_str:\n                self.tree.body.insert(last_import_index + 1, new_import)\n\n    def apply_arbitrary_change(self, new_source_code: str) ->bool:\n        \"\"\"\n        Rewrites the entire file's AST from a new source string.\n        This method resets the adapter if one exists, or uses fallback.\n        \"\"\"\n        if self.adapter:\n            try:\n                adapter_class = type(self.adapter)\n                self.adapter = adapter_class(new_source_code)\n                return True\n            except Exception:\n                return False\n        else:\n            try:\n                new_tree = ast.parse(new_source_code)\n                self.tree = new_tree\n                self.nodes = self._map_nodes()\n                if ASTTOKENS_AVAILABLE:\n                    self.source_code = new_source_code\n                    self.atok = asttokens.ASTTokens(self.source_code, parse\n                        =True)\n                return True\n            except SyntaxError:\n                return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"Serializes the potentially modified code structure back to source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_modified_source()\n        else:\n            return astor.to_source(self.tree)\n\n    def get_diff(self) ->str:\n        \"\"\"Generates a diff between the original source and the modified source.\"\"\"\n        if self.adapter:\n            return self.adapter.get_diff()\n        else:\n            modified_source = self.get_modified_source()\n            return ''.join(difflib.unified_diff(self.source_code.splitlines\n                (keepends=True), modified_source.splitlines(keepends=True),\n                fromfile=f'{self.file_path} (original)', tofile=\n                f'{self.file_path} (modified)'))\n\n    def save_changes(self) ->None:\n        \"\"\"Saves the modified source code back to the file.\"\"\"\n        modified_source = self.get_modified_source()\n        with open(self.file_path, 'w', encoding='utf-8') as f:\n            f.write(modified_source)\n",
    "file": "/mnt/ProjectData/omni/code_editor.py"
  },
  {
    "id": 203,
    "hash": "cc52aa524d0929867d5d2ea3697229e6",
    "content": "\"\"\"\nGenerated file.\n\"\"\"\nimport os\n\"\"\"\nFileCreator - A utility for creating files.\n\nThis module provides a simple, encapsulated way to create files,\nensuring that their parent directories exist before writing.\n\"\"\"\n\n\nclass FileCreator:\n    \"\"\"\n    A utility class to handle the creation of new files.\n    \"\"\"\n\n    @staticmethod\n    def create(file_path: str, content: str) ->None:\n        \"\"\"\n        Creates a file at the specified path with the given content.\n\n        This method will automatically create any necessary parent\n        directories for the file path.\n\n        Args:\n            file_path: The full path where the file should be created.\n            content: The string content to write to the file.\n\n        Raises:\n            IOError: If there is an error creating the directories or writing the file.\n        \"\"\"\n        try:\n            directory = os.path.dirname(file_path)\n            if directory:\n                os.makedirs(directory, exist_ok=True)\n            with open(file_path, 'w', encoding='utf-8') as f:\n                f.write(content)\n        except (IOError, OSError) as e:\n            raise IOError(f\"Failed to create file '{file_path}': {e}\") from e\n",
    "file": "/mnt/ProjectData/omni/file_creator.py"
  },
  {
    "id": 204,
    "hash": "04a24ceab008bd649d0530d309c72e42",
    "content": "import subprocess\nimport os\nfrom typing import List, Optional, Union\n\n\nclass GitManager:\n    \"\"\"\n    Encapsulates Git-related logic for a specific repository.\n\n    This class provides methods to perform common Git operations such as\n    checking status, getting diffs, staging, committing, and pushing changes.\n    It relies on the Git command-line tool being installed and accessible\n    in the system's PATH.\n    \"\"\"\n\n    def __init__(self, repo_path: str):\n        \"\"\"\n        Initializes the GitManager for a given repository path.\n\n        Args:\n            repo_path: The absolute or relative path to the Git repository.\n\n        Raises:\n            ValueError: If the provided path is not a valid Git repository.\n        \"\"\"\n        if not os.path.isdir(os.path.join(repo_path, '.git')):\n            raise ValueError(\n                f\"The path '{repo_path}' is not a valid Git repository.\")\n        self.repo_path = repo_path\n\n    def _run_command(self, command: List[str]) ->str:\n        \"\"\"\n        Executes a Git command in the repository's directory.\n\n        Args:\n            command: A list of command arguments, starting with 'git'.\n\n        Returns:\n            The standard output of the command as a string.\n\n        Raises:\n            subprocess.CalledProcessError: If the command returns a non-zero exit code.\n        \"\"\"\n        try:\n            result = subprocess.run(command, cwd=self.repo_path, check=True,\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True,\n                encoding='utf-8')\n            return result.stdout.strip()\n        except subprocess.CalledProcessError as e:\n            error_message = (\n                f\"Git command failed: {' '.join(command)}\\nError: {e.stderr.strip()}\"\n                )\n            raise subprocess.CalledProcessError(e.returncode, e.cmd, output\n                =e.stdout, stderr=error_message) from e\n\n    def get_status(self) ->str:\n        \"\"\"\n        Gets the repository status in a condensed format.\n\n        Uses `git status --porcelain` for a machine-readable output.\n\n        Returns:\n            A string representing the repository's status.\n        \"\"\"\n        return self._run_command(['git', 'status', '--porcelain'])\n        \n    def get_changed_files(self) -> List[str]:\n        \"\"\"\n        Gets a list of all changed (modified, added, deleted, untracked, renamed, or copied) files.\n\n        This parses the output of `git status --porcelain`, which provides a stable,\n        machine-readable format.\n\n        Returns:\n            A list of file paths relative to the repository root. For renamed or\n            copied files, it returns the new path.\n        \"\"\"\n        status_output = self.get_status()\n        if not status_output:\n            return []\n        \n        changed_files = []\n        for line in status_output.splitlines():\n            if len(line) < 3:  # Skip malformed lines\n                continue\n                \n            # Git status porcelain format: XY filename\n            # X = index status, Y = working tree status\n            index_status = line[0]\n            worktree_status = line[1]\n            \n            # The filename starts after the two status characters and a space\n            # But let's be more defensive about finding where the filename actually starts\n            filename_start = 2\n            while filename_start < len(line) and line[filename_start] == ' ':\n                filename_start += 1\n                \n            if filename_start >= len(line):\n                continue  # Skip if no filename found\n                \n            path_info = line[filename_start:]\n            \n            # Check if either index or working tree status indicates rename/copy\n            if index_status in ('R', 'C') or worktree_status in ('R', 'C'):\n                if ' -> ' in path_info:\n                    _, new_path = path_info.split(' -> ', 1)  # Use maxsplit=1 for safety\n                    changed_files.append(new_path.strip())\n                else:\n                    # Fallback if format is unexpected\n                    changed_files.append(path_info.strip())\n            else:\n                changed_files.append(path_info.strip())\n        \n        # Remove duplicates while preserving order\n        return list(dict.fromkeys(changed_files))\n\n    def get_diff(self, file_path: Optional[str]=None, staged: bool=False\n        ) ->str:\n        \"\"\"\n        Gets the diff of changes in the repository.\n\n        Args:\n            file_path: Optional. Path to a specific file to diff.\n            staged: If True, shows the diff for staged changes (`--cached`).\n                    Otherwise, shows the diff for unstaged changes.\n\n        Returns:\n            The git diff output as a string.\n        \"\"\"\n        cmd = ['git', 'diff']\n        if staged:\n            cmd.append('--cached')\n        if file_path:\n            cmd.append('--')\n            cmd.append(file_path)\n        return self._run_command(cmd)\n\n    def add(self, files: Union[str, List[str]]) ->None:\n        \"\"\"\n    Stages one or more files, handling each one individually for robustness.\n\n    This approach prevents a single invalid file path from causing the\n    entire 'git add' operation to fail. Warnings will be printed for any\n    files that could not be staged.\n\n    Args:\n        files: A single file path or a list of file paths to stage.\n               Can also be '.' to stage all changes.\n    \"\"\"\n        if isinstance(files, str):\n            files = [files]\n        for file_path in files:\n            try:\n                cmd = ['git', 'add', '--', file_path]\n                self._run_command(cmd)\n            except subprocess.CalledProcessError as e:\n                print(\n                    f\"Warning: Could not stage file '{file_path}'. Git reported: {e.stderr}\"\n                    )\n\n    def commit(self, message: str) ->str:\n        \"\"\"\n        Commits staged changes with a given message.\n\n        Args:\n            message: The commit message.\n\n        Returns:\n            The stdout from the git commit command.\n        \"\"\"\n        return self._run_command(['git', 'commit', '-m', message])\n\n    def push(self, remote: str='origin', branch: Optional[str]=None) ->str:\n        \"\"\"\n        Pushes commits to a remote repository.\n\n        Args:\n            remote: The name of the remote to push to (default: 'origin').\n            branch: The branch to push. If None, uses the current branch.\n\n        Returns:\n            The stdout from the git push command.\n        \"\"\"\n        if branch is None:\n            branch = self.get_current_branch()\n        return self._run_command(['git', 'push', remote, branch])\n\n    def get_current_branch(self) ->str:\n        \"\"\"\n        Determines the current active branch name.\n\n        Returns:\n            The name of the current branch.\n        \"\"\"\n        return self._run_command(['git', 'rev-parse', '--abbrev-ref', 'HEAD'])\n",
    "file": "/mnt/ProjectData/omni/git_manager.py"
  },
  {
    "id": 205,
    "hash": "f3f7ab448ad3e233539c4e4bddcd64f4",
    "content": "# javascript_ast_adapter.py\n\n\"\"\"\nJavaScriptASTAdapter - Concrete AST adapter for JavaScript using tree-sitter.\n\nThis module implements the ASTAdapter interface specifically for JavaScript,\nleveraging the tree-sitter library for parsing and manipulation.\n\"\"\"\n\nimport difflib\nimport re\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for tree-sitter\ntry:\n    import tree_sitter\n    import tree_sitter_languages\n    TREETSITTER_AVAILABLE = True\nexcept ImportError:\n    TREETSITTER_AVAILABLE = False\n    # This will cause an error during initialization if the adapter is used\n\n\nclass JavaScriptASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for JavaScript source code.\n\n    This adapter uses tree-sitter to parse and manipulate JavaScript code.\n    It holds the parsed tree-sitter Tree and provides methods to interact\n    with it according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the JavaScriptASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The JavaScript source code as a string.\n\n        Raises:\n            ValueError: If tree-sitter libraries are not available or if\n                        the source code has invalid JavaScript syntax.\n        \"\"\"\n        if not TREETSITTER_AVAILABLE:\n            raise ValueError(\"tree-sitter and tree-sitter-languages are required for JavaScript support.\")\n            \n        # Store source code for diffing and manipulation\n        self.source_code: str = source_code\n        # Will hold the parsed tree-sitter tree\n        self.tree: Optional[tree_sitter.Tree] = None\n        # Will hold a mapping of element names to their tree-sitter nodes\n        self.nodes: Dict[str, tree_sitter.Node] = {}\n        # Tree-sitter language parser\n        self.language = tree_sitter_languages.get_language(\"javascript\")\n        self.parser = tree_sitter.Parser(self.language)\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the JavaScript source code and maps elements.\n\n        Args:\n            source_code: The JavaScript source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid JavaScript syntax.\n        \"\"\"\n        try:\n            # Encode the source code in bytes as required by tree-sitter\n            self.tree = self.parser.parse(bytes(source_code, \"utf-8\"))\n        except Exception as e:\n            raise ValueError(f\"Failed to parse JavaScript source: {e}\") from e\n\n        self.nodes = self._map_nodes()\n\n    def _map_nodes(self) -> Dict[str, tree_sitter.Node]:\n        \"\"\"\n        Walks the tree and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their tree-sitter nodes.\n        \"\"\"\n        nodes: Dict[str, tree_sitter.Node] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        # Define the types of nodes we're interested in\n        target_types = {\n            \"function_declaration\", \"class_declaration\", \n            \"variable_declarator\", \"import_statement\"\n        }\n        \n        # Walk the tree using a stack-based approach\n        stack = [self.tree.root_node]\n        while stack:\n            node = stack.pop()\n            \n            # Check if this is a target node type\n            if node.type in target_types:\n                # Extract the name for different node types\n                name = self._get_node_name(node)\n                if name and name not in nodes:\n                    nodes[name] = node\n            \n            # Add children to the stack for further processing\n            for child in reversed(node.children):  # Reverse to maintain order when popping\n                stack.append(child)\n                \n        return nodes\n    \n    def _get_node_name(self, node: tree_sitter.Node) -> Optional[str]:\n        \"\"\"\n        Extracts the name of a node based on its type.\n        \n        Args:\n            node: The tree-sitter node to extract the name from.\n            \n        Returns:\n            The name of the node, or None if no name could be found.\n        \"\"\"\n        if node.type == \"function_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"class_declaration\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"variable_declarator\":\n            # Find the identifier child\n            for child in node.children:\n                if child.type == \"identifier\":\n                    return child.text.decode(\"utf-8\")\n        elif node.type == \"import_statement\":\n            # This is a more complex case - for now, we'll use a simplified approach\n            # Extract the module name from the import statement\n            # e.g., in \"import foo from 'bar'\", we want \"foo\"\n            # This is a simplified implementation and might need refinement\n            import_clause = None\n            for child in node.children:\n                if child.type == \"import_clause\":\n                    import_clause = child\n                    break\n            \n            if import_clause:\n                # Check for a simple identifier\n                for child in import_clause.children:\n                    if child.type == \"identifier\":\n                        return child.text.decode(\"utf-8\")\n                    elif child.type == \"named_imports\":\n                        # Handle named imports like { foo, bar }\n                        # For simplicity, we'll just return a placeholder\n                        # A more complete implementation would extract all names\n                        return f\"import_from_{hash(node.text.decode('utf-8')) % 10000}\"\n        \n        return None\n\n    def _find_node_by_position(self, start_point: Tuple[int, int], \n                              end_point: Optional[Tuple[int, int]] = None) -> Optional[tree_sitter.Node]:\n        \"\"\"\n        Finds a node in the tree that corresponds to a given range.\n        \n        Args:\n            start_point: A (row, column) tuple indicating the start position.\n            end_point: A (row, column) tuple indicating the end position.\n            \n        Returns:\n            The tree-sitter node that corresponds to the range, or None if not found.\n        \"\"\"\n        if not self.tree:\n            return None\n            \n        # A simple approach: find the smallest node that contains the range\n        # This is a simplified implementation and might need refinement\n        def contains_range(node):\n            node_start = (node.start_point[0], node.start_point[1])\n            node_end = (node.end_point[0], node.end_point[1])\n            if end_point:\n                return (node_start <= start_point and node_end >= end_point)\n            else:\n                return node_start <= start_point <= node_end\n        \n        # Walk the tree to find matching nodes\n        stack = [self.tree.root_node]\n        candidates = []\n        \n        while stack:\n            current_node = stack.pop()\n            if contains_range(current_node):\n                candidates.append(current_node)\n                # Add children to continue searching for smaller nodes\n                stack.extend(current_node.children)\n        \n        # Return the smallest (last) candidate\n        return candidates[-1] if candidates else None\n    \n    def _get_line_info_from_point(self, point: Tuple[int, int]) -> Dict[str, Any]:\n        \"\"\"\n        Converts a tree-sitter point to line information.\n        \n        Args:\n            point: A (row, column) tuple from tree-sitter.\n            \n        Returns:\n            A dictionary with line_start and line_end information.\n        \"\"\"\n        # Tree-sitter uses 0-based indexing for rows\n        return {\n            'line_start': point[0] + 1,  # Convert to 1-based\n            'line_end': point[0] + 1\n        }\n\n    def _reparse_tree(self, new_source: str) -> None:\n        \"\"\"\n        Re-parses the tree with new source code.\n        \n        This is necessary because tree-sitter trees are immutable.\n        \n        Args:\n            new_source: The new source code to parse.\n        \"\"\"\n        self.source_code = new_source\n        self.tree = self.parser.parse(bytes(new_source, \"utf-8\"))\n        self.nodes = self._map_nodes()\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return node.text.decode(\"utf-8\")\n            except Exception:\n                # Handle potential decoding issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.type,\n            'line_start': node.start_point[0] + 1,  # Convert to 1-based\n            'line_end': node.end_point[0] + 1,\n            'body_items': []\n        }\n\n        # Add body items for functions and classes\n        if node.type in (\"function_declaration\", \"class_declaration\"):\n            # Find the body block\n            body_node = None\n            for child in node.children:\n                if child.type == \"statement_block\":\n                    body_node = child\n                    break\n            \n            if body_node:\n                # Process statements in the body\n                for i, item in enumerate(body_node.children):\n                    # Skip '{' and '}' tokens\n                    if item.type in (\"{\", \"}\"):\n                        continue\n                    \n                    item_info = {\n                        'index': i,\n                        'type': item.type,\n                        'line_start': item.start_point[0] + 1,\n                        'line_end': item.end_point[0] + 1\n                    }\n                    \n                    # Add more specific information based on type\n                    if item.type == \"variable_declaration\":\n                        item_info['declares'] = \"variable\"\n                    elif item.type == \"return_statement\":\n                        item_info['returns'] = True\n                    elif item.type in (\"if_statement\", \"for_statement\", \"while_statement\"):\n                        item_info['has_body'] = True\n                    \n                    structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n            \n        # A simplified approach to extracting a snippet by line numbers\n        # This would need to be more sophisticated for production use\n        source_lines = self.source_code.split('\\n')\n        # Adjust for 0-based indexing\n        start_idx = max(0, line_start - 1)\n        end_idx = min(len(source_lines), line_end)\n        \n        if start_idx < end_idx:\n            return '\\n'.join(source_lines[start_idx:end_idx])\n        \n        return None\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Replace the node's text in the source code\n        new_source = self.source_code[:start_byte] + new_code + self.source_code[end_byte:]\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass  # If we can't even re-parse the original, we're in trouble\n            return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree:\n            return False\n            \n        # For simplicity, we'll add the new code at the end of the file\n        # A more sophisticated implementation would handle the anchor and positioning\n        new_source = self.source_code.rstrip() + \"\\n\\n\" + new_code + \"\\n\"\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        node = self.nodes[element_name]\n        \n        # Get the start and end bytes of the node\n        start_byte = node.start_byte\n        end_byte = node.end_byte\n        \n        # Find the full lines that contain the node\n        # This is a simplified approach to avoid leaving partial lines\n        source_lines = self.source_code.split('\\n')\n        start_line = node.start_point[0]\n        end_line = node.end_point[0]\n        \n        # Create new source without those lines\n        new_lines = source_lines[:start_line] + source_lines[end_line+1:]\n        new_source = '\\n'.join(new_lines)\n        \n        # Re-parse the tree with the new source\n        try:\n            self._reparse_tree(new_source)\n            return True\n        except Exception:\n            # If parsing fails, revert to the original source\n            try:\n                self._reparse_tree(self.source_code)\n            except Exception:\n                pass\n            return False\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        # This is a complex operation that would require more sophisticated\n        # tree navigation and manipulation than what's shown here.\n        # For now, we'll provide a basic implementation.\n        \n        node = self.nodes.get(element_name)\n        if not node:\n            return False\n            \n        # Handle line-based replacement\n        if line_start is not None:\n            # Convert to 0-based indexing\n            start_idx = max(0, line_start - 1)\n            end_idx = line_end if line_end is not None else start_idx + 1\n            \n            source_lines = self.source_code.split('\\n')\n            if start_idx < len(source_lines):\n                # Replace the specified lines\n                end_idx = min(end_idx, len(source_lines))\n                new_lines = source_lines[:start_idx] + [new_code] + source_lines[end_idx:]\n                new_source = '\\n'.join(new_lines)\n                \n                # Re-parse the tree with the new source\n                try:\n                    self._reparse_tree(new_source)\n                    return True\n                except Exception:\n                    # If parsing fails, revert to the original source\n                    try:\n                        self._reparse_tree(self.source_code)\n                    except Exception:\n                        pass\n        \n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        # For tree-sitter, the source code is already maintained separately\n        return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        \n        # Ensure line endings are consistent for diffing\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/javascript_ast_adapter.py"
  },
  {
    "id": 206,
    "hash": "89fa0c06ca34019316daa58ce8fa9a20",
    "content": "import json\nimport os\nfrom typing import List, Dict, Optional\nfrom rag_manager import RAGManager\n\n\nclass MemoryManager:\n    \"\"\"Manages persistent chat memory, look data, and RAG integration via JSON.\"\"\"\n\n    def __init__(self, memory_file: str):\n        self.memory_file = memory_file\n        self.memory: Dict[str, List] = self.load_memory()\n        self.rag_manager = RAGManager()\n\n    def load_memory(self) ->Dict[str, List]:\n        try:\n            with open(self.memory_file, 'r') as f:\n                return json.load(f)\n        except FileNotFoundError:\n            default = {'chat': [], 'look': []}\n            self.save_memory(default)\n            return default\n        except json.JSONDecodeError:\n            print('[yellow]Invalid memory file. Resetting.[/]')\n            return {'chat': [], 'look': []}\n\n    def save_memory(self, memory: Optional[Dict[str, List]]=None) ->None:\n        if memory is None:\n            memory = self.memory\n        with open(self.memory_file, 'w') as f:\n            json.dump(memory, f, indent=4)\n\n    def add_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.memory['chat'].append({'role': role, 'content': content})\n        self.save_memory()\n\n    def add_chat_message(self, role: str, content: str) ->None:\n        \"\"\"\n        Add a message to the chat history and save immediately.\n        This is an alias for add_message to maintain compatibility.\n        \n        Args:\n            role: The role of the message sender (e.g., 'user', 'assistant')\n            content: The message content\n        \"\"\"\n        self.add_message(role, content)\n\n    def add_look_data(self, file_path: str, content: str) ->None:\n        \"\"\"\n    Adds a watched item (directory or file) to memory, distinguishing its type.\n\n    This method stores structured data that differentiates between a project\n    directory (containing a manifest) and a single file (containing its content).\n    It also prevents duplicate entries by updating existing ones.\n\n    Args:\n        file_path: The path to the directory or file.\n        content: The manifest for a directory or the content for a file.\n    \"\"\"\n        item_type = 'directory' if os.path.isdir(file_path) else 'file'\n        for item in self.memory['look']:\n            if item.get('file') == file_path:\n                item['content'] = content\n                item['type'] = item_type\n                self.save_memory()\n                return\n        self.memory['look'].append({'type': item_type, 'file': file_path,\n            'content': content})\n        self.save_memory()\n        if item_type == 'file':\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    file_content = f.read()\n                self.rag_manager.add_documents([file_content], [{'file':\n                    file_path}])\n            except Exception as e:\n                print(\n                    f'[yellow]Warning: Could not add {file_path} to RAG index: {e}[/]'\n                    )\n\n    def get_project_root(self) ->Optional[str]:\n        \"\"\"\n        Finds the root directory of the project currently in memory.\n\n        The project root is defined as the first item in the 'look' memory\n        that is of type 'directory'.\n\n        Returns:\n            The absolute path to the project root directory, or None if not found.\n        \"\"\"\n        for item in self.memory.get('look', []):\n            if item.get('type') == 'directory':\n                return item.get('file')\n        return None\n\n    def get_memory_context(self) ->str:\n        \"\"\"\n        Dynamically builds the context using RAG and chat history.\n\n        It retrieves relevant file content from the RAG index based on the latest\n        user query, includes project manifests for directories, and appends the\n        recent chat history.\n        \"\"\"\n        context = ''\n        for look in self.memory.get('look', []):\n            path = look.get('file')\n            if path and os.path.isdir(path):\n                content = look.get('content', '')\n                context += (\n                    f'--- Project Manifest for {path} ---\\n{content}\\n\\n')\n        last_user_message = next((msg['content'] for msg in reversed(self.\n            memory.get('chat', [])) if msg['role'] == 'user'), None)\n        if last_user_message:\n            rag_results = self.search_rag(last_user_message, k=3)\n            if rag_results:\n                context += '--- Relevant context from RAG ---\\n'\n                for doc, score, meta in rag_results:\n                    file_path = meta.get('file', 'Unknown source')\n                    context += f'Source: {file_path} (Score: {score:.4f})\\n'\n                    context += f'Content: {doc}\\n---\\n'\n                context += '\\n'\n        for msg in self.memory.get('chat', []):\n            context += f\"{msg['role'].capitalize()}: {msg['content']}\\n\"\n        return context.strip()\n\n    def clear_memory(self) ->None:\n        self.memory = {'chat': [], 'look': []}\n        self.save_memory()\n        self.rag_manager.clear_index()\n\n    def search_rag(self, query: str, k: int=3) ->List[tuple]:\n        \"\"\"\n        Search the RAG index for relevant documents.\n        \n        Args:\n            query: The search query\n            k: Number of results to return\n            \n        Returns:\n            List of (document_content, score, metadata) tuples\n        \"\"\"\n        return self.rag_manager.search(query, k)\n",
    "file": "/mnt/ProjectData/omni/memory_manager.py"
  },
  {
    "id": 207,
    "hash": "fefce358bada61faf78f7880c778938c",
    "content": "\"\"\"\nOmni - AI-powered code generation and project-aware editing CLI tool\n\nIntegrates modular UI, memory, personality, and AST-based code editing.\n\"\"\"\nimport os\nimport subprocess\nimport requests\nimport json\nimport sys\nimport re\nimport argparse\nimport ast\nfrom datetime import datetime\nimport threading\nimport queue as Queue\nimport time\nfrom typing import List, Dict, Optional\nfrom rich import print\nfrom rich.panel import Panel\nfrom rich.console import Console\nfrom rich.tree import Tree\nfrom ui_manager import UIManager\nfrom personality_manager import PersonalityManager\nfrom memory_manager import MemoryManager\nfrom code_editor import CodeEditor\nfrom file_creator import FileCreator\nfrom git_manager import GitManager\nimport traceback\nDEFAULT_BACKEND = 'openrouter'\nOLLAMA_MODEL = 'phi4-reasoning'\nOPENROUTER_MODEL = 'qwen/qwen3-coder'\nDEFAULT_SAVE_DIR = os.path.expanduser('/mnt/ProjectData/omni/omni_saves/')\nCONFIG_FILE = 'config.json'\nMEMORY_FILE = 'memory.json'\nOLLAMA_API_URL = 'http://localhost:11434/api/generate'\nOPENROUTER_API_URL = 'https://openrouter.ai/api/v1/chat/completions'\nOPENROUTER_MODELS_API_URL = 'https://openrouter.ai/api/v1/models'\nOPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\ncurrent_backend = DEFAULT_BACKEND\ncurrent_model = (OLLAMA_MODEL if DEFAULT_BACKEND == 'ollama' else\n    OPENROUTER_MODEL)\nOLLAMA_MODELS = {'deepseek': 'deepseek-coder:6.7b', 'codellama':\n    'codellama:13b', 'mistral': 'mistral:latest', 'llama2': 'llama2:latest',\n    'phind': 'phind-codellama:34b'}\nos.makedirs(DEFAULT_SAVE_DIR, exist_ok=True)\nTEMPLATES = {'flask':\n    \"\"\"from flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/')\ndef home():\n    return '<h1>Hello, Flask!</h1>'\n\nif __name__ == '__main__':\n    app.run(debug=True)\"\"\"\n    , 'html5':\n    \"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>New Page</title>\n</head>\n<body>\n    <h1>Hello World</h1>\n</body>\n</html>\"\"\"\n    , 'scraper':\n    \"\"\"import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.content, 'html.parser')\n        print(soup.title.text)\n    except Exception as e:\n        print(f\"[bold red]Error scraping {url}:[/] {e}\")\n\nif __name__ == \"__main__\":\n    scrape(\"https://example.com\")\"\"\"\n    }\nconsole = Console()\npersonality_manager = PersonalityManager(CONFIG_FILE)\nmemory_manager = MemoryManager(MEMORY_FILE)\nui_manager = UIManager()\nlast_query: Optional[str] = None\nlast_response: Optional[str] = None\nlast_code: Optional[str] = None\n\n\ndef start_ollama_server() ->None:\n    if current_backend != 'ollama':\n        return\n    try:\n        requests.get('http://localhost:11434', timeout=1)\n    except requests.exceptions.ConnectionError:\n        print('[cyan]Starting Ollama server...[/]')\n        subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL)\n\n\ndef query_llm(prompt: str) ->str:\n    personality = personality_manager.get_current_personality()\n    system_prompt = personality.get('system_prompt', '') if personality else ''\n    memory_context = memory_manager.get_memory_context()\n    rag_context = ''\n    try:\n        from rag_manager import RAGManager\n        project_root = memory_manager.get_project_root()\n        if project_root:\n            rag_manager = RAGManager()\n            if rag_manager.get_document_count() > 0:\n                results = rag_manager.search(prompt, k=3)\n                if results:\n                    rag_context = '\\n\\nRelevant context from codebase:\\n'\n                    for i, (doc, score, meta) in enumerate(results, 1):\n                        file_path = meta.get('file', 'Unknown')\n                        rag_context += f'{i}. [{file_path}] {doc}\\n'\n    except Exception:\n        pass\n    full_prompt = (\n        f'{system_prompt}\\n\\n{memory_context}{rag_context}\\n\\nUser: {prompt}')\n    with ui_manager.show_spinner('AI is listening and thinking...'):\n        if current_backend == 'ollama':\n            response = query_ollama(full_prompt)\n        elif current_backend == 'openrouter':\n            response = query_openrouter(full_prompt)\n        else:\n            response = '[bold red]Error:[/] Unknown backend'\n    return response\n\n\ndef query_openrouter(prompt: str) ->str:\n    if not OPENROUTER_API_KEY:\n        return '[bold red]Error:[/] OPENROUTER_API_KEY not set.'\n    headers = {'Authorization': f'Bearer {OPENROUTER_API_KEY}',\n        'Content-Type': 'application/json'}\n    payload = {'model': current_model, 'messages': [{'role': 'user',\n        'content': prompt}]}\n    try:\n        response = requests.post(OPENROUTER_API_URL, headers=headers, json=\n            payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['choices'][0]['message']['content']\n    except Exception as e:\n        error_details = ''\n        try:\n            error_details = response.json()\n        except:\n            error_details = response.text if hasattr(response, 'text'\n                ) else str(e)\n        return (\n            f'[bold red]OpenRouter Error:[/] {e}\\n[dim]Details: {error_details}[/dim]'\n            )\n\n\ndef query_ollama(prompt: str) ->str:\n    payload = {'model': current_model, 'prompt': prompt, 'stream': False}\n    try:\n        response = requests.post(OLLAMA_API_URL, json=payload, timeout=90)\n        response.raise_for_status()\n        return response.json()['response']\n    except Exception as e:\n        return f'[bold red]Ollama Error:[/] {e}'\n\n\ndef extract_code(text: str) ->List[tuple[str, str]]:\n    matches = re.findall('```(\\\\w*)\\\\n([\\\\s\\\\S]*?)```', text)\n    return [(lang or 'text', code.strip()) for lang, code in matches\n        ] if matches else []\n\n\ndef list_models(args: list=None) ->None:\n    if current_backend == 'ollama':\n        print('[bold cyan]Popular Ollama Models:[/]')\n        for name, model_id in OLLAMA_MODELS.items():\n            print(\n                f\"{'\u2b50' if model_id == current_model else '  '} [yellow]{name:12}[/] \u2192 {model_id}\"\n                )\n    elif current_backend == 'openrouter':\n        list_openrouter_models(args or [])\n\n\ndef list_openrouter_models(args: list):\n    try:\n        from simple_term_menu import TerminalMenu\n    except ImportError:\n        ui_manager.show_error(\n            \"'simple-term-menu' is required. `pip install simple-term-menu`\")\n        return\n    try:\n        with ui_manager.show_spinner('Fetching models...'):\n            response = requests.get(OPENROUTER_MODELS_API_URL)\n            response.raise_for_status()\n        api_models_data = response.json().get('data', [])\n    except requests.RequestException as e:\n        ui_manager.show_error(f'Error fetching models: {e}')\n        return\n    all_models, sources = [], set()\n    for model_data in api_models_data:\n        if (model_id := model_data.get('id')):\n            sources.add(model_id.split('/')[0])\n            pricing = model_data.get('pricing', {})\n            is_free = pricing.get('prompt') == '0' and pricing.get('completion'\n                ) == '0'\n            all_models.append({'id': model_id, 'name': model_data.get(\n                'name'), 'source': model_id.split('/')[0], 'is_free': is_free})\n    all_models.sort(key=lambda x: (x['source'], x['name']))\n    if args and args[0].lower() == 'sources':\n        print('[bold cyan]Available Model Sources:[/]')\n        [print(f'  [yellow]{s}[/]') for s in sorted(list(sources))]\n        return\n    models_to_display, title = all_models, 'Select an OpenRouter Model'\n    if args:\n        filter_keyword = args[0].lower()\n        title = f\"Select a Model from '{filter_keyword}'\"\n        models_to_display = [m for m in all_models if filter_keyword in m[\n            'source'].lower()]\n        if not models_to_display:\n            ui_manager.show_error(f\"No models for source: '{filter_keyword}'\")\n            return\n    menu_entries = [\n        f\"{'\u2b50' if m['id'] == current_model else '  '} {m['name']} [dim]({m['id']}){' [green](FREE)[/]' if m['is_free'] else ''}[/dim]\"\n         for m in models_to_display]\n    try:\n        cursor_idx = next((i for i, m in enumerate(models_to_display) if m[\n            'id'] == current_model), 0)\n        chosen_index = TerminalMenu(menu_entries, title=f'{title}',\n            cursor_index=cursor_idx, cycle_cursor=True, clear_screen=True\n            ).show()\n        if chosen_index is not None:\n            set_model(models_to_display[chosen_index]['id'])\n        else:\n            print('Model selection cancelled.')\n    except Exception as e:\n        ui_manager.show_error(f'Menu display error: {e}')\n\n\ndef set_model(model_id: str) ->None:\n    global current_model\n    current_model = model_id\n    ui_manager.show_success(f'Model set to: {current_model}')\n\n\ndef switch_backend(backend_name: str) ->None:\n    global current_backend, current_model\n    backend_name = backend_name.lower()\n    if backend_name not in ['ollama', 'openrouter']:\n        ui_manager.show_error(f'Unknown backend: {backend_name}')\n        return\n    current_backend = backend_name\n    current_model = (OLLAMA_MODEL if backend_name == 'ollama' else\n        OPENROUTER_MODEL)\n    ui_manager.show_success(\n        f'Switched to {backend_name} backend with model: {current_model}')\n    if backend_name == 'ollama':\n        start_ollama_server()\n\n\ndef generate_project_manifest(path: str) ->tuple[str, List[str]]:\n    manifest = ''\n    file_paths = []\n    tree = Tree(f'[bold cyan]Project: {os.path.basename(path)}[/]')\n    exclude_dirs = {'__pycache__', '.git', 'venv', 'node_modules', '.idea',\n        'ollama'}\n    for root, dirs, files in os.walk(path):\n        dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.\n            startswith('.')]\n        relative_path = os.path.relpath(root, path)\n        branch = tree\n        if relative_path != '.':\n            parts = relative_path.split(os.sep)\n            for part in parts:\n                child = next((c for c in branch.children if c.label ==\n                    f'[magenta]{part}[/]'), None)\n                if not child:\n                    child = branch.add(f'[magenta]{part}[/]')\n                branch = child\n        for fname in sorted(files):\n            ext = os.path.splitext(fname)[1]\n            if ext not in ('.py', '.js', '.html', '.css', '.md', '.txt'):\n                continue\n            rel_path = os.path.join(relative_path, fname\n                ) if relative_path != '.' else fname\n            file_paths.append(rel_path)\n            branch.add(f'[green]{fname}[/]' if ext == '.py' else\n                f'[dim]{fname}[/]')\n            manifest += f'File: {rel_path}\\n\\n'\n    console.print(tree)\n    return manifest.strip(), file_paths\n\n\ndef look_command(path: str) ->None:\n    \"\"\"\n    Scans a directory or file and loads it into memory. It can resolve paths\n    relative to the current working directory or the project root in memory.\n    If a new directory is scanned, the previous 'look' context is cleared\n    to ensure the context remains relevant.\n    \"\"\"\n    resolved_path = resolve_file_path(path)\n    if not resolved_path:\n        ui_manager.show_error(f'\u274c Path not found: {path}')\n        return\n    if resolved_path != os.path.abspath(path):\n        ui_manager.show_success(\n            f\"Found '{path}' in project. Using: {resolved_path}\")\n    if os.path.isdir(resolved_path):\n        ui_manager.show_success(\n            \"New project directory detected. Clearing previous 'look' context.\"\n            )\n        memory_manager.memory['look'] = []\n        with ui_manager.show_spinner('Generating project manifest...'):\n            manifest = generate_project_manifest(resolved_path)\n        memory_manager.add_look_data(resolved_path, manifest)\n        ui_manager.show_success('\u2705 Project manifest added to memory.')\n    else:\n        try:\n            with ui_manager.show_spinner('Loading file...'):\n                with open(resolved_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n            for item in memory_manager.memory['look']:\n                if item.get('file') == resolved_path:\n                    item['content'] = content\n                    memory_manager.save_memory()\n                    ui_manager.show_success(\n                        '\u2705 Refreshed file content in memory.')\n                    return\n            memory_manager.add_look_data(resolved_path, content)\n            ui_manager.show_success('\u2705 File content added to memory.')\n        except Exception as e:\n            ui_manager.show_error(f'\u274c Error reading file: {e}')\n\n\ndef resolve_file_path(path: str) ->Optional[str]:\n    \"\"\"Resolves a file path, checking CWD first, then against project root in memory.\"\"\"\n    if os.path.exists(path):\n        return os.path.abspath(path)\n    project_root = memory_manager.get_project_root()\n    if project_root:\n        full_path = os.path.join(project_root, path)\n        if os.path.exists(full_path):\n            return full_path\n    return None\n\n\ndef _create_prompt_for_file_creation(file_name: str, instruction: str) ->str:\n    \"\"\"\n    Generate a robust prompt for file creation that instructs the AI to act as an expert,\n    produce complete and clean code, and avoid any extra commentary.\n    \"\"\"\n    return f\"\"\"You are an expert programmer tasked with creating a new file. Your goal is to generate complete, production-ready content based on the user's instruction.\n\nIMPORTANT RULES:\n- Provide ONLY the raw file content - no explanations, notes, or commentary outside the file itself\n- Include all necessary imports, boilerplate, and complete implementations\n- If creating code, ensure it's syntactically correct and follows best practices\n- For configuration files, use appropriate formatting (JSON, YAML, etc.)\n- For documentation files, use proper markdown formatting\n\nFile to create: {file_name}\nUser instruction: {instruction}\n\nGenerate the complete file content now:\"\"\"\n\n\ndef handle_file_create_command(file_path: str, instruction: str):\n    \"\"\"\n    Uses the LLM to generate content for a new file based on an instruction.\n    \"\"\"\n    global last_code\n    if os.path.exists(file_path):\n        if ui_manager.get_user_input(\n            f\"File '{file_path}' already exists. Overwrite? (y/n): \").lower(\n            ) not in ['yes', 'y']:\n            ui_manager.show_error('File creation cancelled.')\n            return\n    prompt = _create_prompt_for_file_creation(os.path.basename(file_path),\n        instruction)\n    with ui_manager.show_spinner(\n        f\"AI is generating content for '{file_path}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    if code_blocks:\n        new_content = code_blocks[0][1]\n    else:\n        new_content = response.strip()\n    if not new_content:\n        ui_manager.show_error('AI did not return any content.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    print(Panel(new_content, title=\n        f'[bold yellow]Proposed content for {file_path}[/]', border_style=\n        'yellow'))\n    if ui_manager.get_user_input('Create this file? (y/n): ').lower() in ['yes'\n        , 'y']:\n        try:\n            FileCreator.create(file_path, new_content)\n            last_code = new_content\n            ui_manager.show_success(f'File created successfully: {file_path}')\n        except IOError as e:\n            ui_manager.show_error(f'Error creating file: {e}')\n    else:\n        ui_manager.show_error('File creation cancelled.')\n\n\ndef look_all_command() ->None:\n    \"\"\"\n    Finds the project manifest in memory, reads every file listed, and adds their content to memory.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first to generate a manifest.\"\n            )\n        return\n    manifest_data = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and item.get('type'\n            ) == 'directory':\n            manifest_data = item.get('content')\n            break\n    if not manifest_data or not isinstance(manifest_data, (list, tuple)\n        ) or len(manifest_data) != 2:\n        ui_manager.show_error(\n            \"Could not find a valid project manifest in memory. Please run 'look <directory>' again.\"\n            )\n        return\n    file_paths = manifest_data[1]\n    if not file_paths:\n        ui_manager.show_error('No files found in the project manifest.')\n        return\n    total_files = len(file_paths)\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Loading {total_files} files from project manifest...'):\n        for file_path_relative in file_paths:\n            full_path = os.path.join(project_root, file_path_relative)\n            if os.path.isfile(full_path):\n                try:\n                    with open(full_path, 'r', encoding='utf-8') as f:\n                        content = f.read().strip()\n                    if not any(look['file'] == full_path for look in\n                        memory_manager.memory['look']):\n                        memory_manager.add_look_data(full_path, content)\n                        loaded_count += 1\n                except Exception as e:\n                    print(\n                        f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\"\n                        )\n    ui_manager.show_success(\n        f'\u2705 Loaded content for {loaded_count} new files into memory.')\n\n\ndef _load_all_project_files_if_needed():\n    \"\"\"\n    Checks if a project is loaded and automatically loads any files from its\n    manifest that are not already in the 'look' memory. This ensures a\n    complete context for editing and refactoring commands.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        return\n    manifest_content = None\n    for item in memory_manager.memory.get('look', []):\n        if item.get('file') == project_root and 'File:' in item.get('content',\n            ''):\n            manifest_content = item['content']\n            break\n    if not manifest_content:\n        return\n    existing_file_paths = {item['file'] for item in memory_manager.memory.\n        get('look', []) if item.get('type') == 'file'}\n    file_paths_relative = re.findall('File: (.*)', manifest_content)\n    files_to_load = []\n    for rel_path in file_paths_relative:\n        full_path = os.path.join(project_root, rel_path)\n        if full_path not in existing_file_paths and os.path.isfile(full_path):\n            files_to_load.append((full_path, rel_path))\n    if not files_to_load:\n        return\n    loaded_count = 0\n    with ui_manager.show_spinner(\n        f'Auto-loading {len(files_to_load)} project files for context...'):\n        for full_path, file_path_relative in files_to_load:\n            try:\n                with open(full_path, 'r', encoding='utf-8') as f:\n                    content = f.read().strip()\n                memory_manager.add_look_data(full_path, content)\n                loaded_count += 1\n            except Exception as e:\n                print(f\"[yellow]Skipping '{file_path_relative}': {e}[/yellow]\")\n    if loaded_count > 0:\n        ui_manager.show_success(\n            f'\u2705 Loaded {loaded_count} new file(s) into memory for full project context.'\n            )\n\n\ndef _create_prompt_for_element_selection(file_name: str, instruction: str,\n    elements: List[str], element_structures: Dict[str, Dict]) ->str:\n    \"\"\"\n    Create a helper for the first stage of the 'edit' command. This prompt asks the AI\n    to analyze the user's instruction and intelligently select the most relevant code element to modify.\n    \"\"\"\n    element_details = []\n    for elem in elements:\n        if elem in element_structures:\n            struct = element_structures[elem]\n            detail = (\n                f\"{elem} ({struct['type']}, lines {struct['line_start']}-{struct['line_end']})\"\n                )\n            element_details.append(detail)\n        else:\n            element_details.append(elem)\n    elements_str = ', '.join(element_details) if element_details else 'None'\n    return f\"\"\"You are an expert code analyzer. Your task is to identify what should be modified based on the user's instruction.\n\nFile: {file_name}\nAvailable elements: {elements_str}\n\nUser instruction: {instruction}\n\nRESPONSE FORMAT:\nChoose one of these response types:\n1. \"ELEMENT: <element_name>\" - to edit an entire function/class\n2. \"PARTIAL: <element_name> LINES: <start>-<end>\" - to edit specific lines within an element\n3. \"FILE\" - to edit the entire file or multiple elements\n\nVALID ELEMENT NAMES:\n{chr(10).join(f'- {elem}' for elem in elements) if elements else 'None'}\n\nRULES:\n- If the instruction mentions specific line numbers or a specific part of a function, use PARTIAL\n- If the instruction targets an entire function/class, use ELEMENT\n- If the instruction requires changes to multiple elements or file structure, use FILE\n- For PARTIAL edits, provide absolute line numbers from the original file\n- ONLY use element names from the \"Available elements\" list above\n- If no suitable element exists, use \"FILE\"\n- NEVER return an element name that is not in the available list\n\nWhat should be edited?\"\"\"\n\n\ndef _create_prompt_for_element_rewrite(file_name: str, element_name: str,\n    instruction: str, original_code: str, is_full_file: bool=False) ->str:\n    \"\"\"\n    Create a helper for the second stage of the 'edit' command. This prompt instructs the AI\n    to rewrite a specific code element (or the whole file) based on the user's request,\n    demanding a complete and syntactically correct code block as output.\n    \"\"\"\n    if is_full_file:\n        return f\"\"\"You are an expert programmer. Rewrite the entire file to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the entire file\n- Ensure all syntax is correct and the code is ready to run\n- Preserve existing functionality unless explicitly asked to change it\n- Include all necessary imports and maintain the file's structure\n- Do NOT include any explanations or comments outside the code\n\nFile: {file_name}\nTask: {instruction}\n\nCurrent file content:\n```python\n{original_code}\n```\n\nGenerate the complete updated file now:\"\"\"\n    else:\n        return f\"\"\"You are an expert programmer. Rewrite the specified element to accomplish the user's task.\n\nIMPORTANT RULES:\n- Provide ONLY the complete, updated code for the element\n- Include any necessary imports at the top of your code block\n- Ensure the code is syntactically correct and maintains the same interface\n- Do NOT include explanations or comments outside the code block\n- The code must be a drop-in replacement for the original element\n\nFile: {file_name}\nElement to modify: {element_name}\nTask: {instruction}\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the complete updated element now:\"\"\"\n\n\ndef _create_prompt_for_partial_edit(file_name: str, element_name: str,\n    instruction: str, original_snippet: str, line_start: int, line_end: int,\n    full_element_code: str) ->str:\n    \"\"\"\n    Create a prompt for partial edits within a function or class.\n    This allows surgical changes to specific parts of code.\n    \"\"\"\n    return f\"\"\"You are an expert programmer. Make a surgical edit to a specific part of a function/class.\n\nCONTEXT:\n- File: {file_name}\n- Element: {element_name}\n- Lines to modify: {line_start}-{line_end}\n- Task: {instruction}\n\nIMPORTANT RULES:\n- Provide ONLY the code that will replace lines {line_start}-{line_end}\n- Your code must fit seamlessly into the existing function\n- Maintain proper indentation (the code will be auto-indented)\n- Do NOT include the function definition or other parts\n- Do NOT include explanations outside the code\n\nFull element for context:\n```python\n{full_element_code}\n```\n\nCode section to replace (lines {line_start}-{line_end}):\n```python\n{original_snippet}\n```\n\nGenerate ONLY the replacement code for the specified lines:\"\"\"\n\n\ndef handle_file_edit_command(file_path: str, instruction: str):\n    \"\"\"\n    Handles the entire workflow for editing a single file, ensuring full\n    project context is loaded before the AI makes any decisions.\n    Now supports partial edits within functions.\n    \"\"\"\n    global last_code\n    _load_all_project_files_if_needed()\n    resolved_path = resolve_file_path(file_path)\n    if not resolved_path:\n        ui_manager.show_error(f'File not found: {file_path}')\n        return\n    if resolved_path != os.path.abspath(file_path):\n        ui_manager.show_success(\n            f\"Found '{file_path}' in project. Using: {resolved_path}\")\n    try:\n        editor = CodeEditor(resolved_path)\n    except (ValueError, FileNotFoundError) as e:\n        ui_manager.show_error(str(e))\n        return\n    elements = editor.list_elements()\n    element_structures = {}\n    for elem in elements:\n        struct = editor.get_element_structure(elem)\n        if struct:\n            element_structures[elem] = struct\n    prompt1 = _create_prompt_for_element_selection(os.path.basename(\n        resolved_path), instruction, elements, element_structures)\n    with ui_manager.show_spinner('AI is analyzing file...'):\n        ai_response = query_llm(prompt1).strip()\n    if ai_response.upper() == 'FILE':\n        ui_manager.show_success('AI has chosen to edit the entire file.')\n        original_snippet = editor.source_code\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), 'entire file', instruction, original_snippet,\n            is_full_file=True)\n        edit_type = 'FILE'\n        element_to_edit = None\n        line_range = None\n    elif ai_response.startswith('PARTIAL:'):\n        parts = ai_response.split()\n        element_to_edit = parts[1]\n        if 'LINES:' in ai_response:\n            line_part = ai_response.split('LINES:')[1].strip()\n            if '-' in line_part:\n                line_start, line_end = map(int, line_part.split('-'))\n                line_range = line_start, line_end\n            else:\n                ui_manager.show_error('Invalid line range format')\n                return\n        else:\n            ui_manager.show_error('Missing line range for partial edit')\n            return\n        if element_to_edit not in elements:\n            ui_manager.show_error(f\"Element '{element_to_edit}' not found\")\n            return\n        ui_manager.show_success(\n            f\"AI selected partial edit of '{element_to_edit}' (lines {line_start}-{line_end})\"\n            )\n        original_snippet = editor.get_element_body_snippet(element_to_edit,\n            line_start, line_end)\n        if not original_snippet:\n            original_snippet = editor.get_source_of(element_to_edit)\n        full_element_code = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_partial_edit(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet,\n            line_start, line_end, full_element_code)\n        edit_type = 'PARTIAL'\n    elif ai_response.startswith('ELEMENT:'):\n        element_to_edit = ai_response.split(':', 1)[1].strip()\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    else:\n        element_to_edit = ai_response.splitlines()[0]\n        if element_to_edit not in elements:\n            ui_manager.show_error(\n                f\"AI identified '{element_to_edit}', which is not a valid element. Aborting.\"\n                )\n            return\n        ui_manager.show_success(f\"AI selected '{element_to_edit}' for editing.\"\n            )\n        original_snippet = editor.get_source_of(element_to_edit)\n        prompt2 = _create_prompt_for_element_rewrite(os.path.basename(\n            resolved_path), element_to_edit, instruction, original_snippet)\n        edit_type = 'ELEMENT'\n        line_range = None\n    with ui_manager.show_spinner(f'AI is editing...'):\n        response = query_llm(prompt2)\n    code_blocks = extract_code(response)\n    if not code_blocks:\n        ui_manager.show_error('AI did not return a valid code block.')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return\n    new_code = code_blocks[0][1]\n    success = False\n    if edit_type == 'FILE':\n        try:\n            editor.tree = ast.parse(new_code)\n            success = True\n        except SyntaxError as e:\n            ui_manager.show_error(f'AI returned invalid Python syntax: {e}')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    elif edit_type == 'PARTIAL':\n        success = editor.replace_partial(element_to_edit, new_code,\n            line_start=line_range[0], line_end=line_range[1])\n        if not success:\n            ui_manager.show_error('Failed to apply partial edit.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    else:\n        success = editor.replace_element(element_to_edit, new_code)\n        if not success:\n            ui_manager.show_error(\n                'AI returned invalid code; could not be parsed or applied.')\n            print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n            return\n    if not (diff := editor.get_diff()):\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(diff, title=\n        f'[bold yellow]Proposed Changes for {resolved_path}[/]'))\n    if ui_manager.get_user_input('Apply changes? (y/n): ').lower() in ['yes',\n        'y']:\n        editor.save_changes()\n        last_code = editor.get_modified_source()\n        ui_manager.show_success(f'Changes saved to {resolved_path}.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_plan(instruction: str, memory_context: str\n    ) ->str:\n    \"\"\"\n    Create a specialized prompt-generation function for the 'refactor' command.\n    This prompt will explicitly define the required JSON structure for the plan\n    and instruct the AI to act as an expert project manager.\n    \"\"\"\n    return f\"\"\"You are an expert project manager and software architect. Analyze the project context and create a detailed refactoring plan.\n\nYour plan must be a valid JSON object with this exact structure:\n{{\n    \"actions\": [\n        {{\n            \"type\": \"MODIFY\" | \"CREATE\" | \"DELETE\" | \"PARTIAL\",\n            \"file\": \"relative/path/to/file.py\",\n            \"element\": \"function_or_class_name\",  // For MODIFY/DELETE/PARTIAL\n            \"element_name\": \"new_element_name\",    // For CREATE\n            \"line_start\": 10,                      // For PARTIAL only\n            \"line_end\": 20,                        // For PARTIAL only\n            \"reason\": \"Clear explanation of why this change is needed\",\n            \"description\": \"What this action will accomplish\",\n            \"anchor_element\": \"optional_anchor\",   // Optional for CREATE\n            \"position\": \"before\" | \"after\"         // Optional for CREATE\n        }}\n    ]\n}}\n\nACTION TYPES:\n- MODIFY: Change an entire function, class, or method\n- PARTIAL: Change specific lines within a function/class (requires line_start and line_end)\n- CREATE: Add new functions, classes, or files\n- DELETE: Remove functions, classes, variables, or imports\n\nRULES FOR YOUR PLAN:\n- Use PARTIAL when you only need to change a small part of a function\n- Use MODIFY when restructuring an entire function or class\n- Each action must have all required fields based on its type\n- File paths must be relative to the project root\n- Be specific and surgical - avoid unnecessary changes\n- Consider dependencies between changes\n- Order actions logically (e.g., create dependencies before using them)\n\n### Project Context ###\n{memory_context}\n\n### Refactoring Request ###\n{instruction}\n\nGenerate ONLY the JSON plan - no explanations or markdown:\"\"\"\n\n\ndef _get_refactor_plan(instruction: str) ->Optional[List[Dict]]:\n    \"\"\"\n    Generates a refactoring plan from the LLM.\n\n    This function encapsulates the logic for checking project context,\n    constructing a prompt, querying the LLM, and parsing the resulting\n    JSON plan for a refactoring task.\n\n    Args:\n        instruction: The user's high-level refactoring instruction.\n\n    Returns:\n        A list of action dictionaries if a valid plan is generated,\n        otherwise None.\n    \"\"\"\n    if not memory_manager.get_project_root():\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return None\n    memory_context = memory_manager.get_memory_context()\n    plan_prompt = _create_prompt_for_refactor_plan(instruction, memory_context)\n    with ui_manager.show_spinner('AI is creating an execution plan...'):\n        plan_str = query_llm(plan_prompt)\n    try:\n        match = re.search('\\\\{.*\\\\}', plan_str, re.DOTALL)\n        if not match:\n            raise ValueError('No JSON object found in the response.')\n        plan = json.loads(match.group(0))\n        actions = plan.get('actions', [])\n        if not actions:\n            raise ValueError(\"No 'actions' key found in plan or plan is empty.\"\n                )\n        return actions\n    except (json.JSONDecodeError, ValueError) as e:\n        ui_manager.show_error(f'AI failed to generate a valid plan: {e}')\n        print(Panel(plan_str, title=\"[yellow]AI's Invalid Plan Response[/]\",\n            border_style='yellow'))\n        return None\n\n\ndef _display_and_confirm_plan(plan: Dict) ->bool:\n    \"\"\"\n    Displays the generated execution plan to the user and asks for confirmation.\n\n    This helper function separates the UI interaction of plan confirmation from\n    the main refactoring logic.\n\n    Args:\n        plan: A dictionary, expected to contain an 'actions' key with a list of action dicts.\n\n    Returns:\n        True if the user confirms the plan, False otherwise.\n    \"\"\"\n    actions = plan.get('actions', [])\n    if not actions:\n        ui_manager.show_error('The generated plan is empty. Aborting.')\n        return False\n    ui_manager.show_success('AI has created a plan:')\n    for i, action in enumerate(actions):\n        action_type = action.get('type', 'N/A')\n        element = action.get('element') or action.get('element_name', 'N/A')\n        reason = action.get('reason') or action.get('description', '')\n        file_path = action.get('file', '')\n        if action_type == 'PARTIAL':\n            line_start = action.get('line_start', '?')\n            line_end = action.get('line_end', '?')\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} (lines {line_start}-{line_end}) - {reason}'\n                )\n        else:\n            print(\n                f'  [cyan]{i + 1}. {action_type}:[/] {file_path}/{element} - {reason}'\n                )\n    if ui_manager.get_user_input('\\nProceed with this plan? (y/n): ').lower(\n        ) in ['yes', 'y']:\n        return True\n    else:\n        ui_manager.show_error('Execution aborted by user.')\n        return False\n\n\ndef _apply_refactor_changes(editors: Dict[str, CodeEditor]) ->None:\n    \"\"\"\n    Consolidates changes from multiple CodeEditor instances, shows a unified\n    diff, and prompts the user to apply them.\n    \n    This helper function abstracts the final step of a refactor, ensuring\n    all proposed modifications are presented to the user for a final review\n    before any files are written to disk.\n\n    Args:\n        editors: A dictionary mapping absolute file paths to their\n                 corresponding CodeEditor instances which hold the\n                 proposed changes in their AST.\n    \"\"\"\n    full_diff = ''\n    for editor in editors.values():\n        diff = editor.get_diff()\n        if diff:\n            full_diff += diff + '\\n'\n    if not full_diff.strip():\n        ui_manager.show_success('AI made no changes.')\n        return\n    print(Panel(full_diff, title=\n        '[bold yellow]Proposed Project-Wide Changes[/]'))\n    if ui_manager.get_user_input('Apply all changes? (y/n): ').lower() in [\n        'yes', 'y']:\n        for editor in editors.values():\n            editor.save_changes()\n        ui_manager.show_success('\u2705 Project changes applied successfully.')\n    else:\n        ui_manager.show_error('Changes discarded.')\n\n\ndef _create_prompt_for_refactor_action(action_type: str, file_path: str,\n    action_details: Dict) ->str:\n    \"\"\"\n    Create a helper to generate prompts for individual 'CREATE' or 'MODIFY' steps\n    within a refactor plan. This ensures the AI produces code for the specific\n    sub-task in the correct context.\n    \"\"\"\n    if action_type == 'MODIFY':\n        element_name = action_details['element_name']\n        reason = action_details['reason']\n        original_code = action_details['original_code']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- Element: {element_name}\n- Reason for change: {reason}\n\nRULES:\n- Provide ONLY the complete updated code for the element\n- Include any necessary imports at the top\n- Ensure the code integrates properly with the rest of the file\n- Maintain the same function/class signature unless the change requires otherwise\n- No explanations outside the code block\n\nCurrent element code:\n```python\n{original_code}\n```\n\nGenerate the updated element code:\"\"\"\n    elif action_type == 'CREATE':\n        element_name = action_details['element_name']\n        description = action_details['description']\n        return f\"\"\"You are implementing a specific refactoring task as part of a larger plan.\n\nREFACTORING CONTEXT:\n- File: {file_path}\n- New element to create: {element_name}\n- Purpose: {description}\n\nRULES:\n- Provide ONLY the complete code for the new element\n- Include all necessary imports at the top\n- Follow the coding style and patterns used in the project\n- Ensure the code is production-ready and well-structured\n- For non-Python files, provide the complete file content\n- No explanations outside the code block\n\nGenerate the new element code:\"\"\"\n\n\ndef _process_refactor_action(action: Dict, project_base_path: str, editors:\n    Dict) ->bool:\n    \"\"\"\n    Processes a single refactoring action from the plan.\n\n    This function handles the execution of a single action from the refactoring plan,\n    including LLM code generation and applying changes to in-memory editors or files.\n\n    Args:\n        action: A dictionary containing action details (type, file, element, etc.)\n        project_base_path: The absolute path to the project root\n        editors: Dictionary mapping file paths to their CodeEditor instances\n\n    Returns:\n        True if the action was processed successfully, False otherwise\n    \"\"\"\n    file_path_relative = action.get('file')\n    if not file_path_relative:\n        ui_manager.show_error(\n            f\"Action is missing 'file' key. Skipping: {action}\")\n        return False\n    file_path_absolute = os.path.join(project_base_path, file_path_relative)\n    action_type = action.get('type', '').upper()\n    prompt, element_name = '', ''\n    if action_type == 'MODIFY':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_source_of(element_name)\n            if not original_snippet:\n                ui_manager.show_error(\n                    f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                    )\n                return False\n            action_details = {'element_name': element_name, 'reason':\n                reason, 'original_code': original_snippet}\n            prompt = _create_prompt_for_refactor_action('MODIFY',\n                file_path_relative, action_details)\n    elif action_type == 'PARTIAL':\n        element_name = action.get('element')\n        reason = action.get('reason')\n        line_start = action.get('line_start')\n        line_end = action.get('line_end')\n        if not all([element_name, line_start, line_end]):\n            ui_manager.show_error(\n                f'PARTIAL action missing required fields. Skipping: {action}')\n            return False\n        if file_path_relative.endswith('.py'):\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    return False\n            editor = editors[file_path_absolute]\n            original_snippet = editor.get_element_body_snippet(element_name,\n                line_start, line_end)\n            if not original_snippet:\n                original_snippet = editor.get_source_of(element_name)\n                if not original_snippet:\n                    ui_manager.show_error(\n                        f\"Element '{element_name}' in '{file_path_relative}' not found. Skipping.\"\n                        )\n                    return False\n            full_element_code = editor.get_source_of(element_name)\n            prompt = _create_prompt_for_partial_edit(file_path_relative,\n                element_name, reason, original_snippet, line_start,\n                line_end, full_element_code)\n    elif action_type == 'CREATE':\n        element_name = action.get('element_name')\n        description = action.get('description')\n        action_details = {'element_name': element_name, 'description':\n            description}\n        prompt = _create_prompt_for_refactor_action('CREATE',\n            file_path_relative, action_details)\n    else:\n        ui_manager.show_error(f\"Invalid action type '{action_type}'. Skipping.\"\n            )\n        return False\n    with ui_manager.show_spinner(\n        f\"AI: {action_type} on '{element_name or file_path_relative}'...\"):\n        response = query_llm(prompt)\n    code_blocks = extract_code(response)\n    new_content = code_blocks[0][1] if code_blocks else response.strip()\n    if not new_content:\n        ui_manager.show_error(\n            f'AI failed to generate content for action: {action}')\n        print(Panel(response, title=\"[yellow]AI's Raw Response[/]\"))\n        return False\n    if not file_path_relative.endswith('.py'):\n        try:\n            FileCreator.create(file_path_absolute, new_content)\n            ui_manager.show_success(\n                f\"File '{file_path_relative}' created/updated.\")\n            return True\n        except IOError as e:\n            ui_manager.show_error(\n                f\"Failed to create file '{file_path_relative}': {e}\")\n            return False\n    if file_path_absolute not in editors:\n        try:\n            if not os.path.exists(file_path_absolute):\n                os.makedirs(os.path.dirname(file_path_absolute), exist_ok=True)\n                with open(file_path_absolute, 'w') as f:\n                    f.write('')\n            editors[file_path_absolute] = CodeEditor(file_path_absolute)\n        except Exception as e:\n            ui_manager.show_error(\n                f'Error loading file {file_path_absolute}: {e}')\n            return False\n    editor = editors[file_path_absolute]\n    if action_type == 'MODIFY':\n        if not editor.replace_element(element_name, new_content):\n            ui_manager.show_error(\n                f\"Failed to apply MODIFY change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic MODIFY Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'PARTIAL':\n        if not editor.replace_partial(element_name, new_content, line_start,\n            line_end):\n            ui_manager.show_error(\n                f\"Failed to apply PARTIAL change to '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic PARTIAL Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    elif action_type == 'CREATE':\n        anchor = action.get('anchor_element')\n        position = action.get('position', 'after')\n        if not editor.add_element(new_content, anchor_name=anchor, before=\n            position == 'before'):\n            ui_manager.show_error(\n                f\"Failed to apply CREATE change for '{element_name}'.\")\n            print(Panel(new_content, title=\n                f\"[red]Problematic CREATE Code for '{element_name}'[/]\",\n                border_style='red'))\n            return False\n    return True\n\n\ndef handle_project_refactor_command(instruction: str):\n    \"\"\"\n    Orchestrates a multi-file, multi-step code refactoring process.\n    \n    This function serves as a high-level orchestrator that delegates specific tasks\n    to helper functions, improving readability, modularity, and maintainability.\n    \"\"\"\n    _load_all_project_files_if_needed()\n    actions = _get_refactor_plan(instruction)\n    if not actions:\n        return\n    plan = {'actions': actions}\n    if not _display_and_confirm_plan(plan):\n        return\n    editors: Dict[str, CodeEditor] = {}\n    project_base_path = memory_manager.get_project_root()\n    successful_actions = 0\n    total_actions = len(actions)\n    for i, action in enumerate(actions, 1):\n        ui_manager.show_success(f'Processing action {i}/{total_actions}...')\n        action_type = action.get('type', '').upper()\n        file_path_relative = action.get('file')\n        if not file_path_relative:\n            ui_manager.show_error(\n                f\"Action is missing 'file' key. Skipping: {action}\")\n            continue\n        file_path_absolute = os.path.join(project_base_path, file_path_relative\n            )\n        if action_type == 'DELETE':\n            element_name = action.get('element')\n            if not element_name:\n                ui_manager.show_error(\n                    f\"DELETE action missing 'element' key. Skipping: {action}\")\n                continue\n            if not file_path_relative.endswith('.py'):\n                ui_manager.show_error(\n                    f'DELETE actions are only supported for Python files. Skipping.'\n                    )\n                continue\n            if file_path_absolute not in editors:\n                try:\n                    editors[file_path_absolute] = CodeEditor(file_path_absolute\n                        )\n                except Exception as e:\n                    ui_manager.show_error(\n                        f'Error loading file {file_path_absolute}: {e}')\n                    continue\n            editor = editors[file_path_absolute]\n            if editor.delete_element(element_name):\n                successful_actions += 1\n                ui_manager.show_success(\n                    f\"Successfully deleted '{element_name}' from '{file_path_relative}'.\"\n                    )\n            else:\n                ui_manager.show_error(\n                    f\"Failed to delete '{element_name}' from '{file_path_relative}'.\"\n                    )\n        elif _process_refactor_action(action, project_base_path, editors):\n            successful_actions += 1\n        else:\n            ui_manager.show_error(\n                f'Action {i} failed, continuing with remaining actions...')\n    if successful_actions == 0:\n        ui_manager.show_error('No actions were successfully executed.')\n        return\n    elif successful_actions < total_actions:\n        ui_manager.show_error(\n            f'Only {successful_actions}/{total_actions} actions completed successfully.'\n            )\n    else:\n        ui_manager.show_success(\n            f'All {total_actions} actions completed successfully.')\n    _apply_refactor_changes(editors)\n\n\ndef _create_prompt_for_commit_message(diff: str) ->str:\n    \"\"\"\n    Create a dedicated prompt function for the 'commit' command. This prompt will\n    instruct the AI to analyze a git diff and generate a concise commit message\n    following the Conventional Commits standard.\n    \"\"\"\n    return f\"\"\"You are an expert developer writing a Git commit message. Your task is to analyze the provided git diff and create a professional commit message.\n\nCOMMIT MESSAGE RULES:\n- Follow the Conventional Commits specification\n- Format: <type>(<optional scope>): <subject>\n- Types: feat, fix, docs, style, refactor, perf, test, build, ci, chore, revert\n- Subject line: max 50 characters, imperative mood, no period\n- Optional body: explain what and why (not how), wrap at 72 characters\n- Be specific and concise\n- Focus on the intent and impact of the changes\n\nEXAMPLES OF GOOD COMMIT MESSAGES:\n- feat(auth): add OAuth2 integration for Google login\n- fix(api): handle null response in user endpoint\n- refactor(database): optimize query performance for large datasets\n- docs(readme): update installation instructions for Windows\n\nRespond with ONLY the commit message - no markdown, quotes, or explanations.\n\n--- GIT DIFF TO ANALYZE ---\n{diff}\n\nGenerate the commit message:\"\"\"\n\n\ndef handle_commit_command():\n    \"\"\"\n    Orchestrates an AI-assisted Git commit workflow with improved error handling.\n    \"\"\"\n    project_root = memory_manager.get_project_root()\n    if not project_root:\n        ui_manager.show_error(\n            \"No project context in memory. Use 'look <directory>' first.\")\n        return\n    try:\n        git_manager = GitManager(project_root)\n    except ValueError as e:\n        ui_manager.show_error(str(e))\n        return\n    changed_files = git_manager.get_changed_files()\n    if not changed_files:\n        ui_manager.show_success(\n            'No changes to commit. Everything is up to date.')\n        return\n    staged_diff = git_manager.get_diff(staged=True)\n    unstaged_diff = git_manager.get_diff()\n    full_diff = f'{staged_diff}\\n{unstaged_diff}'.strip()\n    if not full_diff.strip():\n        ui_manager.show_success(\n            'No content changes detected (e.g., only file mode changes).')\n        return\n    prompt = _create_prompt_for_commit_message(full_diff)\n    commit_message = query_llm(prompt).strip()\n    if not commit_message:\n        ui_manager.show_error(\n            'AI failed to generate a commit message. Aborting.')\n        return\n    files_to_commit_str = '\\n'.join(f'- {f}' for f in changed_files)\n    plan_panel_content = f\"\"\"[bold]Files to be staged:[/]\n[yellow]{files_to_commit_str}[/]\n\n[bold]AI-Generated Commit Message:[/]\n[green]{commit_message}[/]\"\"\"\n    print(Panel(plan_panel_content, title='[bold cyan]Commit Plan[/]',\n        border_style='cyan'))\n    if ui_manager.get_user_input('\\nProceed with commit? (y/n): ').lower() in [\n        'yes', 'y']:\n        try:\n            git_manager.add(changed_files)\n            ui_manager.show_success('\u2705 Files staged.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Staging failed: {e.stderr}')\n            return\n        try:\n            git_manager.commit(commit_message)\n            ui_manager.show_success('\u2705 Commit successful.')\n        except subprocess.CalledProcessError as e:\n            ui_manager.show_error(f'Commit failed: {e.stderr}')\n            return\n        if ui_manager.get_user_input('Push changes to remote? (y/n): ').lower(\n            ) in ['yes', 'y']:\n            try:\n                git_manager.push()\n                ui_manager.show_success('\u2705 Push successful.')\n            except subprocess.CalledProcessError as e:\n                ui_manager.show_error(f'Push failed: {e.stderr}')\n        else:\n            ui_manager.show_error('Push cancelled.')\n    else:\n        ui_manager.show_error('Commit aborted by user.')\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef handle_rag_query_command(query: str):\n    \"\"\"\n    Handles RAG query commands in the CLI.\n    \n    This function provides a way to query the RAG system from the command line interface.\n    It loads the RAG manager, performs the query, and displays the results.\n    \n    Args:\n        query: The query string to search for in the RAG system.\n    \"\"\"\n    try:\n        rag_manager = RAGManager()\n        if rag_manager.get_document_count() == 0:\n            ui_manager.show_error('RAG index is empty. Add documents first.')\n            return\n        results = rag_manager.search(query, k=3)\n        if not results:\n            ui_manager.show_error('No relevant documents found.')\n            return\n        print(Panel(f'[bold cyan]RAG Query:[/bold cyan] {query}', title=\n            '[bold]Retrieval-Augmented Generation Results[/bold]',\n            border_style='cyan'))\n        for i, (doc, score, metadata) in enumerate(results, 1):\n            file_info = metadata.get('file', 'Unknown source')\n            content_preview = doc[:200] + '...' if len(doc) > 200 else doc\n            result_panel = Panel(\n                f\"\"\"[dim]Source:[/] {file_info}\n[dim]Relevance:[/] {score:.4f}\n\n{content_preview}\"\"\"\n                , title=f'[bold]Result {i}[/bold]', border_style='blue',\n                expand=False)\n            print(result_panel)\n        if ui_manager.get_user_input(\n            '\\nGenerate detailed response with AI? (y/n): ').lower() in ['yes',\n            'y']:\n            context = '\\n\\n'.join([\n                f'Document {i} (Score: {score:.4f}):\\n{doc}' for i, (doc,\n                score, _) in enumerate(results, 1)])\n            prompt = f\"\"\"Based on the following retrieved documents, please answer the query: \"{query}\"\n\nRetrieved Documents:\n{context}\n\nPlease provide a comprehensive answer based only on the information in the documents above.\nIf the documents don't contain enough information to answer the query, please say so.\"\"\"\n            with ui_manager.show_spinner('AI is generating response...'):\n                response = query_llm(prompt)\n            print(Panel(response, title=\n                '[bold green]AI-Generated Response[/bold green]',\n                border_style='green'))\n    except Exception as e:\n        ui_manager.show_error(f'Error processing RAG query: {e}')\n        if os.getenv('OMNIFORGE_DEBUG'):\n            import traceback\n            traceback.print_exc()\n\n\ndef interactive_mode() ->None:\n    global last_query, last_response, last_code\n    try:\n        from Testing.overlay_engine import show_sequential_popup\n        gui_available = True\n    except ImportError:\n        gui_available = False\n    print(Panel(\n        \"\"\"[bold cyan]Omni Interactive Mode[/]\n[dim]Type 'help' for commands, 'exit' to quit.[/dim]\"\"\"\n        , border_style='cyan'))\n    personality_name = personality_manager.get_current_personality().get('name'\n        , 'Default')\n    gui_enabled = False\n    if gui_available:\n        try:\n            with open(CONFIG_FILE, 'r') as f:\n                config = json.load(f)\n                if config.get('gui_enabled', False):\n                    gui_enabled = True\n        except (FileNotFoundError, json.JSONDecodeError):\n            pass\n    refresh_status_panel(personality_name)\n    while True:\n        try:\n            user_input = ui_manager.get_user_input('\\n> ')\n            if not user_input:\n                continue\n            command, *args = user_input.split(maxsplit=1)\n            arg_str = args[0] if args else ''\n            if command == 'exit':\n                memory_manager.save_memory()\n                print('[bold cyan]Goodbye![/]')\n                break\n            elif command == 'help':\n                print(\n                    \"\"\"[bold]Commands:[/]\n\n  [bold cyan]Core & Project Commands[/]\n  [yellow]send <prompt>[/]        - Ask the LLM a question.\n  [yellow]look <path>[/]          - Read file or scan directory into memory.\n  [yellow]look_all[/]            - Recursively scan the project directory into memory.\n  [yellow]create <file> \"instr\"[/] - Create a new file using AI.\n  [yellow]edit <file> \"instr\"[/]   - Edit a specific file using AI.\n  [yellow]refactor \"instr\"[/]      - Refactor project in memory based on instruction.\n  [yellow]commit[/]               - Commit changes with an AI-generated message.\n  [yellow]rag <query>[/]         - Query the RAG system for context retrieval.\n\n  [bold cyan]File & Code Management[/]\n  [yellow]save <filename>[/]     - Save last AI response to a file.\n  [yellow]list[/]               - List saved files.\n  [yellow]run[/]                 - Run the last generated Python code.\n\n  [bold cyan]Session & Config[/]\n  [yellow]history[/]             - Show the full chat history.\n  [yellow]memory clear[/]        - Clear the chat and file memory.\n  [yellow]backend <name>[/]      - Switch AI backend (e.g., openrouter, ollama).\n  [yellow]models [src][/]        - Interactively list and select models.\n  [yellow]set model <id>[/]      - Set the model directly by its ID.\n  [yellow]personality <cmd>[/]   - Manage AI personalities ('list', 'set', 'add').\n\"\"\"\n                    )\n            elif command == 'send':\n                last_query = arg_str\n                response = query_llm(arg_str)\n                last_response = response\n                memory_manager.add_chat_message('user', last_query)\n                memory_manager.add_chat_message('assistant', last_response)\n                if gui_enabled:\n                    threading.Thread(target=show_sequential_popup, args=(\n                        100, 100, response, f'Omni - {personality_name}'),\n                        daemon=True).start()\n                print(Panel(response, title='[cyan]Response[/]'))\n                if (code_blocks := extract_code(response)):\n                    last_code = code_blocks[0][1]\n            elif command == 'look':\n                look_command(arg_str)\n            elif command == 'look_all':\n                look_all_command()\n            elif command == 'create':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_create_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: create <file_path> \"<instruction>\"')\n            elif command == 'edit':\n                try:\n                    file_path, instruction = arg_str.split(' ', 1)\n                    handle_file_edit_command(file_path.strip('\"'),\n                        instruction.strip('\"'))\n                except (ValueError, IndexError):\n                    ui_manager.show_error(\n                        'Usage: edit <file_path> \"<instruction>\"')\n            elif command == 'refactor':\n                if not arg_str:\n                    ui_manager.show_error('Usage: refactor \"<instruction>\"')\n                else:\n                    handle_project_refactor_command(arg_str.strip('\"'))\n            elif command == 'commit':\n                handle_commit_command()\n            elif command == 'models':\n                list_models(arg_str.split())\n            elif command == 'set' and arg_str.startswith('model '):\n                set_model(arg_str[6:])\n            elif command == 'backend':\n                switch_backend(arg_str)\n            elif command == 'history':\n                ui_manager.display_history(memory_manager.get_memory_context())\n            elif command == 'memory' and arg_str == 'clear':\n                memory_manager.clear_memory()\n                ui_manager.show_success('\u2705 Memory cleared')\n            elif command == 'personality':\n                p_args = arg_str.split(maxsplit=1)\n                cmd = p_args[0] if p_args else ''\n                p_arg_str = p_args[1] if len(p_args) > 1 else ''\n                if cmd == 'list':\n                    for p in personality_manager.list_personalities():\n                        print(f\"- {p['name']}: {p['description']}\")\n                elif cmd == 'set' and p_arg_str:\n                    if personality_manager.set_current_personality(p_arg_str):\n                        personality_name = p_arg_str\n                        ui_manager.show_success(\n                            f'Set personality to {personality_name}')\n                    else:\n                        ui_manager.show_error('Personality not found.')\n                else:\n                    ui_manager.show_error(\n                        \"Invalid personality command. Use 'list' or 'set <name>'.\"\n                        )\n            elif command == 'run':\n                run_python_code()\n            elif command == 'save':\n                if last_response:\n                    save_code(last_response, arg_str or\n                        f\"omni_save_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n                        )\n                else:\n                    ui_manager.show_error('No response to save.')\n            elif command == 'list':\n                files = sorted(os.listdir(DEFAULT_SAVE_DIR))\n                print('\\n'.join(f'  - {f}' for f in files) if files else\n                    '[yellow]No saved files.[/]')\n            elif command == 'rag':\n                if not arg_str:\n                    ui_manager.show_error('Usage: rag \"<query>\"')\n                else:\n                    from rag_manager import RAGManager\n                    project_root = memory_manager.get_project_root()\n                    if not project_root:\n                        ui_manager.show_error(\n                            \"No project context in memory. Use 'look <directory>' first.\"\n                            )\n                        continue\n                    rag = RAGManager()\n                    if rag.get_document_count() == 0:\n                        ui_manager.show_error(\n                            'RAG index is empty. Please add documents first.')\n                        continue\n                    results = rag.search(arg_str, k=3)\n                    if not results:\n                        ui_manager.show_error('No relevant documents found.')\n                        continue\n                    print(Panel('[bold]RAG Results:[/]', title=\n                        '[cyan]Retrieval-Augmented Generation[/]'))\n                    for i, (content, score, metadata) in enumerate(results, 1):\n                        file_path = metadata.get('file', 'Unknown')\n                        print(\n                            f'[bold cyan]{i}. {file_path}[/] (Score: {score:.4f})'\n                            )\n                        print(Panel(content[:500] + '...' if len(content) >\n                            500 else content, border_style='dim'))\n                    follow_up = ui_manager.get_user_input(\n                        \"\"\"\nWould you like to ask a follow-up question with this context? (y/n): \"\"\"\n                        )\n                    if follow_up.lower() in ['y', 'yes']:\n                        follow_up_query = ui_manager.get_user_input(\n                            'Follow-up query: ')\n                        if follow_up_query:\n                            context_parts = [\n                                f'Document {i} (Score: {score:.4f}):\\n{content}'\n                                 for i, (content, score, _) in enumerate(\n                                results, 1)]\n                            context = '\\n\\n'.join(context_parts)\n                            rag_prompt = f\"\"\"Based on the following context, please answer the question.\n\nContext:\n{context}\n\nQuestion: {follow_up_query}\"\"\"\n                            response = query_llm(rag_prompt)\n                            print(Panel(response, title=\n                                '[cyan]RAG-Augmented Response[/]'))\n            else:\n                ui_manager.show_error(\"Unknown command. Type 'help'.\")\n            refresh_status_panel(personality_name)\n        except KeyboardInterrupt:\n            memory_manager.save_memory()\n            print('\\n[bold cyan]Goodbye![/]')\n            break\n        except Exception as e:\n            ui_manager.show_error(f'An unexpected error occurred: {e}')\n\n\ndef run_python_code() ->None:\n    global last_code\n    if not last_code:\n        ui_manager.show_error('No Python code in memory to run.')\n        return\n    temp_file = os.path.join(DEFAULT_SAVE_DIR, 'temp_run.py')\n    try:\n        with open(temp_file, 'w') as f:\n            f.write(last_code)\n        print('[bold cyan]\\n--- Running Code ---\\n[/]')\n        subprocess.run([sys.executable, temp_file], check=True)\n        print('[bold cyan]\\n--- Code Finished ---\\n[/]')\n    except Exception as e:\n        ui_manager.show_error(f'Error running code: {e}')\n    finally:\n        if os.path.exists(temp_file):\n            os.remove(temp_file)\n\n\ndef save_code(content: str, filename: str) ->None:\n    filepath = os.path.join(DEFAULT_SAVE_DIR, filename)\n    try:\n        with open(filepath, 'w') as f:\n            f.write(content)\n        ui_manager.show_success(f'Saved to: {filepath}')\n    except IOError as e:\n        ui_manager.show_error(f'Error saving file: {e}')\n\n\ndef main() ->None:\n    try:\n        import astor\n    except ImportError:\n        print(\"[bold red]Error:[/] 'astor' is required. `pip install astor`\")\n        sys.exit(1)\n    try:\n        import simple_term_menu\n    except ImportError:\n        print(\n            \"[bold red]Error:[/] 'simple-term-menu' is required. `pip install simple-term-menu`\"\n            )\n        sys.exit(1)\n    parser = argparse.ArgumentParser(description=\n        'Omni - AI-powered code tool', add_help=False)\n    parser.add_argument('command', nargs='?', help='Main command.')\n    parser.add_argument('args', nargs='*', help='Arguments for the command.')\n    parser.add_argument('-h', '--help', action='store_true')\n    args, _ = parser.parse_known_args()\n    if args.help or not args.command:\n        interactive_mode()\n    elif args.command == 'look' and args.args:\n        look_command(args.args[0])\n    elif args.command == 'edit' and len(args.args) >= 2:\n        handle_file_edit_command(args.args[0], ' '.join(args.args[1:]))\n    elif args.command == 'models':\n        list_models(args.args)\n    else:\n        interactive_mode()\n\n\ndef refresh_status_panel(personality_name: str) ->None:\n    ui_manager.display_status_panel(personality_name, current_backend,\n        current_model, len(memory_manager.memory.get('chat', [])), len(\n        memory_manager.memory.get('look', [])))\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/omni.py"
  },
  {
    "id": 208,
    "hash": "db1585da7840e9dc17f3ab8c0a19f6f2",
    "content": "import json\nfrom typing import Dict, List, Optional\n\nclass PersonalityManager:\n    \"\"\"Manages AI personalities via JSON config.\"\"\"\n\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.personalities: List[Dict[str, str]] = self.load_personalities()\n        self.current_personality: Optional[str] = \"default\"  # Default\n\n    def load_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"Load personalities from JSON; auto-create if missing.\"\"\"\n        default = [{\"name\": \"default\", \"description\": \"Helpful assistant\", \"system_prompt\": \"You are a helpful AI assistant.\"}]\n        default_gui = {\n            \"gui_enabled\": True,\n            \"wake_word\": \"Jarvis\",\n            \"overlay_opacity\": 0.8,\n            \"font_size\": 16\n        }\n        try:\n            with open(self.config_file, 'r') as f:\n                data = json.load(f)\n                if \"personalities\" not in data:\n                    data[\"personalities\"] = default\n                if \"gui_enabled\" not in data:\n                    data.update(default_gui)\n                    self.save_personalities(data[\"personalities\"])  # Save with defaults\n                \n                return data[\"personalities\"]\n        except FileNotFoundError:\n            self.save_personalities(default)\n            return default\n        except json.JSONDecodeError:\n            print(\"[yellow]Invalid config. Resetting to default.[/]\")\n            self.save_personalities(default)\n            return default\n\n    def save_personalities(self, personalities: List[Dict[str, str]]) -> None:\n        \"\"\"Save with GUI config.\"\"\"\n        data = {\"personalities\": personalities}\n        data.update({\"gui_enabled\": True, \"wake_word\": \"Jarvis\", \"overlay_opacity\": 0.8, \"font_size\": 16})  # Defaults\n        with open(self.config_file, 'w') as f:\n            json.dump(data, f, indent=4)\n\n    def add_personality(self, name: str, description: str, system_prompt: str) -> None:\n        \"\"\"Add a new personality.\"\"\"\n        self.personalities.append({\"name\": name, \"description\": description, \"system_prompt\": system_prompt})\n        self.save_personalities(self.personalities)\n\n    def list_personalities(self) -> List[Dict[str, str]]:\n        \"\"\"List all personalities.\"\"\"\n        return self.personalities\n\n    def set_current_personality(self, name: str) -> bool:\n        \"\"\"Set the current personality.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == name:\n                self.current_personality = name\n                return True\n        return False\n\n    def get_current_personality(self) -> Dict[str, str]:\n        \"\"\"Get the current personality dict.\"\"\"\n        for p in self.personalities:\n            if p[\"name\"] == self.current_personality:\n                return p\n        return {}  # Fallback",
    "file": "/mnt/ProjectData/omni/personality_manager.py"
  },
  {
    "id": 209,
    "hash": "da963f141c557fe12f1a26374f3e5ff4",
    "content": "# python_ast_adapter.py\n\n\"\"\"\nPythonASTAdapter - Concrete AST adapter for Python using built-in `ast` and `astor`.\n\nThis module implements the ASTAdapter interface specifically for Python,\nleveraging the standard library's `ast` module for parsing and\nmanipulation, and `astor` for code generation.\n\"\"\"\n\nimport ast\nimport astor\nimport difflib\nfrom typing import List, Optional, Dict, Any, Tuple, Union\nfrom ast_adapter import ASTAdapter, ASTNode\n\n# Optional dependency check for asttokens (for enhanced partial edits)\ntry:\n    import asttokens\n    ASTTOKENS_AVAILABLE = True\nexcept ImportError:\n    ASTTOKENS_AVAILABLE = False\n    # print(\"Warning: asttokens not installed. Partial edits will be limited.\")\n\n\nclass PythonASTAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for Python source code.\n\n    This adapter uses Python's built-in `ast` module to parse and manipulate\n    the code, and `astor` for code generation and source-to-source transformations.\n    It holds the parsed AST tree and provides methods to interact with it\n    according to the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the PythonASTAdapter by parsing the source code.\n\n        Args:\n            source_code: The Python source code as a string.\n        \"\"\"\n        # Store source code for diffing and potential asttokens use\n        self.source_code: str = source_code\n        # Will hold the parsed AST tree\n        self.tree: Optional[ast.AST] = None\n        # Will hold a mapping of element names to their AST nodes\n        self.nodes: Dict[str, ast.AST] = {}\n        # asttokens instance for enhanced source mapping (if available)\n        self.atok: Optional[asttokens.ASTTokens] = None\n\n        # Call the parent's __init__ which in turn calls _parse_and_map\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) -> None:\n        \"\"\"\n        Parses the Python source code and maps elements.\n\n        Args:\n            source_code: The Python source code string to parse.\n\n        Raises:\n            ValueError: If the source code has invalid Python syntax.\n        \"\"\"\n        try:\n            self.tree = ast.parse(source_code)\n        except SyntaxError as e:\n            raise ValueError(f\"Invalid Python syntax: {e}\") from e\n\n        self.nodes = self._map_nodes()\n        if ASTTOKENS_AVAILABLE:\n            try:\n                self.atok = asttokens.ASTTokens(source_code, parse=True)\n            except Exception:\n                # If asttokens fails for any reason, continue without it\n                self.atok = None\n        else:\n            self.atok = None\n\n    def _map_nodes(self) -> Dict[str, ast.AST]:\n        \"\"\"\n        Walks the AST and creates a map of element names to nodes.\n\n        Returns:\n            A dictionary mapping element names (str) to their AST nodes.\n        \"\"\"\n        nodes: Dict[str, ast.AST] = {}\n        if not self.tree:\n            return nodes # Return empty dict if no tree\n\n        for node in ast.walk(self.tree):\n            # Map functions and classes by name\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                # Use 'not in' to prioritize top-level definitions in case of conflicts\n                if node.name not in nodes:\n                    nodes[node.name] = node\n            # Map assignments by target variable name(s)\n            elif isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id not in nodes:\n                        nodes[target.id] = node\n            # Map imports by their alias or original name\n            elif isinstance(node, ast.Import):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n            elif isinstance(node, ast.ImportFrom):\n                for alias in node.names:\n                    name = alias.asname or alias.name\n                    if name not in nodes:\n                        nodes[name] = node\n        return nodes\n\n    def _find_statement_in_body(self, body: List[ast.AST], line_start: int, line_end: Optional[int] = None) -> Optional[Tuple[int, ast.AST]]:\n        \"\"\"\n        Finds a statement within a body based on line numbers.\n\n        Args:\n            body: The list of AST nodes representing the body.\n            line_start: The starting line number to search for.\n            line_end: The optional ending line number.\n\n        Returns:\n            A tuple of (index, statement node) if found, otherwise None.\n        \"\"\"\n        for i, stmt in enumerate(body):\n            if hasattr(stmt, 'lineno'):\n                if line_end:\n                    stmt_end = getattr(stmt, 'end_lineno', stmt.lineno)\n                    # Check for overlap or containment\n                    if (stmt.lineno <= line_start <= stmt_end) or (stmt.lineno <= line_end <= stmt_end) or \\\n                       (line_start <= stmt.lineno and line_end >= stmt_end):\n                        return (i, stmt)\n                else:\n                    if stmt.lineno == line_start:\n                        return (i, stmt)\n        return None\n\n    def _add_imports(self, new_import_nodes: List[Union[ast.Import, ast.ImportFrom]]) -> None:\n        \"\"\"\n        Adds new import nodes to the file's AST, typically at the top.\n\n        Args:\n            new_import_nodes: A list of ast.Import or ast.ImportFrom nodes.\n        \"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return # Cannot add imports without a valid module tree\n\n        # Get string representations of existing imports to avoid duplicates\n        existing_imports_str = set()\n        last_import_index = -1\n        for i, node in enumerate(self.tree.body):\n            if isinstance(node, (ast.Import, ast.ImportFrom)):\n                try:\n                    existing_imports_str.add(astor.to_source(node).strip())\n                except Exception:\n                    # If astor fails, skip adding to set (might lead to potential duplicate, but safer)\n                    pass\n                last_import_index = i\n\n        # Insert new imports after the last existing import\n        # Reverse them so they are inserted in the correct order\n        for new_import in reversed(new_import_nodes):\n            try:\n                new_import_str = astor.to_source(new_import).strip()\n                if new_import_str not in existing_imports_str:\n                    self.tree.body.insert(last_import_index + 1, new_import)\n                    last_import_index += 1 # Update index for next insertion\n            except Exception:\n                # If we can't generate source, we can't check for duplicates, skip\n                self.tree.body.insert(last_import_index + 1, new_import)\n                last_import_index += 1\n\n    # --- Implementing abstract methods from ASTAdapter ---\n\n    def list_elements(self) -> List[str]:\n        \"\"\"Lists the names of the main top-level elements.\"\"\"\n        return list(self.nodes.keys())\n\n    def get_source_of(self, element_name: str) -> Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        node = self.nodes.get(element_name)\n        if node:\n            try:\n                return astor.to_source(node)\n            except Exception:\n                # Handle potential astor issues gracefully\n                return None\n        return None\n\n    def get_element_structure(self, element_name: str) -> Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        node = self.nodes.get(element_name)\n        if not node:\n            return None\n\n        structure = {\n            'name': element_name,\n            'type': node.__class__.__name__,\n            'line_start': getattr(node, 'lineno', None),\n            'line_end': getattr(node, 'end_lineno', None),\n            'body_items': []\n        }\n\n        if hasattr(node, 'body'):\n            for i, item in enumerate(node.body):\n                item_info = {\n                    'index': i,\n                    'type': item.__class__.__name__,\n                    'line_start': getattr(item, 'lineno', None),\n                    'line_end': getattr(item, 'end_lineno', None)\n                }\n\n                if isinstance(item, ast.Assign) and item.targets:\n                    target = item.targets[0]\n                    if isinstance(target, ast.Name):\n                        item_info['assigns'] = target.id\n                elif isinstance(item, (ast.If, ast.While, ast.For)):\n                    item_info['has_body'] = bool(getattr(item, 'body', None))\n                elif isinstance(item, ast.Return):\n                    item_info['returns'] = True\n\n                structure['body_items'].append(item_info)\n\n        return structure\n\n    def get_element_body_snippet(self, element_name: str, line_start: int, line_end: int) -> Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        if not self.atok:\n            return None # asttokens is required for precise original source retrieval\n\n        node = self.nodes.get(element_name)\n        if not node or not hasattr(node, 'body'):\n            return None\n\n        statements = []\n        for stmt in node.body:\n            if hasattr(stmt, 'lineno') and hasattr(stmt, 'end_lineno'):\n                 # Check for overlap or containment of the statement within the requested range\n                stmt_start = stmt.lineno\n                stmt_end = stmt.end_lineno\n                if (stmt_start >= line_start and stmt_end <= line_end) or \\\n                   (stmt_start <= line_end and stmt_end >= line_start): # Overlap\n                    statements.append(stmt)\n\n        if not statements:\n            return None\n\n        # Use asttokens to get the original source text for accuracy\n        try:\n            # Combine text ranges of the found statements\n            combined_text = \"\"\n            last_end_pos = None\n            for stmt in sorted(statements, key=lambda s: s.lineno):\n                # Get the text range for the statement\n                stmt_text = self.atok.get_text_range(stmt)\n                if last_end_pos is not None and stmt_text[0] > last_end_pos:\n                     # Add the original whitespace/newlines between statements\n                    combined_text += self.source_code[last_end_pos:stmt_text[0]]\n                combined_text += self.atok.get_text(stmt)\n                last_end_pos = stmt_text[1]\n            return combined_text.strip()\n        except Exception:\n            # Fallback if asttokens text retrieval fails\n            return '\\n'.join(astor.to_source(stmt).strip() for stmt in statements)\n\n    def replace_element(self, element_name: str, new_code: str) -> bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name not in self.nodes or not self.tree:\n            return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except SyntaxError:\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body: # Ensure there's actual code body to replace with\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # Walk the tree to find the parent node containing the element to replace\n        for parent_node in ast.walk(self.tree):\n            if hasattr(parent_node, 'body') and isinstance(parent_node.body, list):\n                try:\n                    old_node = self.nodes[element_name]\n                    idx = parent_node.body.index(old_node)\n                    # Remove the old node\n                    parent_node.body.pop(idx)\n                    # Insert the new nodes\n                    for i, new_node in enumerate(new_code_body):\n                        parent_node.body.insert(idx + i, new_node)\n\n                    # Update the nodes map: remove old, add new top-level definitions\n                    del self.nodes[element_name]\n                    for n in new_code_body:\n                        if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                            self.nodes[n.name] = n\n                    return True\n                except (ValueError, KeyError):\n                    # ValueError from index(), KeyError from accessing self.nodes\n                    continue\n        return False # Element not found in any body\n\n    def add_element(self, new_code: str, anchor_name: Optional[str] = None, before: bool = False) -> bool:\n        \"\"\"Adds a new element to the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n             return False\n\n        try:\n            new_ast_module = ast.parse(new_code)\n        except (SyntaxError, IndexError):\n            return False\n\n        new_imports = [n for n in new_ast_module.body if isinstance(n, (ast.Import, ast.ImportFrom))]\n        new_code_body = [n for n in new_ast_module.body if not isinstance(n, (ast.Import, ast.ImportFrom))]\n\n        if not new_code_body:\n            return False\n\n        if new_imports:\n            self._add_imports(new_imports)\n\n        # --- Determine insertion index ---\n\n        # Find the `if __name__ == \"__main__\":` block index\n        main_block_idx = -1\n        for i, node in enumerate(self.tree.body):\n            if (isinstance(node, ast.If) and\n                isinstance(getattr(node, 'test', None), ast.Compare) and\n                isinstance(getattr(node.test, 'left', None), ast.Name) and\n                node.test.left.id == '__name__' and\n                len(getattr(node.test, 'ops', [])) == 1 and isinstance(node.test.ops[0], ast.Eq) and\n                len(getattr(node.test, 'comparators', [])) == 1):\n\n                comp = node.test.comparators[0]\n                # Check for both ast.Constant ('__main__') and older ast.Str ('__main__')\n                if ((isinstance(comp, ast.Constant) and comp.value == '__main__') or\n                    (isinstance(comp, ast.Str) and comp.s == '__main__')): # type: ignore\n                    main_block_idx = i\n                    break\n\n        insertion_index = -1\n        if anchor_name:\n            # If anchor is specified, find its index\n            if anchor_name not in self.nodes:\n                return False\n            anchor_node = self.nodes[anchor_name]\n            try:\n                anchor_idx = self.tree.body.index(anchor_node)\n                proposed_index = anchor_idx if before else anchor_idx + 1\n                # Prefer to stay before the main block if possible\n                if main_block_idx != -1:\n                    insertion_index = min(proposed_index, main_block_idx)\n                else:\n                    insertion_index = proposed_index\n            except ValueError:\n                return False # Anchor node not found in tree body\n        elif main_block_idx != -1:\n            # If no anchor, but there's a main block, insert before it\n            insertion_index = main_block_idx\n        # If no anchor and no main block, insertion_index remains -1\n\n        # --- Perform the insertion ---\n        if insertion_index == -1:\n            # Append to the end\n            self.tree.body.extend(new_code_body)\n        else:\n            # Insert at the calculated position\n            for i, new_node in enumerate(new_code_body):\n                self.tree.body.insert(insertion_index + i, new_node)\n\n        # Update the nodes map with any new top-level definitions\n        for node in new_code_body:\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n                self.nodes[node.name] = node # This might overwrite if names clash\n\n        return True\n\n    def delete_element(self, element_name: str) -> bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if not self.tree or not hasattr(self.tree, 'body'):\n            return False\n\n        deleted = False\n        if element_name in self.nodes:\n            node_to_delete = self.nodes[element_name]\n            # Walk the tree to find the parent node containing the element\n            for node in ast.walk(self.tree):\n                if hasattr(node, 'body') and isinstance(node.body, list):\n                    try:\n                        node.body.remove(node_to_delete)\n                        deleted = True\n                        break # Assume element appears only once at top level\n                    except ValueError:\n                        continue # This parent doesn't contain the node\n            if deleted:\n                del self.nodes[element_name]\n                # Although nodes map is passed by ref in base __init__, we should call _map_nodes\n                # to ensure consistency after a direct tree modification.\n                self.nodes = self._map_nodes()\n                return True\n\n        # If not found by node reference, try to find by name pattern matching (vars/imports)\n        new_body = []\n        for node in self.tree.body:\n            if isinstance(node, ast.Assign):\n                match = False\n                for target in node.targets:\n                    if isinstance(target, ast.Name) and target.id == element_name:\n                        match = True\n                        deleted = True\n                        break\n                if not match: # Keep the node if it doesn't match\n                    new_body.append(node)\n            elif isinstance(node, ast.Import):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                    # Keep the node if none of its aliases match (should theoretically be the same as above)\n                     new_body.append(node)\n                else:\n                    deleted = True # The import node is being completely removed\n            elif isinstance(node, ast.ImportFrom):\n                new_aliases = [alias for alias in node.names if not ((alias.name == element_name) or (alias.asname == element_name))]\n                if new_aliases:\n                    node.names = new_aliases\n                    new_body.append(node)\n                elif not any((alias.name == element_name) or (alias.asname == element_name) for alias in node.names):\n                     new_body.append(node)\n                else:\n                    deleted = True\n            else:\n                new_body.append(node)\n\n        if deleted:\n            self.tree.body = new_body\n            # Remap nodes after structural changes\n            self.nodes = self._map_nodes()\n\n        return deleted\n\n    def replace_partial(self, element_name: str, new_code: str,\n                       line_start: Optional[int] = None, line_end: Optional[int] = None,\n                       statement_index: Optional[int] = None) -> bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        if element_name not in self.nodes:\n            return False\n\n        node = self.nodes[element_name]\n        # Ensure the node has a body to modify\n        if not hasattr(node, 'body') or not isinstance(node.body, list):\n            return False\n\n        # Parse the new code to get AST nodes for the replacement\n        try:\n             # Heuristic: If new code looks like a def/class, extract its body.\n             # Otherwise, treat as standalone statements.\n            if new_code.strip().startswith(('def ', 'class ', 'async def ')):\n                # Parse as if it's a module with a single function/class\n                temp_module = ast.parse(new_code)\n                if temp_module.body and hasattr(temp_module.body[0], 'body'):\n                    new_statements = temp_module.body[0].body # Get the inner body\n                else:\n                    return False # Malformed attempt to define a func/class\n            else:\n                # Parse as a module and take its body\n                new_ast_module = ast.parse(new_code)\n                new_statements = new_ast_module.body\n        except SyntaxError:\n            return False # Invalid new code\n\n        if not new_statements: # Nothing to insert\n            return False\n\n        # --- Determine what to replace based on parameters ---\n        if statement_index is not None:\n            # Replace by statement index\n            if 0 <= statement_index < len(node.body):\n                # Replace the single statement at index with the list of new statements\n                node.body[statement_index:statement_index+1] = new_statements\n                return True\n        elif line_start is not None:\n            # Replace by line number(s)\n            result = self._find_statement_in_body(node.body, line_start, line_end)\n            if result:\n                idx, _ = result\n                if line_end:\n                    # Find the last statement within the specified range to replace multiple\n                    end_idx = idx\n                    # Iterate from the found index forward\n                    for i in range(idx, len(node.body)):\n                        stmt = node.body[i]\n                        stmt_s_ln = getattr(stmt, 'lineno', None)\n                        stmt_e_ln = getattr(stmt, 'end_lineno', stmt_s_ln)\n                        if stmt_s_ln is not None and stmt_e_ln is not None:\n                            # Check if the statement ends within the range or starts within the range\n                            # This handles overlapping ranges correctly\n                             if stmt_e_ln <= line_end or stmt_s_ln <= line_end:\n                                 end_idx = i\n                             else:\n                                 break # Statement is past the end range\n                        else:\n                            break # Can't determine statement range\n                    node.body[idx:end_idx+1] = new_statements\n                else:\n                    # line_end not specified, only replace the statement at line_start\n                    node.body[idx:idx+1] = new_statements\n                return True\n\n        # If none of the conditions were met to perform a replacement\n        return False\n\n    def get_modified_source(self) -> str:\n        \"\"\"Serializes the modified AST back into source code.\"\"\"\n        if self.tree:\n            try:\n                return astor.to_source(self.tree)\n            except Exception as e:\n                 # Fallback error handling, should ideally not happen if tree is valid\n                 return f\"# Error generating source: {e}\\n{self.source_code}\"\n        else:\n            # If somehow the tree is None, return the original source\n            return self.source_code\n\n    def get_diff(self) -> str:\n        \"\"\"Generates a diff between the original and modified source code.\"\"\"\n        modified_source = self.get_modified_source()\n        # Ensure line endings are consistent for diffing, keepends=True preserves them\n        # If source_code had different line endings, this might still cause issues,\n        # but this is a standard approach.\n        original_lines = self.source_code.splitlines(keepends=True)\n        modified_lines = modified_source.splitlines(keepends=True)\n\n        # Avoid diff header if contents are identical\n        if original_lines == modified_lines:\n            return \"\"\n\n        diff = difflib.unified_diff(\n            original_lines,\n            modified_lines,\n            fromfile='original',\n            tofile='modified'\n        )\n        # Join the diff generator into a single string\n        return ''.join(diff)",
    "file": "/mnt/ProjectData/omni/python_ast_adapter.py"
  },
  {
    "id": 210,
    "hash": "2914352eefed9d60de098e021dd79b67",
    "content": "import os\nimport sys\nimport argparse\nfrom typing import List\nfrom rag_manager import RAGManager\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\ndef create_sample_data() ->List[str]:\n    \"\"\"Create sample documents for the RAG example.\"\"\"\n    return [\n        'RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with language generation.'\n        ,\n        'The RAG model retrieves relevant documents from a knowledge base and uses them to generate more accurate responses.'\n        ,\n        'FAISS is a library for efficient similarity search and clustering of dense vectors, often used in RAG systems.'\n        ,\n        'Sentence transformers are used to create embeddings for documents and queries in RAG systems.'\n        ,\n        'Retrieval-Augmented Generation improves language models by allowing them to access external knowledge sources.'\n        ,\n        'In RAG systems, documents are indexed and searchable by their semantic embeddings rather than just keywords.'\n        ,\n        'Python is a great language for implementing RAG systems due to libraries like sentence-transformers and faiss.'\n        ,\n        'The retrieval component of RAG is crucial for finding relevant information before generation.'\n        ]\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\ndef main():\n    \"\"\"Main function demonstrating RAG through CLI.\"\"\"\n    parser = argparse.ArgumentParser(description='RAG CLI Example')\n    parser.add_argument('--query', '-q', type=str, help='Query to search for')\n    parser.add_argument('--add', '-a', type=str, help=\n        'Add a new document to the index')\n    parser.add_argument('--list', '-l', action='store_true', help=\n        'List all documents in the index')\n    parser.add_argument('--clear', '-c', action='store_true', help=\n        'Clear the index')\n    parser.add_argument('--init', '-i', action='store_true', help=\n        'Initialize with sample data')\n    args = parser.parse_args()\n    rag_manager = RAGManager()\n    if args.clear:\n        rag_manager.clear_index()\n        print('Index cleared.')\n        return\n    if args.init:\n        documents = create_sample_data()\n        rag_manager.add_documents(documents)\n        print(f'Added {len(documents)} sample documents to index.')\n        return\n    if args.add:\n        rag_manager.add_documents([args.add])\n        print(f'Added document: {args.add}')\n        return\n    if args.list:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'No documents in index. Use --init to add sample data or --add to add documents.'\n                )\n        else:\n            print(\n                f'Documents in index ({rag_manager.get_document_count()} total):'\n                )\n            for i, meta in enumerate(rag_manager.metadata):\n                print(f\"  {i + 1}. {meta['content']}\")\n        return\n    if args.query:\n        if rag_manager.get_document_count() == 0:\n            print(\n                'Index is empty. Use --init to add sample data or --add to add documents.'\n                )\n            return\n        results = rag_manager.search(args.query, k=3)\n        print(f\"Top 3 results for '{args.query}':\")\n        for i, (doc, score, meta) in enumerate(results, 1):\n            print(f'  {i}. [Score: {score:.4f}] {doc}')\n        return\n    parser.print_help()\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_cli_example.py"
  },
  {
    "id": 211,
    "hash": "c27b11d2eaa8e13cdf8e698417efb75e",
    "content": "import os\nimport sys\nfrom typing import List, Dict, Tuple\n\"\"\"\nExample script demonstrating RAG (Retrieval-Augmented Generation) usage.\n\nThis script shows how to use a simple RAG implementation to answer questions\nbased on a given context or knowledge base.\n\"\"\"\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n    '..')))\n\n\nclass SimpleRAG:\n    \"\"\"A simple RAG implementation for demonstration purposes.\"\"\"\n\n    def __init__(self, knowledge_base: List[str]):\n        \"\"\"\n        Initialize the RAG with a knowledge base.\n        \n        Args:\n            knowledge_base: A list of strings representing the knowledge base.\n        \"\"\"\n        self.knowledge_base = knowledge_base\n\n    def retrieve(self, query: str, top_k: int=3) ->List[str]:\n        \"\"\"\n        Retrieve relevant documents from the knowledge base.\n        \n        This is a simplified implementation using keyword matching.\n        In a real implementation, you would use embeddings and vector search.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            A list of relevant documents.\n        \"\"\"\n        query_words = set(query.lower().split())\n        scores = []\n        for doc in self.knowledge_base:\n            doc_words = set(doc.lower().split())\n            score = len(query_words.intersection(doc_words))\n            scores.append((score, doc))\n        scores.sort(reverse=True)\n        return [doc for score, doc in scores[:top_k]]\n\n    def generate(self, query: str, retrieved_docs: List[str]) ->str:\n        \"\"\"\n        Generate an answer based on the query and retrieved documents.\n        \n        In a real implementation, this would use an LLM to generate the response.\n        For this example, we'll create a simple template-based response.\n        \n        Args:\n            query: The query string.\n            retrieved_docs: The retrieved documents.\n            \n        Returns:\n            A generated answer.\n        \"\"\"\n        context = '\\n'.join(retrieved_docs)\n        prompt = f\"\"\"\n        Context information:\n        {context}\n        \n        Question: {query}\n        \n        Based on the context provided above, please answer the question.\n        If the context doesn't contain relevant information, say so.\n        \"\"\"\n        return self._simple_response_generator(query, retrieved_docs)\n\n    def _simple_response_generator(self, query: str, retrieved_docs: List[str]\n        ) ->str:\n        \"\"\"\n        A simple response generator for demonstration.\n        \"\"\"\n        for doc in retrieved_docs:\n            if 'example' in doc.lower():\n                return (\n                    f'Based on the context provided, I found information about examples. {query} relates to the examples in the knowledge base.'\n                    )\n        return (\n            f\"I couldn't find specific information about '{query}' in the provided context. Please provide more details or check the knowledge base.\"\n            )\n\n    def query(self, query: str, top_k: int=3) ->str:\n        \"\"\"\n        Process a query through the full RAG pipeline.\n        \n        Args:\n            query: The query string.\n            top_k: Number of top documents to retrieve.\n            \n        Returns:\n            The generated answer.\n        \"\"\"\n        retrieved_docs = self.retrieve(query, top_k)\n        answer = self.generate(query, retrieved_docs)\n        return answer\n\n\ndef main():\n    \"\"\"Main function demonstrating the RAG implementation.\"\"\"\n    knowledge_base = ['This is an example document about machine learning.',\n        'Natural language processing is a subfield of artificial intelligence.'\n        , 'Python is a popular programming language for data science.',\n        'The quick brown fox jumps over the lazy dog.',\n        'RAG stands for Retrieval-Augmented Generation.',\n        'Vector databases are used for similarity search in RAG systems.',\n        'Transformers are a type of neural network architecture.',\n        'This example shows how to implement a simple RAG system.']\n    rag = SimpleRAG(knowledge_base)\n    queries = ['What is RAG?', 'How is Python used in data science?',\n        'Tell me about machine learning']\n    print('Simple RAG Example')\n    print('=' * 50)\n    for query in queries:\n        print(f'\\nQuery: {query}')\n        answer = rag.query(query)\n        print(f'Answer: {answer}')\n        print('-' * 30)\n    print(\"\\nInteractive Mode (type 'quit' to exit):\")\n    while True:\n        try:\n            user_query = input('\\nEnter your question: ').strip()\n            if user_query.lower() in ['quit', 'exit', 'q']:\n                break\n            if user_query:\n                answer = rag.query(user_query)\n                print(f'Answer: {answer}')\n        except KeyboardInterrupt:\n            print('\\nGoodbye!')\n            break\n        except EOFError:\n            break\n\n\nif __name__ == '__main__':\n    main()\n",
    "file": "/mnt/ProjectData/omni/rag_example.py"
  },
  {
    "id": 212,
    "hash": "f151986bf2efa7602242590a357fab83",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n    Initialize the RAG manager.\n\n    Args:\n        model_name: Name of the sentence transformer model to use\n        index_path: Path to save/load the FAISS index\n    \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass RAGManager:\n    \"\"\"Manages Retrieval-Augmented Generation operations using sentence transformers.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the RAG manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model_name = model_name\n        from vectordb_manager import VectorDBManager\n        self.vectordb = VectorDBManager(model_name, index_path)\n        self.model = self.vectordb.model\n        self.index_path = self.vectordb.index_path\n        self.metadata_path = self.vectordb.metadata_path\n        self.dimension = self.vectordb.dimension\n        self.index = self.vectordb.index\n        self.metadata = self.vectordb.metadata\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the RAG index.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        for i, meta in enumerate(metadatas):\n            if 'file' not in meta:\n                meta['file'] = f'document_{len(self.metadata) + i}'\n        self.vectordb.add_documents(documents, metadatas)\n        self.metadata = self.vectordb.metadata\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        from vectordb_manager import VectorDBManager\n        temp_vdb = VectorDBManager(model_name=self.model_name, index_path=\n            self.index_path)\n        results = temp_vdb.search(query, k)\n        return results\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n",
    "file": "/mnt/ProjectData/omni/rag_manager.py"
  },
  {
    "id": 213,
    "hash": "abe839eb34332aed54000f1776d5ab60",
    "content": "# Core dependencies\ntree_sitter\ntree_sitter_languages\nlangchain\nlangchain-openai\nlangchain-community\nopenai\nollama\nsentence-transformers\ntorch\ntransformers\nstreamlit\nwatchdog\ngitpython\nchromadb\nastor",
    "file": "/mnt/ProjectData/omni/requirements.txt"
  },
  {
    "id": 214,
    "hash": "629e0568a11413444d2a924d1b912f05",
    "content": "from ast_adapter import ASTAdapter\nfrom typing import List, Optional, Dict, Any\n\"\"\"\nTextAdapter - Concrete AST adapter for plain text files.\n\nThis module implements the ASTAdapter interface specifically for plain text files,\ntreating the entire file content as a single element.\n\"\"\"\n\n\nclass TextAdapter(ASTAdapter):\n    \"\"\"\n    Concrete implementation of ASTAdapter for plain text files.\n\n    This adapter treats the entire text file content as a single element\n    that can be manipulated using the ASTAdapter interface.\n    \"\"\"\n\n    def __init__(self, source_code: str):\n        \"\"\"\n        Initializes the TextAdapter with the source code.\n\n        Args:\n            source_code: The text content as a string.\n        \"\"\"\n        self.source_code: str = source_code\n        super().__init__(source_code)\n\n    def _parse_and_map(self, source_code: str) ->None:\n        \"\"\"\n        Creates a simple mapping for the text content.\n\n        Args:\n            source_code: The text content string.\n        \"\"\"\n        self.nodes = {'content': source_code}\n\n    def list_elements(self) ->List[str]:\n        \"\"\"Lists the names of the main elements (just 'content' for text files).\"\"\"\n        return ['content']\n\n    def get_source_of(self, element_name: str) ->Optional[str]:\n        \"\"\"Gets the source code string for a specific named element.\"\"\"\n        if element_name == 'content':\n            return self.source_code\n        return None\n\n    def get_element_structure(self, element_name: str) ->Optional[Dict]:\n        \"\"\"Gets detailed structural information about an element.\"\"\"\n        if element_name == 'content':\n            return {'name': element_name, 'type': 'TextContent',\n                'line_start': 1, 'line_end': len(self.source_code.\n                splitlines()), 'body_items': []}\n        return None\n\n    def get_element_body_snippet(self, element_name: str, line_start: int,\n        line_end: int) ->Optional[str]:\n        \"\"\"Extracts a snippet of code from within an element's body.\"\"\"\n        if element_name != 'content':\n            return None\n        lines = self.source_code.splitlines()\n        if 1 <= line_start <= len(lines) and 1 <= line_end <= len(lines\n            ) and line_start <= line_end:\n            return '\\n'.join(lines[line_start - 1:line_end])\n        return None\n\n    def replace_element(self, element_name: str, new_code: str) ->bool:\n        \"\"\"Replaces a named element with new code.\"\"\"\n        if element_name == 'content':\n            self.source_code = new_code\n            self._parse_and_map(new_code)\n            return True\n        return False\n\n    def add_element(self, new_code: str, anchor_name: Optional[str]=None,\n        before: bool=False) ->bool:\n        \"\"\"Adds a new element to the file (appends to content for text files).\"\"\"\n        if anchor_name is None or anchor_name == 'content':\n            if before:\n                self.source_code = new_code + self.source_code\n            else:\n                self.source_code = self.source_code + new_code\n            self._parse_and_map(self.source_code)\n            return True\n        return False\n\n    def delete_element(self, element_name: str) ->bool:\n        \"\"\"Deletes a named element from the file.\"\"\"\n        if element_name == 'content':\n            self.source_code = ''\n            self._parse_and_map('')\n            return True\n        return False\n\n    def replace_partial(self, element_name: str, new_code: str, line_start:\n        Optional[int]=None, line_end: Optional[int]=None, statement_index:\n        Optional[int]=None) ->bool:\n        \"\"\"Replaces a specific part of an element's body.\"\"\"\n        if element_name != 'content':\n            return False\n        lines = self.source_code.splitlines()\n        if line_start is not None and 1 <= line_start <= len(lines):\n            start_idx = line_start - 1\n            end_idx = start_idx if line_end is None else min(line_end - 1, \n                len(lines) - 1)\n            new_lines = new_code.splitlines() if new_code else []\n            lines[start_idx:end_idx + 1] = new_lines\n            self.source_code = '\\n'.join(lines)\n            self._parse_and_map(self.source_code)\n            return True\n        return False\n\n    def get_modified_source(self) ->str:\n        \"\"\"Returns the modified source code.\"\"\"\n        return self.source_code\n",
    "file": "/mnt/ProjectData/omni/text_adapter.py"
  },
  {
    "id": 215,
    "hash": "4b879b8e64b677ec78d27f19b384623a",
    "content": "from typing import List\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.text import Text\nfrom rich.status import Status\nfrom rich import box\nfrom contextlib import contextmanager\nfrom rich.markup import escape\nimport gc\n\ntry:\n    from prompt_toolkit import prompt\n    from prompt_toolkit.completion import WordCompleter\n    from prompt_toolkit.history import InMemoryHistory\n    from prompt_toolkit.styles import Style\nexcept ImportError:\n    print('[yellow]prompt_toolkit not installed. Falling back to basic input.[/]')\n    prompt = input\n\n\nclass UIManager:\n    \"\"\"Manages interactive text-based UI with rich for display and prompt_toolkit for input.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initializes the UI manager with a rich console and prompt_toolkit components.\"\"\"\n        self.console = Console()\n        self.history = InMemoryHistory()\n        self.completer = WordCompleter([\n            'send', 'look', 'look_all', 'create', 'edit', 'refactor', 'commit',\n            'save', 'list', 'run', 'history', 'memory', 'backend', 'models',\n            'set', 'personality', 'help', 'exit'\n        ], ignore_case=True)\n        self.prompt_style = Style.from_dict({'prompt': 'bold cyan'})\n\n    def get_user_input(self, prompt_text: str) -> str:\n        try:\n            return prompt(prompt_text, history=self.history, completer=self.completer, style=self.prompt_style)\n        except Exception:\n            self.console.print('[yellow]Warning: Falling back to basic input.[/]')\n            return input(prompt_text)\n\n    def display_history(self, history_text: str) -> None:\n        if not history_text.strip():\n            self.console.print('[dim]No history yet.[/]')\n            return\n        \n        lines = history_text.split('\\n')\n        colored_text = Text()\n        for line in lines:\n            if line.startswith('User:'):\n                colored_text.append(line + '\\n', style='bold blue')\n            elif line.startswith('AI:'):\n                colored_text.append(line + '\\n', style='bold green')\n            elif line.startswith('File '):\n                colored_text.append(line + '\\n', style='yellow')\n            else:\n                colored_text.append(line + '\\n')\n        \n        self.console.print(Panel(\n            colored_text, \n            title='[bold magenta]Chat History[/]', \n            border_style='magenta', \n            expand=False, \n            box=box.ROUNDED\n        ))\n\n    @contextmanager\n    def show_spinner(self, message: str):\n        \"\"\"\n        Context manager that displays a spinner with the given message.\n        Handles Rich LiveError by cleaning up stuck live displays and \n        ensuring proper cleanup on exceptions.\n        \n        Usage:\n            with ui_manager.show_spinner(\"Loading...\"):\n                # do work here\n        \"\"\"\n        # Initialize spinner state if not exists\n        if not hasattr(self, '_spinner_active'):\n            self._spinner_active = False\n        \n        # If spinner is already active, just yield without additional output\n        if self._spinner_active:\n            try:\n                yield\n            except Exception as e:\n                raise e\n            return\n        \n        # Clean up any stuck Rich live displays before starting\n        self._cleanup_stuck_rich_displays()\n        \n        # Mark spinner as active\n        self._spinner_active = True\n        status_context = None\n        \n        try:\n            # Try to use rich status, but with fallback\n            try:\n                status_context = self.console.status(f'[bold yellow]{message}[/]')\n                status_context.__enter__()\n            except Exception:\n                # If rich.status fails, fallback to static print\n                status_context = None\n                self.console.print(f'[bold yellow]{message}[/]')\n            \n            yield\n            \n        except Exception as e:\n            # Re-raise actual work errors\n            raise e\n            \n        finally:\n            # Always cleanup spinner state and rich display\n            self._spinner_active = False\n            if status_context is not None:\n                try:\n                    status_context.__exit__(None, None, None)\n                except:\n                    pass  # Suppress cleanup errors\n            \n            # Force cleanup any remaining rich displays\n            self._cleanup_stuck_rich_displays()\n\n    def _cleanup_stuck_rich_displays(self):\n        \"\"\"\n        Clean up stuck Rich live displays that prevent new ones from starting.\n        Based on solution from: https://github.com/DLR-RM/stable-baselines3/issues/1645\n        \"\"\"\n        try:\n            # Method 1: Reset console live display if exists\n            if hasattr(self.console, '_live') and self.console._live is not None:\n                try:\n                    self.console._live.stop()\n                    self.console._live = None\n                except:\n                    pass\n            \n            # Method 2: Find and close stuck rich/tqdm objects using garbage collection\n            rich_objects = [obj for obj in gc.get_objects() \n                        if hasattr(obj, '__class__') and \n                        ('live' in type(obj).__name__.lower() or \n                            'progress' in type(obj).__name__.lower() or\n                            'status' in type(obj).__name__.lower()) and\n                        hasattr(obj, 'stop')]\n            \n            for rich_obj in rich_objects:\n                try:\n                    if hasattr(rich_obj, 'stop'):\n                        rich_obj.stop()\n                    elif hasattr(rich_obj, 'close'):\n                        rich_obj.close()\n                except:\n                    pass  # Suppress cleanup errors\n                    \n        except:\n            pass  # Suppress all cleanup errors to avoid breaking the main flow\n\n    def display_status_panel(self, personality: str, backend: str, model: str, msg_count: int, look_count: int) -> None:\n        status_text = (\n            f'[bold]Personality:[/] [green]{personality}[/] | '\n            f'[bold]Backend:[/] [green]{backend}[/] | '\n            f'[bold]Model:[/] [green]{model}[/] | '\n            f'[bold]Memory:[/] {msg_count} messages, {look_count} files'\n        )\n        self.console.print(Panel(\n            status_text, \n            title='[bold cyan]Status[/]', \n            border_style='cyan', \n            expand=False, \n            box=box.MINIMAL\n        ))\n\n    def show_success(self, message: str) -> None:\n        self.console.print(f'[green]\u2705 {message}[/]')\n\n    def show_error(self, message: str) -> None:\n        \"\"\"\n        Displays an error message, escaping any markup in the message.\n        \"\"\"\n        safe_message = escape(str(message))\n        self.console.print(f'[red]\u274c {safe_message}[/]')",
    "file": "/mnt/ProjectData/omni/ui_manager.py"
  },
  {
    "id": 216,
    "hash": "dbd143839288b400cafdedb655258434",
    "content": "import os\nimport json\nimport hashlib\nfrom typing import List, Dict, Optional, Tuple\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport faiss\nfrom pathlib import Path\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n\n\nclass VectorDBManager:\n    \"\"\"Manages vector database operations for RAG using sentence transformers and FAISS.\"\"\"\n\n    def __init__(self, model_name: str='all-MiniLM-L6-v2', index_path:\n        Optional[str]=None):\n        \"\"\"\n        Initialize the VectorDB manager.\n\n        Args:\n            model_name: Name of the sentence transformer model to use\n            index_path: Path to save/load the FAISS index\n        \"\"\"\n        self.model = SentenceTransformer(model_name)\n        self.index_path = index_path or 'vectordb_index.bin'\n        self.metadata_path = self.index_path.replace('.bin', '_metadata.json')\n        self.dimension = self.model.get_sentence_embedding_dimension()\n        self.index = None\n        self.metadata: List[Dict] = []\n        self._initialize_index()\n\n    def _initialize_index(self):\n        \"\"\"Initialize or load the FAISS index.\"\"\"\n        if os.path.exists(self.index_path) and os.path.exists(self.\n            metadata_path):\n            self.index = faiss.read_index(self.index_path)\n            with open(self.metadata_path, 'r') as f:\n                self.metadata = json.load(f)\n        else:\n            self.index = faiss.IndexFlatIP(self.dimension)\n            self.metadata = []\n\n    def add_documents(self, documents: List[str], metadatas: Optional[List[\n        Dict]]=None):\n        \"\"\"\n        Add documents to the vector database.\n\n        Args:\n            documents: List of text documents to add\n            metadatas: Optional list of metadata for each document\n        \"\"\"\n        if metadatas is None:\n            metadatas = [{}] * len(documents)\n        embeddings = self.model.encode(documents)\n        faiss.normalize_L2(embeddings)\n        self.index.add(embeddings.astype(np.float32))\n        for i, meta in enumerate(metadatas):\n            doc_hash = hashlib.md5(documents[i].encode()).hexdigest()\n            meta_entry = {'id': len(self.metadata), 'hash': doc_hash,\n                'content': documents[i], **meta}\n            self.metadata.append(meta_entry)\n        self._save_index()\n\n    def search(self, query: str, k: int=5) ->List[Tuple[str, float, Dict]]:\n        \"\"\"\n        Search for relevant documents.\n\n        Args:\n            query: Query string\n            k: Number of results to return\n\n        Returns:\n            List of (document, score, metadata) tuples\n        \"\"\"\n        query_embedding = self.model.encode([query])\n        faiss.normalize_L2(query_embedding)\n        scores, indices = self.index.search(query_embedding.astype(np.\n            float32), k)\n        results = []\n        for score, idx in zip(scores[0], indices[0]):\n            if idx < len(self.metadata):\n                doc_info = self.metadata[idx]\n                results.append((doc_info['content'], float(score), doc_info))\n        return results\n\n    def _save_index(self):\n        \"\"\"Save the FAISS index and metadata to disk.\"\"\"\n        faiss.write_index(self.index, self.index_path)\n        with open(self.metadata_path, 'w') as f:\n            json.dump(self.metadata, f, indent=2)\n\n    def get_document_count(self) ->int:\n        \"\"\"Get the number of documents in the index.\"\"\"\n        return len(self.metadata)\n\n    def clear_index(self):\n        \"\"\"Clear the index and metadata.\"\"\"\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.metadata = []\n        self._save_index()\n",
    "file": "/mnt/ProjectData/omni/vectordb_manager.py"
  },
  {
    "id": 217,
    "hash": "47a91d3ac272236378053b23515fc9b0",
    "content": "import tkinter as tk\nfrom tkinter import ttk\nfrom time import strftime\n\n\ndef update_time():\n    current_time = strftime('%H:%M:%S %p\\n%Y-%m-%d')\n    time_label.config(text=current_time)\n    time_label.after(1000, update_time)\n\n\ndef center_window(root):\n    root.update_idletasks()\n    screen_width = root.winfo_screenwidth()\n    screen_height = root.winfo_screenheight()\n    window_width = root.winfo_width() + 4\n    window_height = root.winfo_height() + 4\n    x = (screen_width - window_width) // 2\n    y = (screen_height - window_height) // 2\n    root.geometry(f'{window_width}x{window_height}+{x}+{y}')\n\n\ndef create_3d_border(parent):\n    border_frame = tk.Frame(parent, bg='#c0c0c0')\n    border_frame.pack(padx=2, pady=2, expand=True, fill=tk.BOTH)\n    tk.Frame(border_frame, height=1, bg='#808080').pack(side=tk.TOP, fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#808080').pack(side=tk.LEFT, fill=tk.Y)\n    tk.Frame(border_frame, height=1, bg='#ffffff').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(border_frame, width=1, bg='#ffffff').pack(side=tk.RIGHT, fill=tk.Y\n        )\n    inner_container = tk.Frame(border_frame, bg='#c0c0c0')\n    inner_container.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1\n        )\n    tk.Frame(inner_container, height=1, bg='#ffffff').pack(side=tk.TOP,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#ffffff').pack(side=tk.LEFT,\n        fill=tk.Y)\n    tk.Frame(inner_container, height=1, bg='#808080').pack(side=tk.BOTTOM,\n        fill=tk.X)\n    tk.Frame(inner_container, width=1, bg='#808080').pack(side=tk.RIGHT,\n        fill=tk.Y)\n    content_area = tk.Frame(inner_container, bg='#c0c0c0')\n    content_area.pack(side=tk.TOP, expand=True, fill=tk.BOTH, padx=1, pady=1)\n    return content_area\n\n\nroot = tk.Tk()\nroot.title('Current Time')\nroot.configure(bg='#008080')\nmain_frame = create_3d_border(root)\nmain_frame.config(padx=4, pady=4)\ninner_frame = tk.Frame(main_frame, bg='#c0c0c0', padx=8, pady=8)\ninner_frame.pack()\ntime_label = tk.Label(inner_frame, bg='#c0c0c0', fg='#000000', font=(\n    'MS Sans Serif', 18, 'bold'), padx=12, pady=8)\ntime_label.pack()\nroot.after(100, lambda : center_window(root))\nupdate_time()\nroot.mainloop()\n",
    "file": "/mnt/ProjectData/omni/omni_saves/watch.py"
  }
]